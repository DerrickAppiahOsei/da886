{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 00:54:13.303376: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-23 00:54:13.315537: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-23 00:54:13.327921: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-23 00:54:13.331690: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-23 00:54:13.342127: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-23 00:54:13.959301: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 00:54:18.662531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79196 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:45:00.0, compute capability: 8.0\n",
      "2024-10-23 00:54:18.664132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 79196 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:46:00.0, compute capability: 8.0\n",
      "2024-10-23 00:54:18.665496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 79196 MB memory:  -> device: 2, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:49:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"  # Only GPUs 0 and 1 will be visible to TensorFlow\n",
    "\n",
    "import tensorflow as tf\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\",\"/gpu:2\"])\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# DataLoader Class Definition\n",
    "# -----------------------------\n",
    "class DataLoader:\n",
    "    def __init__(self, h5_filename):\n",
    "        self.h5_filename = h5_filename\n",
    "        self.images, self.centers = self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        with h5py.File(self.h5_filename, 'r') as f:\n",
    "            images = np.array(f['images'])\n",
    "            centers = np.array(f['centers_training'])\n",
    "        return images, centers\n",
    "\n",
    "    def plot_image_with_centers(self, image_index=None):\n",
    "        if image_index is None:\n",
    "            image_index = np.random.randint(0, len(self.images))\n",
    "\n",
    "        image = self.images[image_index]\n",
    "        centers = self.centers[image_index]\n",
    "\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        valid_centers = centers[centers[:, 0] == 1]\n",
    "        for center in valid_centers:\n",
    "            plt.scatter(center[1], center[2], c='red', marker='o',s=5)  # center[1] is x and center[2] is y\n",
    "        plt.title('Image with Valid Centers Marked')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_centers(centers):\n",
    "        return centers[np.lexsort((centers[:, 0], centers[:, 1]))]\n",
    "\n",
    "    def normalize_data(self):\n",
    "        normalized_images = self.images / np.max(self.images)\n",
    "        sorted_centers = np.array([self.sort_centers(image_centers[:, 1:]) for image_centers in self.centers])\n",
    "        normalized_centers = sorted_centers / np.max(centers)\n",
    "\n",
    "        normalized_midpoints = tf.expand_dims(normalized_centers, axis=1)\n",
    "        return normalized_images, normalized_midpoints.numpy()\n",
    "\n",
    "    def split_data(self, train_size=0.8, random_state=42):\n",
    "        normalized_images, normalized_midpoints_np = self.normalize_data()\n",
    "        return train_test_split(normalized_images, normalized_midpoints_np, train_size=train_size, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Utility Function Definition\n",
    "# -----------------------------\n",
    "def plot_transposed_images_with_midpoints(dataset, image_indices=[0, 1, 2, 3]):\n",
    "    \"\"\"\n",
    "    Extracts multiple images and their midpoints from the given dataset, transposes the images, \n",
    "    corrects the midpoints, and plots the transposed images with the corrected midpoints.\n",
    "\n",
    "    Args:\n",
    "    - dataset (tf.data.Dataset): The dataset from which to extract the images and midpoints.\n",
    "    - image_indices (list): The indices of the images in the batch to visualize. Default is [0, 1, 2, 3].\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract a sample image batch and its corresponding midpoints from the dataset\n",
    "    sample_image_batch, sample_midpoints_batch = next(iter(dataset))\n",
    "\n",
    "    # Create a figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(6, 6))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(image_indices):\n",
    "            # Select the specified image and corresponding midpoints from the batch\n",
    "            sample_image = np.array(sample_image_batch[image_indices[i]])\n",
    "            sample_midpoints = np.array(sample_midpoints_batch[image_indices[i]])\n",
    "\n",
    "            # Transpose the image\n",
    "            transposed_image = sample_image.T\n",
    "\n",
    "            # Correct the midpoints by swapping the x and y coordinates\n",
    "            transposed_midpoints_corrected = sample_midpoints[:, :, [1, 0]]\n",
    "\n",
    "            # Plot the transposed image with corrected midpoints\n",
    "            ax.imshow(transposed_image, cmap='gray')\n",
    "            ax.scatter(\n",
    "                transposed_midpoints_corrected[:, :, 0] * 31, \n",
    "                transposed_midpoints_corrected[:, :, 1] * 31, \n",
    "                c='red', marker='o', s=5\n",
    "            )\n",
    "            ax.set_title(f'Image {image_indices[i]} for this batch')\n",
    "        else:\n",
    "            ax.axis('off')  # If fewer than 4 images are requested, hide the unused subplots\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Custom Loss and Callback Definitions\n",
    "# -----------------------------\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def custom_loss(exponent):\n",
    "    def loss(y_true, y_pred):\n",
    "        diff = tf.abs(y_true - y_pred)\n",
    "        powered_diff = tf.pow(diff, exponent)\n",
    "        return tf.reduce_mean(powered_diff)\n",
    "    return loss\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class DynamicExponentCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, initial_exponent, increment, update_frequency):\n",
    "        super().__init__()\n",
    "        self.exponent = initial_exponent\n",
    "        self.increment = increment\n",
    "        self.update_frequency = update_frequency\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.update_frequency == 0:\n",
    "            self.exponent += self.increment\n",
    "            print(f\"\\nEpoch {epoch + 1}: Increasing exponent to {self.exponent}\")\n",
    "            self.model.loss = self.custom_loss(self.exponent)\n",
    "\n",
    "    def custom_loss(self, exponent):\n",
    "        def loss(y_true, y_pred):\n",
    "            diff = tf.abs(y_true - y_pred)\n",
    "            powered_diff = tf.pow(diff, exponent)\n",
    "            return tf.reduce_mean(powered_diff)\n",
    "        return loss\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'initial_exponent': self.exponent,\n",
    "            'increment': self.increment,\n",
    "            'update_frequency': self.update_frequency,\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my NEW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, regularizers\n",
    "import tensorflow as tf\n",
    "\n",
    "class ModelBuilder:\n",
    "    def __init__(self, input_shape=(32, 32, 1), num_classes=5, num_coordinates=2, learning_rate=1e-4, weights_path=None, l1_reg=0.001, l2_reg=0.01):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.num_coordinates = num_coordinates\n",
    "        self.learning_rate = learning_rate\n",
    "        self.l1_reg = l1_reg\n",
    "        self.l2_reg = l2_reg\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        # Load weights if a path is provided\n",
    "        if weights_path is not None:\n",
    "            self.model.load_weights(weights_path)\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "\n",
    "    def build_model(self):\n",
    "        \n",
    "        l1 = regularizers.l1(self.l1_reg)\n",
    "        l2 = regularizers.l2(self.l2_reg)\n",
    "        \n",
    "        # CBAM Attention Block\n",
    "        def cbam_block(input_tensor, reduction_ratio=16):\n",
    "            \"\"\"CBAM block, which includes channel and spatial attention\"\"\"\n",
    "            # Channel Attention\n",
    "            channel_attention = layers.GlobalAveragePooling2D()(input_tensor)\n",
    "            channel_attention = layers.Reshape((1, 1, input_tensor.shape[-1]))(channel_attention)\n",
    "            channel_attention = layers.Dense(input_tensor.shape[-1] // reduction_ratio, activation='relu')(channel_attention)\n",
    "            channel_attention = layers.Dense(input_tensor.shape[-1], activation='sigmoid')(channel_attention)\n",
    "            x = layers.Multiply()([input_tensor, channel_attention])\n",
    "\n",
    "            # Spatial Attention\n",
    "            avg_pool = layers.Lambda(lambda x: tf.reduce_mean(x, axis=-1, keepdims=True))(x)\n",
    "            max_pool = layers.Lambda(lambda x: tf.reduce_max(x, axis=-1, keepdims=True))(x)\n",
    "            concat = layers.Concatenate(axis=-1)([avg_pool, max_pool])\n",
    "            spatial_attention = layers.Conv2D(1, kernel_size=7, padding='same', activation='sigmoid')(concat)\n",
    "            x = layers.Multiply()([x, spatial_attention])\n",
    "\n",
    "            return x\n",
    "    \n",
    "        x_input = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x_input)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = cbam_block(x)  # Add CBAM block here\n",
    "\n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        \n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        # x = cbam_block(x)  # Add CBAM block here\n",
    "        \n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        # x = cbam_block(x)  # Add CBAM block here\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        \n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = cbam_block(x)  # Add CBAM block here\n",
    "        \n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Flatten()(x)\n",
    "        \n",
    "        x_midpoints = layers.Dense(self.num_classes * self.num_coordinates, activation='sigmoid', name='x_midpoints')(x)\n",
    "        x_midpoints_reshape = layers.Reshape((-1, self.num_classes, self.num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "        \n",
    "        return tf.keras.models.Model(x_input, x_midpoints_reshape)\n",
    "\n",
    "    def compile_model(self, loss_function):\n",
    "        self.model.compile(optimizer=self.optimizer, loss=loss_function)\n",
    "\n",
    "    def train_model(self, train_dataset, val_dataset, epochs, callbacks_list):\n",
    "        history = self.model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks_list)\n",
    "        return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Main Script Execution\n",
    "# -----------------------------\n",
    "\n",
    "# Load data\n",
    "# h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KFixed_Mixed_13.h5'             \n",
    "h5_filename = '/home/da886/Final Electron counting project/Images and Labels/13KFixed_Mixed_5_32by32_95index.h5'\n",
    "# h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KFixed_13_SparsespotsRandomIndex.h5'\n",
    "# h5_filename ='/home/da886/Final Electron counting project/Images and Labels/30KFixed-index6_13.h5'\n",
    "data_loader = DataLoader(h5_filename)\n",
    "images, centers = data_loader.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x7fb198444890>, 5282)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l=np.random.randint(0,len(centers))\n",
    "data_loader.plot_image_with_centers(l)\n",
    "plt.imshow(images[l]),l\n",
    "# plt.grid(True),l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x7fb19036db10>, 5282)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[l]),l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., 18.,  9.],\n",
       "       [ 1.,  4., 18.],\n",
       "       [ 1.,  6.,  8.],\n",
       "       [ 1., 29., 21.],\n",
       "       [ 1., 21., 11.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.random.randint(0,len(centers))\n",
    "centers[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the data and split it into training and validation sets\n",
    "train_images, val_images, train_midpoints, val_midpoints = data_loader.split_data()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0, 0.0, 1.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(train_images), np.max(train_images), np.min(train_midpoints), np.max(train_midpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images: (10400, 32, 32), Train Midpoints: (10400, 1, 5, 2)\n",
      "Validation Images: (2600, 32, 32), Validation Midpoints: (2600, 1, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 1000\n",
    "train_dataset = train_dataset.shuffle(buffer_size=8000, reshuffle_each_iteration=True).batch(batch_size)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=8000).batch(batch_size)\n",
    "\n",
    "# Check the shape of the datasets\n",
    "print(f'Train Images: {train_images.shape}, Train Midpoints: {train_midpoints.shape}')\n",
    "print(f'Validation Images: {val_images.shape}, Validation Midpoints: {val_midpoints.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_transposed_images_with_midpoints(train_dataset, image_indices=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set up learning rate scheduler\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.9, patience=10, verbose=1, mode='min', min_lr=7e-6\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,250</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m1,179,904\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m10,250\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m2\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,234,186</span> (31.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,234,186\u001b[0m (31.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,234,186</span> (31.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,234,186\u001b[0m (31.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# dynamic_exponent_callback = DynamicExponentCallback(2, 1, 400)\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    model_builder = ModelBuilder()\n",
    "\n",
    "    model_builder.build_model()\n",
    "\n",
    "    model_builder.model.summary()\n",
    "\n",
    "    model_builder.compile_model(loss_function=tf.keras.losses.MeanSquaredError()) \n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 00:55:07.673424: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-23 00:55:07.685068: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-23 00:55:07.711795: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1729644907.771026  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.771026  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.774123  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.822916  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.823002  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.823145  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.823493  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.823505  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.823713  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.829577  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.829591  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.829818  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.847275  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.847293  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.847299  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.849389  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.849417  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.849726  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.850137  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.850147  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.850385  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.850812  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.850840  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.851005  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.852770  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.852853  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.853200  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.870942  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.871012  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.871363  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.871601  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.871680  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.871987  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.872252  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.872256  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.872510  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.872972  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.873014  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.873167  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.873699  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.873711  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.873912  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.874488  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.874501  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.874703  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.876501  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.876750  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.876784  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.878508  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.878698  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.878941  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.880490  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.880982  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.881186  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.882462  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.882642  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.883060  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.884842  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.884942  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.885208  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.887272  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.887473  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.888343  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.889236  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.889353  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.889462  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.890422  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.896741  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.897212  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.897425  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.898685  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.898778  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.899097  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.984660  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.985148  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.985702  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.986131  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.986580  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.987113  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.987774  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.988424  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.989069  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.989739  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.990759  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.991779  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.997762  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.998123  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.998506  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.998890  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.999242  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644907.999634  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.000792  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.001215  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.001672  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.002047  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.002475  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.002902  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.004025  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.004448  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.005970  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.006434  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.008082  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.009278  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.009714  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.015752  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.016443  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.017193  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.017983  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.018681  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.019531  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.029283  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.029762  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.030243  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.030668  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.031128  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.031689  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.032650  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.033602  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.034613  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.035581  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.036571  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.037567  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.048273  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.048660  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.049072  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.049516  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.049979  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.050455  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.050933  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.051401  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.051889  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.052421  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.052966  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.054115  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.054689  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.055241  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.055779  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.056375  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.056993  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.057650  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.058341  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.058946  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.060000  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.061152  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.062397  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.063720  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.072245  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.072831  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.073472  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.074023  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.074616  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.075384  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.077051  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.078717  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.080410  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.082148  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.083891  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.085684  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.106754  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.107274  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.107815  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.108381  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.109000  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.109588  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.110206  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.110810  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.111424  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.112160  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.112827  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.114652  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.115345  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.116066  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.116773  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.117659  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.118498  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.119509  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.120426  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.121350  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.123274  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.125098  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.127309  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.129718  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.140139  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.140977  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.141675  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.142483  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.143264  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.144207  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.145037  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.145940  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.146796  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.147620  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.148493  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.151458  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.154448  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.157466  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.160479  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.163504  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.166715  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.169978  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.210899  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.211699  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.212553  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.213412  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.214343  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.215249  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.216265  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.217157  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.218107  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.219183  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.220289  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.221426  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.222570  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.224472  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.225842  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.227348  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.228829  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.230049  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.233247  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.234966  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.236598  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.239912  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.244065  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.247231  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.252858  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.253363  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.253835  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.254261  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.254709  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.255236  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.255907  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.256562  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.257211  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.257885  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.258909  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.258962  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.259931  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.260216  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.261329  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.262558  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.264072  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.265250  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.265959  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.266341  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.266532  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.266758  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.267141  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.267492  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.268106  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.268121  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.268940  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.269499  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.269606  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.269970  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.270344  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.270933  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.271016  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.271381  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.271971  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.272536  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.272633  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.273283  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.273732  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.274434  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.275042  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.275480  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.276328  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.277004  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.277760  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.278224  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.278577  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.279281  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.280143  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.283633  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.284016  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.284213  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.284639  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.285095  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.285540  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.286074  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.286756  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.287420  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.288064  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.288735  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.288857  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.289351  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.290150  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.290239  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.290263  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.290717  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.291348  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.291434  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.291928  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.292900  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.293862  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.294892  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.295903  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.296079  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.296909  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.297434  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.297845  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.298013  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.298253  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.298636  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.298986  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.299381  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.300185  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.300612  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.301064  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.301434  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.302022  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.302043  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.302475  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.302959  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.303530  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.303937  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.304583  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.305036  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.305732  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.306339  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.306773  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.308336  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.308440  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.308796  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.309277  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.309363  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.309780  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.310057  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.310260  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.310770  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.310942  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.311272  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.311700  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.311867  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.312348  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.312588  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.312896  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.313595  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.314145  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.314515  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.315333  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.315911  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.316476  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.317020  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.317627  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.318249  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.318910  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.319596  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.320202  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.321262  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.321557  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.322049  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.322502  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.322682  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.323118  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.323576  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.323787  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.324164  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.325274  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.325355  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.326324  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.327358  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.328339  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.329337  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.330338  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.333488  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.334108  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.334761  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.335313  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.335911  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.336691  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.338372  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.340065  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.341084  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.341473  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.341830  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.342009  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.342460  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.342937  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.343461  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.343638  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.343951  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.344428  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.344919  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.345550  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.345626  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.346172  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.347458  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.347532  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.348048  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.348617  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.349162  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.349761  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.350386  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.351047  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.351743  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.352347  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.353062  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.354129  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.355273  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.356524  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.357858  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.366097  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.366699  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.367349  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.367908  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.368509  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.368921  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.369346  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.369517  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.370069  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.370650  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.371045  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.371293  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.371884  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.372502  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.372753  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.373128  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.373751  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.374612  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.374692  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.375374  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.376373  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.377244  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.377970  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.378173  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.378734  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.379453  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.379998  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.380360  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.381209  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.382228  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.383145  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.384080  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.386006  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.387854  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.390076  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.392519  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.395505  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.396765  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.398053  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.399415  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.400819  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.401124  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.401653  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.402346  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.402446  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.402538  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.403035  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.403395  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.403800  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.403901  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.404114  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.404408  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.405035  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.405256  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.405373  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.405962  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.406044  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.406793  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.407145  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.407154  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.407552  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.408006  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.408236  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.408673  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.408936  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.409804  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.410077  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.410419  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.410695  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.410876  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.411730  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.411800  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.412190  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.412532  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.413431  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.414060  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.414303  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.414747  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.415332  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.416253  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.416738  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.417202  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.417786  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.418273  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.419042  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.420213  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.420851  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.421466  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.422038  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.424092  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.424182  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.424343  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.426171  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.426796  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.427174  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.430432  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.431914  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.433791  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.434940  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.436832  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.437708  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.437909  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.438434  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.439250  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.440040  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.440994  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.441828  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.442740  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.443842  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.444663  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.445540  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.448539  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.450294  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.451564  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.452371  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.454171  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.454628  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.456253  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.457682  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.458847  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.460931  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.460948  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.463018  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.464190  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.465390  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.467557  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.467656  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.469867  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.472158  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.474931  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.475730  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.476583  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.477449  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.478389  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.479303  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.480330  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.481223  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.482178  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.483260  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.483509  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.484388  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.485529  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.486679  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.488589  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.489976  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.491513  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.492946  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.494170  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.495066  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.497409  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.499127  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.500770  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.504117  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.506585  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.508386  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.508580  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.509374  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.510230  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.511101  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.511600  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.512050  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.512965  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.513989  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.514891  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.515839  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.516926  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.517717  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.518050  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.519181  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.520318  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.522227  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.523157  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.523610  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.524433  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.525139  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.525554  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.526580  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.526806  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.527828  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.528337  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.528726  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.529535  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.530802  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.531024  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.532147  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.532752  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.533584  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.534403  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.534852  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.536335  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.536360  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.539690  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.540458  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.542114  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.543882  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.547042  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.547925  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.552521  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.553784  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.558633  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.559619  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.559916  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.561038  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.562297  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.563812  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.565003  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.565497  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.566293  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.567630  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.569054  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.570310  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.571819  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.571897  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.577568  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.578150  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.583377  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.589224  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.595059  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.600923  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.607120  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.613330  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.659823  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.661087  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.662383  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.663660  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.665067  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.666456  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.667931  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.669333  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.670806  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.672331  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.674062  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.675802  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.677667  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.680361  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.682667  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.685114  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.687642  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.689647  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.694401  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.695654  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.695779  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.697079  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.698363  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.698728  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.699795  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.701175  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.701728  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.702651  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.704052  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.705527  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.707054  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.708793  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.710536  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.712323  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.712456  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.713888  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.714547  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.715138  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.715981  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.716600  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.717427  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.717822  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.718839  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.719995  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.720074  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.721389  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.722534  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.722735  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.723795  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.724543  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.724741  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.726261  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.726828  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.728935  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.729243  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.730242  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.731491  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.731577  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.733296  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.733844  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.734164  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.736250  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.736366  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.737278  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.739568  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.740512  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.743963  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.747603  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.747859  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.751751  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.752058  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.753848  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.755679  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.756832  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.757795  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.759663  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.760449  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.761510  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.762462  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.764554  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.766959  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.767341  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.769044  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.771438  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.771516  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.773199  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.773951  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.782686  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.784256  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.785582  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.793817  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.797293  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.802099  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.803263  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.804436  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.805678  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.805983  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.807177  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.808327  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.809002  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.809628  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.811105  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.812469  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.813687  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.814959  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.817877  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.820317  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.821116  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.827223  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.831561  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.833498  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.839880  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.843464  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.846163  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.852843  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.855655  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.859361  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.941539  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.942755  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.943938  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.945161  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.946400  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.947628  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.948969  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.950304  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.951554  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.952862  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.954417  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.955961  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.957753  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.959824  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.961972  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.963871  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.966473  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.972279  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.975079  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.978109  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.980325  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.980645  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.982386  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.984619  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.987165  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.989556  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.992002  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.994651  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.997046  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644908.999618  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.002864  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.006173  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.007814  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.008248  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.008741  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.009125  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.009701  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.010247  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.011421  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.012619  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.013417  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.013808  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.014767  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.015167  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.016984  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.017370  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.017945  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.019154  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.019259  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.021506  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.022720  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.024062  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.026433  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.027487  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.028904  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.030578  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.030996  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.031476  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.031644  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.031904  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.032324  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.032785  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.033189  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.033556  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.033652  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.034240  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.034369  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.034760  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.035242  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.035737  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.036128  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.036518  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.037135  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.037242  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.037728  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.038308  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.039538  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.040380  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.040502  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.041848  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.043131  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.043747  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.046214  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.047164  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.050884  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.050910  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.055282  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.059946  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.064597  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.068761  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.070899  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.070925  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.072109  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.073680  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.074899  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.076074  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.077145  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.077401  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.078910  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.080298  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.081543  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.082842  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.083053  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.089046  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.094152  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.095237  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.101552  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.107951  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.111832  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.113036  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.114386  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.114458  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.115959  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.117167  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.118333  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.119661  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.121287  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.121370  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.122678  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.123918  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.125210  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.127925  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.131468  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.137711  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.144105  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.150628  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.157115  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.164017  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.170696  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.210653  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.211878  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.213067  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.214339  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.215600  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.216843  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.218192  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.219523  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.220833  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.222167  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.223738  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.225304  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.227119  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.229237  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.231418  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.233338  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.235948  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.241797  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.244610  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.250207  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.253563  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.254797  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.256005  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.257235  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.258484  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.259721  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.261086  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.262437  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.263694  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.265010  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.266577  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.268140  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.269949  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.272051  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.274381  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.276317  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.277110  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.277546  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.278049  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.278439  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.278993  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.279565  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.280743  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.281944  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.283116  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.284460  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.284954  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.285966  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.287636  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.287880  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.293595  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.295537  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.296797  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.297175  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.299210  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.299287  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.299808  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.299893  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.300435  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.300506  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.301037  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.301119  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.301641  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.301719  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.302122  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.302534  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.302929  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.303525  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.303699  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.304047  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.304530  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.305285  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.305581  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.305757  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.306148  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.306254  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.306551  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.307040  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.307135  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.307762  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.307779  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.308212  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.308405  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.308695  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.310350  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.310531  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.311023  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.311505  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.311822  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.312107  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.312653  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.313230  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.313326  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.313886  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.315163  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.316489  414035 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.316566  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.317761  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.318912  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.323978  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.324417  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.324924  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.325322  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.326457  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.327673  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.332562  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.333779  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.335155  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.336687  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.338336  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.341898  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.342326  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.342776  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.343185  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.343596  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.345602  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.347614  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.349196  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.349630  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.349892  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.350109  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.350330  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.350787  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.351331  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.351631  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.351809  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.352051  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.352305  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.352601  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.352778  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.353182  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.353790  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.354004  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.354338  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.354540  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.354838  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.355102  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.355345  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.355828  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.355933  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.356334  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.356982  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.357476  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.358066  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.360050  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.361542  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.361842  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.362856  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.365888  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.366055  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.368837  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.392671  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.394074  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.394509  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.394956  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.395406  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.395860  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.396333  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.396785  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.397207  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.397662  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.398103  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.398540  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.399020  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.399483  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.400008  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.400500  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.400960  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.401431  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.402373  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.402832  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.404045  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.404661  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.405328  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.408774  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.410894  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.414917  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.418051  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.421155  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.424619  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.442603  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.443428  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.443892  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.444665  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.445656  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.446099  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.447583  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.448213  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.449739  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.450308  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.450908  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.452749  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.454408  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.457557  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.460658  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.470668  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.475006  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.476126  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.477252  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.478434  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.479730  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.480900  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.482163  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.483362  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.484592  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.485857  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.487001  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.488267  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.489672  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.491026  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.492612  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.494419  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.496299  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.502303  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.508289  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.514723  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.526742  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.971166  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644909.973236  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.045579  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.045588  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.046532  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.046787  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.047065  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.047543  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.048115  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.048197  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.048610  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.049687  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.049911  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.050912  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.051142  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.051630  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.052230  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.052252  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.052748  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.053190  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.053556  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.053779  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.054286  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.055141  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.055455  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.056083  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.056421  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.056698  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.057355  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.057991  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.058148  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.058831  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.059509  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.059640  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.061098  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.061176  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.062397  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.062753  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.063676  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.064467  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.064907  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.071675  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.073484  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.075656  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.078005  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.081152  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.081668  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.082187  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.082649  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.083123  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.084128  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.084333  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.085470  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.086573  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.087053  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.087564  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.088354  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.088806  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.089353  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.089989  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.090252  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.090846  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.091823  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.092476  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.096809  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.097345  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.505912  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.508157  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.508936  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.509452  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.509647  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.510046  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.510447  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.510834  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.510932  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.511252  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.511954  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.512624  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.512761  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.513184  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.513573  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.514176  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.514322  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.514581  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.514981  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.515429  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.516107  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.516200  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.516691  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.517175  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.517516  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.517777  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.518330  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.519094  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.519103  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.519675  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.520601  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.520976  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.522060  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.522245  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.523495  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.523706  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.524666  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.527792  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.529265  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.530852  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.532723  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.533213  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.534382  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.534506  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.535013  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.535557  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.536229  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.536326  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.536775  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.537386  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.537487  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.537905  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.538268  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.538494  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.538614  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.538860  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.539053  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.539542  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.539631  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.540386  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.540663  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.540702  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.541314  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.541465  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.542143  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.542349  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.542584  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.542986  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.542990  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.543511  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.543904  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.544105  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.544772  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.544788  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.544928  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.545444  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.545451  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.546060  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.546168  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.546713  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.546901  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.547173  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.547338  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.547710  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.548229  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.549609  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.550326  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.550546  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.551092  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.551889  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.552456  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.553966  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.554469  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.555604  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.556173  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.558572  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.559696  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.561355  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.562943  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.566110  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.568186  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.569288  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.575496  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.576185  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.576611  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.577168  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.577243  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.577686  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.578153  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.578627  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.579080  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.579509  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.579969  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.580411  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.580847  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.581314  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.581772  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.582301  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.582782  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.583245  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.583712  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.584659  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.585290  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.585524  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.586093  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.586224  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.586331  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.586923  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.587070  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.587489  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.587813  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.588368  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.588799  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644910.589521  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.119232  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.119330  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.119375  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.120280  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.120910  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.121727  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.122025  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.123679  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.124955  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.125197  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.128197  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.128409  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.128551  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.131713  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.131837  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.135002  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.149844  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.150927  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.151447  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.151799  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.152336  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.152872  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.153116  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.426205  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.426215  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.426323  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.426878  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.427914  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.428083  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.428215  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.428887  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.429846  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.430152  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.430197  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.430830  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.431327  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.431660  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.431751  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.432802  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.433025  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.433356  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.434331  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.434806  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.434933  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.435652  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.436794  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.437012  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.438337  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.438416  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.438857  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.439779  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.441233  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.441429  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.441620  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.442889  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.443582  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.444751  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.446259  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.446712  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.448103  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.448706  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.454876  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.455161  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.459488  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.460811  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.461032  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.462016  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.463255  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.464494  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.465828  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.467067  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.467622  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.468400  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.469668  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.470966  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.472295  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.473502  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.474830  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.475626  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.476294  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.477991  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.478027  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.479727  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.480036  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.480143  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.481619  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.482202  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.483584  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.484345  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.486482  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.488470  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.490112  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.490628  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.492860  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.495001  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.496200  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.497107  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.499140  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.501756  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.502258  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.502860  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.504294  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.506616  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.509376  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.512491  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.514340  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.515971  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.526840  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.537011  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.538295  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.549617  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.562413  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.574331  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.577681  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.578824  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.580129  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.581346  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.582530  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.583737  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.585022  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.586295  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.586654  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.587565  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.588963  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.590367  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.591971  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.593556  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.595272  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.596953  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.598752  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.600910  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.603303  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.609400  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.611754  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.612901  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.614207  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.614998  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.615435  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.616617  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.617843  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.619125  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.620393  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.621702  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.621868  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.623125  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.624527  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.626132  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.627704  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.629400  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.631074  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.632889  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.635058  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.637436  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.643601  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.646378  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.647797  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.649240  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.649347  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.650639  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.651979  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.653366  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.654801  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.656307  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.656384  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.657791  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.659280  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.660694  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.662168  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.663992  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.665385  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.667155  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.668872  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.670674  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.672377  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.674340  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.676138  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.679727  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.680952  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.681583  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.682379  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.683565  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.683777  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.685162  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.686509  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.687901  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.689343  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.690470  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.690731  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.692207  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.693701  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.695130  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.696612  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.697375  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.698453  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.699847  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.701622  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.703361  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.705162  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.706235  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.706891  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.708869  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.710684  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.714227  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.715095  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.716204  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.718072  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.723950  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.725022  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.731950  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.732749  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.735571  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.737637  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.739844  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.740849  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.741996  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.744191  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.746398  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.748738  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.749677  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.751084  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.753474  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.756043  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.758704  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.758812  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.761585  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.764601  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.767601  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.767911  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.771321  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.774718  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.779064  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.783816  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.789605  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.801454  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.819571  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.822154  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.824692  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.827223  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.829778  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.832383  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.834911  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.837530  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.840239  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.843073  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.845687  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.848466  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.851229  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.853210  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.854020  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.854398  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.855661  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.856398  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.857013  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.858358  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.858730  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.860077  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.861394  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.861992  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.863973  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.864570  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.866149  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.868148  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.868437  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.871069  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.871871  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.872865  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.875437  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.878888  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.879917  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.883327  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.887410  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.887771  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.888598  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.889851  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.891183  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.891507  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.892263  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.892536  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.894399  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.894476  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.895395  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.896340  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.896519  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.898324  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.898570  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.900500  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.900720  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.902926  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.903004  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.905002  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.905548  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.907211  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.907380  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.908614  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.909473  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.911623  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.913721  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.914375  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.915771  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.918417  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.921753  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.922353  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.924169  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.926574  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.927014  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.928643  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.930236  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.930682  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.932705  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.933823  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.934861  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.935958  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.937022  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.939017  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.941162  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.943403  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.944731  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.945561  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.947654  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.949623  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.949794  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.952403  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.955024  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.956209  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.957448  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.960324  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.963297  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.963587  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.967185  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.967616  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.978121  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.979178  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.980536  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.989736  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644911.992522  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.001258  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.004896  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.014252  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.026683  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.038648  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.154428  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.156488  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.158698  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.160842  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.163036  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.165244  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.167578  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.169915  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.172290  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.174853  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.177499  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.180330  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.183489  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.186950  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.187634  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.189694  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.190391  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.191920  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.193823  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.194076  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.196294  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.198227  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.198521  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.200869  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.203101  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.203266  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.205645  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.208208  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.208952  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.210860  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.213645  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.215666  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.216699  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.217947  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.220240  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.220362  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.220878  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.222779  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.223685  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.225261  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.227095  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.228416  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.231431  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.231994  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.235445  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.236201  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.239008  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.239084  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.241608  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.242035  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.243072  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.244164  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.246697  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.247460  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.249275  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.251884  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.252939  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.253996  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.254444  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.257076  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.259178  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.259803  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.262653  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.265273  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.268080  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.270860  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.272149  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.273646  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.274829  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.274909  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.276045  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.277480  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.278395  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.280022  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.281068  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.282602  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.284253  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.285213  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.287842  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.287951  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.290476  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.290953  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.291695  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.292213  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.293202  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.293437  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.294711  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.295271  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.296025  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.296198  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.297341  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.298661  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.298958  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.299044  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.299866  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.301148  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.301870  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.302506  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.303410  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.303769  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.304681  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.305003  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.306458  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.307512  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.308082  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.308091  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.309466  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.309924  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.311089  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.311806  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.312292  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.312895  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.314904  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.315076  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.315684  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.318296  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.320643  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.321915  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.325668  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.326432  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.328960  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.329270  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.332239  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.332770  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.337266  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.339021  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.341752  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.342775  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.345683  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.345698  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.349605  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.352076  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.356660  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.363499  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.370469  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.376807  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.384231  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.390547  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.400221  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.404275  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.417997  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.427084  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.428365  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.429691  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.430999  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.432316  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.433630  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.433962  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.435045  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.436443  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.437868  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.439382  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.440911  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.442521  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.444327  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.446471  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.448377  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.450325  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.452801  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.455824  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.458810  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.464727  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.476728  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.478221  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.479674  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.481264  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.482654  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.484399  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.486303  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.488362  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.490271  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.492551  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.494764  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.496832  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.498666  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.500760  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.503161  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.505588  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.508020  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.509827  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.511618  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.514282  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.517300  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.520331  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.522985  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.526221  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.528931  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.535670  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.542406  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.549406  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.556402  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.564500  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.572520  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.638038  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.640336  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.642679  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.645096  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.647587  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.650782  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.654384  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.657861  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.661523  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.665524  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.669897  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.671124  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.673400  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.675382  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.675742  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.678155  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.680636  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.681615  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.683825  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.687382  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.690844  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.691087  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.692408  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.693779  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.694492  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.695186  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.696663  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.697080  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.698570  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.698674  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.700589  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.702499  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.703084  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.704684  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.708593  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.710078  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.713058  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.713093  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.714363  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.714860  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.715582  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.715966  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.716873  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.718129  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.719566  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.719656  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.720854  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.722042  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.723323  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.724662  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.725871  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.725969  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.727195  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.728641  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.730107  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.730333  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.731504  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.733108  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.733876  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.734910  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.736879  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.742640  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.747687  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.748503  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.749015  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.749481  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.750470  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.750489  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.751302  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.751778  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.752133  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.753107  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.753212  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.753962  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.754323  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.754561  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.754851  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.755755  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.755942  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.756635  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.757161  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.757441  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.758532  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.758639  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.759418  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.760010  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.760606  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.761149  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.761326  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.761555  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.762704  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.762817  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.763856  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.764177  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.765064  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.765668  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.766233  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.767070  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.767726  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.768701  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.769481  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.770509  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.772547  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.772661  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.774111  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.775753  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.778226  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.779236  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.782612  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.784057  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.785921  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.789903  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.796678  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.803253  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.809616  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.823439  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.824274  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.825170  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.826034  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.826877  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.827764  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.828651  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.829555  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.830492  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.831427  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.832459  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.833602  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.834678  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.835818  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.837076  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.838489  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.840086  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.843229  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.849733  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.851013  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.851320  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.852544  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.852558  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.853450  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.853877  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.854356  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.855334  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.855432  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.856360  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.856666  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.857301  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.858095  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.858338  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.859435  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.859546  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.860730  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.860986  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.862033  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.862511  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.863450  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.864060  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.864853  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.865681  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.865895  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.867073  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.867495  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.868347  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.869644  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.869827  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.871334  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.871554  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.872861  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.873492  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.874137  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.875858  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.876051  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.878156  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.879057  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.881675  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.882030  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.884480  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.885301  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.885791  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.887137  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.887923  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.888477  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.888923  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.889827  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.891147  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.892684  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.892788  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.894205  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.895651  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.896307  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.897183  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.898796  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.899797  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.900589  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.900602  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.901303  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.902413  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.902773  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.904407  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.904701  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.904801  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.905809  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.906649  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.907587  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.908625  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.909517  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.911132  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.911615  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.913539  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.914189  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.915849  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.917234  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.918091  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.920176  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.922011  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.923242  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.924120  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.926542  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.928996  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.931464  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.933299  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.935230  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.936245  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.937742  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.937933  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.939217  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.940871  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.941038  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.942292  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.944161  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.944238  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.946073  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.946920  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.948171  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.950132  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.950289  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.952429  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.953029  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.954656  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.956726  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.958543  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.959897  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.960637  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.963056  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.964420  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.965323  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.965512  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.966244  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.966738  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.967378  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.967983  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.968576  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.969579  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.969804  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.970844  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.971618  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.971912  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.973885  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.973988  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.974304  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.977126  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.977333  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.978805  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.980466  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.980570  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.980923  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.983255  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.984279  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.986517  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.987687  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.989100  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.989258  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.992489  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.996073  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644912.997233  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.002871  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.004218  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.004824  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.005383  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.005956  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.006536  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.007129  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.007723  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.008317  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.008863  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.009470  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.010036  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.010142  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.010893  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.011517  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.012239  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.012856  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.013544  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.014310  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.015065  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.016888  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.017089  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.018586  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.020246  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.022198  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.024138  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.025257  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.026057  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.033412  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.044816  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.045402  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.046026  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.046626  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.047215  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.047836  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.048449  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.049085  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.049722  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.050356  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.051041  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.051797  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.052536  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.053314  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.054140  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.055088  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.056014  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.057700  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.063947  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.064612  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.065256  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.065853  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.066539  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.067222  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.067926  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.068631  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.069305  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.069985  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.070727  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.071456  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.072254  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.073093  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.073836  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.074583  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.075378  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.076281  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.077158  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.078019  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.079141  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.080097  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.081500  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.082703  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.084626  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.086546  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.088466  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.090387  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.092564  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.094745  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.097246  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.116437  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.117767  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.119134  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.120529  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.122001  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.123768  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.125773  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.127182  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.127682  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.127889  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.128645  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.129369  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.129863  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.130134  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.130894  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.131674  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.132502  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.134283  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.135286  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.135456  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.136870  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.138321  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.138506  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.140494  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.141245  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.143477  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.144711  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.146835  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.150775  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.152572  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.153930  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.155291  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.156679  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.158151  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.158758  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.158954  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.159484  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.160093  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.160109  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.160635  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.161190  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.161713  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.162129  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.162317  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.162785  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.163273  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.163824  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.164043  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.164398  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.164962  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.165509  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.166375  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.166388  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.167046  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.167766  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.168497  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.169183  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.170332  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.171354  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.171685  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.172386  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.173483  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.173851  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.174752  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.174916  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.174936  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.175864  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.175947  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.176691  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.177537  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.177820  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.178394  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.179272  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.180146  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.181019  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.181268  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.181834  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.182798  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.183675  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.184849  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.185555  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.185792  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.186040  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.186506  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.187107  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.187203  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.187371  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.187686  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.188316  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.188400  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.188870  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.189395  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.189620  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.189999  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.190555  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.190796  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.191139  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.191715  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.192261  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.192918  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.193554  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.194142  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.194241  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.195026  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.195332  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.195632  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.196654  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.197262  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.200362  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.201820  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.202461  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.203176  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.204047  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.204050  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.204767  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.205310  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.205837  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.206423  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.207041  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.207471  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.207633  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.208233  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.208829  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.209433  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.209991  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.210594  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.210718  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.210831  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.211625  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.211641  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.212318  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.212501  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.213081  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.213332  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.214051  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.214226  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.214860  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.215084  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.215674  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.215967  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.216517  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.216855  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.217658  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.217830  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.218735  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.218841  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.219709  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.219946  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.220595  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.221047  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.221778  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.222285  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.222716  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.223513  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.223852  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.224890  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.225161  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.226103  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.226538  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.227268  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.230410  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.233502  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.236581  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.240018  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.241704  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.242231  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.242785  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.243465  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.243480  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.244228  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.244780  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.245483  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.246009  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.246747  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.247189  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.248100  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.248315  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.248969  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.249717  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.249910  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.250778  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.251301  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.251635  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.252633  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.252730  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.253537  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.254452  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.255415  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.256362  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.257400  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.258552  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.259632  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.260546  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.260817  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.260995  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.261398  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.261769  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.262262  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.262342  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.262761  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.263136  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.263567  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.263756  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.263994  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.264382  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.264807  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.265459  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.265472  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.265978  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.266471  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.267107  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.267733  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.268369  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.268661  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.269097  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.269745  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.270493  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.271513  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.272713  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.275028  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.276798  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.277775  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.278676  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.279572  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.279966  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.280354  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.280730  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.280829  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.281209  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.281725  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.281824  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.282177  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.282648  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.282823  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.283113  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.283554  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.283980  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.284170  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.284180  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.284603  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.285292  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.285316  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.285340  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.285791  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.286396  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.286417  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.286624  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.286865  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.287461  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.287477  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.287932  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.288400  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.288499  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.289631  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.289712  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.290621  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.291035  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.291543  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.292083  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.292496  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.293299  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.293335  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.293503  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.293805  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.294254  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.294711  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.294851  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.294936  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.295433  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.296044  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.296059  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.296320  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.296571  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.297099  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.297203  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.297619  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.297835  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.298146  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.298366  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.298686  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.299233  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.299396  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.299752  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.299863  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.300299  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.300833  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.300910  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.301192  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.301370  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.301795  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.302234  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.302636  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.302855  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.302958  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.303315  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.303771  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.304565  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.304936  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.305304  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.306167  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.306271  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.307204  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.308228  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.308457  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.309266  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.310304  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.312081  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.314385  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.315357  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.315707  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.316267  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.317164  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.318231  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.318323  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.318711  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.319145  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.319442  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.319601  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.319698  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.320196  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.320389  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.320621  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.321146  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.321421  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.321718  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.322232  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.322411  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.323017  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.323240  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.323804  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.323910  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.325116  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.325217  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.326232  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.326612  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.327519  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.327616  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.328021  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.329148  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.330336  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.331674  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.331775  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.333138  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.334255  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.334843  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.334864  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.335351  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.335848  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.336519  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.336540  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.337477  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.337788  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.338054  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.338554  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.339199  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.339484  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.339999  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.340721  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.341333  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.341757  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.345134  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.345290  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.347237  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.347861  414029 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.348897  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.352490  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.356087  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.359681  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.363815  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.367942  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.391257  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.392159  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.393082  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.394201  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.395381  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.396392  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.397639  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.398710  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.400738  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.403859  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.405521  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.407061  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.410867  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.414275  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.419087  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.427031  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.427914  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.428830  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.429952  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.430854  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.431133  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.431481  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.432162  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.432283  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.432776  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.433408  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.433572  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.434021  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.434762  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.434835  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.435371  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.435922  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.436524  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.436862  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.437141  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.437889  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.438517  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.439237  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.439986  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.440062  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.440693  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.441464  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.441727  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.442228  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.443271  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.444071  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.445749  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.447066  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.447434  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.449399  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.450459  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.451356  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.453273  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.455255  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.466927  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.467546  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.468108  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.468696  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.469279  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.469877  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.470479  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.471074  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.471630  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.472084  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.472280  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.472704  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.472897  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.473348  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.473662  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.473964  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.474309  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.474572  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.475096  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.475268  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.475781  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.475952  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.476520  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.476696  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.477444  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.477515  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.478285  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.478368  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.478992  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.479746  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.480193  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.480504  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.481285  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.481884  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.482126  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.483069  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.483569  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.484018  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.485539  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.485732  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.487480  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.489389  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.492075  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.492751  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.493393  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.493991  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.494676  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.495367  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.496068  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.496771  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.497445  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.498123  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.498863  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.499604  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.500399  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.501248  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.501990  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.502731  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.503485  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.504387  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.505270  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.506131  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.507248  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.508297  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.508349  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.508919  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.509568  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.509755  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.510198  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.510840  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.511003  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.511480  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.512109  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.512745  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.512964  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.513412  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.514047  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.514790  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.514945  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.515561  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.516301  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.516916  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.517121  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.517949  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.518997  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.519022  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.519957  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.521204  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.521666  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.523407  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.525933  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.527995  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.528679  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.529327  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.529922  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.530614  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.531296  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.532001  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.532704  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.533382  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.534069  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.534815  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.535560  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.536361  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.537203  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.537953  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.538718  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.539473  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.540374  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.541255  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.542113  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.543234  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.544193  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.545602  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.546795  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.548721  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.550645  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.552568  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.554499  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.555873  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.556610  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.556768  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.557376  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.558096  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.558887  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.559036  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.559667  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.560445  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.561275  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.561549  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.563077  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.564235  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.565651  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.567244  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.569246  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.572204  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.575553  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.587395  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.587923  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.588449  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.588978  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.589539  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.590063  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.590632  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.591160  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.591329  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.591666  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.592051  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.592258  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.592942  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.592958  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.593570  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.593733  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.594132  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.594500  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.594869  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.595287  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.595542  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.596097  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.596299  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.597058  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.597134  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.597832  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.598877  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.599049  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.600178  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.600252  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.601271  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.601611  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.602386  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.603221  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.603502  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.604600  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.605221  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.608148  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.611482  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.614215  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.614686  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.615158  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.615638  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.616118  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.616671  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.617233  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.617782  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.618381  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.618939  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.619510  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.620089  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.620639  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.621300  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.621933  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.622552  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.623332  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.623550  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.623988  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.624174  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.624704  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.625030  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.625246  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.625805  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.626460  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.627041  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.627522  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.628011  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.628562  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.629116  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.629680  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.630224  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.630334  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.631084  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.631111  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.631875  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.631899  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.632660  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.632741  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.633253  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.633488  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.633797  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.634236  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.634413  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.634993  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.635399  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.635622  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.636164  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.636443  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.636783  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.637516  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.637595  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.638146  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.638830  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.638909  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.639533  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.639943  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.640295  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.641011  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.641126  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.641783  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.642710  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.643515  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.644320  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.645151  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.646241  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.647334  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.648427  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.649526  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.650852  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.650918  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.651342  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.651807  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.652182  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.652359  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.652834  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.653382  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.653974  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.654055  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:35\u001b[0m 16s/step - loss: 0.0961"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1729644913.654583  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.655198  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.655386  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.655768  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.656334  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.656908  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.657451  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.658112  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.658741  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.659366  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.660148  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.660741  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.661773  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.666875  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.667508  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.668146  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.668779  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.669352  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.669879  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.670457  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.670616  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.671089  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.671251  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.671799  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.671898  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.672391  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.672557  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.673008  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.673319  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.673624  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.673886  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.674251  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.674608  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.674832  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.675165  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.675461  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.676249  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.676409  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.676908  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.677578  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.677743  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.678666  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.678950  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.679485  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.680287  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.680530  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.681130  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.681851  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.682234  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.683324  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.684425  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.685518  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.686729  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.687935  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.689301  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.689367  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.689805  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.690204  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.690574  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.691081  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.691159  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.691580  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.691961  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.692362  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.692771  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.693159  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.693581  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.694064  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.694574  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.695068  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.695705  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.696333  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.696969  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.697661  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.698310  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.699064  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.700089  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.701166  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.703058  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.706199  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.706724  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.707271  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.707888  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.708063  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.708471  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.708665  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.708887  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.709382  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.709449  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.709838  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.710144  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.710319  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.710828  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.710904  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.711356  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.711797  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.712002  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.712244  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.712672  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.713250  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.713322  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.713712  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.714200  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.714751  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.714825  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.715262  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.716040  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.716399  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.717727  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.720601  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.721103  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.721552  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.722000  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.722500  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.722956  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.723453  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.723907  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.724411  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.724918  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.725305  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.725431  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.725749  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.725983  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.726168  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.726651  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.726730  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.727234  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.727331  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.727817  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.727894  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.728393  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.728473  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.728968  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.729049  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.729556  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.729637  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.730135  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.730154  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.730705  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.730783  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.731322  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.731402  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.731846  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.732245  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.732421  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.733120  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.733205  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.733970  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.734039  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.734625  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.735078  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.735336  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.736027  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.736173  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.736800  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.737212  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.737842  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.738264  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.738937  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.740839  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.745761  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.746229  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.746326  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.746833  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.746904  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.747382  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.747461  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.747942  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.747961  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.748522  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.748580  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.749097  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.749180  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.749599  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.749768  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.750053  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.750388  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.750559  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.750954  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.751058  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.751502  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.751737  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.751976  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.752588  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.752667  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.753030  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.753524  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.753779  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.754311  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.754886  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.756206  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.758968  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.759466  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.760192  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.760651  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.761009  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.761151  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.761484  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.761637  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.762024  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.762195  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.762583  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.762748  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.763163  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.763482  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.763798  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.764007  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.764425  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.764590  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.764948  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.765136  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.765733  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.765813  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.766257  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.766582  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.766748  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.767215  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.767370  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.767660  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.768035  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.769560  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.770131  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.770147  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.770600  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.771052  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.771840  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.772237  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.772570  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.772881  414025 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.773301  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.774327  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.775345  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.776371  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.777392  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.785157  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.785618  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.786029  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.786491  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.786974  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.787392  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.787916  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.788473  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.788982  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.789747  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.790521  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.791612  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.792709  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.794017  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.798752  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.799168  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.799651  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.800156  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.800692  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.801323  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.801878  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.802382  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.803034  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.803812  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.804530  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.805140  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.807058  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.809140  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644913.809772  414013 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 9/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0963"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 00:55:14.183977: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-10-23 00:55:14.184172: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "2024-10-23 00:55:14.184568: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "W0000 00:00:1729644914.209335  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.209808  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.210142  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.210506  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.210895  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.211299  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.211660  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.212037  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.212469  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.212646  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.212962  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.213151  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.213400  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.214021  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.214025  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.214189  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.214833  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.214858  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.215010  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.215568  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.215784  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.215862  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.216236  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.216665  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.216758  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.216963  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.217279  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.217532  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.217713  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.217927  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.218273  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.218482  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.218713  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.218933  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.219270  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.219440  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.219696  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.220057  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.220226  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.220396  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.220732  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.220846  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.221296  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.221539  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.221601  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.222388  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.222411  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.222531  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.223197  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.223362  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.223378  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.223804  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.224280  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.224380  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.224558  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.224960  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.225242  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.225339  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.225576  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.226094  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.226556  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.226748  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.227290  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.227481  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.228174  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.228335  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.228864  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.229041  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.229696  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.229733  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.230319  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.230516  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.231204  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.244842  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.245271  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.245615  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.245953  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.246281  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.246619  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.246960  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.247341  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.247691  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.248056  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.248386  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.248735  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.249086  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.249446  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.249786  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.250173  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.250534  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.250933  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.251138  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.251343  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.251700  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.251935  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.252161  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.252407  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.252602  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.253140  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.253236  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.253346  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.253558  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.254046  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.254208  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.254296  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.255005  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.255033  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.255061  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.255750  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.255925  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.255946  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.256225  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.256715  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.256810  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.256996  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.257225  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.257586  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.257741  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.257815  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.258516  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.258574  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.258666  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.259265  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.259398  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.259518  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.259740  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.260095  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.260251  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.260334  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.260766  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.260985  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.261226  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.261803  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.261831  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.262176  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.262714  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.263289  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.263749  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.264300  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.264480  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.264979  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.265067  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.265581  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.265645  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.266032  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.266266  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.266459  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.266989  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.267026  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.267538  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.267634  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.268057  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.268158  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.268447  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.268791  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.269142  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.269504  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.269888  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.269908  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.270386  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.270488  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.271039  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.271153  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.271408  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.271699  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.271797  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.272160  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.272264  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.272525  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.272933  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.273035  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.273457  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.273554  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.274260  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.274269  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.274697  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.274891  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.275160  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.275494  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.275673  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.276214  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.276315  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.276797  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.277703  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.278069  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.278410  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.278726  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.279062  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.279441  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.279963  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.280480  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.280766  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.281185  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.281268  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.281578  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.282019  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.282029  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.282359  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.282833  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.282842  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.283167  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.283575  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.283660  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.283919  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.283993  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.284459  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.284475  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.284984  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.285004  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.285312  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.285812  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.285829  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.286290  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.286305  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.286703  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.286883  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.287072  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.287586  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.287602  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.288210  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.288335  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.288414  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.288767  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.288900  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.289211  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.289511  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.289522  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.290052  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.290220  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.290233  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.290803  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.290819  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.290942  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.291173  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.291529  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.291720  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.291899  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.292261  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.292450  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.292646  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.293117  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.293223  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.293959  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.294350  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.294711  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.295114  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.295321  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.295558  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.295731  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.296100  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.296183  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.296625  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.296703  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.297005  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.297210  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.297381  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.297668  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.297783  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.298155  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.298366  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.298542  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.298943  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.299099  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.299326  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.299766  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.300038  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.300374  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.300553  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.300647  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.300868  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.301044  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.301564  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.301698  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.301970  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.302153  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.302413  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.302589  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.302936  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.303111  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.303523  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.303785  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.303960  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.304380  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.304596  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.304962  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.305429  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.305665  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.306422  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.306437  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.307112  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.307413  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.307798  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.308445  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.308452  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.308877  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.309246  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.309656  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.310133  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.310944  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.311745  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.312569  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.313454  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.314099  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.314578  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.314664  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.315089  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.315585  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.315663  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.315999  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.316471  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.317401  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.317494  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.317771  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.318171  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.318356  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.318549  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.318938  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.319314  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.319427  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.319806  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.320333  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.320436  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.320731  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.321181  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.321436  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.321628  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.322342  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.322677  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.323102  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.323535  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.323964  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.324510  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.324605  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.324889  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.325232  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.325333  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.325752  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.325853  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.326159  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.326503  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.326612  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.327155  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.327235  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.327556  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.327944  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.328231  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.328428  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.328848  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.329269  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.329896  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.330472  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.330558  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.331139  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.331227  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.331780  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.331854  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.331865  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.332167  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.332434  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.332612  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.333233  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.333265  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.333697  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.333870  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.334112  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.334488  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.334599  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.335116  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.335194  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.335586  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.336043  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.336217  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.337136  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.337298  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.337586  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.338019  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.338383  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.338559  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.339064  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.339645  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.339718  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.340194  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.340289  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.340962  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.341086  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.341402  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.341617  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.341883  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.342304  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.342412  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.342937  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.343400  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.343516  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.344012  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.344502  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.344605  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.345099  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.345717  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.345731  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.346841  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.347081  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.347865  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.348629  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.348634  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.349073  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.349542  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.350092  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.350182  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.350705  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.351198  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.351446  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.351711  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.352241  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.352881  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.352965  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.353452  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.354288  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.354817  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.355084  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.355720  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.355821  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.356294  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.356373  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.356795  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.357257  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.357659  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.357836  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.358338  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.358852  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.359052  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.359396  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.359896  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.360521  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.360595  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.361931  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.362106  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.363276  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.363565  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.364609  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.365971  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.367353  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.368749  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.370206  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.372433  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.372884  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.373375  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.373869  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.374395  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.374912  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.375475  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.375964  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.376491  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.377084  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.377681  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.378294  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.378888  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.379804  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.380160  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.380701  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.380783  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.381271  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.381501  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.381788  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.382394  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.382478  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.382930  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.383160  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.383515  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.384017  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.384548  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.384895  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.385155  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.385913  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.385994  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.386765  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.386881  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.386962  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.387243  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.387493  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.387765  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.388405  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.388621  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.388704  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.388956  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.389389  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.389572  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.390276  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.390361  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.390541  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.390790  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.391100  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.391340  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.391816  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.391998  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.392262  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.392613  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.393235  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.393564  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.393854  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.394383  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.394489  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.394784  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.395317  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.395513  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.396445  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.396774  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.397176  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.397845  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.398601  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.399600  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.400364  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.400540  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.401341  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.402254  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.402424  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.403023  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.403795  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.403871  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.404529  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.405173  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.405707  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.405938  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.406623  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.407265  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.407462  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.407953  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.408697  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.409433  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.409614  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.410117  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.411137  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.411860  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.412552  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.412660  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.413200  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.413947  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.414634  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.415093  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.415290  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.415967  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.416715  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.417562  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.417650  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.418255  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.418435  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.419130  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.419719  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.420117  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.420369  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.420719  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.421142  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.421825  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.422563  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.422672  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.423178  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.423353  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.424104  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.424804  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.425196  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.425622  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.425698  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.427933  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.428217  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.428293  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.430679  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.430851  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.433085  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.433386  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.435563  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.436101  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.438090  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.440604  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.443288  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.460829  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.461467  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.462135  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.462800  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.463513  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.464225  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.464971  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.465664  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.466397  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.467176  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.468028  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.469051  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.469159  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.469925  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.470027  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.470611  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.471400  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.471495  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.472208  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.472505  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.472930  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.473802  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.473899  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.474590  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.474972  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.475337  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.475673  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.476097  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.476240  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.476407  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.477225  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.477294  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.477914  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.478189  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.478647  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.479245  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.479436  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.479519  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.480267  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.480512  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.480857  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.481035  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.481636  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.481815  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.482198  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.482602  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.482798  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.483468  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.483967  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.484343  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.484968  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.485249  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.485622  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.486479  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.487550  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.488017  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.488841  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.489405  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.490005  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.490734  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.491025  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.494105  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.494263  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.495124  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.495482  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.496147  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.496823  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.497043  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.498014  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.498246  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.499225  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.500204  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.501142  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.501664  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.502226  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.503172  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.503533  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.504254  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.504709  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.505350  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.505608  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.506571  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.507769  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.508747  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.509684  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.509950  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.510771  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.511279  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.511716  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.512313  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.512808  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.513209  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.513914  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.514193  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.514468  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.515405  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.516398  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.517342  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.518468  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.518638  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.519002  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.519434  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.520525  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.521607  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.523193  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.523653  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.526235  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.527762  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.528344  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.530771  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.532427  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.533130  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.535332  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.537142  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.538168  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.539999  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.541951  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.544714  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.547021  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.549531  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.554529  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.602488  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.603541  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.604507  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.605546  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.606743  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.607869  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.609016  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.610252  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.611398  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.611461  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.612584  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.612689  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.613569  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.614118  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.614626  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.615570  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.615829  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.617074  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.617181  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.617769  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.618244  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.618978  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.619086  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.619498  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.620089  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.620615  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.620889  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.621158  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.621821  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.622352  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.622927  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.623247  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.623481  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.624878  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.624955  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.625053  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.626127  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.626457  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.627260  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.627486  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.628119  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.628467  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.630173  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.630186  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.630291  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.631606  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.632339  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.633099  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.634348  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.634757  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.635710  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.636683  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.636856  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.638704  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.639278  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.640692  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.643088  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.644818  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.645638  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.647736  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.648041  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.648437  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.649049  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.649675  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.650704  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.651338  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.651986  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.652712  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.653485  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.653661  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.654327  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.655066  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.656935  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.657712  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.657816  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.658442  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.659080  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.659906  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.660204  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.660546  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.661200  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.661935  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.662791  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.662890  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.663645  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.664383  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.665697  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.665964  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.666686  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.666918  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.667330  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.667969  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.668961  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.668978  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.669474  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.669653  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.670319  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.671063  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.672009  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.672090  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.672191  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.672870  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.673616  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.675168  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.675261  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.676171  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.678350  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.678690  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.681327  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.681436  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.684410  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.684486  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.687585  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.690469  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.693465  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.708368  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.709000  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.709609  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.710282  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.710982  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.711631  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.712287  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.712939  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.713625  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.714318  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.715094  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.715875  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.716804  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.717854  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.718052  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.718686  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.718910  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.719321  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.720118  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.720220  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.720834  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.721256  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.721503  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.722172  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.722557  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.722848  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.723537  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.724237  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.725154  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.725165  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.725960  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.726618  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.726908  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.727270  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.728030  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.728106  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.728845  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.728958  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.729166  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.729586  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.730291  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.730469  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.730974  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.731563  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.731743  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.732450  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.732879  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.733158  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.733948  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.734743  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.735294  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.735696  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.736715  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.737764  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.739178  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.739353  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.739464  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.740417  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.741719  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.743095  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.745498  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.749249  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.749322  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.749662  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.749840  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.750216  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.750693  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.751444  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.752163  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.753082  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.753982  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.754930  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.756039  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.757134  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.759590  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.759735  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.760026  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.760399  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.760881  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.761739  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.761847  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.762168  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.762631  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.762718  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.763120  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.763572  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.763657  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.763914  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.764246  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.764714  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.764808  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.765159  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.765608  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.765712  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.765968  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.766358  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.766819  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.766930  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.767209  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.767571  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.768115  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.768209  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.768553  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.769843  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.769899  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.770496  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.770506  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.770993  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.771103  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.771496  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.771845  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.772265  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.773006  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.773337  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.773356  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.773483  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.773800  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.774244  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.774316  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.774714  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.774802  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.775106  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.775307  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.775473  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.775805  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.776196  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.776374  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.776571  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.776919  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.777321  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.777538  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.777710  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.778097  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.778468  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.778651  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.778891  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.779316  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.780249  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.780629  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.781121  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.781597  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.782340  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.783396  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.783599  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.783769  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.784238  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.784590  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.784961  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.785052  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.785383  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.785721  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.786051  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.786402  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.786744  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.787095  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.787485  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.787838  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.788220  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.788571  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.788987  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.789418  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.790419  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.790741  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.791308  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.791802  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.792387  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.793115  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.794240  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.795465  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.798830  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.799216  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.799544  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.799858  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.800167  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.800499  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.800923  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.801033  414034 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.801272  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.801592  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.801910  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.802237  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.802554  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.802990  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.803303  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.803632  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.803997  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.804373  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.804780  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.805168  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.805541  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.805607  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.806009  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.806474  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.806549  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.806891  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.807451  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.807457  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.807840  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.808340  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.808465  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.808849  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.809115  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.809326  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.809819  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.809908  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.810235  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.810620  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.810994  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.811386  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.811752  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.812139  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.812546  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.812977  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.813390  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.814097  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.814112  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.814604  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.814742  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.814979  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.815368  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.815458  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.815960  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.816095  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.816315  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.816750  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.817063  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.817151  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.817514  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.818034  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.818040  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.818386  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.818867  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.818992  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.819255  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.819651  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.819842  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.820028  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.820401  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.820790  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.821657  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.822974  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.823871  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.824256  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.824728  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.824862  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.824865  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.825413  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.825543  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.825869  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.826116  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.826311  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.826525  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.826804  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.827000  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.827259  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.827464  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.827719  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.827929  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.828189  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.828390  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.828638  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.828866  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.829054  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.829294  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.829540  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.829730  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.830013  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.830437  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.830689  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.830869  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.831194  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.831376  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.831706  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.831892  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.832330  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.832758  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.832831  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.833273  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.833724  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.834281  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.834400  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.834569  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.834924  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.835081  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.835646  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.835843  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.836173  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.836175  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.836732  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.836828  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.837090  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.837512  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.837863  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.837961  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.838310  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.838878  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.838886  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.839238  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.839757  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.839866  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.840122  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.840463  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.840804  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.841323  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.841895  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.842272  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.842647  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.843050  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.843403  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.843996  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.844127  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.844615  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.844747  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.845159  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.845484  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.845700  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.846208  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.846307  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.846608  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.847046  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.847431  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.847784  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.847934  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.848335  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.848728  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.849137  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.849238  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.849575  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.849974  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.850370  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.850674  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.850702  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.850899  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.851184  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.851379  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.851595  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.852133  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.852343  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.852461  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.852622  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.853004  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.853409  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.853921  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.854029  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.854337  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.854731  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.855118  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.855534  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.855708  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.855930  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.856281  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.856623  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.857137  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.857493  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.857867  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.858249  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.858783  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.858885  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.859176  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.859363  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.859611  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.859779  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.860183  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.860282  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.860651  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.861209  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.861265  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.861595  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.862078  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.862162  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.862463  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.862866  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.863276  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.863559  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.863902  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.864298  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.864940  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.865692  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.866325  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.867085  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.867753  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.870460  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.870923  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.871305  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.871714  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.872117  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.872506  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.872910  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.873295  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.873694  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.874209  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.874215  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.874572  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.874602  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.874694  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.874972  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.875299  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.875427  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.875440  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.875677  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.875852  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.876255  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.876384  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.876476  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.876650  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.877359  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.877438  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.877448  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.877820  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.878008  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.878163  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.878296  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.878475  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.878718  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.879136  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.879137  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.879248  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.879645  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.879754  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.879924  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.880199  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.880299  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.880968  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.881054  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.881067  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.881867  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.881947  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.882491  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.882773  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.882852  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.883518  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.883875  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.884270  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.884290  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.884947  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.885734  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.885753  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.886460  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.887118  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.887352  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.888410  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.888569  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.889455  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.890372  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.891012  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.891643  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.892397  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.892480  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.893109  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.893726  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.894470  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.894857  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.895025  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.895324  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.895411  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.895787  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.896073  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.896241  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.896632  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.896812  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.896987  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.897397  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.897688  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.897843  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.897861  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.898247  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.898412  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.898645  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.899147  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.899219  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.899780  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.899945  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.900186  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.900656  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.901621  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.901698  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.902642  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.902891  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.903060  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.903666  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.906393  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.908890  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.909351  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.909976  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.910613  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.911262  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.911433  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.911895  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.912217  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.912526  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.913270  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.914011  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.914741  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.915376  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.916057  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.916405  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.916721  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.917374  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.918046  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.918778  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.919651  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.920682  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.921709  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.924425  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.925639  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.926945  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.929459  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.934366  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.942621  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.943237  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.943468  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.944016  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.944677  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.945348  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.945976  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.946621  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.947278  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.947978  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.948678  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.949389  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.950275  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.951070  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.951925  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.952781  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.953654  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.954690  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.955706  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.956309  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.957104  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.957283  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.957783  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.958500  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.959126  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.959833  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.959934  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.960596  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.961290  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.961989  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.962833  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.963724  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.964516  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.965369  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.966219  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.967090  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.967175  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.968072  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.968164  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.968816  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.969558  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.970320  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.970693  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.971085  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.971846  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.972603  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.973061  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.973532  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.973611  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.974341  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.974423  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.975162  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.975337  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.976048  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.976233  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.976737  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.977002  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.977377  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.978098  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.978165  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.978824  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.979099  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.979537  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.979982  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.980217  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.980247  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.981147  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.981168  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.981193  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.982247  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.982279  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.982346  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.983018  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.983332  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.983408  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.983796  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.984220  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.984487  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.984594  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.985064  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.985349  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.986071  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.986309  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.986392  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.987249  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.987480  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.987490  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.988360  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.988470  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.989176  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.989799  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.989962  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.990720  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.991776  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.991858  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.992171  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.992850  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.993721  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.994593  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.994968  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.995424  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.996360  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.997235  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.998765  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.998873  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.998923  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.999777  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644914.999871  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.000504  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.000768  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.001237  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.001996  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.002484  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.002765  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.003513  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.003863  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.004262  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.005041  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.005792  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.006204  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.006561  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.006970  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.007352  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.008098  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.009018  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.010046  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.010128  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.010593  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.010993  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.011856  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.012682  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.013614  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.014233  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.014482  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.016050  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.016981  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.017923  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.017927  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.021034  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.021573  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.024144  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.027748  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.031373  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.034992  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.038618  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.058324  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.058989  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.059664  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.060394  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.061105  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.061979  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.062935  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.063907  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.064977  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.066054  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.067277  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.068145  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.069349  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.070007  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.070678  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.071173  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.071422  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.072128  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.073001  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.073969  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.074952  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.076017  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.077084  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.078297  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.079164  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.079774  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.080768  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.081710  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.082163  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.082706  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.083718  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.084917  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.086101  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.086127  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.086824  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.087075  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.087503  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.088267  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.088355  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.089076  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.089331  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.089954  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.090388  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.090885  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.090919  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.091543  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.092007  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.092109  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.092521  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.092962  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.093187  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.093699  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.093956  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.094266  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.094915  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.095019  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.095488  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.096046  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.096284  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.096457  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.097078  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.098108  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.098182  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.099272  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.099492  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.099651  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.100339  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.101363  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.102527  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.103496  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.104653  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.105230  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.105750  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.107023  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.107920  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.108646  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.108906  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.109847  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.110265  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.110355  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.110837  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.111847  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.112832  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.113847  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.114772  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.115477  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.115924  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.116024  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.117071  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.118105  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.119245  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.120213  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.120856  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.120953  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.121389  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.122472  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.123748  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.125422  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.125591  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.126028  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.126903  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.130276  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.131253  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.132449  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.135889  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.137345  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.140519  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.142365  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.147526  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.152187  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.156825  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.190769  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.191784  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.192871  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.193872  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.194910  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.195973  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.197061  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.198165  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.199285  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.200667  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.200681  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.201721  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.201916  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.202818  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.203217  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.203819  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.204613  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.204868  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.205954  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.206150  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.207058  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.207638  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.208170  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.209244  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.209349  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.210518  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.211116  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.211726  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.213038  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.213223  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.214431  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.215619  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.216074  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.216089  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.217099  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.217558  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.218196  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.219071  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.219244  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.220335  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.220454  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.220938  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.221410  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.222505  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.222971  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.223615  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.224721  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.225341  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.225951  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.227168  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.228523  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.230024  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.230112  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.230428  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.231580  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.231756  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.232963  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.233131  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.234145  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.234604  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.235351  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.236573  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.236656  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.237902  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.238597  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.239175  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.239867  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.240381  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.241052  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.241173  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.241706  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.242354  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.243004  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.243520  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.244250  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.244709  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.245535  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.245969  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.245988  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.246815  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.247222  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.247960  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.248480  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.249410  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.249696  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.250534  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.251016  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.251793  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.252301  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.253668  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.253750  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.255025  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.255372  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.255710  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.256299  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.257072  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.257146  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.257443  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.258244  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.258720  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.258910  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.259407  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.260028  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.260718  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.260794  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.261278  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.261892  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.262771  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.263023  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.263188  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.264570  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.264663  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.264824  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.265789  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.266528  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.266615  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.267099  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.268148  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.268380  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.269591  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.270097  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.270864  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.272180  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.272309  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.272472  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.273585  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.273982  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.275004  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.275676  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.276107  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.277333  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.277896  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.279038  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.280706  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.281095  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.282301  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.283596  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.283822  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.285731  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.286711  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.287655  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.289411  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.289430  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.291107  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.292337  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.295109  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.296474  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.297956  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.301696  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.302037  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.303587  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.307597  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.310086  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.313162  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.318713  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.325127  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.397694  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.398773  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.399870  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.401015  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.402167  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.403606  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.405240  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.405333  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.406327  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.406905  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.407430  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.408802  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.408817  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.409966  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.410608  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.411414  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.412529  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.413002  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.414557  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.414887  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.416196  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.417537  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.417982  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.418936  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.419921  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.420090  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.421171  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.422393  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.422502  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.423652  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.423906  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.425167  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.425263  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.426833  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.428428  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.430067  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.431468  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.431840  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.433720  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.434564  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.435257  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.436017  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.436309  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.436694  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.437349  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.438023  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.438701  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.438938  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.439328  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.440014  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.440696  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.441368  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.442013  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.442053  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.442988  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.443001  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.443661  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.443838  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.444334  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.444557  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.445003  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.445255  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.445421  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.445708  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.446491  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.446575  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.447117  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.447572  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.447814  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.448495  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.449163  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.449997  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.450699  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.450798  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.451529  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.452229  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.453056  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.453488  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.453966  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.454932  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.455816  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.455986  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.456506  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.457138  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.457910  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.458018  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.458500  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.458677  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.459358  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.460035  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.460773  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.460896  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.461387  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.461564  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.462252  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.462923  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.463346  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.463587  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.464124  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.464322  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.465064  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.465939  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.465960  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.466757  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.467660  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.468761  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.468875  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.471591  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.471793  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.474537  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.477336  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.479808  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.482268  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.484950  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.494518  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.495190  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.495893  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.496552  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.497228  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.497916  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.498626  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.499341  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.500067  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.500814  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.501716  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.501827  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.502659  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.502741  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.503373  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.503630  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.504050  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.504806  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.504887  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.505692  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.505802  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.506415  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.506750  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.507142  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.508116  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.508136  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.508877  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.509622  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.509720  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.510516  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.510963  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.511410  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.512414  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.513434  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.513541  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.514383  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.514860  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.515701  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.515721  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.516433  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.517219  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.517318  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.518004  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.518586  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.518759  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.519471  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.520196  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.520966  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.521033  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.521144  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.521893  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.521964  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.522795  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.522870  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.523738  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.523815  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.524751  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.524839  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.525498  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.525851  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.526504  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.526770  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.527524  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.527713  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.528439  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.528461  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.528878  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.529357  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.529461  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.530158  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.530364  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.530545  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.530966  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.531844  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.531935  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.532033  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.532781  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.532949  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.533789  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.534201  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.534446  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.534810  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.535129  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.535737  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.536039  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.536660  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.537183  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.537738  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.538334  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.538820  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.539232  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.539925  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.540380  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.541171  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.541748  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.541800  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.542080  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.542590  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.543104  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.543249  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.543417  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.544394  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.544464  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.544574  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.545258  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.545603  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.546113  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.546188  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.546500  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.547105  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.547430  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.547650  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.548113  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.549150  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.549257  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.550180  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.550479  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.550587  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.551201  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.551793  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.552265  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.553443  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.553564  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.553638  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.554708  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.554878  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.555773  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.556748  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.556820  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.557580  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.557965  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.559091  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.559721  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.560245  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.560452  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.561139  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.562490  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.563132  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.563404  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.563850  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.565041  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.566397  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.566665  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.566735  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.567889  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.569774  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.570746  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.573149  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.573612  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.576531  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.579449  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.582803  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.586160  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.614924  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.615653  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.616358  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.617086  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.617827  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.618695  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.619664  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.620587  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.620829  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.621701  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.621778  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.622490  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.623213  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.623958  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.624191  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.624825  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.625548  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.625792  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.626824  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.626934  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.627873  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.628486  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.630338  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.631085  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.631685  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.632980  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.633555  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.634384  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.634642  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.634725  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.635109  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.635829  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.636568  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.637353  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.637509  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.638509  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.639438  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.640466  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.640711  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.642940  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.644225  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.644264  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.644837  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.645320  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.645579  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.645823  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.646310  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.646807  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.647114  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.647359  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.647836  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.648342  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.648881  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.649561  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.649732  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.650074  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.650179  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.650754  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.650866  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.651494  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.651588  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.652015  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.652191  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.652511  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.652977  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.653197  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.653296  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.653625  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.653800  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.654410  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.654503  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.654929  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.655461  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.656126  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.656305  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.656638  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.657319  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.657692  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.657917  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.658451  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.659224  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.659306  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.659905  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.660584  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.660790  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.662449  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.662541  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.662900  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.663444  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.664230  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.664245  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.664268  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.664737  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.665218  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.665632  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.665806  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.666342  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.666812  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.667208  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.667380  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.667914  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.668663  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.668765  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.669170  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.669702  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.670359  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.670376  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.670952  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.671597  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.672196  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.672880  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.674595  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.676121  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.677617  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.678985  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.679653  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.680140  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.680368  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.680703  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.681232  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.681758  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.681927  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.682314  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.682815  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.683329  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.683842  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.684362  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.684961  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.685753  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.685750  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.686501  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.686516  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.687311  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.687325  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.687964  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.688076  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.688467  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.688814  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.689022  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.689743  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.689757  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.690271  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.690782  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.691274  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.691370  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.691967  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.692570  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.693214  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.693823  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.694461  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.695179  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.695955  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.697100  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.697436  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.697440  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.697702  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.697940  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.698241  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.698503  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.698769  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.699157  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.699529  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.699702  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.700120  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.700289  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.700753  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.700865  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.701470  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.701548  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.702163  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.702245  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.702897  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.702976  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.703390  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.703559  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.703723  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.704008  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.704200  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.704603  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.704705  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.704876  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.705340  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.705555  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.705636  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.705885  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.706169  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.706550  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.706574  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.706861  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.707179  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.707387  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.707555  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.707767  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.708311  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.708523  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.708605  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.709402  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.709495  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.709715  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.710204  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.710307  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.711118  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.711228  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.712092  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.712199  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.712765  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.713166  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.713453  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.714108  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.714948  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.715033  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.715290  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.715928  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.716034  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.716713  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.716844  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.716930  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.717250  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.717623  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.717815  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.718487  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.718689  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.718769  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.719063  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.719731  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.719843  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.720387  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.720492  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.721080  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.721441  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.721759  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.722123  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.722489  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.723073  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.723240  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.723843  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.723999  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.724642  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.724748  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.725304  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.725832  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.726062  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.726353  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.726828  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.727591  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.727956  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.728251  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.729076  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.729770  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.730136  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.731610  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.731766  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.733359  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.734950  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.736540  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.738120  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.739914  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.741706  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.750009  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.750527  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.751067  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.751670  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.752293  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.752855  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.753501  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.754078  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.755050  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.755579  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.756090  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.756695  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.756780  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.757421  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.757588  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.758063  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.758367  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.758635  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.759282  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.759860  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.760073  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.760826  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.761599  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.762305  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.763105  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.763714  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.763898  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.765679  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.765688  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.766299  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.766849  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.767207  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.767465  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.768093  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.768651  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.769404  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.769503  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.770078  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.771030  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.772041  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.772594  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.772665  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.772987  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.773417  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.773562  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.773816  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.774227  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.774399  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.774644  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.775030  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.775431  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.775820  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.776114  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.776288  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.776737  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.777128  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.777519  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.777683  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.777789  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.778101  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.778204  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.778608  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.778715  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.779024  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.779212  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.779426  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.779901  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.780012  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.780084  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.780429  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.780842  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.781018  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.781258  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.781675  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.781864  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.782092  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.782762  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.782957  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.783176  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.783602  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.784149  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.784161  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.784602  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.785213  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.785314  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.785696  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.786261  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.786737  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.787540  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.788333  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.788367  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.788797  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.789224  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.789340  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.789631  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.790008  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.790345  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.790449  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.790852  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.791389  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.791407  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.791807  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.792197  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.792586  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.793033  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.793423  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.793846  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.794128  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.794289  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.794530  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.794747  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.794969  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.795283  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.795457  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.795900  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.795980  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.796396  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.796825  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.796995  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.797243  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.797674  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.797853  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.798090  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.798566  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.798739  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.799076  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.799253  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.799675  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.799899  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.799988  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.800304  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.800408  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.801112  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.801152  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.801222  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.801778  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.801794  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.802451  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.802479  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.802576  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.802882  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.803401  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.803510  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.803815  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.804208  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.804833  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.805281  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.805726  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.806198  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.806665  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.807200  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.807706  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.808514  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.808581  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.809040  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.809567  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.810016  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.810302  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.810466  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.810716  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.810908  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.811144  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.811375  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.811576  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.811859  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.812033  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.812329  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.812504  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.812795  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.812970  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.813444  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.813475  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.813523  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.814202  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.814294  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.814305  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.814958  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.814979  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.815003  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.0962"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1729644915.815772  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.815855  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.815868  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.816542  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.816577  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.816655  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.817323  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.817360  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.817433  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.817958  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.818109  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.818126  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.818440  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.818838  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.818861  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.818977  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.819582  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.819672  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.819675  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.820468  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.820537  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.820554  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.821101  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.821293  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.821504  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.821614  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.821849  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.822088  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.822931  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.822940  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.823527  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.823632  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.823997  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.824551  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.824662  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.825082  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.825806  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.825819  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.826424  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.826660  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.826770  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.827018  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.827189  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.827805  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.827962  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.828040  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.828267  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.828813  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.828853  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.829036  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.829261  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.829812  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.829948  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.830153  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.830324  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.830852  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.830959  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.831404  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.831475  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.832048  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.832148  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.832602  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.833114  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.833217  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.833680  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.834281  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.834384  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.834868  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.835437  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.835540  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.835989  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.836558  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.836653  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.837068  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.837667  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.838209  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.838927  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.839557  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.840474  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.841392  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.842320  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.843242  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.843711  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.844219  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.844317  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.844668  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.845107  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.845353  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.845572  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.846027  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.846615  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.846684  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.847107  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.848014  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.848656  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.848811  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.849379  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.849491  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.849832  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.850437  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.850518  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.850902  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.851467  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.851571  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.851939  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.852412  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.852936  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.853322  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.853912  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.854438  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.854635  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.855412  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.856351  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.857697  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.858747  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.859318  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.859417  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.859857  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.860292  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.860738  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.861194  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.861650  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.862117  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.862159  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.862524  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.862895  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.863125  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.863303  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.863682  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.863846  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.864064  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.864448  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.864606  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.864823  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.865187  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.865448  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.865630  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.865997  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.866487  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.866562  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.866906  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.866967  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.867412  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.867520  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.868185  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.868196  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.868288  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.868717  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.868805  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.869178  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.869287  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.869678  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.869990  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.870013  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.870148  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.870644  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.871037  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.871560  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.871661  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.872055  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.872164  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.872577  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.872787  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.873043  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.873218  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.873428  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.873972  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.874065  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.874370  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.874892  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.874989  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.875368  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.875712  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.875822  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.876219  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.876703  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.877099  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.877694  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.878404  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.878988  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.879742  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.879838  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.880312  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.880391  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.880835  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.880915  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.881360  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.881435  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.881888  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.881967  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.882354  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.882460  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.882738  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.882910  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.883143  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.883324  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.883561  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.883714  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.884000  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.884158  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.884389  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.884609  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.884786  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.884825  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.885016  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.885519  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.885573  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.885672  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.886263  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.886285  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.886302  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.887025  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.887101  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.887114  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.887481  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.887764  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.887800  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.887966  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.888213  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.888598  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.888624  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.888732  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.889351  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.889417  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.889427  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.890038  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.890047  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.890150  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.890580  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.890776  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.890931  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.891068  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.891251  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.891590  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.891682  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.891877  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.892220  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.892314  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.892755  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.892780  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.892961  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.893238  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.893438  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.893728  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.893803  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.894496  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.894580  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.894965  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.895187  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.895498  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.895936  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.896042  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.896737  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.896747  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.897230  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.897453  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.897622  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.897879  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.898099  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.898288  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.898573  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.898586  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.898966  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.899215  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.899408  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.899935  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.899950  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.900335  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.900614  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.900780  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.901249  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.901360  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.901637  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.902179  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.902200  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.902564  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.903109  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.903125  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.903518  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.903932  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.904348  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.904593  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.904936  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.905054  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.905442  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.905604  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.906078  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.906108  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.906660  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.906736  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.907083  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.907242  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.907478  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.907775  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.907933  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.908370  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.908590  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.908971  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.909235  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.909405  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.909595  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.909890  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.909990  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.910299  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.910420  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.911131  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.911145  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.911236  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.911574  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.912074  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.912211  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.912235  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.912618  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.913035  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.913242  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.914000  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.914028  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.914618  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.915284  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.916046  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.916721  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.918354  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.918713  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.919017  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.919334  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.919631  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.919931  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.920341  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.920413  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.920845  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.920925  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.921362  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.921447  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.921732  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.921932  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.922109  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.922505  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.922579  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.923023  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.923059  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.923096  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.923723  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.923737  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.923765  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.924383  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.924415  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.924488  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.924959  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.924972  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.925251  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.925559  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.925573  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.926153  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.926222  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.926234  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.926673  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.926844  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.927157  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.927228  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.927350  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.927673  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.927830  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.928167  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.928250  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.928352  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.928595  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.929034  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.929173  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.929190  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.929659  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.929742  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.930220  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.930532  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.930632  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.931222  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.931234  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.931573  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.931901  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.932007  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.932372  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.932682  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.933051  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.933418  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.933836  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.934302  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.934800  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.935250  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.935562  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.935811  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.935993  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.936299  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.936599  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.936836  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.936907  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.937336  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.937415  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.937943  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.937965  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.938423  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.938500  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.938789  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.939008  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.939214  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.939421  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.939601  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.939839  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.940009  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.940265  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.940445  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.940761  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.940864  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.940878  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.941495  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.941573  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.941583  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.942250  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.942314  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.942327  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.942888  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.942915  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.943013  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.943409  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.943445  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.943782  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.943951  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.943968  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.944660  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.944732  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.944740  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.945215  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.945233  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.945483  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.945837  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.945858  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.946382  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.946594  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.946609  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.947312  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.947335  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.947439  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.947964  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.948067  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.948695  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.948714  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.949391  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.949410  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.950072  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.950962  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.951744  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.952790  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.953201  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.953504  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.954756  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.955247  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.955597  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.955948  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.956222  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.956399  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.956613  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.956797  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.956946  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.957024  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.957312  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.957645  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.957681  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.957814  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.958022  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.958287  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.958384  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.958666  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.958889  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.959063  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.959333  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.959511  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.959870  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.960320  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.960399  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.960815  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.960840  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.961418  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.961462  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.961556  414015 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.962118  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.962237  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.962593  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.962730  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.962951  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.963433  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.963453  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.963889  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.963995  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.964596  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.964615  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.965045  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.965652  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.965672  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.966217  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.966685  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.966848  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.967439  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.967989  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.971231  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.971553  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.971898  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.972238  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.972581  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.972921  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.973280  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.973661  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.974060  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.974521  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.974998  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.975590  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.976277  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.976943  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.979923  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.980320  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.980623  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.983250  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.983587  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.983935  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.984291  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.984851  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.985281  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.985673  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.986584  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644915.987541  414005 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.486078  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.486533  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.487062  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.487541  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.487948  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.488370  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.488791  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.489234  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.489655  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.490633  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.491174  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.491866  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.491957  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.492581  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.492583  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.493111  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.493322  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.493643  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.493895  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.494187  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.494442  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.494827  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.495032  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.495336  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.495545  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.496112  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.496352  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.496717  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.496927  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.497325  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.497528  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.498101  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.498229  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.498825  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.498928  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.499433  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.499593  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.499635  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.500482  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.500544  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.500647  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.501318  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.501402  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.501436  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.501758  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.502148  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.502306  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.502395  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.502658  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.502960  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.503367  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.503369  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.503652  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.503990  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.503992  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.504467  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.504705  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.504809  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.505256  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.505504  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.505511  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.506229  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.506607  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.506625  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.506839  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.507189  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.507272  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.507524  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.507875  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.507961  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.508705  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.508822  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.508901  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.509195  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.509742  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.510187  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.510280  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.510427  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.510810  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.511132  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.511137  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.511411  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.511793  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.512157  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.512292  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.512501  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.512801  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.513067  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.513522  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.513825  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.513964  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.514180  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.514802  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.515178  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.515936  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.516472  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.516493  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.516908  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.517253  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.517515  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.518517  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.518598  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.519080  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.519581  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.520112  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.520306  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.521132  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.522127  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.522986  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.523663  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.524564  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.525026  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.525120  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.525470  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.525842  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.526281  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.526371  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.526725  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.527092  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.527176  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.528280  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.528580  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.529727  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.529910  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.530741  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.531554  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.532762  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.534037  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.535286  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.535976  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.536498  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.536905  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.537325  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.537769  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.538168  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.538587  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.540145  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.541486  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.542306  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.543114  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.544277  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.545571  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.546827  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.547290  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.547736  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.548094  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.548472  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.548872  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.549224  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.549598  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.550991  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.552313  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.553134  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.553948  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.555109  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.555913  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.556288  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.556480  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.556673  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.557056  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.557438  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.557913  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.557930  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.558327  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.558740  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.559147  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.559568  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.560064  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.560490  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.560934  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.561371  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.561824  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.562309  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.563132  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.563828  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.564306  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.564977  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.565787  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.567711  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.568053  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.568421  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.568813  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.569196  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.569594  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.569995  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.570408  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.570822  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.571238  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.571738  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.572162  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.572590  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.572612  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.573198  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.573279  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.573715  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.573828  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.574203  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.574384  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.574595  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.575055  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.575242  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.575476  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.576066  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.576155  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.576525  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.576706  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.577067  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.577512  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.577616  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.578121  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.578355  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.578669  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.579059  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.579623  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.579630  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.580024  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.580411  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.580856  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.580972  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.581283  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.581695  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.582120  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.582538  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.583037  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.583522  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.583629  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.584080  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.584526  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.584957  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.585000  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.585548  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.585625  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.586011  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.586116  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.586506  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.586672  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.587094  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.587280  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.587593  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.587896  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.588095  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.588179  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.588750  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.588826  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.589176  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.589802  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.589816  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.589920  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.590413  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.590636  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.591069  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.591176  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.592403  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.593684  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.596096  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.597641  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.598099  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.598626  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.598705  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.599157  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.599544  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.599978  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.600314  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.600484  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.600913  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.601327  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.601905  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.602086  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.602414  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.602927  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.603332  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.604265  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.605546  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.607950  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.610317  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.611928  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.613562  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.614784  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.631791  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.632209  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.632636  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.633062  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.633508  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.633934  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.634371  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.634841  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.635318  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.635808  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.636315  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.636836  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.637384  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.637979  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.638624  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.639305  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.640550  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.641163  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.641852  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.642971  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.643980  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.644462  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.644880  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.645459  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.645559  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.645903  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.646350  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.646813  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.647266  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.647742  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.648225  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.648719  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.649231  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.649758  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.650310  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.650909  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.651551  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.652236  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.652667  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.653237  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.653500  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.653773  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.654130  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.654410  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.654962  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.655057  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.655616  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.655819  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.656418  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.656460  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.656559  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.657111  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.657218  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.657657  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.657821  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.657836  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.658298  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.658712  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.658833  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.659034  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.659416  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.659523  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.659910  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.660434  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.660614  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.661130  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.661640  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.662167  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.662930  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.662940  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.663543  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.664188  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.664875  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.665240  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.666125  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.666381  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.666790  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.666965  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.667184  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.667616  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.667630  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.668257  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.668790  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.668960  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.669507  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.669679  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.670195  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.670297  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.670841  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.670917  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.671488  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.672245  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.672356  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.673063  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.673835  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.674780  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.676225  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.677762  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.678559  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.679465  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.680045  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.680658  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.680741  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.681375  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.681977  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.682411  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.682594  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.683141  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.683625  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.683801  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.684371  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.685166  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.685873  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.686635  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.688155  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.689032  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.691125  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.691370  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.693283  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.695775  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.696226  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.700709  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.703679  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.708310  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.763330  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.763893  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.764432  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.765006  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.765568  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.766133  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.766716  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.767323  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.767975  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.768664  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.769320  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.770003  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.770732  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.771569  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.772433  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.774393  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.775301  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.776266  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.777341  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.777570  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.778139  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.778692  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.779481  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.779494  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.780062  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.780640  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.781219  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.782056  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.782074  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.782745  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.783436  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.784106  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.784810  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.785543  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.786399  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.787283  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.789249  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.789643  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.790240  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.790400  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.790429  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.791081  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.791096  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.791395  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.791799  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.791909  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.792506  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.792690  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.792790  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.793100  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.793509  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.793695  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.794421  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.794591  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.794692  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.795425  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.795438  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.796299  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.796312  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.797223  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.797251  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.797350  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.798059  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.798159  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.798926  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.799027  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.800021  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.800034  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.800916  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.802857  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.803568  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.803786  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.804757  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.805600  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.805810  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.806370  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.807036  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.807210  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.807922  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.808097  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.808845  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.809010  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.809617  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.810483  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.811266  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.811448  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.812239  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.812339  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.813073  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.813983  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.814796  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.815591  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.818362  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.819924  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.820274  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.820696  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.821509  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.822230  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.822718  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.822951  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.823716  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.824569  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.825038  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.825320  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.826200  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.827067  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.827092  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.827866  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.828671  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.830470  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.832234  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.833565  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.835202  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.836587  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.840019  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.840810  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.844121  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.848683  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.848858  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.853609  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.862163  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.995051  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.995822  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.996636  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.997399  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.998199  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.999030  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644916.999912  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.000756  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.001741  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.002867  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.003883  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.004919  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.005951  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.007274  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.008692  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.010197  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.011727  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.012505  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.013324  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.013585  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.014110  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.014925  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.015213  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.015782  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.016669  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.017013  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.017537  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.018537  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.019674  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.020251  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.020711  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.021761  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.022807  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.024137  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.024566  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.025246  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.025595  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.026046  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.026883  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.027126  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.027674  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.028482  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.029371  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.030267  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.030533  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.031130  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.032260  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.032338  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.033416  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.034155  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.034448  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.034612  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.035494  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.035785  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.036549  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.036962  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.037417  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.037898  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.038304  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.039409  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.039518  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.041105  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.041111  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.041785  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.042219  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.043393  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.044468  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.044826  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.046011  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.046203  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.047295  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.048191  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.048617  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.050000  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.051763  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.052958  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.053260  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.054140  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.055397  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.055566  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.056710  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.057597  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.058195  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.059292  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.060475  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.061284  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.061917  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.063094  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.064369  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.065684  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.067715  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.068918  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.069599  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.070111  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.071457  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.072519  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.072702  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.074171  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.075285  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.076469  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.077666  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.077913  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.078477  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.079093  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.080381  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.081710  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.086716  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.086893  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.088512  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.094422  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.095049  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.095943  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.102921  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.104114  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.111154  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.113558  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.113659  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.120245  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.129538  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.131107  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.147064  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.437635  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.438856  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.440081  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.441273  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.442567  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.443913  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.445354  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.446663  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.448243  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.449606  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.451250  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.452919  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.454677  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.456991  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.457918  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.459138  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.459430  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.460383  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.461583  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.461854  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.462890  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.464238  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.465672  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.466998  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.467834  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.468598  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.469984  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.470762  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.471758  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.471905  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.473149  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.473434  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.474408  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.475221  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.475636  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.476932  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.477552  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.478320  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.479234  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.479757  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.479979  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.481297  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.481317  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.482386  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.482911  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.483287  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.484316  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.485209  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.485978  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.487811  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.487827  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.488396  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.489721  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.489833  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.491342  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.491640  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.492071  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.493859  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.494625  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.496301  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.497049  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.498202  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.499986  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.500357  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.501902  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.502613  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.502985  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.503866  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.505804  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.505982  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.508287  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.509394  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.510191  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.511990  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.513845  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.514206  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.516641  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.518091  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.518520  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.520002  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.520676  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.521954  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.522918  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.523929  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.526396  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.526952  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.528320  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.530132  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.532354  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.534102  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.534828  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.536723  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.538881  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.541119  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.543711  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.547500  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.552294  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.559811  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.564424  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.565821  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.575894  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.580662  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.582874  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.593022  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.596937  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.599194  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.613811  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.615522  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.629516  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.632415  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.651305  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644917.669546  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.277405  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.279424  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.281448  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.283480  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.285668  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.287939  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.290397  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.292653  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.295396  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.297778  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.300665  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.303598  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.306646  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.306849  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.308684  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.310720  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.311394  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.312781  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.314976  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.315862  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.316900  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.317266  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.318963  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.319751  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.320501  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.321038  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.322025  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.323111  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.324811  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.325324  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.327228  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.327639  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.330427  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.330608  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.331968  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.332944  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.333377  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.335712  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.336541  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.337600  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.338148  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.340887  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.341130  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.344133  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.345402  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.347354  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.349214  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.350097  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.350397  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.351493  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.351777  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.352750  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.353850  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.354997  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.356182  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.356443  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.357931  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.359486  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.360782  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.361021  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.361743  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.362123  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.363441  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.367425  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.370868  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.372577  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.378246  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.379107  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.379529  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.380305  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.381414  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.382653  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.383751  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.384877  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.385044  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.386469  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.388072  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.388151  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.389709  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.391000  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.392323  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.393641  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.396235  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.396889  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.398086  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.399193  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.400446  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.401125  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.401563  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.402713  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.404142  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.404531  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.405644  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.407203  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.408427  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.409782  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.409959  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.411128  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.418522  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.418691  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.421155  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.426806  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.427524  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.435179  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.436113  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.437480  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.444448  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.451764  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.452912  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.468406  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.469772  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.486848  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.733983  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.735149  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.736296  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.737419  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.738635  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.739913  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.741167  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.742343  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.743640  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.744912  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.746420  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.747910  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.749662  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.751740  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.754294  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.756433  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.766562  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.767729  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.768879  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.770011  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.771209  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.772497  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.773762  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.774947  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.776253  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.776546  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.777550  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.779070  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.780575  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.782503  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.782591  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.784789  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.784900  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.785349  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.786107  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.787360  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.787463  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.788529  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.789651  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.789823  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.791198  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.792469  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.793656  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.794962  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.796255  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.796705  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.797138  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.797523  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.797900  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.798010  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.798426  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.798902  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.799510  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.799618  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.800812  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.801392  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.802285  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.803503  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.803905  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.805590  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.806097  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.807648  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.808258  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.810063  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.810152  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.812054  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.816022  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.818785  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.828519  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.830061  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.830313  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.830544  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.830731  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.831068  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.831176  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.831661  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.831743  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.832248  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.832330  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.832901  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.832916  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.833464  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.833560  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.833902  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.834382  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.834595  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.834853  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.834951  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.835350  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.835733  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.836220  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.836570  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.836679  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.837230  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.837406  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.837652  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.838363  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.838378  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.839019  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.839587  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.840108  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.840595  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.841426  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.842214  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.842872  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.844805  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.845966  414004 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.846770  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.852110  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.852561  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.852959  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.853392  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.853820  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.854306  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.854793  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.856121  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.857635  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.859281  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.860997  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.863105  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.865320  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.865761  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.865870  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.866259  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.866658  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.867059  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.867477  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.867766  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.867949  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.868374  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.868827  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.869195  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.869678  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.870067  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.870571  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.870954  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.871468  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.871871  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.872352  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.872990  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.873560  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.875421  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.876871  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.880027  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.886320  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.886722  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.887121  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.887526  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.887937  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.888354  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.888778  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.889209  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.889657  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.890030  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.890564  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.890967  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.891457  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.891849  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.892369  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.892774  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.893254  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.893889  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.894469  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.896334  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.897797  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644918.900961  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "2024-10-23 00:55:19.144745: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "W0000 00:00:1729644919.150032  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.150446  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.150737  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.150825  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.151305  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.151318  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.151779  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.151886  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.152213  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.152317  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.152710  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.152817  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.153078  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.153246  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.153498  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.153775  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.153888  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.154232  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.154342  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.154731  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.154840  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.155230  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.155244  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.155686  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.155787  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.156206  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.156310  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.156725  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.156829  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.157264  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.157376  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.157825  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.157929  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.158385  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.158489  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.158979  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.159090  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.159568  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.159672  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.160054  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.160232  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.160850  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.160869  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.161179  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.161467  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.161585  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.162090  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.162107  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.162683  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.162708  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.162864  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.163324  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.163488  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.163493  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.163796  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.164016  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.164271  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.164420  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.164564  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.164848  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.164956  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.165341  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.165478  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.165924  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.166070  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.166193  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.166511  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.166694  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.166857  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.167063  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.167379  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.167497  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.168136  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.168176  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.168308  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.168725  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.169088  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.169185  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.169361  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.169659  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.169915  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.170113  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.170263  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.170510  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.170741  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.171001  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.171149  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.171459  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.171836  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.172107  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.172110  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.172873  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.172874  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.173383  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.173647  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.173882  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.174401  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.174594  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.174923  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.175448  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.176204  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.176536  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.176922  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.177406  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.178043  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.178063  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.178446  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.178781  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.178869  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.179389  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.179402  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.179743  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.180081  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.180168  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.180653  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.180802  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.180888  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.181083  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.181399  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.181682  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.181944  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.182122  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.182280  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.182705  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.182724  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.182833  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.183088  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.183508  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.183625  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.183646  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.183959  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.184551  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.184818  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.184825  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.184995  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.185467  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.185810  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.185948  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.186038  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.186433  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.186758  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.186860  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.187522  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.187536  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.187794  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.188445  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.188709  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.188871  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.189665  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.189774  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.190403  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.191292  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.192188  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.202140  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.202441  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.202757  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.203071  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.203405  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.203742  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.204076  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.204424  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.204788  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.204935  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.205103  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.205582  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.205593  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.205686  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.206211  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.206223  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.206311  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.206862  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.206893  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.207040  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.207419  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.207575  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.207751  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.207962  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.208239  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.208553  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.208571  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.208905  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.209118  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.209161  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.209487  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.209698  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.209734  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.210050  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.210269  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.210310  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.210851  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.211013  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.211109  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.211653  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.211700  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.211842  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.212060  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.212672  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.212716  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.213201  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.213793  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.213925  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.214230  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.214778  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.214980  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.215384  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.215668  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.216352  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.217270  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.218166  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.218225  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.218544  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.218872  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.219189  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.219536  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.219876  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.220205  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.220560  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.220894  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.221296  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.221678  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.221736  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.222253  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.222363  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.222697  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.223139  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.223256  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.223518  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.223872  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.224283  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.224392  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.224752  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.225085  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.225493  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.225966  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.226069  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.226480  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.227545  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.227564  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.228562  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.228679  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.229716  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.230124  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.230632  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.230854  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.231159  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.231519  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.231735  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.231903  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.232238  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.232595  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.232834  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.233008  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.233359  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.233761  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.233930  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.234178  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.234523  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.234981  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.235062  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.235423  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.235807  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.236319  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.236719  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.237134  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.237623  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.238212  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.244490  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.244862  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.245195  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.245512  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.245860  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.246203  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.246545  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.246900  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.247239  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.247641  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.248024  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.248427  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.249338  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.250220  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.251762  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.253257  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.254291  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.255478  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.255569  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.255847  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.256204  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.256629  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.256727  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.257081  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.257434  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.257792  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.258165  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.258550  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.258958  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.259357  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.259932  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.260046  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.260503  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.260608  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.261077  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.261092  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.261575  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.261685  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.261958  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.262238  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.262414  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.262779  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.263293  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.263394  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.263906  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.264004  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.264567  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.264585  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.264984  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.265496  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.265601  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.266187  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.266192  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.266662  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.266892  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.267162  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.267787  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.267897  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.268828  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.269315  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.269830  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.270608  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.271178  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.271867  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.272768  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.274536  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.275014  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.275418  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.275860  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.276295  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.276689  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.277109  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.277506  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.277926  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.278481  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.278982  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.279497  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.279541  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.279955  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.280375  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.280825  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.281140  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.281361  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.281586  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.281823  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.281986  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.282404  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.282499  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.282821  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.283010  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.283034  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.283529  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.283608  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.283896  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.284476  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.284553  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.284567  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.285071  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.285154  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.285469  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.285762  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.285934  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.286340  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.286752  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.287308  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.287527  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.287631  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.287806  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.288286  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.288795  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.289177  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.289396  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.289717  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.290186  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.290597  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.290773  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.291546  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.292271  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.292354  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.292976  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.293417  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.293892  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.294246  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.295290  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.298012  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.299903  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.300437  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.300889  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.301292  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.301746  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.302191  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.302593  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.303020  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.303420  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.303844  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.304402  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.304908  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.305473  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.307039  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.308566  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.309928  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.312733  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.314607  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.317335  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.319239  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.343372  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.343812  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.344238  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.344668  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.345109  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.345545  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.345986  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.346446  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.346935  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.347436  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.347936  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.348451  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.348990  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.349299  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.349730  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.349838  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.350346  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.350446  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.350803  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.351243  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.351814  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.351923  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.352276  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.352620  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.352797  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.353464  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.353478  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.353979  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.354213  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.354499  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.355162  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.355279  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.355825  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.356493  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.356597  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.357229  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.358003  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.358620  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.359277  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.359976  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.360705  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.361501  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.362695  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.364207  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.365519  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.366106  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.366673  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.367210  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.367725  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.368280  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.368585  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.369034  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.369153  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.369816  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.369832  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.370382  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.370478  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.370952  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.371057  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.371404  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.371641  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.371822  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.371871  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.372389  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.372596  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.372670  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.373148  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.373324  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.373669  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.373883  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.374198  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.374431  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.374927  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.374966  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.375068  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.375574  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.375741  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.376324  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.376406  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.377106  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.377182  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.377774  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.377875  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.378588  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.378671  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.379228  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.379401  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.380088  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.380398  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.380822  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.381658  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.381736  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.382720  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.382942  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.384529  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.384607  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.385654  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.387183  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.388629  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.389508  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.392024  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.392496  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.392677  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.393252  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.393917  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.394016  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.394464  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.395018  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.395580  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.395760  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.396284  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.396894  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.397412  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.397989  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.398574  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.400983  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.400999  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.403713  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.406352  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.408667  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.411613  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.414600  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.419873  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.491187  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.491752  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.492345  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.492908  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.493497  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.494106  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.494741  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.495347  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.496045  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.496822  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.497524  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.498253  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.499077  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.499215  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.499818  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.500012  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.500439  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.501110  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.501213  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.501805  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.502136  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.502433  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.503077  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.503696  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.504616  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.504631  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.505420  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.505713  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.506150  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.507007  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.507117  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.507751  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.508307  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.508673  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.509642  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.510396  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.510679  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.513215  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.513231  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.514319  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.515621  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.516811  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.517802  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.518368  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.519053  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.519139  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.519706  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.520303  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.520925  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.521563  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.521643  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.521793  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.522204  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.522475  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.522922  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.523289  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.523720  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.524162  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.524451  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.524964  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.525207  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.526169  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.526185  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.526980  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.527158  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.527770  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.528160  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.528750  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.529205  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.529532  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.530396  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.530409  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.531449  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.531516  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.531624  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.532280  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.532718  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.533171  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.534120  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.534191  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.535082  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.535427  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.535597  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.535868  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.536653  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.537594  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.537704  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.538483  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.539372  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.539858  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.540422  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.540502  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.544474  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.544990  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.548779  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.548863  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.549715  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.549971  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.550540  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.551422  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.552223  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.553166  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.554069  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.554098  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.554865  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.555552  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.555858  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.556629  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.557513  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.558410  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.559140  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.561221  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.562450  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.564771  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.566751  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.570496  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.571387  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.571924  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.576963  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.580767  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.582598  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.588309  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.598580  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.765839  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.766687  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.767523  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.768334  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.769211  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.770126  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.771101  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.771995  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.773053  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.773970  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.775051  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.776261  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.776407  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.777375  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.777482  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.778245  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.779142  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.779245  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.780129  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.780708  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.781076  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.782058  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.782292  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.782975  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.784047  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.784980  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.786073  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.786362  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.787201  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.788265  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.788434  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.789949  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.790400  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.791536  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.793125  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.793707  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.794556  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.795406  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.796222  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.797154  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.797331  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.797915  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.798116  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.799307  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.799428  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.799502  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.800219  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.800722  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.801297  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.801663  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.801959  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.802236  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.803346  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.803458  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.804592  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.804918  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.805778  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.806101  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.807299  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.807542  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.808888  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.809100  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.809356  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.810354  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.810683  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.810768  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.811727  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.812073  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.813183  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.813360  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.814668  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.814846  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.816262  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.816731  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.817458  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.819012  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.819093  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.820655  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.820949  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.821911  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.823299  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.824729  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.826524  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.827791  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.828404  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.829084  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.830309  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.831568  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.832599  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.833161  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.834336  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.835772  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.837324  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.838317  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.838576  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.840000  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.840180  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.841432  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.847925  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.849249  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.850295  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.856802  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.857699  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.860119  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.866929  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.867558  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.870016  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.876769  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.880081  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.886647  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.888454  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.896952  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.901188  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644919.918039  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.277981  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.279319  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.280635  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.281946  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.283367  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.284823  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.286414  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.287871  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.289626  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.291314  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.291339  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.292706  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.293172  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.294057  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.295067  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.295407  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.296844  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.297056  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.298359  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.299838  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.300004  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.301486  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.302555  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.303278  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.304828  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.305380  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.306700  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.307998  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.308603  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.309349  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.310756  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.310837  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.312171  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.312950  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.313666  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.313742  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.315220  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.316353  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.316533  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.316845  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.318320  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.319389  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.320137  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.320306  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.321693  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.323551  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.325432  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.327067  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.327435  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.329712  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.330144  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.330698  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.330715  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.331492  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.332219  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.333039  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.333122  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.334114  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.334662  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.335117  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.335893  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.340508  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.343599  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.344338  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.345162  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.345955  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.346363  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.346716  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.347012  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.347481  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.348502  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.349526  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.350979  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.351783  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.355079  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.356082  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.360394  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.361085  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.361327  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.361414  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.362131  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.362882  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.363642  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.364663  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.365684  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.366748  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.366859  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.371287  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.371363  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.376749  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.376851  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.377352  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.382252  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.382885  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.387269  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.392111  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.392650  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.398087  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.407930  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 689ms/step - loss: 0.0961 - val_loss: 0.0875 - learning_rate: 1.0000e-04\n",
      "Epoch 2/3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1729644920.555653  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.556421  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.557187  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.557953  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.558738  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.559573  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.560413  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.561274  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.562097  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.562936  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.563828  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.564692  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.565694  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.566697  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.567826  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.569197  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.570770  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.572174  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.572709  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.573492  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.574290  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.575070  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.575875  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.576711  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.577562  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.578437  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.579264  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.580117  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.581021  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.581895  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.582910  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.583923  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.585065  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.585913  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.586465  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.588039  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.588604  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.589531  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.589610  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.590064  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.590335  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.591122  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.591994  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.592078  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.592916  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.593765  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.593995  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.594657  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.595477  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.596326  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.597220  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.598110  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.599123  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.600133  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.601273  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.602658  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.603278  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.603611  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.603714  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.604102  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.604282  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.604474  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.604845  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.605311  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.605856  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.605939  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.607180  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.607797  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.608230  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.609296  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.609580  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.610929  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.611584  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.612283  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.613601  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.614711  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.619723  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.621065  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.621447  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.621805  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.622156  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.622531  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.623007  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.623490  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.623908  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.624765  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.625742  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.625949  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.626121  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.626443  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.626762  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.627215  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.627234  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.627597  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.627901  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.627999  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.628330  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.628664  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.628984  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.629096  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.629459  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.629837  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.630240  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.630420  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.630639  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.631016  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.631565  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.631983  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.632098  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.632520  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.632991  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.633157  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.633483  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.635130  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.635976  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.637349  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.637738  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.638254  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.638332  414028 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.638639  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.639013  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.639482  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.639962  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.641209  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.642275  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.643350  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.644699  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.645200  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.645219  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.645681  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.646016  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.646351  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.646650  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.646780  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.647116  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.647471  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.647872  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.648035  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.648253  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.648638  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.649060  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.649229  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.649470  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.649854  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.650273  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.650679  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.651114  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.651569  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.652054  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.653733  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.654596  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.656881  414016 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.660631  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.660957  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.661285  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.661610  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.661944  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.662280  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.662620  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.662963  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.663307  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.663670  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.664182  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.664570  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.664958  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.665349  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.665776  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.666178  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.666599  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.667050  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.667530  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.669189  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.670038  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729644920.672306  414031 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0795"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 00:55:21.268562: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0792 - val_loss: 0.0724 - learning_rate: 1.0000e-04\n",
      "Epoch 3/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0729 - val_loss: 0.0701 - learning_rate: 1.0000e-04\n",
      "Epoch 4/3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 00:55:22.758986: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0691 - val_loss: 0.0670 - learning_rate: 1.0000e-04\n",
      "Epoch 5/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0625 - val_loss: 0.0522 - learning_rate: 1.0000e-04\n",
      "Epoch 6/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0550"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 00:55:24.851901: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0550 - val_loss: 0.0472 - learning_rate: 1.0000e-04\n",
      "Epoch 7/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.0476 - val_loss: 0.0419 - learning_rate: 1.0000e-04\n",
      "Epoch 8/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0409 - val_loss: 0.0370 - learning_rate: 1.0000e-04\n",
      "Epoch 9/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0330 - val_loss: 0.0273 - learning_rate: 1.0000e-04\n",
      "Epoch 10/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0294 - val_loss: 0.0277 - learning_rate: 1.0000e-04\n",
      "Epoch 11/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0270 - val_loss: 0.0268 - learning_rate: 1.0000e-04\n",
      "Epoch 12/3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 00:55:30.678217: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.0242 - val_loss: 0.0247 - learning_rate: 1.0000e-04\n",
      "Epoch 13/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0228 - val_loss: 0.0232 - learning_rate: 1.0000e-04\n",
      "Epoch 14/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0214 - val_loss: 0.0226 - learning_rate: 1.0000e-04\n",
      "Epoch 15/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0203 - val_loss: 0.0209 - learning_rate: 1.0000e-04\n",
      "Epoch 16/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0196 - val_loss: 0.0196 - learning_rate: 1.0000e-04\n",
      "Epoch 17/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.0188 - val_loss: 0.0188 - learning_rate: 1.0000e-04\n",
      "Epoch 18/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0183 - val_loss: 0.0187 - learning_rate: 1.0000e-04\n",
      "Epoch 19/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0179 - val_loss: 0.0182 - learning_rate: 1.0000e-04\n",
      "Epoch 20/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0171 - val_loss: 0.0181 - learning_rate: 1.0000e-04\n",
      "Epoch 21/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0169 - val_loss: 0.0175 - learning_rate: 1.0000e-04\n",
      "Epoch 22/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0163"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 00:55:41.298140: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.0163 - val_loss: 0.0172 - learning_rate: 1.0000e-04\n",
      "Epoch 23/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0159 - val_loss: 0.0174 - learning_rate: 1.0000e-04\n",
      "Epoch 24/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0154 - val_loss: 0.0166 - learning_rate: 1.0000e-04\n",
      "Epoch 25/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0153 - val_loss: 0.0167 - learning_rate: 1.0000e-04\n",
      "Epoch 26/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0148 - val_loss: 0.0160 - learning_rate: 1.0000e-04\n",
      "Epoch 27/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0148 - val_loss: 0.0161 - learning_rate: 1.0000e-04\n",
      "Epoch 28/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0143 - val_loss: 0.0173 - learning_rate: 1.0000e-04\n",
      "Epoch 29/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0143 - val_loss: 0.0147 - learning_rate: 1.0000e-04\n",
      "Epoch 30/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0140 - val_loss: 0.0141 - learning_rate: 1.0000e-04\n",
      "Epoch 31/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0136 - val_loss: 0.0151 - learning_rate: 1.0000e-04\n",
      "Epoch 32/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0133 - val_loss: 0.0149 - learning_rate: 1.0000e-04\n",
      "Epoch 33/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0129 - val_loss: 0.0158 - learning_rate: 1.0000e-04\n",
      "Epoch 34/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0129 - val_loss: 0.0136 - learning_rate: 1.0000e-04\n",
      "Epoch 35/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0125 - val_loss: 0.0142 - learning_rate: 1.0000e-04\n",
      "Epoch 36/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0122 - val_loss: 0.0145 - learning_rate: 1.0000e-04\n",
      "Epoch 37/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - loss: 0.0120 - val_loss: 0.0144 - learning_rate: 1.0000e-04\n",
      "Epoch 38/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0118 - val_loss: 0.0132 - learning_rate: 1.0000e-04\n",
      "Epoch 39/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0119 - val_loss: 0.0130 - learning_rate: 1.0000e-04\n",
      "Epoch 40/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0116 - val_loss: 0.0125 - learning_rate: 1.0000e-04\n",
      "Epoch 41/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 143ms/step - loss: 0.0115 - val_loss: 0.0134 - learning_rate: 1.0000e-04\n",
      "Epoch 42/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0115 - val_loss: 0.0124 - learning_rate: 1.0000e-04\n",
      "Epoch 43/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0112 - val_loss: 0.0126 - learning_rate: 1.0000e-04\n",
      "Epoch 44/3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 00:56:04.501451: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0109 - val_loss: 0.0134 - learning_rate: 1.0000e-04\n",
      "Epoch 45/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0106 - val_loss: 0.0129 - learning_rate: 1.0000e-04\n",
      "Epoch 46/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0108 - val_loss: 0.0120 - learning_rate: 1.0000e-04\n",
      "Epoch 47/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0104 - val_loss: 0.0125 - learning_rate: 1.0000e-04\n",
      "Epoch 48/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0102 - val_loss: 0.0120 - learning_rate: 1.0000e-04\n",
      "Epoch 49/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0100 - val_loss: 0.0119 - learning_rate: 1.0000e-04\n",
      "Epoch 50/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0100 - val_loss: 0.0117 - learning_rate: 1.0000e-04\n",
      "Epoch 51/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0096 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 52/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0096 - val_loss: 0.0115 - learning_rate: 1.0000e-04\n",
      "Epoch 53/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0092 - val_loss: 0.0110 - learning_rate: 1.0000e-04\n",
      "Epoch 54/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0091 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 55/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0091 - val_loss: 0.0117 - learning_rate: 1.0000e-04\n",
      "Epoch 56/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0088 - val_loss: 0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 57/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0089 - val_loss: 0.0104 - learning_rate: 1.0000e-04\n",
      "Epoch 58/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0087 - val_loss: 0.0113 - learning_rate: 1.0000e-04\n",
      "Epoch 59/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0086 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 60/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0085 - val_loss: 0.0097 - learning_rate: 1.0000e-04\n",
      "Epoch 61/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0083 - val_loss: 0.0106 - learning_rate: 1.0000e-04\n",
      "Epoch 62/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0083 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
      "Epoch 63/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0080 - val_loss: 0.0109 - learning_rate: 1.0000e-04\n",
      "Epoch 64/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0080 - val_loss: 0.0102 - learning_rate: 1.0000e-04\n",
      "Epoch 65/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0077 - val_loss: 0.0099 - learning_rate: 1.0000e-04\n",
      "Epoch 66/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0075 - val_loss: 0.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 67/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0077 - val_loss: 0.0100 - learning_rate: 1.0000e-04\n",
      "Epoch 68/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0076 - val_loss: 0.0098 - learning_rate: 1.0000e-04\n",
      "Epoch 69/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0073 - val_loss: 0.0105 - learning_rate: 1.0000e-04\n",
      "Epoch 70/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0073 - val_loss: 0.0095 - learning_rate: 1.0000e-04\n",
      "Epoch 71/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0072 - val_loss: 0.0094 - learning_rate: 1.0000e-04\n",
      "Epoch 72/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0070 - val_loss: 0.0096 - learning_rate: 1.0000e-04\n",
      "Epoch 73/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0070 - val_loss: 0.0088 - learning_rate: 1.0000e-04\n",
      "Epoch 74/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0069 - val_loss: 0.0090 - learning_rate: 1.0000e-04\n",
      "Epoch 75/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0067 - val_loss: 0.0090 - learning_rate: 1.0000e-04\n",
      "Epoch 76/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0067 - val_loss: 0.0092 - learning_rate: 1.0000e-04\n",
      "Epoch 77/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0065 - val_loss: 0.0086 - learning_rate: 1.0000e-04\n",
      "Epoch 78/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0064 - val_loss: 0.0088 - learning_rate: 1.0000e-04\n",
      "Epoch 79/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0062 - val_loss: 0.0090 - learning_rate: 1.0000e-04\n",
      "Epoch 80/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0062 - val_loss: 0.0086 - learning_rate: 1.0000e-04\n",
      "Epoch 81/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0064 - val_loss: 0.0091 - learning_rate: 1.0000e-04\n",
      "Epoch 82/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0062 - val_loss: 0.0084 - learning_rate: 1.0000e-04\n",
      "Epoch 83/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0063 - val_loss: 0.0084 - learning_rate: 1.0000e-04\n",
      "Epoch 84/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0061 - val_loss: 0.0084 - learning_rate: 1.0000e-04\n",
      "Epoch 85/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0060 - val_loss: 0.0088 - learning_rate: 1.0000e-04\n",
      "Epoch 86/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0057"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 00:56:48.810673: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0057 - val_loss: 0.0083 - learning_rate: 1.0000e-04\n",
      "Epoch 87/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0056 - val_loss: 0.0084 - learning_rate: 1.0000e-04\n",
      "Epoch 88/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0057 - val_loss: 0.0085 - learning_rate: 1.0000e-04\n",
      "Epoch 89/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0056 - val_loss: 0.0081 - learning_rate: 1.0000e-04\n",
      "Epoch 90/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0054 - val_loss: 0.0081 - learning_rate: 1.0000e-04\n",
      "Epoch 91/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0054 - val_loss: 0.0083 - learning_rate: 1.0000e-04\n",
      "Epoch 92/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0053 - val_loss: 0.0081 - learning_rate: 1.0000e-04\n",
      "Epoch 93/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0052 - val_loss: 0.0081 - learning_rate: 1.0000e-04\n",
      "Epoch 94/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0052 - val_loss: 0.0078 - learning_rate: 1.0000e-04\n",
      "Epoch 95/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0050 - val_loss: 0.0076 - learning_rate: 1.0000e-04\n",
      "Epoch 96/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0048 - val_loss: 0.0078 - learning_rate: 1.0000e-04\n",
      "Epoch 97/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0049 - val_loss: 0.0083 - learning_rate: 1.0000e-04\n",
      "Epoch 98/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0048 - val_loss: 0.0080 - learning_rate: 1.0000e-04\n",
      "Epoch 99/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0049 - val_loss: 0.0073 - learning_rate: 1.0000e-04\n",
      "Epoch 100/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.0047 - val_loss: 0.0077 - learning_rate: 1.0000e-04\n",
      "Epoch 101/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0046 - val_loss: 0.0080 - learning_rate: 1.0000e-04\n",
      "Epoch 102/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0046 - val_loss: 0.0081 - learning_rate: 1.0000e-04\n",
      "Epoch 103/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0048 - val_loss: 0.0082 - learning_rate: 1.0000e-04\n",
      "Epoch 104/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0045 - val_loss: 0.0081 - learning_rate: 1.0000e-04\n",
      "Epoch 105/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.0045 - val_loss: 0.0072 - learning_rate: 1.0000e-04\n",
      "Epoch 106/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 143ms/step - loss: 0.0044 - val_loss: 0.0077 - learning_rate: 1.0000e-04\n",
      "Epoch 107/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0043 - val_loss: 0.0077 - learning_rate: 1.0000e-04\n",
      "Epoch 108/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0044 - val_loss: 0.0075 - learning_rate: 1.0000e-04\n",
      "Epoch 109/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0040 - val_loss: 0.0071 - learning_rate: 1.0000e-04\n",
      "Epoch 110/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.0041 - val_loss: 0.0077 - learning_rate: 1.0000e-04\n",
      "Epoch 111/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0040 - val_loss: 0.0075 - learning_rate: 1.0000e-04\n",
      "Epoch 112/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0039 - val_loss: 0.0076 - learning_rate: 1.0000e-04\n",
      "Epoch 113/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0040 - val_loss: 0.0074 - learning_rate: 1.0000e-04\n",
      "Epoch 114/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0040 - val_loss: 0.0077 - learning_rate: 1.0000e-04\n",
      "Epoch 115/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0039 - val_loss: 0.0073 - learning_rate: 1.0000e-04\n",
      "Epoch 116/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0037 - val_loss: 0.0071 - learning_rate: 1.0000e-04\n",
      "Epoch 117/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0039 - val_loss: 0.0078 - learning_rate: 1.0000e-04\n",
      "Epoch 118/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0037 - val_loss: 0.0072 - learning_rate: 1.0000e-04\n",
      "Epoch 119/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0036\n",
      "Epoch 119: ReduceLROnPlateau reducing learning rate to 8.999999772640876e-05.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0036 - val_loss: 0.0079 - learning_rate: 1.0000e-04\n",
      "Epoch 120/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0036 - val_loss: 0.0069 - learning_rate: 9.0000e-05\n",
      "Epoch 121/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0035 - val_loss: 0.0077 - learning_rate: 9.0000e-05\n",
      "Epoch 122/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0036 - val_loss: 0.0076 - learning_rate: 9.0000e-05\n",
      "Epoch 123/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0035 - val_loss: 0.0075 - learning_rate: 9.0000e-05\n",
      "Epoch 124/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0034 - val_loss: 0.0069 - learning_rate: 9.0000e-05\n",
      "Epoch 125/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0033 - val_loss: 0.0075 - learning_rate: 9.0000e-05\n",
      "Epoch 126/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0033 - val_loss: 0.0075 - learning_rate: 9.0000e-05\n",
      "Epoch 127/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0032 - val_loss: 0.0072 - learning_rate: 9.0000e-05\n",
      "Epoch 128/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0032 - val_loss: 0.0071 - learning_rate: 9.0000e-05\n",
      "Epoch 129/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0031 - val_loss: 0.0073 - learning_rate: 9.0000e-05\n",
      "Epoch 130/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0031 - val_loss: 0.0067 - learning_rate: 9.0000e-05\n",
      "Epoch 131/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0031 - val_loss: 0.0073 - learning_rate: 9.0000e-05\n",
      "Epoch 132/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0031 - val_loss: 0.0068 - learning_rate: 9.0000e-05\n",
      "Epoch 133/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0030 - val_loss: 0.0072 - learning_rate: 9.0000e-05\n",
      "Epoch 134/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0031 - val_loss: 0.0071 - learning_rate: 9.0000e-05\n",
      "Epoch 135/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0030 - val_loss: 0.0066 - learning_rate: 9.0000e-05\n",
      "Epoch 136/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0031 - val_loss: 0.0071 - learning_rate: 9.0000e-05\n",
      "Epoch 137/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0030 - val_loss: 0.0078 - learning_rate: 9.0000e-05\n",
      "Epoch 138/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0029 - val_loss: 0.0067 - learning_rate: 9.0000e-05\n",
      "Epoch 139/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.0028 - val_loss: 0.0072 - learning_rate: 9.0000e-05\n",
      "Epoch 140/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0027\n",
      "Epoch 140: ReduceLROnPlateau reducing learning rate to 8.100000122794882e-05.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 142ms/step - loss: 0.0027 - val_loss: 0.0071 - learning_rate: 9.0000e-05\n",
      "Epoch 141/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0026 - val_loss: 0.0069 - learning_rate: 8.1000e-05\n",
      "Epoch 142/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0026 - val_loss: 0.0065 - learning_rate: 8.1000e-05\n",
      "Epoch 143/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0026 - val_loss: 0.0062 - learning_rate: 8.1000e-05\n",
      "Epoch 144/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.0025 - val_loss: 0.0068 - learning_rate: 8.1000e-05\n",
      "Epoch 145/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0026 - val_loss: 0.0066 - learning_rate: 8.1000e-05\n",
      "Epoch 146/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0025 - val_loss: 0.0064 - learning_rate: 8.1000e-05\n",
      "Epoch 147/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0024 - val_loss: 0.0070 - learning_rate: 8.1000e-05\n",
      "Epoch 148/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0025 - val_loss: 0.0065 - learning_rate: 8.1000e-05\n",
      "Epoch 149/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.0024 - val_loss: 0.0061 - learning_rate: 8.1000e-05\n",
      "Epoch 150/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0024 - val_loss: 0.0072 - learning_rate: 8.1000e-05\n",
      "Epoch 151/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0025 - val_loss: 0.0064 - learning_rate: 8.1000e-05\n",
      "Epoch 152/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0024 - val_loss: 0.0068 - learning_rate: 8.1000e-05\n",
      "Epoch 153/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0024\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 7.289999848580919e-05.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0024 - val_loss: 0.0064 - learning_rate: 8.1000e-05\n",
      "Epoch 154/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.0024 - val_loss: 0.0066 - learning_rate: 7.2900e-05\n",
      "Epoch 155/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0023 - val_loss: 0.0066 - learning_rate: 7.2900e-05\n",
      "Epoch 156/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0022 - val_loss: 0.0062 - learning_rate: 7.2900e-05\n",
      "Epoch 157/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0022 - val_loss: 0.0064 - learning_rate: 7.2900e-05\n",
      "Epoch 158/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0022 - val_loss: 0.0065 - learning_rate: 7.2900e-05\n",
      "Epoch 159/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0021 - val_loss: 0.0068 - learning_rate: 7.2900e-05\n",
      "Epoch 160/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0021 - val_loss: 0.0064 - learning_rate: 7.2900e-05\n",
      "Epoch 161/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0021 - val_loss: 0.0065 - learning_rate: 7.2900e-05\n",
      "Epoch 162/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0020 - val_loss: 0.0065 - learning_rate: 7.2900e-05\n",
      "Epoch 163/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0020\n",
      "Epoch 163: ReduceLROnPlateau reducing learning rate to 6.56100019114092e-05.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0020 - val_loss: 0.0071 - learning_rate: 7.2900e-05\n",
      "Epoch 164/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0020 - val_loss: 0.0064 - learning_rate: 6.5610e-05\n",
      "Epoch 165/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0020 - val_loss: 0.0065 - learning_rate: 6.5610e-05\n",
      "Epoch 166/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0019 - val_loss: 0.0061 - learning_rate: 6.5610e-05\n",
      "Epoch 167/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0019 - val_loss: 0.0065 - learning_rate: 6.5610e-05\n",
      "Epoch 168/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0019 - val_loss: 0.0064 - learning_rate: 6.5610e-05\n",
      "Epoch 169/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.0019 - val_loss: 0.0067 - learning_rate: 6.5610e-05\n",
      "Epoch 170/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0019 - val_loss: 0.0064 - learning_rate: 6.5610e-05\n",
      "Epoch 171/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0018 - val_loss: 0.0062 - learning_rate: 6.5610e-05\n",
      "Epoch 172/3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 00:58:14.698906: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0018 - val_loss: 0.0059 - learning_rate: 6.5610e-05\n",
      "Epoch 173/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0018 - val_loss: 0.0062 - learning_rate: 6.5610e-05\n",
      "Epoch 174/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0018 - val_loss: 0.0063 - learning_rate: 6.5610e-05\n",
      "Epoch 175/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0018 - val_loss: 0.0070 - learning_rate: 6.5610e-05\n",
      "Epoch 176/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0018 - val_loss: 0.0065 - learning_rate: 6.5610e-05\n",
      "Epoch 177/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0018 - val_loss: 0.0066 - learning_rate: 6.5610e-05\n",
      "Epoch 178/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0018 - val_loss: 0.0068 - learning_rate: 6.5610e-05\n",
      "Epoch 179/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.0017 - val_loss: 0.0062 - learning_rate: 6.5610e-05\n",
      "Epoch 180/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0017 - val_loss: 0.0067 - learning_rate: 6.5610e-05\n",
      "Epoch 181/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0017 - val_loss: 0.0064 - learning_rate: 6.5610e-05\n",
      "Epoch 182/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0016\n",
      "Epoch 182: ReduceLROnPlateau reducing learning rate to 5.904900172026828e-05.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0017 - val_loss: 0.0066 - learning_rate: 6.5610e-05\n",
      "Epoch 183/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0016 - val_loss: 0.0066 - learning_rate: 5.9049e-05\n",
      "Epoch 184/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.0016 - val_loss: 0.0063 - learning_rate: 5.9049e-05\n",
      "Epoch 185/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0016 - val_loss: 0.0065 - learning_rate: 5.9049e-05\n",
      "Epoch 186/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0016 - val_loss: 0.0064 - learning_rate: 5.9049e-05\n",
      "Epoch 187/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0016 - val_loss: 0.0060 - learning_rate: 5.9049e-05\n",
      "Epoch 188/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0015 - val_loss: 0.0056 - learning_rate: 5.9049e-05\n",
      "Epoch 189/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0015 - val_loss: 0.0063 - learning_rate: 5.9049e-05\n",
      "Epoch 190/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0016 - val_loss: 0.0062 - learning_rate: 5.9049e-05\n",
      "Epoch 191/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0015 - val_loss: 0.0060 - learning_rate: 5.9049e-05\n",
      "Epoch 192/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0015 - val_loss: 0.0061 - learning_rate: 5.9049e-05\n",
      "Epoch 193/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0015 - val_loss: 0.0061 - learning_rate: 5.9049e-05\n",
      "Epoch 194/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0015 - val_loss: 0.0068 - learning_rate: 5.9049e-05\n",
      "Epoch 195/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0015 - val_loss: 0.0062 - learning_rate: 5.9049e-05\n",
      "Epoch 196/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0015 - val_loss: 0.0066 - learning_rate: 5.9049e-05\n",
      "Epoch 197/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0015 - val_loss: 0.0061 - learning_rate: 5.9049e-05\n",
      "Epoch 198/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0014\n",
      "Epoch 198: ReduceLROnPlateau reducing learning rate to 5.314410154824145e-05.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0014 - val_loss: 0.0066 - learning_rate: 5.9049e-05\n",
      "Epoch 199/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.0014 - val_loss: 0.0063 - learning_rate: 5.3144e-05\n",
      "Epoch 200/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0014 - val_loss: 0.0062 - learning_rate: 5.3144e-05\n",
      "Epoch 201/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0014 - val_loss: 0.0062 - learning_rate: 5.3144e-05\n",
      "Epoch 202/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0014 - val_loss: 0.0062 - learning_rate: 5.3144e-05\n",
      "Epoch 203/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0014 - val_loss: 0.0067 - learning_rate: 5.3144e-05\n",
      "Epoch 204/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0013 - val_loss: 0.0062 - learning_rate: 5.3144e-05\n",
      "Epoch 205/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0013 - val_loss: 0.0060 - learning_rate: 5.3144e-05\n",
      "Epoch 206/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0013 - val_loss: 0.0062 - learning_rate: 5.3144e-05\n",
      "Epoch 207/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0013 - val_loss: 0.0065 - learning_rate: 5.3144e-05\n",
      "Epoch 208/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0013\n",
      "Epoch 208: ReduceLROnPlateau reducing learning rate to 4.7829690083744934e-05.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0013 - val_loss: 0.0066 - learning_rate: 5.3144e-05\n",
      "Epoch 209/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.0012 - val_loss: 0.0069 - learning_rate: 4.7830e-05\n",
      "Epoch 210/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0012 - val_loss: 0.0061 - learning_rate: 4.7830e-05\n",
      "Epoch 211/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0013 - val_loss: 0.0068 - learning_rate: 4.7830e-05\n",
      "Epoch 212/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0012 - val_loss: 0.0065 - learning_rate: 4.7830e-05\n",
      "Epoch 213/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0012 - val_loss: 0.0063 - learning_rate: 4.7830e-05\n",
      "Epoch 214/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0012 - val_loss: 0.0062 - learning_rate: 4.7830e-05\n",
      "Epoch 215/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0012 - val_loss: 0.0061 - learning_rate: 4.7830e-05\n",
      "Epoch 216/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0012 - val_loss: 0.0064 - learning_rate: 4.7830e-05\n",
      "Epoch 217/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0012 - val_loss: 0.0069 - learning_rate: 4.7830e-05\n",
      "Epoch 218/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0012\n",
      "Epoch 218: ReduceLROnPlateau reducing learning rate to 4.304672074795235e-05.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0012 - val_loss: 0.0062 - learning_rate: 4.7830e-05\n",
      "Epoch 219/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0012 - val_loss: 0.0061 - learning_rate: 4.3047e-05\n",
      "Epoch 220/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0012 - val_loss: 0.0063 - learning_rate: 4.3047e-05\n",
      "Epoch 221/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0012 - val_loss: 0.0057 - learning_rate: 4.3047e-05\n",
      "Epoch 222/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0011 - val_loss: 0.0066 - learning_rate: 4.3047e-05\n",
      "Epoch 223/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0011 - val_loss: 0.0058 - learning_rate: 4.3047e-05\n",
      "Epoch 224/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0011 - val_loss: 0.0061 - learning_rate: 4.3047e-05\n",
      "Epoch 225/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0011 - val_loss: 0.0062 - learning_rate: 4.3047e-05\n",
      "Epoch 226/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0011 - val_loss: 0.0060 - learning_rate: 4.3047e-05\n",
      "Epoch 227/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0011 - val_loss: 0.0065 - learning_rate: 4.3047e-05\n",
      "Epoch 228/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0011\n",
      "Epoch 228: ReduceLROnPlateau reducing learning rate to 3.8742047036066654e-05.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0011 - val_loss: 0.0065 - learning_rate: 4.3047e-05\n",
      "Epoch 229/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0011 - val_loss: 0.0066 - learning_rate: 3.8742e-05\n",
      "Epoch 230/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0011 - val_loss: 0.0061 - learning_rate: 3.8742e-05\n",
      "Epoch 231/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0011 - val_loss: 0.0061 - learning_rate: 3.8742e-05\n",
      "Epoch 232/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0010 - val_loss: 0.0061 - learning_rate: 3.8742e-05\n",
      "Epoch 233/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0010 - val_loss: 0.0061 - learning_rate: 3.8742e-05\n",
      "Epoch 234/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0010 - val_loss: 0.0059 - learning_rate: 3.8742e-05\n",
      "Epoch 235/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0010 - val_loss: 0.0061 - learning_rate: 3.8742e-05\n",
      "Epoch 236/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0010 - val_loss: 0.0059 - learning_rate: 3.8742e-05\n",
      "Epoch 237/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0010 - val_loss: 0.0062 - learning_rate: 3.8742e-05\n",
      "Epoch 238/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0010\n",
      "Epoch 238: ReduceLROnPlateau reducing learning rate to 3.4867842987296176e-05.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0010 - val_loss: 0.0065 - learning_rate: 3.8742e-05\n",
      "Epoch 239/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 9.8941e-04 - val_loss: 0.0059 - learning_rate: 3.4868e-05\n",
      "Epoch 240/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 9.9441e-04 - val_loss: 0.0063 - learning_rate: 3.4868e-05\n",
      "Epoch 241/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 9.7374e-04 - val_loss: 0.0061 - learning_rate: 3.4868e-05\n",
      "Epoch 242/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 9.5679e-04 - val_loss: 0.0061 - learning_rate: 3.4868e-05\n",
      "Epoch 243/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 9.5448e-04 - val_loss: 0.0061 - learning_rate: 3.4868e-05\n",
      "Epoch 244/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 9.4495e-04 - val_loss: 0.0056 - learning_rate: 3.4868e-05\n",
      "Epoch 245/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 9.4904e-04 - val_loss: 0.0062 - learning_rate: 3.4868e-05\n",
      "Epoch 246/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 9.3466e-04 - val_loss: 0.0062 - learning_rate: 3.4868e-05\n",
      "Epoch 247/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 9.2404e-04 - val_loss: 0.0064 - learning_rate: 3.4868e-05\n",
      "Epoch 248/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 9.3012e-04\n",
      "Epoch 248: ReduceLROnPlateau reducing learning rate to 3.138105967082083e-05.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 9.4104e-04 - val_loss: 0.0061 - learning_rate: 3.4868e-05\n",
      "Epoch 249/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 9.2873e-04 - val_loss: 0.0063 - learning_rate: 3.1381e-05\n",
      "Epoch 250/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 9.1060e-04 - val_loss: 0.0060 - learning_rate: 3.1381e-05\n",
      "Epoch 251/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 9.2348e-04 - val_loss: 0.0061 - learning_rate: 3.1381e-05\n",
      "Epoch 252/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 9.0355e-04 - val_loss: 0.0065 - learning_rate: 3.1381e-05\n",
      "Epoch 253/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 9.1955e-04 - val_loss: 0.0059 - learning_rate: 3.1381e-05\n",
      "Epoch 254/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 8.9391e-04 - val_loss: 0.0062 - learning_rate: 3.1381e-05\n",
      "Epoch 255/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 9.0630e-04 - val_loss: 0.0059 - learning_rate: 3.1381e-05\n",
      "Epoch 256/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 8.8233e-04 - val_loss: 0.0056 - learning_rate: 3.1381e-05\n",
      "Epoch 257/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 8.6169e-04 - val_loss: 0.0067 - learning_rate: 3.1381e-05\n",
      "Epoch 258/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 8.5826e-04\n",
      "Epoch 258: ReduceLROnPlateau reducing learning rate to 2.824295370373875e-05.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 8.6854e-04 - val_loss: 0.0058 - learning_rate: 3.1381e-05\n",
      "Epoch 259/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 8.7619e-04 - val_loss: 0.0059 - learning_rate: 2.8243e-05\n",
      "Epoch 260/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 8.7873e-04 - val_loss: 0.0059 - learning_rate: 2.8243e-05\n",
      "Epoch 261/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.6474e-04 - val_loss: 0.0062 - learning_rate: 2.8243e-05\n",
      "Epoch 262/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 8.5358e-04 - val_loss: 0.0062 - learning_rate: 2.8243e-05\n",
      "Epoch 263/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 8.6704e-04 - val_loss: 0.0058 - learning_rate: 2.8243e-05\n",
      "Epoch 264/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 8.5661e-04 - val_loss: 0.0061 - learning_rate: 2.8243e-05\n",
      "Epoch 265/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 8.4988e-04 - val_loss: 0.0062 - learning_rate: 2.8243e-05\n",
      "Epoch 266/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 8.4803e-04 - val_loss: 0.0065 - learning_rate: 2.8243e-05\n",
      "Epoch 267/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 8.4175e-04 - val_loss: 0.0064 - learning_rate: 2.8243e-05\n",
      "Epoch 268/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 8.3687e-04\n",
      "Epoch 268: ReduceLROnPlateau reducing learning rate to 2.5418658333364876e-05.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 8.4532e-04 - val_loss: 0.0060 - learning_rate: 2.8243e-05\n",
      "Epoch 269/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 8.3752e-04 - val_loss: 0.0062 - learning_rate: 2.5419e-05\n",
      "Epoch 270/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 8.3213e-04 - val_loss: 0.0053 - learning_rate: 2.5419e-05\n",
      "Epoch 271/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 8.1248e-04 - val_loss: 0.0060 - learning_rate: 2.5419e-05\n",
      "Epoch 272/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 8.1044e-04 - val_loss: 0.0057 - learning_rate: 2.5419e-05\n",
      "Epoch 273/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 8.0309e-04 - val_loss: 0.0063 - learning_rate: 2.5419e-05\n",
      "Epoch 274/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 7.9476e-04 - val_loss: 0.0061 - learning_rate: 2.5419e-05\n",
      "Epoch 275/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 8.0070e-04 - val_loss: 0.0059 - learning_rate: 2.5419e-05\n",
      "Epoch 276/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.9847e-04 - val_loss: 0.0062 - learning_rate: 2.5419e-05\n",
      "Epoch 277/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.8898e-04 - val_loss: 0.0066 - learning_rate: 2.5419e-05\n",
      "Epoch 278/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 7.8201e-04 - val_loss: 0.0063 - learning_rate: 2.5419e-05\n",
      "Epoch 279/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 7.8909e-04 - val_loss: 0.0059 - learning_rate: 2.5419e-05\n",
      "Epoch 280/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 7.6018e-04\n",
      "Epoch 280: ReduceLROnPlateau reducing learning rate to 2.2876792172610294e-05.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 7.6856e-04 - val_loss: 0.0062 - learning_rate: 2.5419e-05\n",
      "Epoch 281/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 7.7515e-04 - val_loss: 0.0065 - learning_rate: 2.2877e-05\n",
      "Epoch 282/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.8244e-04 - val_loss: 0.0067 - learning_rate: 2.2877e-05\n",
      "Epoch 283/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 7.6964e-04 - val_loss: 0.0058 - learning_rate: 2.2877e-05\n",
      "Epoch 284/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 7.5836e-04 - val_loss: 0.0064 - learning_rate: 2.2877e-05\n",
      "Epoch 285/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 7.5539e-04 - val_loss: 0.0065 - learning_rate: 2.2877e-05\n",
      "Epoch 286/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.5174e-04 - val_loss: 0.0061 - learning_rate: 2.2877e-05\n",
      "Epoch 287/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 7.4656e-04 - val_loss: 0.0062 - learning_rate: 2.2877e-05\n",
      "Epoch 288/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 7.4242e-04 - val_loss: 0.0057 - learning_rate: 2.2877e-05\n",
      "Epoch 289/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 7.4917e-04 - val_loss: 0.0066 - learning_rate: 2.2877e-05\n",
      "Epoch 290/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 7.3922e-04\n",
      "Epoch 290: ReduceLROnPlateau reducing learning rate to 2.0589113773894496e-05.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 7.4803e-04 - val_loss: 0.0064 - learning_rate: 2.2877e-05\n",
      "Epoch 291/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.4077e-04 - val_loss: 0.0060 - learning_rate: 2.0589e-05\n",
      "Epoch 292/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.2961e-04 - val_loss: 0.0069 - learning_rate: 2.0589e-05\n",
      "Epoch 293/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 7.2544e-04 - val_loss: 0.0060 - learning_rate: 2.0589e-05\n",
      "Epoch 294/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 7.3170e-04 - val_loss: 0.0064 - learning_rate: 2.0589e-05\n",
      "Epoch 295/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 7.1485e-04 - val_loss: 0.0063 - learning_rate: 2.0589e-05\n",
      "Epoch 296/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.2353e-04 - val_loss: 0.0063 - learning_rate: 2.0589e-05\n",
      "Epoch 297/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.1548e-04 - val_loss: 0.0063 - learning_rate: 2.0589e-05\n",
      "Epoch 298/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 7.1860e-04 - val_loss: 0.0062 - learning_rate: 2.0589e-05\n",
      "Epoch 299/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 7.1628e-04 - val_loss: 0.0067 - learning_rate: 2.0589e-05\n",
      "Epoch 300/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 7.0505e-04\n",
      "Epoch 300: ReduceLROnPlateau reducing learning rate to 1.8530202396505047e-05.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 7.1312e-04 - val_loss: 0.0063 - learning_rate: 2.0589e-05\n",
      "Epoch 301/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.9627e-04 - val_loss: 0.0065 - learning_rate: 1.8530e-05\n",
      "Epoch 302/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.0482e-04 - val_loss: 0.0063 - learning_rate: 1.8530e-05\n",
      "Epoch 303/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 6.8185e-04 - val_loss: 0.0060 - learning_rate: 1.8530e-05\n",
      "Epoch 304/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 6.8841e-04 - val_loss: 0.0058 - learning_rate: 1.8530e-05\n",
      "Epoch 305/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 6.9074e-04 - val_loss: 0.0064 - learning_rate: 1.8530e-05\n",
      "Epoch 306/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.8911e-04 - val_loss: 0.0061 - learning_rate: 1.8530e-05\n",
      "Epoch 307/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.8536e-04 - val_loss: 0.0061 - learning_rate: 1.8530e-05\n",
      "Epoch 308/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 6.8310e-04 - val_loss: 0.0059 - learning_rate: 1.8530e-05\n",
      "Epoch 309/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 6.6889e-04 - val_loss: 0.0059 - learning_rate: 1.8530e-05\n",
      "Epoch 310/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 6.7782e-04\n",
      "Epoch 310: ReduceLROnPlateau reducing learning rate to 1.667718133830931e-05.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.8489e-04 - val_loss: 0.0068 - learning_rate: 1.8530e-05\n",
      "Epoch 311/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.7238e-04 - val_loss: 0.0064 - learning_rate: 1.6677e-05\n",
      "Epoch 312/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 6.7403e-04 - val_loss: 0.0060 - learning_rate: 1.6677e-05\n",
      "Epoch 313/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 6.7064e-04 - val_loss: 0.0056 - learning_rate: 1.6677e-05\n",
      "Epoch 314/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 6.7767e-04 - val_loss: 0.0068 - learning_rate: 1.6677e-05\n",
      "Epoch 315/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.6060e-04 - val_loss: 0.0060 - learning_rate: 1.6677e-05\n",
      "Epoch 316/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 6.7005e-04 - val_loss: 0.0064 - learning_rate: 1.6677e-05\n",
      "Epoch 317/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 6.6171e-04 - val_loss: 0.0062 - learning_rate: 1.6677e-05\n",
      "Epoch 318/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 6.5943e-04 - val_loss: 0.0064 - learning_rate: 1.6677e-05\n",
      "Epoch 319/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.5248e-04 - val_loss: 0.0061 - learning_rate: 1.6677e-05\n",
      "Epoch 320/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 6.4104e-04\n",
      "Epoch 320: ReduceLROnPlateau reducing learning rate to 1.5009462549642194e-05.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.4858e-04 - val_loss: 0.0061 - learning_rate: 1.6677e-05\n",
      "Epoch 321/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 6.4809e-04 - val_loss: 0.0061 - learning_rate: 1.5009e-05\n",
      "Epoch 322/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 6.3974e-04 - val_loss: 0.0062 - learning_rate: 1.5009e-05\n",
      "Epoch 323/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 6.5357e-04 - val_loss: 0.0062 - learning_rate: 1.5009e-05\n",
      "Epoch 324/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.5379e-04 - val_loss: 0.0056 - learning_rate: 1.5009e-05\n",
      "Epoch 325/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 6.3893e-04 - val_loss: 0.0062 - learning_rate: 1.5009e-05\n",
      "Epoch 326/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 6.3795e-04 - val_loss: 0.0063 - learning_rate: 1.5009e-05\n",
      "Epoch 327/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - loss: 6.3555e-04 - val_loss: 0.0062 - learning_rate: 1.5009e-05\n",
      "Epoch 328/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 6.3464e-04 - val_loss: 0.0066 - learning_rate: 1.5009e-05\n",
      "Epoch 329/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.3414e-04 - val_loss: 0.0061 - learning_rate: 1.5009e-05\n",
      "Epoch 330/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 6.2193e-04\n",
      "Epoch 330: ReduceLROnPlateau reducing learning rate to 1.3508516622096067e-05.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 6.2923e-04 - val_loss: 0.0062 - learning_rate: 1.5009e-05\n",
      "Epoch 331/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 6.2479e-04 - val_loss: 0.0061 - learning_rate: 1.3509e-05\n",
      "Epoch 332/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 6.2841e-04 - val_loss: 0.0064 - learning_rate: 1.3509e-05\n",
      "Epoch 333/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.2766e-04 - val_loss: 0.0062 - learning_rate: 1.3509e-05\n",
      "Epoch 334/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.2250e-04 - val_loss: 0.0061 - learning_rate: 1.3509e-05\n",
      "Epoch 335/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 6.2220e-04 - val_loss: 0.0066 - learning_rate: 1.3509e-05\n",
      "Epoch 336/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 6.1830e-04 - val_loss: 0.0064 - learning_rate: 1.3509e-05\n",
      "Epoch 337/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 6.2377e-04 - val_loss: 0.0058 - learning_rate: 1.3509e-05\n",
      "Epoch 338/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.1597e-04 - val_loss: 0.0064 - learning_rate: 1.3509e-05\n",
      "Epoch 339/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.1649e-04 - val_loss: 0.0056 - learning_rate: 1.3509e-05\n",
      "Epoch 340/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 6.0938e-04\n",
      "Epoch 340: ReduceLROnPlateau reducing learning rate to 1.2157664878031938e-05.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 6.1542e-04 - val_loss: 0.0062 - learning_rate: 1.3509e-05\n",
      "Epoch 341/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 6.1104e-04 - val_loss: 0.0060 - learning_rate: 1.2158e-05\n",
      "Epoch 342/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 6.0666e-04 - val_loss: 0.0064 - learning_rate: 1.2158e-05\n",
      "Epoch 343/3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 01:01:10.270997: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.0515e-04 - val_loss: 0.0064 - learning_rate: 1.2158e-05\n",
      "Epoch 344/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 6.0696e-04 - val_loss: 0.0063 - learning_rate: 1.2158e-05\n",
      "Epoch 345/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 6.0286e-04 - val_loss: 0.0058 - learning_rate: 1.2158e-05\n",
      "Epoch 346/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 5.9922e-04 - val_loss: 0.0064 - learning_rate: 1.2158e-05\n",
      "Epoch 347/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.9418e-04 - val_loss: 0.0057 - learning_rate: 1.2158e-05\n",
      "Epoch 348/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.9245e-04 - val_loss: 0.0061 - learning_rate: 1.2158e-05\n",
      "Epoch 349/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 5.9722e-04 - val_loss: 0.0061 - learning_rate: 1.2158e-05\n",
      "Epoch 350/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 6.0146e-04\n",
      "Epoch 350: ReduceLROnPlateau reducing learning rate to 1.0941898472083266e-05.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 6.0798e-04 - val_loss: 0.0065 - learning_rate: 1.2158e-05\n",
      "Epoch 351/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 5.9715e-04 - val_loss: 0.0062 - learning_rate: 1.0942e-05\n",
      "Epoch 352/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.8461e-04 - val_loss: 0.0059 - learning_rate: 1.0942e-05\n",
      "Epoch 353/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.8262e-04 - val_loss: 0.0059 - learning_rate: 1.0942e-05\n",
      "Epoch 354/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 5.8283e-04 - val_loss: 0.0061 - learning_rate: 1.0942e-05\n",
      "Epoch 355/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 5.8190e-04 - val_loss: 0.0066 - learning_rate: 1.0942e-05\n",
      "Epoch 356/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 5.7807e-04 - val_loss: 0.0067 - learning_rate: 1.0942e-05\n",
      "Epoch 357/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 5.7863e-04 - val_loss: 0.0065 - learning_rate: 1.0942e-05\n",
      "Epoch 358/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.8583e-04 - val_loss: 0.0060 - learning_rate: 1.0942e-05\n",
      "Epoch 359/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 5.7848e-04 - val_loss: 0.0054 - learning_rate: 1.0942e-05\n",
      "Epoch 360/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.6623e-04\n",
      "Epoch 360: ReduceLROnPlateau reducing learning rate to 9.847708952293033e-06.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 5.7350e-04 - val_loss: 0.0064 - learning_rate: 1.0942e-05\n",
      "Epoch 361/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 5.7668e-04 - val_loss: 0.0060 - learning_rate: 9.8477e-06\n",
      "Epoch 362/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.8374e-04 - val_loss: 0.0065 - learning_rate: 9.8477e-06\n",
      "Epoch 363/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 5.7196e-04 - val_loss: 0.0064 - learning_rate: 9.8477e-06\n",
      "Epoch 364/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 5.6901e-04 - val_loss: 0.0063 - learning_rate: 9.8477e-06\n",
      "Epoch 365/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 5.6925e-04 - val_loss: 0.0062 - learning_rate: 9.8477e-06\n",
      "Epoch 366/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 5.6431e-04 - val_loss: 0.0062 - learning_rate: 9.8477e-06\n",
      "Epoch 367/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.6005e-04 - val_loss: 0.0060 - learning_rate: 9.8477e-06\n",
      "Epoch 368/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.6714e-04 - val_loss: 0.0059 - learning_rate: 9.8477e-06\n",
      "Epoch 369/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 5.6814e-04 - val_loss: 0.0061 - learning_rate: 9.8477e-06\n",
      "Epoch 370/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 5.5987e-04\n",
      "Epoch 370: ReduceLROnPlateau reducing learning rate to 8.862937647791114e-06.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 5.6678e-04 - val_loss: 0.0066 - learning_rate: 9.8477e-06\n",
      "Epoch 371/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 5.6401e-04 - val_loss: 0.0061 - learning_rate: 8.8629e-06\n",
      "Epoch 372/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 5.5600e-04 - val_loss: 0.0064 - learning_rate: 8.8629e-06\n",
      "Epoch 373/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.5778e-04 - val_loss: 0.0061 - learning_rate: 8.8629e-06\n",
      "Epoch 374/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 5.5044e-04 - val_loss: 0.0063 - learning_rate: 8.8629e-06\n",
      "Epoch 375/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 5.6671e-04 - val_loss: 0.0060 - learning_rate: 8.8629e-06\n",
      "Epoch 376/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 5.5558e-04 - val_loss: 0.0063 - learning_rate: 8.8629e-06\n",
      "Epoch 377/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.5318e-04 - val_loss: 0.0064 - learning_rate: 8.8629e-06\n",
      "Epoch 378/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 147ms/step - loss: 5.4823e-04 - val_loss: 0.0060 - learning_rate: 8.8629e-06\n",
      "Epoch 379/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - loss: 5.4836e-04 - val_loss: 0.0067 - learning_rate: 8.8629e-06\n",
      "Epoch 380/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 5.4266e-04\n",
      "Epoch 380: ReduceLROnPlateau reducing learning rate to 7.976643883012003e-06.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 5.4948e-04 - val_loss: 0.0064 - learning_rate: 8.8629e-06\n",
      "Epoch 381/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.4853e-04 - val_loss: 0.0059 - learning_rate: 7.9766e-06\n",
      "Epoch 382/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 5.4830e-04 - val_loss: 0.0062 - learning_rate: 7.9766e-06\n",
      "Epoch 383/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 5.4449e-04 - val_loss: 0.0066 - learning_rate: 7.9766e-06\n",
      "Epoch 384/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 5.4854e-04 - val_loss: 0.0061 - learning_rate: 7.9766e-06\n",
      "Epoch 385/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.3801e-04 - val_loss: 0.0064 - learning_rate: 7.9766e-06\n",
      "Epoch 386/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.3927e-04 - val_loss: 0.0058 - learning_rate: 7.9766e-06\n",
      "Epoch 387/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 5.4315e-04 - val_loss: 0.0061 - learning_rate: 7.9766e-06\n",
      "Epoch 388/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 5.3435e-04 - val_loss: 0.0056 - learning_rate: 7.9766e-06\n",
      "Epoch 389/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 5.3805e-04 - val_loss: 0.0063 - learning_rate: 7.9766e-06\n",
      "Epoch 390/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 5.3449e-04\n",
      "Epoch 390: ReduceLROnPlateau reducing learning rate to 7.178979740274372e-06.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.4020e-04 - val_loss: 0.0060 - learning_rate: 7.9766e-06\n",
      "Epoch 391/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.4281e-04 - val_loss: 0.0067 - learning_rate: 7.1790e-06\n",
      "Epoch 392/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 5.2933e-04 - val_loss: 0.0067 - learning_rate: 7.1790e-06\n",
      "Epoch 393/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 5.3455e-04 - val_loss: 0.0061 - learning_rate: 7.1790e-06\n",
      "Epoch 394/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 5.3817e-04 - val_loss: 0.0064 - learning_rate: 7.1790e-06\n",
      "Epoch 395/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.3112e-04 - val_loss: 0.0060 - learning_rate: 7.1790e-06\n",
      "Epoch 396/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.1871e-04 - val_loss: 0.0068 - learning_rate: 7.1790e-06\n",
      "Epoch 397/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 5.3032e-04 - val_loss: 0.0063 - learning_rate: 7.1790e-06\n",
      "Epoch 398/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 5.2971e-04 - val_loss: 0.0063 - learning_rate: 7.1790e-06\n",
      "Epoch 399/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 5.3216e-04 - val_loss: 0.0060 - learning_rate: 7.1790e-06\n",
      "Epoch 400/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 5.2554e-04\n",
      "Epoch 400: ReduceLROnPlateau reducing learning rate to 7e-06.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.3071e-04 - val_loss: 0.0060 - learning_rate: 7.1790e-06\n",
      "Epoch 401/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.2734e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 402/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 5.3235e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 403/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 5.2676e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 404/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 5.2157e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 405/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 5.2631e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 406/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.2033e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 407/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 5.1864e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 408/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 5.1802e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 409/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 5.2159e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 410/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 5.2860e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 411/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.1906e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 412/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.1617e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 413/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.0452e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 414/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 5.1896e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 415/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.2320e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 416/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 5.1677e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 417/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.0912e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 418/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.0610e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 419/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 5.1179e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 420/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.1830e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 421/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.0884e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 422/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.0719e-04 - val_loss: 0.0057 - learning_rate: 7.0000e-06\n",
      "Epoch 423/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 5.0700e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 424/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.0741e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 425/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.1002e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 426/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.0222e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 427/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.0647e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 428/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.0378e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 429/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.0248e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 430/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.0425e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 431/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.0256e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 432/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.0691e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 433/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.0378e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 434/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.9875e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 435/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.0025e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 436/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 4.9468e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 437/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.9370e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 438/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.9118e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 439/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.8750e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 440/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.9038e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 441/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.8970e-04 - val_loss: 0.0058 - learning_rate: 7.0000e-06\n",
      "Epoch 442/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.8917e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 443/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.9238e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 444/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.9797e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 445/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.9289e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 446/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.9366e-04 - val_loss: 0.0058 - learning_rate: 7.0000e-06\n",
      "Epoch 447/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.9192e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 448/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.9065e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 449/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.8961e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 450/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.8618e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 451/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.9034e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 452/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.8418e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 453/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.8573e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 454/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.9098e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 455/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.8405e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 456/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 4.7684e-04 - val_loss: 0.0058 - learning_rate: 7.0000e-06\n",
      "Epoch 457/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.7687e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 458/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.7830e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 459/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.7296e-04 - val_loss: 0.0057 - learning_rate: 7.0000e-06\n",
      "Epoch 460/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.7534e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 461/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.7769e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 462/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.7738e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 463/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 4.6754e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 464/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.6975e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 465/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.7857e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 466/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.7400e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 467/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.7363e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 468/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.7137e-04 - val_loss: 0.0057 - learning_rate: 7.0000e-06\n",
      "Epoch 469/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.6589e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 470/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.7226e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 471/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.7582e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 472/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 4.6764e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 473/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.6620e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 474/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.6490e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 475/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.6216e-04 - val_loss: 0.0057 - learning_rate: 7.0000e-06\n",
      "Epoch 476/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.6233e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 477/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.6832e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 478/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.6190e-04 - val_loss: 0.0058 - learning_rate: 7.0000e-06\n",
      "Epoch 479/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.6196e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 480/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.6557e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 481/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 4.6620e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 482/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.6033e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 483/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 4.6235e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 484/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.6151e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 485/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.5533e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 486/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.5762e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 487/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.5804e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 488/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.5553e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 489/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.5157e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 490/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.5621e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 491/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.5409e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 492/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.5490e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 493/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.5695e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 494/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.5341e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 495/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.4933e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 496/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.5466e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 497/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.4512e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 498/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 4.4661e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 499/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 4.4702e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 500/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.4905e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 501/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.4520e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 502/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 4.4173e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 503/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.4397e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 504/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.4264e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 505/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.4217e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 506/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.4231e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 507/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.4140e-04 - val_loss: 0.0058 - learning_rate: 7.0000e-06\n",
      "Epoch 508/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.3888e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 509/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.4468e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 510/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.4409e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 511/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.3424e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 512/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.3836e-04 - val_loss: 0.0057 - learning_rate: 7.0000e-06\n",
      "Epoch 513/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.3740e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 514/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.3644e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 515/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.3713e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 516/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 4.3595e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 517/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.3370e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 518/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.3316e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 519/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.3435e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 520/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.3223e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 521/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.2847e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 522/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.3082e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 523/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.2995e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 524/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.2631e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 525/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.2814e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 526/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.2361e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 527/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.2635e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 528/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.2666e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 529/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.2078e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 530/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.2324e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 531/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.1884e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 532/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.2195e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 533/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.1646e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 534/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.1770e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 535/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.1879e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 536/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.1301e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 537/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.1340e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 538/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.1039e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 539/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.1410e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 540/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.0570e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 541/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.0904e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 542/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.1616e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 543/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.1027e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 544/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.1079e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 545/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.1163e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 546/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 4.1085e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 547/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.1577e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 548/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.1064e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 549/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.0842e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 550/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.1427e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 551/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.0901e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 552/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.1163e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 553/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.0352e-04 - val_loss: 0.0058 - learning_rate: 7.0000e-06\n",
      "Epoch 554/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.0252e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 555/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.0064e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 556/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.0557e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 557/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 3.9543e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 558/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.9739e-04 - val_loss: 0.0057 - learning_rate: 7.0000e-06\n",
      "Epoch 559/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.9857e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 560/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 4.0110e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 561/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.0025e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 562/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.9614e-04 - val_loss: 0.0058 - learning_rate: 7.0000e-06\n",
      "Epoch 563/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.9982e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 564/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.9200e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 565/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.9239e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 566/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.9307e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 567/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.9685e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 568/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.9705e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 569/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.9540e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 570/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 3.9414e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 571/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.8980e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 572/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.9433e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 573/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.9241e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 574/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.8509e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 575/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.8953e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 576/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.8873e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 577/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.8261e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 578/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.8279e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 579/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.8530e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 580/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.8207e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 581/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.7900e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 582/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.8217e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 583/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.7685e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 584/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.7936e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 585/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.7573e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 586/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.8141e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 587/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.8392e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 588/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.7933e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 589/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.7395e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 590/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.7922e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 591/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.7818e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 592/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.7568e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 593/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.7713e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 594/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.7096e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 595/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.7726e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 596/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.6991e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 597/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.6654e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 598/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.6992e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 599/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.7392e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 600/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.6466e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 601/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.6608e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 602/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.7764e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 603/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.6800e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 604/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.6395e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 605/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.6680e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 606/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.6475e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 607/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.6073e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 608/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.6655e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 609/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.6127e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 610/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.6232e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 611/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.5812e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 612/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.5786e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 613/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.6058e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 614/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.5886e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 615/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.5882e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 616/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.6187e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 617/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.5760e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 618/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.6046e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 619/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.5631e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 620/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.5460e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 621/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.5250e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 622/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.5297e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 623/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 3.5311e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 624/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.5268e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 625/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.5461e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 626/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.5435e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 627/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.4943e-04 - val_loss: 0.0058 - learning_rate: 7.0000e-06\n",
      "Epoch 628/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.4883e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 629/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.5333e-04 - val_loss: 0.0057 - learning_rate: 7.0000e-06\n",
      "Epoch 630/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4905e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 631/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4853e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 632/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4267e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 633/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4679e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 634/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.4696e-04 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 635/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4102e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 636/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4633e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 637/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4710e-04 - val_loss: 0.0058 - learning_rate: 7.0000e-06\n",
      "Epoch 638/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.4621e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 639/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4684e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 640/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.4706e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 641/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.4122e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 642/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4213e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 643/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4082e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 644/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.3742e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 645/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4022e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 646/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.3417e-04 - val_loss: 0.0058 - learning_rate: 7.0000e-06\n",
      "Epoch 647/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.3107e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 648/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.3358e-04 - val_loss: 0.0058 - learning_rate: 7.0000e-06\n",
      "Epoch 649/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.3785e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 650/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.3304e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 651/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.3498e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 652/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.3024e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 653/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.3192e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 654/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.3272e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 655/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.3460e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 656/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.3613e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 657/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.3032e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 658/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 3.2434e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 659/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.3115e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 660/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.2903e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 661/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.3144e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 662/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.2888e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 663/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2978e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 664/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.2765e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 665/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2591e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 666/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2191e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 667/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.2285e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 668/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.2763e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 669/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2443e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 670/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1959e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 671/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2477e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 672/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1824e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 673/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1693e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 674/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.1991e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 675/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.1452e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 676/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2093e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 677/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1478e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 678/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.1774e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 679/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1671e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 680/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1417e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 681/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.1280e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 682/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1263e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 683/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1366e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 684/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 3.1223e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 01:05:56.174180: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.1665e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 685/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.1389e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 686/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.0950e-04 - val_loss: 0.0058 - learning_rate: 7.0000e-06\n",
      "Epoch 687/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.1228e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 688/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1142e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 689/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1243e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 690/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1142e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 691/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.0958e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 692/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0761e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 693/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1318e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 694/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.0626e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 695/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0850e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 696/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.0643e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 697/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.0597e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 698/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0433e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 699/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.0442e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 700/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.0415e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 701/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0090e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 702/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.0293e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 703/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.9926e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 704/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.9762e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 705/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.0113e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 706/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0201e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 707/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 3.0141e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 708/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9687e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 709/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.0350e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 710/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.9524e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 711/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.9913e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 712/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9277e-04 - val_loss: 0.0058 - learning_rate: 7.0000e-06\n",
      "Epoch 713/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.9448e-04 - val_loss: 0.0054 - learning_rate: 7.0000e-06\n",
      "Epoch 714/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9590e-04 - val_loss: 0.0058 - learning_rate: 7.0000e-06\n",
      "Epoch 715/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9625e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 716/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9280e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 717/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9397e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 718/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9225e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 719/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9517e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 720/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.9356e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 721/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9249e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 722/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.9606e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 723/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.9086e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 724/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.9382e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 725/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9148e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 726/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8879e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 727/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8860e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 728/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 2.8397e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 729/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.8988e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 730/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.8680e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 731/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8070e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 732/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8593e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 733/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8604e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 734/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8039e-04 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 735/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8812e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 736/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.8157e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 737/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.8339e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 738/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.9117e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 739/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.8530e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 740/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8316e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 741/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8493e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 742/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.7860e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 743/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.7687e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 744/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.7806e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 745/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.7670e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 746/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7913e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 747/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8261e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 748/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7500e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 749/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7540e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 750/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7836e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 751/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7455e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 752/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7832e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 753/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.7526e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 754/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7262e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 755/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.7504e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 756/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6960e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 757/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 2.7405e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 758/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7341e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 759/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 2.7518e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 760/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7460e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 761/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6952e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 762/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.7148e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 763/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6901e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 764/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.6973e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 765/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.6633e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 766/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6952e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 767/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6961e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 768/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6238e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 769/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 2.6361e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 770/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6339e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 771/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6712e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 772/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6558e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 773/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6787e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 774/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.5872e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 775/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6249e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 776/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5876e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 777/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.6268e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 778/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6504e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 779/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.6014e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 780/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.6171e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 781/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5836e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 782/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6136e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 783/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5893e-04 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 784/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5865e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 785/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6102e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 786/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.5639e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 787/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5761e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 788/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5477e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 789/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.5166e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 790/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.5532e-04 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 791/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5314e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 792/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5328e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 793/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5804e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 794/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5419e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 795/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.5418e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 796/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.5260e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 797/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5272e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 798/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.5045e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 799/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.4838e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 800/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5014e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 801/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4283e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 802/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4625e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 803/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 2.4660e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 804/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4721e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 805/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4767e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 806/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.4635e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 807/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5004e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 808/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4377e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 809/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5339e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 810/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4474e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 811/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4731e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 812/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4362e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 813/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5154e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 814/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4456e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 815/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.4270e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 816/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.4216e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 817/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3905e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 818/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3882e-04 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 819/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.3918e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 820/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4344e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 821/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4133e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 822/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4112e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 823/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3852e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 824/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4157e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 825/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3631e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 826/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3670e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 827/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4082e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 828/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.3970e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 829/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3680e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 830/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3787e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 831/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3301e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 832/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3378e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 833/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3841e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 834/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3281e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 835/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3456e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 836/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.3257e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 837/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3006e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 838/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.3486e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 839/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.2943e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 840/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.3060e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 841/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3198e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 842/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3088e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 843/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.2892e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 844/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.3201e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 845/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.2728e-04 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 846/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2780e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 847/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.2784e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 848/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2794e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 849/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3264e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 850/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2737e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 851/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2370e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 852/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.2481e-04 - val_loss: 0.0058 - learning_rate: 7.0000e-06\n",
      "Epoch 853/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2873e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 854/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2397e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 855/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2491e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 856/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2447e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 857/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.2378e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 858/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 2.2226e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 859/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.2251e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 860/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2326e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 861/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1860e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 862/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2286e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 863/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.2066e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 864/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.2139e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 865/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.2097e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 866/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.2190e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 867/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2109e-04 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 868/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1861e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 869/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2160e-04 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 870/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1923e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 871/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1875e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 872/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1582e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 873/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.1937e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 874/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1638e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 875/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1772e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 876/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.1915e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 877/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1746e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 878/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.1843e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 879/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1668e-04 - val_loss: 0.0057 - learning_rate: 7.0000e-06\n",
      "Epoch 880/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1400e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 881/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 2.1120e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 882/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1026e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 883/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1635e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 884/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1231e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 885/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.1261e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 886/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1468e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 887/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1490e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 888/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.0818e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 889/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0863e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 890/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1081e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 891/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.0893e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 892/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.0750e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 893/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.0993e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 894/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0730e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 895/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0618e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 896/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0678e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 897/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0986e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 898/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.0765e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 899/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.0616e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 900/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.1147e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 901/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0863e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 902/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.0382e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 903/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0843e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 904/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0284e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 905/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0512e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 906/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0698e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 907/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0685e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 908/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0313e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 909/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0545e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 910/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.0025e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 911/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.0151e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 912/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0325e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 913/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.0027e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 914/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9844e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 915/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0025e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 916/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 2.0298e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 917/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.0390e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 918/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9848e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 919/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0067e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 920/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9851e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 921/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.0281e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 922/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.9894e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 923/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9913e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 924/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0030e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 925/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9684e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 926/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9502e-04 - val_loss: 0.0058 - learning_rate: 7.0000e-06\n",
      "Epoch 927/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.9553e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 928/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9367e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 929/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.9661e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 930/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.9504e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 931/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.9412e-04 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 932/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9625e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 933/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.9486e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 934/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9099e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 935/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9271e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 936/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.9394e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 937/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9269e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 938/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.9216e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 939/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9341e-04 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 940/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9491e-04 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 941/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.9111e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 942/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.9145e-04 - val_loss: 0.0056 - learning_rate: 7.0000e-06\n",
      "Epoch 943/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 1.9366e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 944/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9311e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 945/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.9398e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 946/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9501e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 947/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.9074e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 948/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8845e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 949/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.9109e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 950/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9003e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 951/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8711e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 952/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.8594e-04 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 953/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8988e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 954/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8680e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 955/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8731e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 956/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.8859e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 957/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.8509e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 958/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8479e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 959/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8567e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 960/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.8340e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 961/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.8426e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 962/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8647e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 963/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.8461e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 964/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8451e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 965/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8198e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 966/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8240e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 967/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8377e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 968/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7838e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 969/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7887e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 970/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8381e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 971/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8007e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 972/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8229e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 973/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8483e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 974/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7906e-04 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 975/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8532e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 976/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8218e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 977/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.7971e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 978/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7824e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 979/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8060e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 980/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7553e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 981/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.7565e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 982/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.7992e-04 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 983/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7979e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 984/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7794e-04 - val_loss: 0.0058 - learning_rate: 7.0000e-06\n",
      "Epoch 985/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7345e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 986/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7534e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 987/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.7637e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 988/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7441e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 989/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.7414e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 990/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7377e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 991/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7374e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 992/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7392e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 993/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.7623e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 994/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7453e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 995/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.7449e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 996/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7315e-04 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 997/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.7209e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 998/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6998e-04 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 999/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.7261e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 1000/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6952e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1001/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.6881e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1002/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.7014e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1003/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7014e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1004/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7269e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1005/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.7135e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 1006/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.6854e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1007/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6712e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1008/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6707e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1009/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.6908e-04 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1010/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.7021e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1011/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.6954e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1012/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7006e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1013/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6978e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1014/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7049e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1015/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.6398e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1016/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6900e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1017/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6529e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1018/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6906e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1019/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6638e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1020/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6764e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1021/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6510e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1022/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.6734e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1023/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6363e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1024/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6450e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1025/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.6737e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 1026/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.6386e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1027/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6396e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 1028/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6310e-04 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1029/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.6240e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1030/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6031e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 1031/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6593e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1032/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.6207e-04 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1033/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6211e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1034/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6050e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1035/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.6291e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 1036/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5849e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1037/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6121e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1038/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.5991e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1039/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.6172e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1040/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6238e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1041/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5945e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1042/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5942e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 1043/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5991e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1044/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.5696e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1045/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5899e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1046/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5824e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1047/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5603e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 1048/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5663e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1049/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5680e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1050/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5593e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1051/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5510e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1052/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5587e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1053/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5726e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1054/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5637e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1055/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5742e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1056/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.5596e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1057/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5601e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 1058/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.5534e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 1059/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5473e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1060/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5455e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1061/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.5151e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1062/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5426e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1063/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.5365e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1064/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.5257e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1065/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5219e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 1066/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5359e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1067/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5269e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1068/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.5107e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1069/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.5070e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1070/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.4887e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1071/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5277e-04 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1072/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.4960e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1073/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.4979e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 1074/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.4896e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 1075/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5156e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1076/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5245e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1077/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5129e-04 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1078/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5144e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1079/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.4939e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1080/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.4833e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1081/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5129e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1082/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.4629e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1083/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.4882e-04 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1084/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.4812e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 1085/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.4422e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1086/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.4676e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1087/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.4539e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1088/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.4508e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1089/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.4836e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1090/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.4632e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1091/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.4575e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1092/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.4827e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1093/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.4448e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1094/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.4267e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1095/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.4241e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1096/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.4355e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1097/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.4205e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1098/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.4526e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1099/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.4369e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1100/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.4519e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1101/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.4451e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1102/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.4199e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1103/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.4186e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1104/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.4126e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 1105/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.4361e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 1106/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.4212e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 1107/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.4210e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1108/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.4142e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1109/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.4146e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1110/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.4085e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1111/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3892e-04 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1112/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3997e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1113/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3884e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1114/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3874e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1115/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.3957e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 1116/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3854e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1117/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3920e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1118/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3916e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1119/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3755e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 1120/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3825e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1121/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3810e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1122/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.3731e-04 - val_loss: 0.0058 - learning_rate: 7.0000e-06\n",
      "Epoch 1123/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3842e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1124/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3679e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1125/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.3646e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1126/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3693e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1127/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.3506e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1128/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3772e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1129/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3470e-04 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1130/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3671e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1131/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3420e-04 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1132/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3545e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 1133/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3511e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1134/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.3213e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1135/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3460e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1136/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.3433e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1137/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.3480e-04 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1138/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3534e-04 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1139/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3309e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1140/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.3254e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1141/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3344e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1142/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3567e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1143/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.3625e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1144/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.3004e-04 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1145/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3212e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1146/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3026e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1147/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.2932e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1148/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3214e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1149/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3151e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1150/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.3178e-04 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1151/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3127e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1152/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.3090e-04 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1153/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.2810e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1154/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.2931e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1155/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.3144e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1156/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3026e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1157/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.3239e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1158/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3111e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1159/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.2960e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1160/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.2933e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1161/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.2899e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1162/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.2923e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1163/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.2791e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1164/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.2760e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1165/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.2691e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1166/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.2606e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1167/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.2653e-04 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 1168/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.2958e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 1169/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.2763e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1170/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.3028e-04 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1171/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.2631e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1172/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.2879e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1173/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.2626e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1174/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.2393e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1175/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.2615e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1176/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.2587e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1177/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.2396e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1178/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.2360e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1179/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.2378e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1180/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.2426e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1181/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.2556e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1182/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.2518e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 1183/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.2396e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1184/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.2319e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1185/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.2344e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1186/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.2526e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1187/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.2341e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 1188/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.1991e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1189/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.2218e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1190/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.2197e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1191/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.2193e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 1192/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.2212e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1193/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.2234e-04 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1194/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.2066e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1195/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.2158e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1196/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.2196e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1197/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.2099e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1198/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.2084e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1199/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.1905e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1200/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.1967e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1201/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1955e-04 - val_loss: 0.0059 - learning_rate: 7.0000e-06\n",
      "Epoch 1202/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1895e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1203/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.2026e-04 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1204/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1872e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1205/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1982e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1206/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.1876e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1207/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.1725e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1208/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1754e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1209/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.1572e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1210/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1675e-04 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1211/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.1628e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1212/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1645e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1213/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1648e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1214/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1795e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1215/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1841e-04 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1216/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1501e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1217/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1673e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1218/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.1403e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1219/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.1834e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1220/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.1525e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1221/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1687e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1222/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1358e-04 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1223/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1300e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1224/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1624e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1225/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1546e-04 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 1226/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1342e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1227/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1439e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1228/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.1556e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1229/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1674e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1230/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.1411e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1231/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.1603e-04 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 1232/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1602e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1233/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1566e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1234/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1449e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1235/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1107e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1236/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.1205e-04 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1237/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1239e-04 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 1238/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1093e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1239/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1162e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1240/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.1385e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1241/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.1191e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1242/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.1314e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1243/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.1093e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1244/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.1216e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1245/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1068e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1246/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.1117e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1247/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.0873e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1248/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.0960e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1249/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.0787e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1250/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.1329e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1251/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.1034e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1252/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.1336e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1253/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.1267e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1254/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.1177e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1255/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.1214e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1256/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 1.1192e-04 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1257/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.0796e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1258/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.0659e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1259/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.0914e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1260/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.0781e-04 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1261/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.0905e-04 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1262/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.0973e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1263/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.0713e-04 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 1264/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.0752e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1265/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 298ms/step - loss: 1.0712e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1266/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.0997e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1267/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.0798e-04 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 1268/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.0822e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1269/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.0774e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1270/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.0751e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1271/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.0503e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1272/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.0553e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1273/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 1.0507e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1274/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.0887e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1275/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.0712e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1276/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.0764e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1277/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.0589e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1278/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.0397e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1279/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 1.0506e-04 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1280/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.0433e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1281/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.0395e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1282/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.0561e-04 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 1283/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.0423e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1284/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.0337e-04 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 1285/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.0329e-04 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1286/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.0303e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1287/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.0530e-04 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1288/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.0459e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1289/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.0324e-04 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1290/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.0450e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1291/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.0322e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1292/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.0336e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1293/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.0085e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1294/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.0105e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1295/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.0180e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1296/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.0188e-04 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 1297/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.0037e-04 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1298/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.0306e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1299/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.0222e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1300/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.0097e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1301/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.0213e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1302/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.0293e-04 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1303/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.0358e-04 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 1304/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.0300e-04 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1305/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.0297e-04 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1306/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.0323e-04 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1307/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 9.8599e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1308/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 9.8948e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1309/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.8774e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1310/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.9044e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1311/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.8871e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1312/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.8471e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1313/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.9344e-05 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1314/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 9.7719e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1315/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 9.7913e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1316/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.7665e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1317/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.8586e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1318/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 9.6844e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1319/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.0034e-04 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1320/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.5684e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1321/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.8631e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1322/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.8928e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1323/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.8662e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1324/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 9.7473e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1325/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.7361e-05 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 1326/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.7525e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1327/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.7009e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1328/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 9.5814e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1329/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 9.6944e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1330/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 9.5334e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1331/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 9.5661e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1332/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 9.4684e-05 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1333/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.6597e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1334/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.4118e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1335/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.3951e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1336/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 9.5254e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1337/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.3066e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1338/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 9.5240e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1339/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.4241e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1340/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.4754e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1341/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 9.5483e-05 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1342/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.5051e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1343/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.4691e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1344/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.5280e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1345/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.1787e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 1346/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.4948e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1347/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.4520e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1348/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 9.4378e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1349/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.4613e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1350/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 9.5095e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1351/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 9.3568e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1352/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.2452e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1353/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 9.3423e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1354/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 9.2673e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1355/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 9.2317e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1356/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.2068e-05 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1357/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 9.1049e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1358/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.1074e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1359/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 9.1698e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1360/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 9.1533e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1361/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 9.2278e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1362/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 9.1515e-05 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1363/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.1304e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1364/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 9.1240e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1365/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 9.0902e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1366/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 9.0804e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1367/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 8.8588e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 01:14:53.084649: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 9.0174e-05 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 1368/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 9.1402e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1369/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 9.1482e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1370/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.8986e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1371/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.9962e-05 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1372/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 8.8623e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1373/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.9100e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1374/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 9.1629e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1375/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 9.1117e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1376/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.8899e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1377/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.9496e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1378/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 9.0350e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1379/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.7885e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1380/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.9309e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1381/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 8.7816e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1382/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.8724e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1383/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.7491e-05 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1384/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 8.8651e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1385/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.7236e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1386/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 8.6281e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1387/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.8853e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1388/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.8462e-05 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1389/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.9908e-05 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 1390/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.6367e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1391/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.7358e-05 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1392/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 8.7320e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1393/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.8030e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1394/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 8.7743e-05 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1395/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.6797e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1396/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 8.5816e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1397/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.6848e-05 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 1398/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.5784e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1399/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.5903e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1400/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.6408e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1401/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.6108e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1402/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.5198e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1403/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 8.5870e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1404/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 8.5036e-05 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1405/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 8.5320e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1406/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.3767e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1407/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.5288e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1408/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.5456e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1409/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 8.4695e-05 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1410/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 8.6032e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1411/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 8.4550e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1412/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 8.4280e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1413/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.5375e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1414/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.4117e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1415/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 8.4257e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1416/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 8.3556e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1417/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 8.3924e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1418/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.3649e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1419/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 8.4873e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1420/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 8.4464e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1421/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.3269e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1422/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 8.2697e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1423/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 8.3200e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1424/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 8.4156e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1425/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.2523e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1426/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.3553e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1427/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 8.2742e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1428/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 7.9630e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1429/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.1007e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1430/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 8.2435e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1431/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.3583e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1432/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.2393e-05 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1433/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.1192e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1434/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 8.1460e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1435/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.1326e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1436/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.9328e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1437/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 8.2176e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1438/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 8.0868e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1439/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.1501e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1440/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 8.0906e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1441/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.0429e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1442/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 8.0822e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1443/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 8.2377e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1444/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 8.0365e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1445/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 8.1741e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1446/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.1410e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1447/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 7.9724e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1448/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 7.8909e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1449/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.9183e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1450/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 7.9858e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1451/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.8465e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1452/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.9736e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1453/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 7.9781e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1454/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 7.9033e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1455/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.8011e-05 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1456/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.8209e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1457/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 8.0362e-05 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1458/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 7.9695e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1459/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 7.9308e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1460/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 7.8479e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1461/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.8039e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1462/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 7.8604e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1463/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 7.8112e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1464/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 7.9306e-05 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1465/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 7.8169e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1466/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.8820e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1467/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 7.7519e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1468/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 7.8450e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1469/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.8627e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1470/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 7.7549e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1471/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.6848e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1472/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 7.5934e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1473/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 7.5546e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1474/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.6446e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1475/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.5361e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1476/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 7.5338e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1477/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 7.5800e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1478/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.7133e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1479/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 7.7703e-05 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 1480/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.5491e-05 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1481/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 7.4732e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1482/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 7.4944e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1483/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.4498e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1484/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.5365e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1485/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.7443e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1486/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.5289e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1487/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.5320e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1488/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 7.5837e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1489/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.5744e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1490/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.5128e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1491/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.3169e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1492/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.2420e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1493/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.4516e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1494/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 7.4519e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1495/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 7.5599e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1496/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 7.4394e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1497/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.4525e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1498/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.4768e-05 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1499/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 7.3633e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1500/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.2631e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1501/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.3300e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1502/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 7.4752e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 1503/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 7.4283e-05 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1504/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.4509e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1505/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.2184e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1506/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.2567e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1507/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.3137e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1508/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.3016e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1509/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 7.2310e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1510/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 7.0860e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1511/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 7.2793e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1512/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.2000e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1513/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.1870e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1514/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 7.1980e-05 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1515/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 7.2650e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1516/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.1832e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 1517/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 7.1787e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1518/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.1292e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 1519/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 7.3160e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1520/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.1022e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1521/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 7.2071e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1522/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 7.1991e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1523/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.1474e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1524/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 7.0669e-05 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 1525/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.9208e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1526/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.1352e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1527/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.9191e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1528/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.0953e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1529/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.9234e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1530/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.0236e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1531/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.9016e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1532/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 7.0352e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1533/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.9630e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1534/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.9864e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1535/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.8664e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1536/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.9319e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1537/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.8887e-05 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1538/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 6.8461e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1539/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.8795e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1540/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.8930e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1541/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.8922e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1542/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.9560e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1543/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.9367e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1544/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 6.8741e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1545/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.0328e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 1546/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.8769e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1547/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.9769e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1548/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.9037e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1549/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.7852e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1550/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.5763e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1551/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.6830e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1552/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.9144e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1553/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.1527e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1554/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.7926e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1555/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 6.8532e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1556/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.6763e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1557/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.7540e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1558/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.8463e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1559/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 7.0316e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1560/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.9300e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1561/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.8248e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 1562/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.7399e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1563/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.6939e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1564/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 6.7987e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1565/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.6160e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1566/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.7417e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1567/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 6.6149e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1568/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.7984e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1569/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.6529e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1570/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 6.6986e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1571/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.5520e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1572/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 6.6712e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1573/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.5833e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1574/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.7103e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1575/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.5268e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1576/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 6.5951e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1577/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.6217e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1578/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.4283e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1579/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.5674e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1580/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.5516e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 1581/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.4518e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1582/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 6.5252e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1583/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.4647e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1584/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.5537e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1585/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.4718e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1586/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.3424e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1587/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.4764e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1588/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 6.6112e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1589/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.4630e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1590/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.7096e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1591/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.5341e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1592/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.4788e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1593/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.4067e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1594/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.2902e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1595/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 6.4672e-05 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1596/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.4165e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1597/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 6.5706e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1598/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.3002e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1599/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.3821e-05 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 1600/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.3650e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1601/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.2932e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1602/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.3194e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1603/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.3258e-05 - val_loss: 0.0077 - learning_rate: 7.0000e-06\n",
      "Epoch 1604/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.1637e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1605/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.2537e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1606/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.4168e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1607/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.2510e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1608/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.2968e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1609/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.2776e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 1610/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.2293e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 1611/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.3079e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1612/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.1859e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 1613/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.3272e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1614/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.2974e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1615/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.2086e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1616/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 6.2414e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1617/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.1928e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1618/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.0639e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1619/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.1039e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1620/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 6.0876e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1621/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.0115e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1622/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.9896e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1623/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.1271e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1624/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.2155e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1625/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.2682e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1626/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.9290e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1627/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 6.0598e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1628/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.0123e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1629/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.9651e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1630/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 5.9586e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1631/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.0698e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1632/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 6.1598e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1633/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.1314e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1634/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 6.0454e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1635/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.0871e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1636/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.2011e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 1637/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.0062e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1638/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 6.0342e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1639/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.0638e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1640/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.1148e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1641/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.1060e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1642/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.0475e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1643/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.9235e-05 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1644/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 6.0182e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1645/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.7389e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1646/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 6.0468e-05 - val_loss: 0.0060 - learning_rate: 7.0000e-06\n",
      "Epoch 1647/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.9510e-05 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1648/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.9625e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1649/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.8918e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1650/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.8339e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1651/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.8334e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 1652/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.9280e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1653/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.9999e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 1654/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.1182e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1655/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 6.0161e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1656/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 6.0057e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1657/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.8764e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1658/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.8835e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1659/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.8724e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1660/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.7489e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1661/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.7010e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1662/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.8375e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1663/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 5.9083e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1664/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.8587e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1665/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.6711e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1666/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.7997e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1667/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.8210e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1668/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 5.6453e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1669/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 5.6169e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1670/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.8123e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1671/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.8007e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1672/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.7932e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1673/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.6424e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1674/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.6543e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 1675/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.5975e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1676/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.7392e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1677/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.6188e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1678/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.7115e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1679/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.7330e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1680/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.6549e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1681/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.6920e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 1682/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.6308e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1683/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.7587e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1684/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.6711e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1685/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.7167e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1686/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.7539e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1687/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.6305e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1688/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.5268e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1689/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.6850e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1690/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.5770e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1691/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.6043e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1692/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.5557e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1693/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.5951e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1694/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.8113e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1695/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 5.6915e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1696/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.6108e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1697/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.4972e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1698/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.5040e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1699/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.5695e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1700/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.7057e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1701/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.3610e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1702/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.3893e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1703/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.5986e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1704/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.4096e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1705/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.4535e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1706/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.5181e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1707/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.4589e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1708/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.4095e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1709/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.3954e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1710/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.3867e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1711/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.4813e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1712/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.4747e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1713/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.4034e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1714/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.3556e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1715/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.2849e-05 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1716/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.2752e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1717/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.4886e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1718/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.4625e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1719/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.5669e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1720/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 5.5778e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1721/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.4632e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1722/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.3957e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1723/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.2831e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1724/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.4520e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1725/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.3879e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1726/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.3298e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1727/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.3918e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1728/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.2436e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1729/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.3645e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1730/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.2312e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1731/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.2064e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1732/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.2927e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1733/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.2788e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1734/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 5.4279e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 1735/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.3964e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1736/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.2640e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1737/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.2018e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1738/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.3358e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1739/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 5.3070e-05 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1740/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 5.1836e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 1741/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.1575e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1742/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.2991e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 1743/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.3924e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1744/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.3711e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1745/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.1323e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1746/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.2175e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1747/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 5.1835e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 1748/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.1685e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1749/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.3189e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1750/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.1434e-05 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1751/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.1594e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1752/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.0675e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1753/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.0341e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1754/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 5.1233e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1755/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.9884e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1756/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.1072e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1757/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.0561e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1758/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.0687e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1759/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.0749e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1760/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.0862e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1761/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.3142e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1762/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.2064e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1763/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.1588e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1764/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 5.0350e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1765/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.1938e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1766/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.1246e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1767/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.1234e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1768/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.9583e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1769/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.9967e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1770/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.0848e-05 - val_loss: 0.0061 - learning_rate: 7.0000e-06\n",
      "Epoch 1771/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.8649e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 1772/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.8626e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1773/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.9502e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1774/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.0860e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 1775/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.8929e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 1776/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 4.9366e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1777/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.9061e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1778/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.9661e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1779/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.8871e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1780/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.8540e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1781/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.8343e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 1782/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.8142e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1783/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.8140e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1784/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.9459e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1785/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.9354e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1786/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.0116e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 1787/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.8741e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1788/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.9543e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1789/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 4.8017e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1790/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.9874e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1791/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.0534e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1792/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 5.0768e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1793/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.9462e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1794/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.9888e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1795/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.8594e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1796/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.8853e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1797/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.9018e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1798/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.7827e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 1799/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.9455e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 1800/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 5.0374e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1801/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.8721e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 1802/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.8803e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1803/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.9198e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1804/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.8405e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 1805/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.7410e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 1806/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.8601e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1807/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.7290e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1808/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.7320e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 1809/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.7360e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1810/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.8707e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1811/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.7704e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1812/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.7607e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1813/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.7185e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 1814/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.9407e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1815/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.7826e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1816/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.8705e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1817/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.8753e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1818/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.6579e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1819/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.9147e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1820/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.6850e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1821/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.6561e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1822/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.7845e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1823/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.8069e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1824/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.6142e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1825/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.6123e-05 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1826/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.6938e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1827/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.6389e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1828/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.7316e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1829/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.6675e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1830/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.6903e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1831/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.7050e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1832/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.6669e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1833/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.5600e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1834/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.5016e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1835/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.5384e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1836/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.6111e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1837/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.6037e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 1838/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.6601e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1839/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 4.6711e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 1840/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.7245e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1841/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.6578e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1842/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.6686e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1843/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.6349e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1844/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.5838e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1845/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.6365e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1846/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.7531e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1847/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.5016e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1848/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.5944e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1849/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.5964e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1850/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.5472e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1851/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 4.4534e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 1852/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.4490e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1853/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.4869e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1854/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.5432e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1855/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 4.5266e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1856/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.5376e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1857/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.5760e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 1858/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.4784e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1859/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.5527e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1860/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.4891e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1861/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.5101e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1862/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.4984e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1863/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.5112e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1864/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.5356e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1865/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.4889e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1866/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.5505e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1867/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.3943e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 1868/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.3502e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 1869/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.3639e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1870/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.3318e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1871/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.3732e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1872/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 4.2479e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 1873/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.3103e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1874/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.4911e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1875/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.3974e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1876/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.4906e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1877/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.5483e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1878/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.4628e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1879/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.4194e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1880/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.3806e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1881/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.3182e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1882/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.3175e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1883/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.3638e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1884/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.3327e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1885/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.2871e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1886/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.2695e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1887/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.2417e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1888/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.6032e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1889/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.5048e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 1890/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.3471e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1891/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.3495e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1892/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.2693e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1893/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.3219e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1894/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.2743e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1895/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.3259e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1896/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.2891e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 1897/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.2446e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1898/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.3667e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1899/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 4.4334e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1900/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.3267e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1901/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.3468e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1902/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.3048e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1903/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 4.1340e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1904/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.1491e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1905/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.1219e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 1906/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.1282e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1907/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.1648e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1908/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.1782e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1909/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.1575e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1910/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.1839e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1911/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.3099e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1912/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.4528e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1913/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.3041e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1914/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.3875e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1915/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.5489e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1916/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.2368e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1917/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 4.1270e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 1918/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.2761e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1919/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.1415e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1920/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 4.2433e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1921/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.2978e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 1922/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.2185e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1923/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.2016e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1924/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.1414e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1925/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.1768e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1926/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.0625e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1927/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.1442e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1928/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.0596e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1929/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.1074e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1930/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.1256e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1931/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.1115e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1932/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.0484e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1933/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.0987e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1934/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.0877e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 1935/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.0961e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1936/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.2628e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1937/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.1142e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1938/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.0079e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1939/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.9277e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1940/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 4.0935e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1941/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.1507e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1942/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.1901e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1943/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.2118e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1944/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.0698e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1945/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.0883e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1946/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.9624e-05 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1947/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 4.1303e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1948/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.1899e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1949/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.0216e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 1950/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.3122e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1951/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.9927e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 1952/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.2460e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1953/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.1737e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1954/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.0641e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1955/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.0419e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1956/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.9117e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1957/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.9227e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1958/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.9298e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1959/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.9040e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1960/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.9712e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1961/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.9058e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1962/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.8963e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1963/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.9405e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1964/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.9186e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1965/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.9179e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1966/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.9956e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1967/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.9924e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1968/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.9203e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1969/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.8336e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1970/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.8874e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1971/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.8072e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 1972/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.8824e-05 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 1973/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.8544e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1974/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.9592e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1975/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.8692e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1976/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.8930e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1977/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.9412e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 1978/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.8108e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1979/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.8295e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 1980/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.8529e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1981/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.7798e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1982/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 4.1622e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 1983/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.0700e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 1984/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.8773e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1985/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.8145e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1986/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.8896e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 1987/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.9904e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 1988/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.7530e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 1989/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 3.8187e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 1990/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.9771e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1991/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 4.3262e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1992/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.0913e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 1993/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.8579e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1994/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.8059e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 1995/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.8284e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 1996/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.8495e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 1997/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.9750e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 1998/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.9930e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 1999/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 4.0069e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2000/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.8710e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 2001/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.7958e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 2002/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.7080e-05 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 2003/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.7644e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2004/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.6901e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 2005/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.9200e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2006/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.8122e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2007/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.7871e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2008/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.8854e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2009/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.7456e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2010/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.7295e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2011/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.7515e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2012/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.6589e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2013/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.6601e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2014/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.7845e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2015/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.7281e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2016/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.6211e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2017/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.7046e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2018/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.7112e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2019/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.6207e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2020/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.7140e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2021/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.6246e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2022/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.8238e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2023/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.7287e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2024/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.6607e-05 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 2025/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 3.7974e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 2026/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.7395e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2027/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.8092e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2028/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.8555e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2029/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 3.8349e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2030/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.7456e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2031/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.8724e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2032/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.6867e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2033/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.5608e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 2034/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.5366e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2035/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.6083e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2036/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.6659e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2037/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.5823e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2038/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.5337e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2039/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.6214e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2040/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.6510e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2041/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.5564e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2042/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.6869e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2043/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.9010e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2044/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.8263e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2045/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.7367e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2046/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.8202e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2047/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.7888e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2048/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 3.7097e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2049/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.7120e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2050/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.6666e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2051/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.6000e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2052/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.6930e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2053/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.5274e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2054/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4391e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2055/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.5301e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 2056/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.6040e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2057/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.5881e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2058/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.6084e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2059/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4767e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2060/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 3.4771e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2061/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.5623e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2062/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.5931e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2063/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.5046e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2064/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4998e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2065/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4574e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2066/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.5182e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2067/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.6292e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2068/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4443e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2069/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4369e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2070/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.4610e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2071/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4813e-05 - val_loss: 0.0079 - learning_rate: 7.0000e-06\n",
      "Epoch 2072/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.3599e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2073/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.4174e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2074/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.5059e-05 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 2075/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4521e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2076/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.5464e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2077/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4390e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2078/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4946e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2079/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4026e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 2080/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.5264e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2081/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.5406e-05 - val_loss: 0.0077 - learning_rate: 7.0000e-06\n",
      "Epoch 2082/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4099e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2083/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.2711e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2084/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4804e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2085/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.6047e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2086/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.5308e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2087/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.4639e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2088/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.3930e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2089/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.3112e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2090/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.3309e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2091/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4572e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2092/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.4423e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2093/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.4340e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2094/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 3.4522e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2095/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.3601e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2096/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.5352e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2097/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.4775e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2098/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.3947e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2099/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4416e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2100/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.5563e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2101/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 3.4182e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2102/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.2592e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2103/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.3362e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2104/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4395e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 2105/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4173e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2106/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.3618e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2107/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.5578e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2108/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.5481e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2109/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.6571e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2110/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.5698e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2111/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.3537e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2112/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4673e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2113/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4201e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2114/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4408e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2115/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.3540e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2116/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.3259e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2117/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.3796e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2118/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2658e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2119/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2068e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 2120/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2596e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2121/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2099e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 2122/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.4110e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2123/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.3198e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 2124/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2834e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2125/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2964e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2126/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2627e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2127/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2923e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2128/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.3435e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2129/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.3878e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2130/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2419e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2131/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.2999e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2132/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4602e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2133/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 3.2857e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2134/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.5204e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2135/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.5200e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2136/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.3531e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2137/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4903e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2138/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.1766e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2139/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1613e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2140/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2049e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2141/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1867e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2142/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1367e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2143/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1420e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2144/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1936e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2145/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.1800e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2146/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1148e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2147/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.5157e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2148/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.5682e-05 - val_loss: 0.0063 - learning_rate: 7.0000e-06\n",
      "Epoch 2149/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.3353e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2150/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2584e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2151/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1890e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2152/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.3141e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2153/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.1993e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2154/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2864e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2155/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2548e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2156/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2431e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2157/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2103e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 2158/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1589e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2159/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.4424e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2160/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.3095e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2161/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.2265e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2162/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2106e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 2163/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1657e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2164/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0594e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2165/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.1888e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2166/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.2622e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2167/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2165e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2168/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1164e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2169/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.1200e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2170/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0798e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2171/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.2249e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2172/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.1582e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2173/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2060e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2174/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1745e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 2175/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1126e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2176/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.0566e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2177/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0315e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2178/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2351e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2179/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2369e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2180/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0723e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2181/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0789e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2182/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0241e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 2183/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.2184e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2184/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1032e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2185/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0112e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2186/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.1032e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2187/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.0170e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2188/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9970e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 2189/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1947e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2190/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.2053e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2191/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.0807e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2192/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2264e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2193/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2634e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2194/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1328e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2195/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2191e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2196/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1789e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2197/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1468e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2198/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1466e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2199/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0132e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2200/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.1226e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2201/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1069e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2202/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0480e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2203/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0547e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2204/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2129e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2205/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.2368e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2206/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2904e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2207/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2566e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2208/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.3740e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2209/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.1183e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2210/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.0705e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2211/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0264e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2212/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9364e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2213/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.9076e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2214/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0109e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2215/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0012e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2216/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0276e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2217/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.1811e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2218/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0727e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2219/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1012e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2220/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1202e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2221/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0821e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2222/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9695e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2223/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9633e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2224/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0223e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2225/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.9992e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2226/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.0642e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2227/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.0878e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2228/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.2776e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2229/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.0112e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2230/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0450e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2231/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0102e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2232/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1007e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2233/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1403e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2234/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9727e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2235/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1210e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2236/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0641e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2237/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.1302e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2238/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.0836e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2239/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.0191e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2240/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9831e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2241/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.9928e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2242/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.9665e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2243/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.8302e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2244/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.9017e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2245/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.8946e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2246/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8644e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2247/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9859e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2248/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.9862e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2249/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9421e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2250/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7849e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 2251/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8897e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2252/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8765e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 2253/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8524e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2254/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.8780e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2255/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9533e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2256/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9232e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2257/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.9134e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2258/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8777e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2259/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9827e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2260/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8677e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 2261/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9136e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2262/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9310e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2263/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7887e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2264/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8727e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2265/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8825e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2266/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.8600e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2267/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.8767e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2268/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9097e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2269/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8513e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 2270/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.7542e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2271/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.8468e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2272/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.9105e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2273/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 3.1380e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2274/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.3599e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2275/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0547e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2276/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 2.9996e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2277/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.8685e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2278/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.8674e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2279/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8795e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2280/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7842e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2281/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.8050e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2282/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.9044e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2283/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 3.0540e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2284/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8699e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2285/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8001e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2286/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7321e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2287/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.6874e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2288/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8402e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2289/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.9217e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2290/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.7912e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2291/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8966e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2292/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8500e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2293/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8228e-05 - val_loss: 0.0077 - learning_rate: 7.0000e-06\n",
      "Epoch 2294/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7725e-05 - val_loss: 0.0077 - learning_rate: 7.0000e-06\n",
      "Epoch 2295/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.7423e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2296/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.6563e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2297/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7709e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2298/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.7369e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2299/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7751e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2300/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.7718e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2301/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.8564e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2302/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.8025e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2303/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8374e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2304/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7878e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2305/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 3.0444e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2306/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8999e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2307/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7857e-05 - val_loss: 0.0077 - learning_rate: 7.0000e-06\n",
      "Epoch 2308/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9322e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2309/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7237e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2310/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8704e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2311/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.8721e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2312/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.8685e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2313/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.9976e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2314/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.8701e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2315/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.7875e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2316/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7697e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2317/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7674e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2318/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.6652e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2319/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6787e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2320/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 2.6944e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2321/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6586e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2322/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.6825e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2323/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.6899e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2324/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8192e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2325/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9470e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2326/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7894e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2327/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8498e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2328/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8862e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 2329/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.6575e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2330/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7549e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2331/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7821e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2332/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6516e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2333/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7111e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2334/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7433e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2335/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7823e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2336/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.9793e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2337/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8202e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2338/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7619e-05 - val_loss: 0.0062 - learning_rate: 7.0000e-06\n",
      "Epoch 2339/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.7374e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2340/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8297e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2341/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8334e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2342/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8001e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2343/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6967e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2344/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6167e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2345/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.7675e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2346/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8148e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2347/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6396e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2348/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6411e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2349/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7038e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2350/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.7264e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2351/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.7787e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2352/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.7010e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2353/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.6085e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2354/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5884e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2355/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5954e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2356/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7407e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2357/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.7237e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2358/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.6304e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2359/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6687e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2360/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.6674e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2361/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.6761e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2362/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5638e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2363/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6241e-05 - val_loss: 0.0079 - learning_rate: 7.0000e-06\n",
      "Epoch 2364/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.6849e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2365/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.8026e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2366/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7137e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2367/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6254e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2368/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6786e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2369/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6049e-05 - val_loss: 0.0078 - learning_rate: 7.0000e-06\n",
      "Epoch 2370/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.7661e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2371/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7603e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2372/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5988e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2373/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5885e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2374/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.5864e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2375/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.5871e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2376/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5809e-05 - val_loss: 0.0077 - learning_rate: 7.0000e-06\n",
      "Epoch 2377/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5872e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2378/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.5069e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2379/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.5304e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2380/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.5930e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2381/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5286e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2382/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5095e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2383/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7051e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2384/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.7473e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2385/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6552e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2386/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6554e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2387/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6384e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2388/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5764e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2389/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5439e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2390/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.6270e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2391/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7513e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2392/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.6231e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2393/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5868e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2394/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5166e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2395/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6841e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2396/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.5425e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2397/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.6501e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2398/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7921e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2399/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7081e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2400/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5816e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2401/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5524e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2402/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5526e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2403/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6058e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 2404/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.5783e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2405/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5472e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2406/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5223e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2407/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.5857e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2408/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.5615e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2409/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5825e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2410/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4959e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2411/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4853e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2412/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.6046e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2413/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5446e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2414/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5262e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2415/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.4695e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2416/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5364e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2417/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4117e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2418/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5128e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2419/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5098e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2420/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.6591e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2421/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.6085e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2422/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5892e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2423/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 2.5852e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2424/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.4771e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2425/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5886e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2426/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.5107e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2427/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.5408e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2428/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5000e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2429/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3902e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2430/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4255e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2431/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.5188e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2432/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4980e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2433/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.5603e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2434/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4122e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2435/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4610e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2436/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4609e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2437/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.4191e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2438/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4112e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2439/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6450e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2440/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4385e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2441/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.4440e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2442/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.5079e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2443/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5028e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2444/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4168e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2445/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4430e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2446/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4142e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2447/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4109e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2448/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4918e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2449/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4011e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2450/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6195e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2451/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.5723e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2452/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4239e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2453/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4726e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2454/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 2.4220e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2455/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4651e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2456/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.3859e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2457/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.6297e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2458/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5367e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2459/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4848e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2460/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5797e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2461/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4917e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2462/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4484e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2463/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5545e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2464/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.5685e-05 - val_loss: 0.0077 - learning_rate: 7.0000e-06\n",
      "Epoch 2465/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5215e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2466/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4019e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2467/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5232e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2468/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7893e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2469/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.4411e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2470/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5085e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2471/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5932e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2472/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4863e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2473/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4750e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 2474/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.4222e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2475/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 2.3020e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2476/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3490e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2477/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4639e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2478/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.3466e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2479/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.3022e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2480/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3456e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2481/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.4022e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2482/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 2.4006e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2483/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.4251e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2484/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.4159e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2485/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3374e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2486/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4293e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2487/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.4221e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2488/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3752e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2489/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5107e-05 - val_loss: 0.0078 - learning_rate: 7.0000e-06\n",
      "Epoch 2490/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.3723e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2491/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.3979e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2492/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.4291e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 2493/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.2599e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2494/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.2537e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2495/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.3040e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2496/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3082e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2497/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3012e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2498/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3783e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2499/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3994e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2500/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.3499e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2501/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4363e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2502/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3438e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2503/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 2.3502e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2504/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.3449e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2505/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.4114e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2506/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.4194e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2507/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5806e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2508/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 2.6213e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2509/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7217e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2510/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.6094e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2511/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3665e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2512/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.3487e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2513/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2671e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2514/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2206e-05 - val_loss: 0.0078 - learning_rate: 7.0000e-06\n",
      "Epoch 2515/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3246e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2516/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5249e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2517/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3767e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2518/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3966e-05 - val_loss: 0.0077 - learning_rate: 7.0000e-06\n",
      "Epoch 2519/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 2.6702e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2520/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.4958e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2521/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4378e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2522/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.5604e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2523/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.4124e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2524/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.4954e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2525/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 2.4171e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2526/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.3044e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2527/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3350e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2528/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.2843e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2529/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.2654e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2530/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.1691e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2531/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2374e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2532/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1675e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2533/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.1873e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2534/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.1609e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2535/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.1491e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2536/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2466e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2537/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4253e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2538/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2710e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2539/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2057e-05 - val_loss: 0.0077 - learning_rate: 7.0000e-06\n",
      "Epoch 2540/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1560e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2541/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2090e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2542/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.2261e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2543/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.2504e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2544/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.2909e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2545/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.4519e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2546/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5191e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2547/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2149e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2548/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.2129e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2549/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.1535e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2550/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2190e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2551/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1144e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2552/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2864e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2553/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2601e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2554/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.1816e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2555/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2218e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2556/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.2315e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2557/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1939e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2558/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.2636e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2559/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.5190e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2560/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.7533e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2561/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 2.6107e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2562/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.5215e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2563/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.3033e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2564/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2435e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2565/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.1969e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2566/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1252e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2567/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.1362e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2568/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.1944e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2569/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2310e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2570/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.2171e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2571/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1682e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2572/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.1005e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2573/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2557e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2574/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.3721e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2575/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.5210e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2576/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3096e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2577/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3350e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2578/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2533e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2579/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3131e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2580/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1784e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2581/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2036e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2582/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1471e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2583/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.2138e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2584/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2754e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2585/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1713e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2586/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1251e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2587/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2012e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2588/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2356e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2589/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1262e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2590/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1442e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2591/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1707e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2592/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2888e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2593/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 2.5124e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2594/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.2784e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2595/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.1253e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2596/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2640e-05 - val_loss: 0.0077 - learning_rate: 7.0000e-06\n",
      "Epoch 2597/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 2.4345e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2598/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2713e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2599/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2379e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2600/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.1217e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2601/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2929e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2602/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 2.0957e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2603/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1194e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2604/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0846e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2605/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1713e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2606/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3418e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2607/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2583e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2608/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2153e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2609/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.3448e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2610/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.2002e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2611/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1068e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2612/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1167e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2613/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.1802e-05 - val_loss: 0.0079 - learning_rate: 7.0000e-06\n",
      "Epoch 2614/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.2611e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2615/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2919e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2616/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1312e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2617/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1830e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2618/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.1414e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2619/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1717e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2620/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0782e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2621/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1326e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2622/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1279e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2623/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1655e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2624/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4457e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2625/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2313e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2626/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.2595e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2627/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 2.1659e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2628/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1177e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2629/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.0711e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2630/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0451e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2631/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0457e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2632/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 2.1570e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2633/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 2.1436e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2634/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.2067e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2635/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1390e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2636/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.0694e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2637/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.0926e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2638/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1346e-05 - val_loss: 0.0078 - learning_rate: 7.0000e-06\n",
      "Epoch 2639/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.1383e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2640/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.0632e-05 - val_loss: 0.0079 - learning_rate: 7.0000e-06\n",
      "Epoch 2641/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.0434e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2642/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0713e-05 - val_loss: 0.0081 - learning_rate: 7.0000e-06\n",
      "Epoch 2643/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 2.0583e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2644/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.0465e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2645/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1378e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2646/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1928e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2647/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.3098e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2648/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2069e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2649/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.2258e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2650/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.2056e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2651/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1943e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2652/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.0705e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2653/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.0149e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2654/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9721e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2655/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0852e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2656/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.2141e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2657/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1870e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2658/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.2232e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2659/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.0813e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2660/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1359e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2661/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.2968e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2662/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0622e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2663/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.0671e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2664/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.9913e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2665/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.9704e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2666/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.0464e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2667/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0012e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2668/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 2.0766e-05 - val_loss: 0.0077 - learning_rate: 7.0000e-06\n",
      "Epoch 2669/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.1966e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2670/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.1917e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2671/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.1686e-05 - val_loss: 0.0080 - learning_rate: 7.0000e-06\n",
      "Epoch 2672/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.1874e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2673/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1760e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2674/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.0325e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2675/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0218e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2676/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0615e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2677/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3518e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2678/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0469e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2679/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9645e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2680/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0022e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2681/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9781e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2682/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.9921e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2683/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.0897e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2684/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0944e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2685/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 2.0141e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2686/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0225e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2687/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.0758e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2688/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.9699e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2689/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1753e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2690/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1170e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2691/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0086e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2692/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1242e-05 - val_loss: 0.0077 - learning_rate: 7.0000e-06\n",
      "Epoch 2693/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0026e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2694/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0519e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2695/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1885e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2696/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.0817e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2697/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9465e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2698/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 2.0311e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 2699/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0224e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2700/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0844e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2701/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9022e-05 - val_loss: 0.0064 - learning_rate: 7.0000e-06\n",
      "Epoch 2702/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9489e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2703/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9645e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2704/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.0733e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2705/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1412e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2706/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9343e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2707/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.9971e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2708/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9789e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2709/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9418e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2710/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.9636e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 2711/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9245e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2712/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9241e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2713/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9452e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2714/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.9913e-05 - val_loss: 0.0077 - learning_rate: 7.0000e-06\n",
      "Epoch 2715/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.0379e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2716/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3233e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2717/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.3043e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2718/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1921e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2719/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1511e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2720/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9712e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2721/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.0291e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2722/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9535e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2723/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9961e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2724/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9383e-05 - val_loss: 0.0078 - learning_rate: 7.0000e-06\n",
      "Epoch 2725/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9689e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2726/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8498e-05 - val_loss: 0.0077 - learning_rate: 7.0000e-06\n",
      "Epoch 2727/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9102e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2728/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.3871e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2729/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.4491e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2730/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.2859e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2731/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.1863e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2732/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0802e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2733/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 2.0293e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 01:32:40.282452: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.0614e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2734/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1289e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2735/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0089e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2736/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.0628e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2737/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0158e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2738/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8772e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2739/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8434e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2740/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9602e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2741/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9746e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2742/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.9494e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2743/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9448e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2744/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9374e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2745/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.9803e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2746/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0246e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2747/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9358e-05 - val_loss: 0.0079 - learning_rate: 7.0000e-06\n",
      "Epoch 2748/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9508e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2749/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9943e-05 - val_loss: 0.0077 - learning_rate: 7.0000e-06\n",
      "Epoch 2750/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9990e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2751/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9535e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2752/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8863e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2753/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9329e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2754/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9853e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2755/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.9191e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2756/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.9301e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2757/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8532e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2758/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8459e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2759/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9831e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2760/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.0163e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2761/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.0803e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2762/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9048e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2763/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9297e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2764/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9237e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2765/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0364e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2766/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8965e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2767/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9999e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2768/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 2.1310e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2769/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1162e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2770/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.9411e-05 - val_loss: 0.0077 - learning_rate: 7.0000e-06\n",
      "Epoch 2771/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9257e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2772/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9392e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2773/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8870e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2774/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8665e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2775/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.9247e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2776/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1259e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2777/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1151e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2778/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.9807e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2779/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8921e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2780/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9238e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2781/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.1620e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2782/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1378e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2783/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9996e-05 - val_loss: 0.0078 - learning_rate: 7.0000e-06\n",
      "Epoch 2784/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8747e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 2785/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8610e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2786/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9799e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2787/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9993e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2788/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9037e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2789/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9603e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2790/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8706e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2791/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7855e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2792/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8148e-05 - val_loss: 0.0078 - learning_rate: 7.0000e-06\n",
      "Epoch 2793/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8160e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2794/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8638e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2795/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0028e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2796/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.2168e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2797/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.1091e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2798/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.9583e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2799/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0164e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2800/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9523e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2801/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8811e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2802/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.8684e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2803/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.7696e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2804/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8759e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2805/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.7719e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2806/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7959e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2807/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.7809e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2808/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8235e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2809/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8539e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2810/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8214e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2811/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.7536e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2812/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9099e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2813/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.9427e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2814/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9231e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2815/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8173e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2816/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8669e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2817/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.9482e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2818/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.8464e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2819/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.8913e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2820/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0990e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2821/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.9824e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2822/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9046e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2823/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.9343e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2824/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9484e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2825/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8888e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2826/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0048e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2827/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.0023e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2828/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.0088e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2829/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8700e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2830/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.8465e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2831/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8550e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2832/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8700e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2833/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.9340e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2834/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.0301e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2835/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9317e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2836/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0454e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2837/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.9843e-05 - val_loss: 0.0078 - learning_rate: 7.0000e-06\n",
      "Epoch 2838/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8725e-05 - val_loss: 0.0077 - learning_rate: 7.0000e-06\n",
      "Epoch 2839/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8331e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2840/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8099e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2841/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7639e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2842/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7552e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2843/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8318e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2844/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8521e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2845/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9904e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2846/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9391e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2847/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9975e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2848/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9425e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2849/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8122e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2850/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8449e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2851/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8537e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2852/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7949e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2853/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7922e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2854/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8665e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2855/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8653e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2856/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8213e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2857/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.8227e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2858/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8925e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2859/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.9011e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2860/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9097e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2861/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8260e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2862/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8080e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2863/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8113e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2864/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7018e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2865/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8084e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2866/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8342e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2867/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9205e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2868/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9891e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2869/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8889e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2870/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8219e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2871/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8796e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2872/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 2.0252e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2873/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9921e-05 - val_loss: 0.0078 - learning_rate: 7.0000e-06\n",
      "Epoch 2874/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8290e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2875/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8629e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2876/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7731e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2877/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.6838e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2878/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6637e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2879/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.7513e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2880/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8005e-05 - val_loss: 0.0077 - learning_rate: 7.0000e-06\n",
      "Epoch 2881/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7528e-05 - val_loss: 0.0077 - learning_rate: 7.0000e-06\n",
      "Epoch 2882/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7505e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2883/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.7414e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2884/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.8328e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2885/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8691e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2886/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8102e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2887/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8794e-05 - val_loss: 0.0077 - learning_rate: 7.0000e-06\n",
      "Epoch 2888/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7646e-05 - val_loss: 0.0077 - learning_rate: 7.0000e-06\n",
      "Epoch 2889/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7367e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2890/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9060e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2891/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8326e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2892/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0117e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2893/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8371e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 2894/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.9150e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2895/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8473e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2896/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7373e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2897/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6450e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2898/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6666e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2899/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7224e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2900/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7751e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2901/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7375e-05 - val_loss: 0.0077 - learning_rate: 7.0000e-06\n",
      "Epoch 2902/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7277e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2903/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8149e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2904/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7664e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2905/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.0568e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2906/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 2.0076e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2907/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8805e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2908/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8828e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2909/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9663e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2910/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7590e-05 - val_loss: 0.0077 - learning_rate: 7.0000e-06\n",
      "Epoch 2911/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7413e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2912/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.7832e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2913/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.7216e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2914/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7361e-05 - val_loss: 0.0065 - learning_rate: 7.0000e-06\n",
      "Epoch 2915/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7543e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2916/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7152e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2917/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8690e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2918/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8842e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2919/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8772e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2920/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7809e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2921/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.7599e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2922/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.7493e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2923/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.7575e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2924/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7837e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2925/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6511e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2926/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6268e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2927/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6263e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2928/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.6339e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2929/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8675e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2930/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8479e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2931/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8693e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2932/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9012e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2933/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.4359e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2934/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.9346e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2935/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.8274e-05 - val_loss: 0.0077 - learning_rate: 7.0000e-06\n",
      "Epoch 2936/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7438e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2937/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.7235e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2938/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.6710e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2939/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.6361e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2940/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6695e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2941/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6157e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2942/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8015e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2943/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.7109e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2944/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7157e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2945/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.6625e-05 - val_loss: 0.0068 - learning_rate: 7.0000e-06\n",
      "Epoch 2946/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.6785e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2947/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6018e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2948/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7301e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2949/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.7070e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2950/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6619e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2951/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6881e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2952/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.7199e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2953/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.6910e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2954/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8018e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2955/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.9194e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2956/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8890e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2957/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8024e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2958/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7367e-05 - val_loss: 0.0077 - learning_rate: 7.0000e-06\n",
      "Epoch 2959/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.7474e-05 - val_loss: 0.0078 - learning_rate: 7.0000e-06\n",
      "Epoch 2960/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6770e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2961/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.6673e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2962/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6449e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2963/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6532e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2964/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6734e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2965/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.6092e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2966/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7581e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2967/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.7419e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2968/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7319e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2969/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9693e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2970/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9641e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2971/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8277e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2972/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7711e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2973/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6882e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2974/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6970e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2975/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6724e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2976/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6724e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2977/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6491e-05 - val_loss: 0.0080 - learning_rate: 7.0000e-06\n",
      "Epoch 2978/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.5509e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2979/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.6052e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2980/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6504e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2981/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7514e-05 - val_loss: 0.0079 - learning_rate: 7.0000e-06\n",
      "Epoch 2982/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6274e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2983/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 1.6651e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2984/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6927e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 2985/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6214e-05 - val_loss: 0.0066 - learning_rate: 7.0000e-06\n",
      "Epoch 2986/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5691e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2987/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6597e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2988/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6394e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2989/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6618e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2990/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.8062e-05 - val_loss: 0.0075 - learning_rate: 7.0000e-06\n",
      "Epoch 2991/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9138e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n",
      "Epoch 2992/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 2.1146e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2993/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9669e-05 - val_loss: 0.0076 - learning_rate: 7.0000e-06\n",
      "Epoch 2994/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.9576e-05 - val_loss: 0.0074 - learning_rate: 7.0000e-06\n",
      "Epoch 2995/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 1.7753e-05 - val_loss: 0.0069 - learning_rate: 7.0000e-06\n",
      "Epoch 2996/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.7162e-05 - val_loss: 0.0067 - learning_rate: 7.0000e-06\n",
      "Epoch 2997/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5755e-05 - val_loss: 0.0071 - learning_rate: 7.0000e-06\n",
      "Epoch 2998/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.5949e-05 - val_loss: 0.0070 - learning_rate: 7.0000e-06\n",
      "Epoch 2999/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.5797e-05 - val_loss: 0.0072 - learning_rate: 7.0000e-06\n",
      "Epoch 3000/3000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.6795e-05 - val_loss: 0.0073 - learning_rate: 7.0000e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model with the custom callback\n",
    "history = model_builder.train_model(\n",
    "    train_dataset, \n",
    "    val_dataset, \n",
    "    epochs=3000,\n",
    "    callbacks_list=[lr_scheduler]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Extract the losses from the history object\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "train_loss_x_midpoints = history.history.get('x_midpoints_reshape_loss', train_loss)\n",
    "val_loss_x_midpoints = history.history.get('val_x_midpoints_reshape_loss', val_loss)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2,1)\n",
    "plt.plot(train_loss_x_midpoints, label='Train Loss x_midpoints_reshape')\n",
    "plt.plot(val_loss_x_midpoints, label='Validation Loss x_midpoints_reshape')\n",
    "plt.xlabel('Epochs')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss ')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder.model.save(\"/home/da886/Analysis/13KFixed_Mixed_5_32by32_95index-best.keras\")\n",
    "# loaded_model = tf.keras.models.load_model(\n",
    "# \"/home/da886/Analysis/30KFixed_13_SparsespotsrandomSPOTS.keras\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1, batch shape: (800, 32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1729696519.681444  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.681483  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.682174  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.682819  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.682890  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.683060  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.683563  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.683648  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.683813  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.684204  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.684254  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.684486  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.684799  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.684876  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.685104  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.685464  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.685500  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.685676  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.686162  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.686210  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.686446  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.686767  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.686805  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.687063  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.687344  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.687406  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.687668  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.688021  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.688058  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.688307  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.688604  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.688663  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.688961  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.689310  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.689347  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.689597  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.689937  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.689978  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.690151  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.690714  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.690930  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.690955  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.691337  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.691621  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.691666  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.691966  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.692196  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.692322  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.692539  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.692867  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.692920  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.693118  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.693510  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.693559  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.693846  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.694237  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.694262  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.694437  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.694811  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.694834  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.695431  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.695487  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.695630  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.696588  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.713302  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.713577  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.713726  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.714066  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.714191  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.714389  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.714747  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.714878  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.715058  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.715388  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.715429  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.715612  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.715944  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.716018  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.716272  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.716520  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.716573  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.716890  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.717185  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.717227  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.717520  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.717762  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.717811  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.718136  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.718368  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.718479  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.718699  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.718930  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.719110  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.719350  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.719568  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.719728  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.720017  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.720316  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.720378  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.720660  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.720912  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.720986  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.721278  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.721509  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.721612  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.721931  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.722169  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.722212  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.722536  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.722759  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.722893  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.723099  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.723325  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.723557  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.723754  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.723969  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.724236  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.724452  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.724646  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.724871  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.725096  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.725297  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.725489  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.725775  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.726221  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.726234  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.726492  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.726757  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.726814  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.727055  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.727304  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.727343  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.727696  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.727915  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.727947  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.728678  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.728693  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.728727  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.729324  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.729339  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.729459  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.730143  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.730212  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.730238  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.730601  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.741545  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.741665  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.741884  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.742077  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.742266  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.742446  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.742632  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.742814  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.742996  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.743183  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.743372  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.743555  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.743740  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.743925  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.744109  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.744291  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.744488  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.744499  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.744691  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.745042  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.745124  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.745250  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.745507  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.745792  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.745814  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.746024  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.746218  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.746336  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.746472  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.746755  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.747022  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.747034  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.747189  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.747624  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.747641  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.747791  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.748210  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.748227  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.748348  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.748679  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.748977  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.749035  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.749274  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.749540  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.749573  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.749720  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.750056  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.750193  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.750288  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.750576  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.750917  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.751241  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.751751  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.751849  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.752129  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.752369  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.752437  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.752559  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.752712  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.753047  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.753283  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.753301  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.753445  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.753911  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.753940  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.753965  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.754309  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.754377  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.754636  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.754738  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.754818  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.755027  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.755208  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.755396  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.755581  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.755765  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.755946  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.756132  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.756312  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.756614  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.756798  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.756847  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.757064  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.757342  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.757419  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.757591  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.757765  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.758032  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.758087  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.758290  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.758526  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.758599  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.758727  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.759030  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.759243  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.759252  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.759504  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.759759  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.759833  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.759965  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.760223  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.760491  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.760504  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.760703  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.761041  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.761065  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.761215  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.761485  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.761602  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.761799  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.762102  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.762118  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.762258  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.762684  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.763022  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.763306  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.763586  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.763874  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.764150  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.764431  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.764711  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.764986  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.765285  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.765641  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.766041  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.766345  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.768082  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.768235  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.768426  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.768623  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.768817  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.769008  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.769199  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.769386  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.769571  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.769759  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.769947  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.770143  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.770325  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.770508  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.770696  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.770879  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.771066  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.771250  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.771432  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.771611  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.771795  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.771980  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.772151  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.772177  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.772371  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.772617  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.772824  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.772957  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.773093  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.773348  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.773539  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.773638  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.773928  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.774152  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.774269  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.774591  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.774671  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.774779  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.774991  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.775280  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.775499  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.775613  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.775890  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.775916  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.776171  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.776333  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.776431  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.776748  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.776831  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.777086  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.777458  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.777825  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.778237  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.778646  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.779285  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.779301  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.779525  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.779844  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.779947  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.780316  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.780553  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.780607  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.780769  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.780907  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.781095  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.781271  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.781455  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.781641  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.781827  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.782013  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.782204  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.782386  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.782577  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.782754  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.782949  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.783128  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.783319  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.783506  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.783698  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.783888  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.784346  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.784356  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.784371  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.784888  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.784903  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.784934  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.785443  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.785457  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.785481  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.785982  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.785997  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.786018  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.786520  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.786535  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.786557  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.787067  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.787079  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.787099  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.787448  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.787703  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.787800  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.787992  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.788294  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.788317  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.788448  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.788792  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.788926  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.788949  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.789492  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.789509  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.789535  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.789925  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.790213  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.790349  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.790691  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.790777  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.791150  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.791245  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.791577  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.791847  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.792113  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.792384  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.792813  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.793120  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.793435  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.793777  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.795486  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.795780  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.796040  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.796297  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.796547  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.796799  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.796955  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.797130  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.797336  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.797528  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.797723  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.797913  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.798108  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.798292  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.798483  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.798677  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.798864  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.799054  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.799203  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.799498  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.799570  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.799690  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.799977  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.800077  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.800473  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.800487  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.800603  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.800807  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.801203  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.801339  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.801449  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.801565  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.801803  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.801912  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.802208  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.802335  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.802604  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.802918  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.802955  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.803192  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.803331  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.803623  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.803829  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.803908  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.804262  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.804360  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.804548  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.804818  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.805052  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.805317  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.805562  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.805761  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.806058  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.806569  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.806994  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.807476  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.807909  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.809059  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.809298  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.809541  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.809783  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.810031  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.810284  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.810546  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.810797  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.811058  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.811337  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.811653  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.811841  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.812034  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.812220  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.812413  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.812595  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.812781  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.812977  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.813161  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.813358  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.813549  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.813822  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.814130  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.814176  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.814360  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.814675  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.814941  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.814974  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.815186  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.815475  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.815489  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.815650  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.815966  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.816148  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.816274  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.816490  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.816686  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.816758  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.816953  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.817190  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.817482  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.817537  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.817669  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.817935  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.818190  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.818466  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.818537  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.818663  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.818877  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.819211  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.819437  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.819611  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.819883  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.819987  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.820310  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.820411  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.820809  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.820890  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.821323  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.821407  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.821621  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.821944  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.822049  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.822364  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.822648  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.822747  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.823173  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.823601  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.824197  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.824611  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.825014  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.825292  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.825565  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.825851  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.826137  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.826429  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.826719  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.827011  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.827312  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.827624  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.827935  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.828244  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.828416  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.828624  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.828842  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.829045  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.829256  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.829450  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.829657  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.829866  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.829962  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.830093  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.830623  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.830699  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.830706  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.831276  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.831291  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.831300  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.831874  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.831909  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.831992  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.832401  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.832516  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.832693  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.832843  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.833037  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.833349  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.833713  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.833733  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.833848  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.834117  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.834275  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.834787  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.834908  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.835014  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.835270  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.835780  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.835930  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.835950  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.836555  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.836763  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.837201  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.837424  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.838015  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.838236  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.838663  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.838918  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.839578  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.839684  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.840256  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.840917  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.846057  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.851405  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.851689  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.851919  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.851976  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.852398  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.852455  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.852603  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.852925  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.853070  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.853156  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.853467  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.853696  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.853735  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.854141  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.854302  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.854395  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.854712  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.854852  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.854954  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.855278  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.855439  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.855525  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.855843  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.855989  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.856095  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.856409  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.856552  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.856643  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.857092  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.857177  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.857278  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.857735  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.857916  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.857965  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.858261  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.858478  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.858560  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.859106  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.859176  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.859322  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.859635  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.859716  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.860362  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.860371  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.860475  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.860870  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.860952  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.861407  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.861491  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.861855  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.862199  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.862209  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.862594  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.862758  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.863108  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.863208  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.863696  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.864152  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.864235  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.864535  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.865250  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.865519  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.866215  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.870659  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.871023  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.871340  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.871659  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.871663  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.872148  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.872234  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.872679  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.872767  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.873180  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.873259  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.873688  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.873770  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.874226  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.874307  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.874852  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.874866  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.875363  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.875447  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.875862  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.875960  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.876257  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.876719  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.876834  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.877074  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.877856  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.877961  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.878991  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.879074  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.880042  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.880415  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.881389  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.881495  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1729696519.882599  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.882611  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.883570  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.884792  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.885725  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.886145  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.886470  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.886802  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.887121  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.887446  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.887768  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.888091  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.888401  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.888732  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.889065  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.889395  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.889726  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.890088  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.890475  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.890868  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.891260  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.891680  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.892118  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.892554  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.893536  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.894482  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.901507  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.901845  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.902172  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.902471  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.902818  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.903178  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.904291  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.904680  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.905153  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.905825  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.906540  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.907211  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.908001  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.908067  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.908340  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.908763  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.908836  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.909395  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.909401  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.909427  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.909874  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.909969  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.910433  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.910444  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.911109  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.911145  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.911219  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.911574  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.911658  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.912160  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.912178  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.912669  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.912748  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.913184  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.913262  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.913798  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.913813  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.914372  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.914483  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.914915  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.915013  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.915491  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.915576  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.916067  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.916145  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.916670  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.916751  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.917274  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.917360  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.917928  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.918016  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.918456  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.919073  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.919170  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.920197  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.920299  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.920503  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.920819  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.921279  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.921304  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.921612  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.922125  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.922434  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.922866  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.923193  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.923494  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.923860  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.924241  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.924645  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.924974  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.925347  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.925668  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.926000  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.926421  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.926826  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.927302  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.927721  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.927820  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.928072  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.928523  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.928594  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.928604  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.929017  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.929128  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.929538  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.929647  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.929975  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.930212  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.930226  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.930651  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.930826  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.931094  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.931544  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.931730  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.932149  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.932255  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.932855  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.932957  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.933665  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.933769  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.934368  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.934641  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.935224  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.935500  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.936070  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.936635  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.937205  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.937251  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.937567  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.937836  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.938248  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.938321  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.938656  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.938790  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.938954  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.939236  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.939506  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.939965  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.940467  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.940981  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.941550  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.942106  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.943088  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.944328  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.945937  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.946205  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.946494  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.946774  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.947074  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.947336  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.947599  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.947869  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.948146  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.948515  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.948794  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.949091  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.949386  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.949757  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.950104  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.950514  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.950647  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.951114  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.951206  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.951214  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.951752  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.951797  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.952187  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.952357  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.952461  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.952776  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.952919  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.953000  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.953460  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.953635  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.953652  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.954242  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.954326  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.954347  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.954614  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.954818  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.955017  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.955189  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.955577  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.955715  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.955731  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.956081  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.956308  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.956449  413937 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.956588  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.956764  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.956957  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.957290  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.957394  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.957883  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.957924  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.958420  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.958503  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.959071  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.959087  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.959452  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.959622  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.959876  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.960222  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.960326  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.960882  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.960969  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.961586  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.961684  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.962226  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.962837  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.963372  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.969779  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.970109  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.970347  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.970372  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.970806  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.970883  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.971291  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.971302  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.971705  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.971816  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.972025  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.972221  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.972412  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.972658  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.972766  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.973104  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.973202  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.973595  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.973770  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.974226  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.974334  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.974827  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.974930  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.975421  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.975572  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.975983  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.976564  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.976976  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.977853  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.978263  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.979472  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.979847  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.979943  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.980188  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.980387  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.980637  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.980748  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.981053  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.981176  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.981434  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.981566  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.981811  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.981942  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.982219  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.982343  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.982550  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.982707  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.983075  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.983156  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.983461  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.983569  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.983792  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.983978  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.984230  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.984334  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.984751  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.984836  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.985218  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.985324  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.985626  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.985790  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.986099  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.986201  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.986548  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.986832  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.987363  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.987446  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.987894  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.987996  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.988492  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.988576  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.989023  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.989639  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.990287  413893 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.990375  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729696519.990871  413895 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Processing batch 3, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Processing batch 4, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Processing batch 5, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Processing batch 6, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Processing batch 7, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Processing batch 8, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Processing batch 9, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Processing batch 10, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Processing batch 11, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Processing batch 12, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Processing batch 13, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the function for visualizing midpoints\n",
    "def visualize_midpoints(image, midpoints, title=\"Predicted Midpoint Visualization\"):\n",
    "    \"\"\"\n",
    "    Visualizes midpoints on an image without using a probability vector.\n",
    "\n",
    "    Parameters:\n",
    "    - image: A 3D tensor representing the image.\n",
    "    - midpoints: A 2D tensor representing the midpoint coordinates (x, y).\n",
    "    - title: The title of the plot.\n",
    "\n",
    "    Returns:\n",
    "    None (displays the image with midpoints).\n",
    "    \"\"\"\n",
    "    # Convert to NumPy arrays for easier handling\n",
    "    image_np = image\n",
    "    midpoints_np = midpoints\n",
    "\n",
    "    # Denormalize image if necessary (adjust based on your normalization method)\n",
    "    denormalized_image = image_np  # Modify if normalization was applied during training\n",
    "\n",
    "    # Visualize the image\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(denormalized_image, cmap='gray')\n",
    "    plt.title(title)\n",
    "\n",
    "    # Plot midpoints directly, only if they are not (0, 0)\n",
    "    for i, (x, y) in enumerate(midpoints_np):\n",
    "        if x >= 0 and y >= 0:  # Only plot if the point is not (0, 0)\n",
    "            plt.scatter(x, y, color='red', s=5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Create the validation dataset\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n",
    "# val_dataset = val_dataset.batch(800)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)\n",
    "# # Initialize lists to collect the data\n",
    "all_images = []\n",
    "all_true_midpoints = []\n",
    "all_pred_midpoints = []\n",
    "\n",
    "# # Loop through each batch in the validation dataset, predict, and collect results\n",
    "# for i, (data_batch, midpoints_batch) in enumerate(val_dataset):\n",
    "\n",
    "for i, (data_batch, midpoints_batch) in enumerate(train_dataset):\n",
    "    print(f\"Processing batch {i + 1}, batch shape: {data_batch.shape}\")\n",
    "    \n",
    "    # Get the model predictions\n",
    "    predictions =model_builder.model.predict(data_batch)\n",
    "\n",
    "    # Extend the lists to store data from each batch\n",
    "    all_images.extend(data_batch.numpy())  # Store all images\n",
    "    all_true_midpoints.extend(midpoints_batch.numpy())  # Store all true midpoints\n",
    "    all_pred_midpoints.extend(predictions)  # Store all predicted midpoints\n",
    "\n",
    "# Convert lists to arrays for easier indexing\n",
    "all_images = np.array(all_images)\n",
    "all_true_midpoints = np.array(all_true_midpoints)\n",
    "all_pred_midpoints = np.array(all_pred_midpoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "# train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9600, 32, 32), (9600, 1, 13, 2), (9600, 1, 13, 2))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images.shape,all_pred_midpoints.shape,all_true_midpoints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Select an index to visualize from the entire dataset\n",
    "index_to_visualize = np.random.randint(0, len(all_images))\n",
    "\n",
    "# index_to_visualize = 11548\n",
    "# Visualize the selected image with predicted and true midpoints\n",
    "visualize_midpoints(all_images[index_to_visualize], all_pred_midpoints[index_to_visualize, 0, :, :] * np.max(centers), title=\"Predicted Midpoints\")\n",
    "visualize_midpoints(all_images[index_to_visualize], all_true_midpoints[index_to_visualize, 0, :, :] * np.max(centers), title=\"Ground Truth Midpoints\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0009482383, 30.999704)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(all_pred_midpoints)*np.max(centers),np.max(all_pred_midpoints)*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 31.0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(all_true_midpoints)*np.max(centers),np.max(all_true_midpoints)*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0, 0.0, 31.0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(train_images), np.max(train_images), np.min(train_midpoints)*np.max(centers), np.max(train_midpoints)*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 4.2590027,  3.908059 ],\n",
       "         [27.263153 ,  4.3831873],\n",
       "         [ 5.8743353,  6.6574388],\n",
       "         [14.020337 ,  8.760142 ],\n",
       "         [ 4.1754484, 10.7192545],\n",
       "         [ 4.123699 , 11.2907295],\n",
       "         [22.326601 , 11.401616 ],\n",
       "         [ 7.203351 , 12.493043 ],\n",
       "         [ 5.814977 , 12.613149 ],\n",
       "         [21.202332 , 14.556165 ],\n",
       "         [ 8.0557995, 17.444569 ],\n",
       "         [ 8.055367 , 18.544151 ],\n",
       "         [ 5.2744675, 26.596989 ]]], dtype=float32),\n",
       " array([[[ 4.,  3.],\n",
       "         [28.,  6.],\n",
       "         [ 6.,  7.],\n",
       "         [14.,  9.],\n",
       "         [ 4., 10.],\n",
       "         [ 4., 10.],\n",
       "         [22., 11.],\n",
       "         [ 7., 12.],\n",
       "         [ 6., 14.],\n",
       "         [21., 15.],\n",
       "         [ 8., 17.],\n",
       "         [ 8., 18.],\n",
       "         [ 5., 28.]]], dtype=float32))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pred_midpoints[2]*np.max(centers),all_true_midpoints[2]*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1., 35., 12.],\n",
       "        [ 1., 63., 52.],\n",
       "        [ 1., 11., 43.],\n",
       "        ...,\n",
       "        [ 1., 10., 33.],\n",
       "        [ 1., 11., 48.],\n",
       "        [ 1., 59., 49.]],\n",
       "\n",
       "       [[ 1.,  5., 24.],\n",
       "        [ 1., 34., 55.],\n",
       "        [ 1., 42., 29.],\n",
       "        ...,\n",
       "        [ 1.,  2., 55.],\n",
       "        [ 1., 13., 17.],\n",
       "        [ 1., 45.,  8.]],\n",
       "\n",
       "       [[ 1., 38., 36.],\n",
       "        [ 1., 11., 33.],\n",
       "        [ 1., 40., 40.],\n",
       "        ...,\n",
       "        [ 1., 45.,  5.],\n",
       "        [ 1.,  8.,  7.],\n",
       "        [ 1., 55., 37.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1., 50., 18.],\n",
       "        [ 1., 20., 19.],\n",
       "        [ 1., 63.,  8.],\n",
       "        ...,\n",
       "        [ 1., 32., 44.],\n",
       "        [ 1., 63., 24.],\n",
       "        [ 1., 51., 52.]],\n",
       "\n",
       "       [[ 1.,  6., 33.],\n",
       "        [ 1., 23., 59.],\n",
       "        [ 1., 13., 48.],\n",
       "        ...,\n",
       "        [ 1., 26., 62.],\n",
       "        [ 1., 20., 42.],\n",
       "        [ 1., 53.,  2.]],\n",
       "\n",
       "       [[ 1., 24., 40.],\n",
       "        [ 1., 30., 43.],\n",
       "        [ 1., 38., 55.],\n",
       "        ...,\n",
       "        [ 1., 31., 56.],\n",
       "        [ 1., 21., 50.],\n",
       "        [ 1., 15.,  6.]]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[2],)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize variables to track the min and max MSE\n",
    "min_mse = float('inf')\n",
    "max_mse = float('-inf')\n",
    "min_mse_index = -1\n",
    "max_mse_index = -1\n",
    "\n",
    "# Loop through each prediction to calculate the MSE\n",
    "for i in range(len(all_pred_midpoints)):\n",
    "    mse = np.mean((all_pred_midpoints[i] - all_true_midpoints[i]) **2)\n",
    "    \n",
    "    if mse < min_mse:\n",
    "        min_mse = mse\n",
    "        min_mse_index = i\n",
    "    \n",
    "    if mse > max_mse:\n",
    "        max_mse = mse\n",
    "        max_mse_index = i\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot an image with its centers\n",
    "def plot_image_with_centers(image, true_center, predicted_center, title):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image.squeeze(), cmap='gray')  # Display the image\n",
    "\n",
    "    # Plot the actual center (Groundtruth)\n",
    "    plt.scatter(true_center[:, 0], true_center[:, 1], color='green', label='Groundtruth', s=10)\n",
    "\n",
    "    # Plot the predicted center\n",
    "    plt.scatter(predicted_center[:, 0], predicted_center[:, 1], color='red', label='Predictions', s=10)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the image with the least MSE\n",
    "plot_image_with_centers(all_images[min_mse_index],\n",
    "                        all_true_midpoints[min_mse_index][0] * np.max(centers),  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[min_mse_index][0] * np.max(centers),  # Adjust for scaling if needed\n",
    "                        f'Image with Least MSE. MSE: {min_mse:.4f}')\n",
    "\n",
    "# Plotting the image with the largest MSE\n",
    "plot_image_with_centers(all_images[max_mse_index],\n",
    "                        all_true_midpoints[max_mse_index][0] * np.max(centers),  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[max_mse_index][0] * np.max(centers),  # Adjust for scaling if needed\n",
    "                        f'Image with Largest MSE. MSE: {max_mse:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5266"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_mse_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "objectdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
