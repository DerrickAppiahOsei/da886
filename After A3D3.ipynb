{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:32:21.745090: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-23 15:32:21.757850: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-23 15:32:21.770710: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-23 15:32:21.774562: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-23 15:32:21.785609: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-23 15:32:22.410476: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:32:26.970153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79196 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:45:00.0, compute capability: 8.0\n",
      "2024-10-23 15:32:26.971819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 79196 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:46:00.0, compute capability: 8.0\n",
      "2024-10-23 15:32:26.973142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 79196 MB memory:  -> device: 2, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:49:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"  # Only GPUs 0 and 1 will be visible to TensorFlow\n",
    "\n",
    "import tensorflow as tf\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\",\"/gpu:2\"])\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# DataLoader Class Definition\n",
    "# -----------------------------\n",
    "class DataLoader:\n",
    "    def __init__(self, h5_filename):\n",
    "        self.h5_filename = h5_filename\n",
    "        self.images, self.centers = self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        with h5py.File(self.h5_filename, 'r') as f:\n",
    "            images = np.array(f['images'])\n",
    "            centers = np.array(f['centers_training'])\n",
    "        return images, centers\n",
    "\n",
    "    def plot_image_with_centers(self, image_index=None):\n",
    "        if image_index is None:\n",
    "            image_index = np.random.randint(0, len(self.images))\n",
    "\n",
    "        image = self.images[image_index]\n",
    "        centers = self.centers[image_index]\n",
    "\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        valid_centers = centers[centers[:, 0] == 1]\n",
    "        for center in valid_centers:\n",
    "            plt.scatter(center[1], center[2], c='red', marker='o',s=5)  # center[1] is x and center[2] is y\n",
    "        plt.title('Image with Valid Centers Marked')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_centers(centers):\n",
    "        return centers[np.lexsort((centers[:, 0], centers[:, 1]))]\n",
    "\n",
    "    def normalize_data(self):\n",
    "        normalized_images = self.images / np.max(self.images)\n",
    "        sorted_centers = np.array([self.sort_centers(image_centers[:, 1:]) for image_centers in self.centers])\n",
    "        normalized_centers = sorted_centers / np.max(centers)\n",
    "\n",
    "        normalized_midpoints = tf.expand_dims(normalized_centers, axis=1)\n",
    "        return normalized_images, normalized_midpoints.numpy()\n",
    "\n",
    "    def split_data(self, train_size=0.8, random_state=42):\n",
    "        normalized_images, normalized_midpoints_np = self.normalize_data()\n",
    "        return train_test_split(normalized_images, normalized_midpoints_np, train_size=train_size, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Utility Function Definition\n",
    "# -----------------------------\n",
    "def plot_transposed_images_with_midpoints(dataset, image_indices=[0, 1, 2, 3]):\n",
    "    \"\"\"\n",
    "    Extracts multiple images and their midpoints from the given dataset, transposes the images, \n",
    "    corrects the midpoints, and plots the transposed images with the corrected midpoints.\n",
    "\n",
    "    Args:\n",
    "    - dataset (tf.data.Dataset): The dataset from which to extract the images and midpoints.\n",
    "    - image_indices (list): The indices of the images in the batch to visualize. Default is [0, 1, 2, 3].\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract a sample image batch and its corresponding midpoints from the dataset\n",
    "    sample_image_batch, sample_midpoints_batch = next(iter(dataset))\n",
    "\n",
    "    # Create a figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(6, 6))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(image_indices):\n",
    "            # Select the specified image and corresponding midpoints from the batch\n",
    "            sample_image = np.array(sample_image_batch[image_indices[i]])\n",
    "            sample_midpoints = np.array(sample_midpoints_batch[image_indices[i]])\n",
    "\n",
    "            # Transpose the image\n",
    "            transposed_image = sample_image.T\n",
    "\n",
    "            # Correct the midpoints by swapping the x and y coordinates\n",
    "            transposed_midpoints_corrected = sample_midpoints[:, :, [1, 0]]\n",
    "\n",
    "            # Plot the transposed image with corrected midpoints\n",
    "            ax.imshow(transposed_image, cmap='gray')\n",
    "            ax.scatter(\n",
    "                transposed_midpoints_corrected[:, :, 0] * 31, \n",
    "                transposed_midpoints_corrected[:, :, 1] * 31, \n",
    "                c='red', marker='o', s=5\n",
    "            )\n",
    "            ax.set_title(f'Image {image_indices[i]} for this batch')\n",
    "        else:\n",
    "            ax.axis('off')  # If fewer than 4 images are requested, hide the unused subplots\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Custom Loss and Callback Definitions\n",
    "# -----------------------------\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def custom_loss(exponent):\n",
    "    def loss(y_true, y_pred):\n",
    "        diff = tf.abs(y_true - y_pred)\n",
    "        powered_diff = tf.pow(diff, exponent)\n",
    "        return tf.reduce_mean(powered_diff)\n",
    "    return loss\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class DynamicExponentCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, initial_exponent, increment, update_frequency):\n",
    "        super().__init__()\n",
    "        self.exponent = initial_exponent\n",
    "        self.increment = increment\n",
    "        self.update_frequency = update_frequency\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.update_frequency == 0:\n",
    "            self.exponent += self.increment\n",
    "            print(f\"\\nEpoch {epoch + 1}: Increasing exponent to {self.exponent}\")\n",
    "            self.model.loss = self.custom_loss(self.exponent)\n",
    "\n",
    "    def custom_loss(self, exponent):\n",
    "        def loss(y_true, y_pred):\n",
    "            diff = tf.abs(y_true - y_pred)\n",
    "            powered_diff = tf.pow(diff, exponent)\n",
    "            return tf.reduce_mean(powered_diff)\n",
    "        return loss\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'initial_exponent': self.exponent,\n",
    "            'increment': self.increment,\n",
    "            'update_frequency': self.update_frequency,\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my NEW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, regularizers\n",
    "import tensorflow as tf\n",
    "\n",
    "class ModelBuilder:\n",
    "    def __init__(self, input_shape=(32, 32, 1), num_classes=5, num_coordinates=2, learning_rate=1e-4, weights_path=None, l1_reg=0.001, l2_reg=0.01):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.num_coordinates = num_coordinates\n",
    "        self.learning_rate = learning_rate\n",
    "        self.l1_reg = l1_reg\n",
    "        self.l2_reg = l2_reg\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        # Load weights if a path is provided\n",
    "        if weights_path is not None:\n",
    "            self.model.load_weights(weights_path)\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "\n",
    "    def build_model(self):\n",
    "        \n",
    "        l1 = regularizers.l1(self.l1_reg)\n",
    "        l2 = regularizers.l2(self.l2_reg)\n",
    "        \n",
    "        # # CBAM Attention Block\n",
    "        # def cbam_block(input_tensor, reduction_ratio=16):\n",
    "        #     \"\"\"CBAM block, which includes channel and spatial attention\"\"\"\n",
    "        #     # Channel Attention\n",
    "        #     channel_attention = layers.GlobalAveragePooling2D()(input_tensor)\n",
    "        #     channel_attention = layers.Reshape((1, 1, input_tensor.shape[-1]))(channel_attention)\n",
    "        #     channel_attention = layers.Dense(input_tensor.shape[-1] // reduction_ratio, activation='relu')(channel_attention)\n",
    "        #     channel_attention = layers.Dense(input_tensor.shape[-1], activation='sigmoid')(channel_attention)\n",
    "        #     x = layers.Multiply()([input_tensor, channel_attention])\n",
    "\n",
    "        #     # Spatial Attention\n",
    "        #     avg_pool = layers.Lambda(lambda x: tf.reduce_mean(x, axis=-1, keepdims=True))(x)\n",
    "        #     max_pool = layers.Lambda(lambda x: tf.reduce_max(x, axis=-1, keepdims=True))(x)\n",
    "        #     concat = layers.Concatenate(axis=-1)([avg_pool, max_pool])\n",
    "        #     spatial_attention = layers.Conv2D(1, kernel_size=7, padding='same', activation='sigmoid')(concat)\n",
    "        #     x = layers.Multiply()([x, spatial_attention])\n",
    "\n",
    "        #     return x\n",
    "    \n",
    "        x_input = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x_input)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = cbam_block(x)  # Add CBAM block here\n",
    "\n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        \n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        # x = cbam_block(x)  # Add CBAM block here\n",
    "        \n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        # x = cbam_block(x)  # Add CBAM block here\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        \n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        # x = cbam_block(x)  # Add CBAM block here\n",
    "        \n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Flatten()(x)\n",
    "        \n",
    "        x_midpoints = layers.Dense(self.num_classes * self.num_coordinates, activation='sigmoid', name='x_midpoints')(x)\n",
    "        x_midpoints_reshape = layers.Reshape((-1, self.num_classes, self.num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "        \n",
    "        return tf.keras.models.Model(x_input, x_midpoints_reshape)\n",
    "\n",
    "    def compile_model(self, loss_function):\n",
    "        self.model.compile(optimizer=self.optimizer, loss=loss_function)\n",
    "\n",
    "    def train_model(self, train_dataset, val_dataset, epochs, callbacks_list):\n",
    "        history = self.model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks_list)\n",
    "        return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Main Script Execution\n",
    "# -----------------------------\n",
    "\n",
    "# Load data\n",
    "# h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KFixed_Mixed_13.h5'             \n",
    "h5_filename = '/home/da886/Final Electron counting project/Images and Labels/33KFixed_Mixed_5_32by32_95index.h5'\n",
    "# h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KFixed_13_SparsespotsRandomIndex.h5'\n",
    "# h5_filename ='/home/da886/Final Electron counting project/Images and Labels/30KFixed-index6_13.h5'\n",
    "data_loader = DataLoader(h5_filename)\n",
    "images, centers = data_loader.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x7f224c4515d0>, 23847)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l=np.random.randint(0,len(centers))\n",
    "data_loader.plot_image_with_centers(l)\n",
    "plt.imshow(images[l]),l\n",
    "# plt.grid(True),l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x7f224c495ed0>, 23847)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[l]),l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., 27., 13.],\n",
       "       [ 1., 16.,  5.],\n",
       "       [ 1., 22., 11.],\n",
       "       [ 1., 26.,  8.],\n",
       "       [ 1.,  7.,  6.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.random.randint(0,len(centers))\n",
    "centers[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the data and split it into training and validation sets\n",
    "train_images, val_images, train_midpoints, val_midpoints = data_loader.split_data()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0, 0.0, 1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(train_images), np.max(train_images), np.min(train_midpoints), np.max(train_midpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images: (26400, 32, 32), Train Midpoints: (26400, 1, 5, 2)\n",
      "Validation Images: (6600, 32, 32), Validation Midpoints: (6600, 1, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 1000\n",
    "train_dataset = train_dataset.shuffle(buffer_size=8000, reshuffle_each_iteration=True).batch(batch_size)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=8000).batch(batch_size)\n",
    "\n",
    "# Check the shape of the datasets\n",
    "print(f'Train Images: {train_images.shape}, Train Midpoints: {train_midpoints.shape}')\n",
    "print(f'Validation Images: {val_images.shape}, Validation Midpoints: {val_midpoints.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_transposed_images_with_midpoints(train_dataset, image_indices=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set up learning rate scheduler\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.9, patience=10, verbose=1, mode='min', min_lr=7e-6\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,250</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m1,179,904\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m10,250\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m2\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,234,186</span> (31.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,234,186\u001b[0m (31.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,234,186</span> (31.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,234,186\u001b[0m (31.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# dynamic_exponent_callback = DynamicExponentCallback(2, 1, 400)\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    model_builder = ModelBuilder()\n",
    "\n",
    "    model_builder.build_model()\n",
    "\n",
    "    model_builder.model.summary()\n",
    "\n",
    "    model_builder.compile_model(loss_function=tf.keras.losses.MeanSquaredError()) \n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:33:43.945088: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/cond/else/_279/cond/StatefulPartitionedCall/functional_1/dropout_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-10-23 15:33:46.229522: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-23 15:33:46.240862: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-23 15:33:46.267643: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1729697626.336959 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.345929 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.346185 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.385094 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.385249 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.385409 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.387800 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.388002 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.388106 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.388278 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.388659 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.388874 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.388974 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.389230 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.389631 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.389638 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.389826 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.390132 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.392290 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.392338 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.392455 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.393024 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.393080 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.393200 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.393722 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.393845 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.393957 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.397435 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.397627 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.397738 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.397926 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.398337 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.398563 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.398559 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.399101 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.399339 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.399379 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.399622 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.400043 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.400168 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.400362 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.400829 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.400975 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.401363 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.401567 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.402121 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.402177 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.402271 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.402824 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.402938 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.403392 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.413374 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.413857 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.413880 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.414098 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.414573 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.414731 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.414846 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.415226 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.415687 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.415710 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.415860 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.416515 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.416655 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.416739 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.417348 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.437361 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.437368 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.438079 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.440185 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.440432 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.440457 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.440632 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.441125 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.441214 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.470892 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.471122 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.471166 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.478829 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.479001 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.479207 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.481062 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.481177 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.481429 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.481742 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.481882 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.482062 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.484083 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.484341 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.484533 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.486156 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.486479 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.486587 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.487427 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.487443 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.487459 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.487931 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.490246 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.490611 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.490729 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.491385 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.491886 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.492123 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.492473 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.493047 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.493811 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.494571 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.494600 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.494983 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.503927 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.504195 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.504211 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.526993 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.526999 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.527029 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.604482 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.607932 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.608297 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.608671 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.609067 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.609412 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.609784 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.611176 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.612489 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.618388 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.619244 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.620433 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.621731 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.622987 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.643672 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.644016 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.644386 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.644764 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.645150 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.645540 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.645936 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.646348 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.646765 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.647183 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.648906 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.650259 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.652415 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.654496 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.656164 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.656661 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.657483 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.658200 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.658691 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.659364 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.660181 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.668613 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.669040 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.669438 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.669878 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.670260 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.670689 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.671106 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.671533 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.671945 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.672475 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.672958 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.673469 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.674787 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.676056 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.678467 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.680865 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.682474 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.684101 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.685331 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.726065 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.726501 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.726934 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.727357 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.727799 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.728225 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.728655 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.729123 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.729603 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.730097 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.730603 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.731122 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.731672 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.732270 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.732904 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.733579 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.734824 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.735434 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.736125 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.737241 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.738255 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.739588 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.831765 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.833001 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.833358 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.833736 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.834132 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.834483 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.834853 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.836295 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.837622 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.838541 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.839379 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.840568 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.841859 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.843127 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.855192 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.856599 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.856966 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.857342 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.857733 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.858095 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.858477 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.859868 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.861180 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.862641 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.863483 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.863934 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.864271 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.864751 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.864824 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.865134 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.865522 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.865903 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.866126 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.866316 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.866730 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.867136 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.867405 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.867578 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.868264 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.868919 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.869630 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.870273 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.870898 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.871380 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.872198 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.872907 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.873392 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.874065 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.874887 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.888123 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.888468 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.888833 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.889212 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.889597 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.889986 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.890384 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.890796 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.891217 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.891631 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.892334 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.892915 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.893552 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.894210 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.894898 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.895377 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.896185 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.896888 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.897367 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.897916 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.898598 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.899402 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.908010 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.908459 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.908853 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.909293 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.909680 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.910112 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.910527 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.910954 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.911365 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.911899 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.912382 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.912894 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.914217 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.915501 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.917898 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.920297 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.921926 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.923566 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.924800 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.934013 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.934454 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.934846 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.935291 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.935670 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.936099 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.936511 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.936932 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.937342 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.937876 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.938369 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.938882 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.940202 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.941478 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.943917 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.946337 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.947942 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.949586 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.950815 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.965710 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.966130 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.966563 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.966994 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.967446 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.967871 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.968307 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.968779 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.969262 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.969750 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.970267 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.970795 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.971346 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.971945 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.972581 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.973265 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.974503 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.975118 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.975810 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.976927 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.977728 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.979067 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.980529 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.991925 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.992334 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.992759 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.993187 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.993634 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.994060 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.994497 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.994970 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.995446 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.995935 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.996443 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.996958 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.997513 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.998112 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.998758 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697626.999435 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.000689 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.001297 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.001998 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.003119 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.004131 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.005479 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.194290 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.194921 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.195446 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.196066 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.196665 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.197175 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.197712 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.198256 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.198815 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.199603 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.200305 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.201061 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.203425 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.205719 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.207666 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.210611 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.215095 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.218094 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.222689 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.303553 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.304128 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.304680 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.305250 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.305808 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.306384 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.306956 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.307568 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.308221 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.308907 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.309573 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.310273 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.311005 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.311849 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.312720 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.314693 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.315604 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.316571 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.317613 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.319481 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.321826 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.330438 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.331179 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.331893 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.332701 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.333394 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.334152 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.335005 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.335742 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.336611 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.337330 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.338107 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.338903 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.342431 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.346731 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.350918 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.354278 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.358975 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.363758 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.372280 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.425224 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.425861 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.426390 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.427013 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.427613 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.428128 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.428668 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.429213 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.429781 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.430572 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.431279 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.432035 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.434417 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.436731 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.438651 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.441580 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.446090 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.449051 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.453784 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.458672 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.459314 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.459838 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.460473 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.461068 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.461584 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.462125 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.462674 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.463242 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.464032 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.464736 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.465485 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.467873 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.470197 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.472161 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.475096 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.479630 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.482613 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.487249 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.533269 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.534053 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.534930 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.535173 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.535847 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.535957 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.536626 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.536744 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.537228 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.537596 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.537813 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.538443 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.538559 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.539040 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.539426 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.539677 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.540498 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.540528 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.541200 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.541694 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.541884 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.542698 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.542802 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.543452 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.543864 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.544311 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.544918 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.545203 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.546267 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.547159 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.547698 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.548091 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.549177 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.549295 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.550245 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.551421 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.552692 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.553310 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.554326 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.555670 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.556134 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.559374 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.563680 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.564268 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.565023 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.565841 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.566562 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.567262 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.568018 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.569010 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.569035 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.569674 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.569842 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.570237 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.570813 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.570921 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.571625 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.571699 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.572215 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.572495 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.572814 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.573334 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.573511 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.574125 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.574179 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.574869 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.575308 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.575556 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.576240 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.576487 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.577045 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.577122 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.577960 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.578055 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.578981 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.579159 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.580615 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.580955 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.581416 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.581830 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.581937 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.582956 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.583129 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.584017 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.584565 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.585838 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.585901 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.586015 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.587185 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.588480 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.588588 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.589171 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.593866 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.595329 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.597172 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.597926 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.598772 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.598792 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.599603 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.600296 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.601084 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.601274 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.601949 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.602688 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.603568 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.604295 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.605077 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.605870 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.607358 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.609474 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.609650 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.613842 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.617748 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.618071 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.621448 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.626170 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.626783 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.630978 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.635955 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.639588 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.653144 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.769450 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.770235 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.771065 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.771834 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.772654 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.773492 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.774379 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.775239 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.776233 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.777359 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.778381 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.779428 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.780468 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.781793 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.783217 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.784732 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.788063 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.789677 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.791651 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.793449 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.796692 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.801017 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.802594 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.803378 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.804221 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.804989 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.805815 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.806661 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.807559 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.808418 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.809412 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.810557 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.811576 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.811593 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.812687 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.812869 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.813753 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.814058 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.815106 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.815413 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.816691 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.816709 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.818322 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.818404 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.819434 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.820612 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.821842 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.822054 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.823216 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.823501 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.824501 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.825315 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.825821 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.828576 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.832623 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.832937 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.838476 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.843530 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.844705 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.845868 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.846880 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.847220 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.848364 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.849824 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.850923 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.852099 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.853533 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.854693 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.855053 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.855990 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.857300 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.864223 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.864294 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.870262 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.873386 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.878682 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.886862 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.890792 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.895963 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.905203 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.922942 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.977202 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.978427 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.979644 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.980839 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.982130 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.983473 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.984913 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.986227 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.987805 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.989180 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.990824 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.992488 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.994250 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.996567 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697627.998984 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.001378 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.007546 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.010476 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.019408 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.021277 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.023224 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.025107 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.027506 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.029381 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.031165 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.033328 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.035724 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.037567 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.039667 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.041863 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.053105 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.066516 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.083359 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.099557 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.115729 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.132525 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.168743 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.215325 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.216568 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.217803 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.219006 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.220298 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.221659 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.223095 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.224418 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.226003 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.227380 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.229022 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.230683 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.232455 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.234793 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.237202 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.239601 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.245522 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.248457 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.251834 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.252549 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.253779 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.255234 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.256446 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.257751 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.259107 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.260554 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.261067 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.261880 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.262959 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.263503 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.265017 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.265101 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.266753 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.266989 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.268432 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.269407 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.270221 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.271314 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.272577 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.273118 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.275009 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.275310 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.277436 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.277734 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.279594 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.281763 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.283459 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.284031 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.286422 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.295298 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.295519 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.297413 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.299373 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.301286 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.303728 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.305609 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.307413 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.308635 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.309628 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.312069 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.313949 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.316095 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.318335 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.325699 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.329564 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.341993 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.342696 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.358215 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.359507 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.375759 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.375833 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.392096 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.409578 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.412855 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.446944 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.813509 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.815547 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.817580 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.819614 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.821795 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.824074 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.826518 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.828755 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.831501 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.833891 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.836806 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.839784 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.842937 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.847352 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.851707 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.856284 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.867672 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.873232 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.885184 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.886363 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.887459 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.888696 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.889793 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.890932 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.892353 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.893817 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.895346 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.896548 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.897847 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.899156 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.906502 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.915127 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.923475 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.931648 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.939950 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.956078 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697628.972173 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.066079 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.068125 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.070176 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.072227 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.074427 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.076709 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.079151 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.081406 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.084153 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.086554 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.089460 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.092481 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.095713 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.098340 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.100333 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.100456 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.102497 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.104530 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.104780 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.106744 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.109018 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.109399 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.111510 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.113784 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.116563 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.118955 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.120943 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.121943 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.124954 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.126608 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.128191 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.132608 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.133193 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.137051 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.141657 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.145525 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.146733 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.147851 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.149117 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.150243 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.151420 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.152869 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.153257 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.154372 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.155923 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.157143 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.158461 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.158931 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.159807 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.167275 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.171259 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.172466 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.173576 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.174828 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.176109 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.176185 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.177290 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.178734 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.180235 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.181777 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.182997 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.184298 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.184701 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.185633 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.193144 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.193213 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.201540 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.201976 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.210395 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.217971 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.218629 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.227067 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.234615 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.243550 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.259698 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.268716 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.269903 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.271056 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.272186 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.273388 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.274671 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.275930 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.277115 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.278420 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.279693 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.281206 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.282716 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.284457 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.286564 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.289123 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.291270 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.311392 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.317363 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.320131 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.331924 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.332354 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.332744 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.333172 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.333583 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.334061 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.334535 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.335825 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.337290 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.338889 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.340590 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.342651 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.345064 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.346958 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.365200 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.365591 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.365975 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.366382 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.366783 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.367196 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.367609 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.368032 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.368479 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.368844 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.369326 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.369710 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.370201 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.370591 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.371101 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.371505 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.371983 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.372608 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.373178 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.375097 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.376536 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.379641 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.532391 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.533580 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.534743 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.535883 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.537084 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.538371 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.539633 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.540823 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.542133 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.543425 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.544935 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.548329 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.550098 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.552175 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.554734 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.556874 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.557684 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.558882 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.560037 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.561175 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.562370 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.563663 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.564937 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.566129 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.567430 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.568715 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.570240 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.571754 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.573512 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.575599 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.577114 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.578203 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.580355 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.583205 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.585984 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.589168 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.600645 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.601140 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.601592 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.602003 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.602434 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.602861 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.603353 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.603849 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.605346 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.606815 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.606983 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.608633 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.609596 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.610402 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.612544 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.615030 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.616991 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.621556 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.621998 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.622395 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.622816 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.623230 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.623711 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.624184 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.625483 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.626954 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.628553 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.630245 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.632313 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.634756 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.635728 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.636128 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.636563 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.636724 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.636987 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.637390 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.637810 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.638232 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.638657 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.639105 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.639472 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.639959 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.640346 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.640840 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.641235 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.641752 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.642161 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.642652 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.643296 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.643871 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.645825 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.647297 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.650467 1798447 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.655176 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.655580 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.655973 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.656377 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.656781 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.657193 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.657603 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.658031 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.658477 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.658845 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.659332 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.659722 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.660208 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.660593 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.661302 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.661701 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.662173 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.664254 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.664825 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.666767 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.668212 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.671346 1798427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.692415 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.694226 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.694603 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.694981 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.695352 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.695735 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.696112 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.696505 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.698240 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.698637 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.699027 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.699481 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.700862 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.701980 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.703101 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.705090 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.707433 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.738465 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.738887 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.739265 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.741179 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.741616 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.741999 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.742394 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.742787 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.744788 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.746748 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.748325 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.748727 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.749163 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.750965 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.751362 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.751817 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.752309 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.753698 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.754162 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.754692 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.755270 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.759298 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.762280 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.796134 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.797789 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.798216 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.798675 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.799104 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.799555 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.800115 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.800635 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.801151 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.801661 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.802169 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.802616 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.803145 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.803668 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.804122 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.805039 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.805535 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.806213 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.806800 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.807454 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.808678 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.811885 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.813770 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.817581 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.820785 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.823976 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.827178 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.903829 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.904681 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.905138 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.905828 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.906550 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.906961 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.909461 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.910395 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.912008 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.912562 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.913152 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.914968 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.916611 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.919825 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.930762 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.931881 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.932971 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.934025 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.935103 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.936313 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.938721 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.939931 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.942313 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.943504 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.944596 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.945946 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.947259 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.948800 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.950566 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.957149 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.964995 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.965488 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.966057 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.966538 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.967148 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.967584 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.968021 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.968494 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.968892 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.969182 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.969687 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.969879 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.970151 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.970333 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.970609 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.970775 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.971203 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.971339 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.971731 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.972184 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.972289 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.972867 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.972977 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.973677 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.974150 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.974231 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.974628 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.975080 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.975359 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.976357 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.976781 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.977493 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.978760 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.978945 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.981881 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.983837 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.986806 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.997960 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.998356 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.998735 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.999468 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697629.999901 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.000293 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.000685 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.001080 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.001778 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.002510 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.003011 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.003278 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.003453 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.003736 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.003912 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.004522 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.005105 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.005338 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.005621 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.005789 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.006072 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.006286 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.006487 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.007063 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.007071 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.007300 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.007916 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.008081 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.008685 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.008885 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.009406 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.009650 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.010128 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.010311 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.010758 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.011339 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.011734 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.012180 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.012670 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.013943 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.014024 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.014431 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.014981 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.015545 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.017046 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.019293 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.022305 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.038072 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.039316 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.039737 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.040193 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.040618 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.040917 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.041288 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.041595 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.041870 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.042047 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.042434 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.042604 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.043094 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.043170 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.043743 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.043829 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.044388 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.044470 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.044890 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.045064 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.045475 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.045648 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.046058 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.046219 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.046528 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.046740 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.047195 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.047479 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.047732 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.047988 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.048275 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.048812 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.048892 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.049416 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.049824 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.050092 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.050510 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.050832 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.051311 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.051898 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.052557 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.053014 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.053287 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.054930 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.055435 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.057337 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.058289 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.060708 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.061501 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.063930 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.064700 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.067142 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.067904 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.070359 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.143743 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.144415 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.144855 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.145393 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.145946 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.146506 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.146544 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.147454 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.147606 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.147980 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.148372 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.148756 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.148953 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.149312 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.149535 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.150059 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.150368 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.151136 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.151517 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.151942 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.152411 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.152690 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.153229 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.153831 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.155124 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.155615 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.155998 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.159224 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.165621 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.166818 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.167913 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.168967 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.169536 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.170045 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.170671 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.171272 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.171779 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.172612 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.172859 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.173884 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.174333 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.175330 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.175577 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.176534 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.176932 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.177648 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.178173 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.179028 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.179608 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.180355 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.180802 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.182028 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.182046 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.183388 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.183835 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.184719 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.186268 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.188043 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.190435 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.194700 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.198339 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.202614 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.205590 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.209909 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.218043 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.222183 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.238260 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.242511 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.300625 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.301761 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.303009 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.304164 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.305295 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.306449 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.307673 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.308888 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.310098 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.311301 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.312640 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.313990 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.315535 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.317062 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.318724 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.320335 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.322070 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.324179 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.326511 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.332182 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.343749 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.345134 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.346484 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.347940 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.349409 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.350870 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.352681 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.354594 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.356412 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.358287 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.360448 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.362310 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.364270 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.366245 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.368021 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.369949 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.371621 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.373397 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.376966 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.379243 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.381319 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.388949 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.396588 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.405199 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.413816 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.422421 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.431018 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.533435 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.534577 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.535833 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.536992 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.538121 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.539111 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.539303 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.540265 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.540531 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.541537 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.541761 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.542711 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.542988 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.543861 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.544206 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.545033 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.545570 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.546288 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.546933 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.547519 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.548496 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.548744 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.550088 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.550158 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.551460 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.551834 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.552826 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.553458 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.554393 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.555215 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.555931 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.557330 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.557605 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.559229 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.559666 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.560996 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.563120 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.565528 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.565606 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.571336 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.576911 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.578438 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.579798 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.581248 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.582712 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.582948 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.584228 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.584409 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.585758 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.586160 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.587227 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.587969 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.588713 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.589785 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.590198 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.591682 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.592033 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.593884 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.594047 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.595805 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.595970 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.597908 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.597990 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.599879 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.600182 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.601664 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.602076 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.603615 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.604075 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.605289 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.606066 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.607084 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.607864 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.609811 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.610592 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.611499 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.612877 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.613300 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.614959 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.616883 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.619156 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.621252 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.622614 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.628952 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.630257 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.636655 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.638892 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.645343 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.647534 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.654039 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.656181 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.662736 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.664829 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697630.671422 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.175636 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.176824 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.178070 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.179401 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.180733 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.182428 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.184318 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.186288 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.188439 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.190699 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.193294 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.195059 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.202068 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.214264 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.216567 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.218509 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.220453 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.222374 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.224427 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.226605 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.228695 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.230795 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.233362 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.235406 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.237893 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.239864 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.242588 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.245665 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.258581 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.271892 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.284319 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.295397 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.310255 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.323583 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.404537 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.405716 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.406958 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.408275 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.409605 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.411301 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.413186 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.415155 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.417103 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.417321 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.418328 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.419722 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.419743 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.421085 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.422431 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.422545 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.424340 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.424418 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.426318 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.428301 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.430466 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.431360 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.432741 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.435364 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.437149 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.443252 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.444219 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.445820 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.447762 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.449867 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.451804 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.453868 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.456051 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.456642 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.458132 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.459073 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.460232 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.461025 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.462812 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.463009 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.464993 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.465062 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.467150 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.467491 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.469408 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.469583 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.471514 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.472385 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.473637 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.475536 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.476233 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.478303 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.480831 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.482839 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.485620 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.488497 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.488767 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.501746 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.501943 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.514517 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.515122 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.525748 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.527553 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.538629 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.540881 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.553649 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.554390 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.567103 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.963657 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.965663 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.967803 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.969875 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.972010 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.974179 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.976312 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.978573 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.980829 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.983141 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.985622 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.988179 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.990886 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.993860 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697631.997138 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.000376 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.003603 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.007755 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.012343 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.018265 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.037142 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.039760 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.042320 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.044899 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.047538 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.049997 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.052572 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.055422 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.058271 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.061218 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.063650 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.067169 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.070970 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.074250 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.077554 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.080885 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.084241 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.088753 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.092430 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.096200 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.108674 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.118929 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.123124 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.130090 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.136020 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.149314 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.162514 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.177316 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.191079 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.198307 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.200325 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.202463 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.204525 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.204830 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.206687 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.208855 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.210997 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.213272 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.213850 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.215559 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.215880 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.217924 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.218102 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.218582 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.220207 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.220438 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.222360 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.223017 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.224563 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.225754 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.226727 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.228700 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.229016 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.231289 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.231977 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.233627 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.235298 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.236137 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.238662 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.238825 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.241583 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.242917 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.244582 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.247547 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.247852 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.251107 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.253634 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.254381 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.258554 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.263192 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.269244 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.272943 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.275571 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.278137 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.280707 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.283530 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.286384 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.288301 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.289230 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.290914 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.292192 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.293479 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.295145 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.296066 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.298492 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.298722 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.301185 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.302034 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.303770 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.305337 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.306626 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.309120 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.309473 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.312417 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.313677 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.314868 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.317355 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.318390 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.321137 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.322163 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.325458 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.328728 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.332057 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.333604 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.335438 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.337292 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.339958 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.341796 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.343647 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.346371 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.347446 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.350559 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.356737 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.359953 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.363686 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.369585 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.370126 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.374321 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.381278 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.382852 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.387213 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.397561 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.400583 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.412216 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.413898 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.425861 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.428805 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.439494 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.442609 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.453127 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.456415 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697632.470209 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.816976 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.819395 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.821854 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.824401 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.827003 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.830362 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.833975 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.837790 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.841965 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.846521 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.852205 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.858616 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.874356 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.891178 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.892340 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.893463 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.894583 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.895741 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.896918 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.898110 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.899303 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.900568 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.901740 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.903113 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.904246 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.905632 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.907160 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.908873 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.915594 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.922563 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.929173 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.935147 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.942900 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697634.949872 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.047291 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.049726 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.052207 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.054761 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.055662 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.057401 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.058131 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.060715 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.060833 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.063342 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.064458 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.066069 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.068290 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.069562 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.072469 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.073329 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.077049 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.077253 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.081509 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.082703 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.086161 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.089094 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.091930 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.098490 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.104918 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.114776 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.121416 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.122589 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.123709 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.124832 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.126002 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.127189 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.128387 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.129588 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.130857 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.131659 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.132027 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.132851 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.133415 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.133994 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.134573 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.135137 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.135974 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.136319 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.137646 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.137665 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.138858 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.139392 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.140075 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.141349 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.142527 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.143900 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.145045 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.146204 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.146450 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.147988 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.149714 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.153194 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.156525 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.159825 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.163578 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.165878 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.170234 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.173708 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.176224 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.180774 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.184069 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.191124 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.270427 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.271633 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.272869 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.274095 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.275329 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.276585 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.277799 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.279128 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.280427 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.281766 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.283178 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.284614 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.286134 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.287843 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.289861 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.291658 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.293491 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.295832 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.298726 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.301878 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.313914 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.315414 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.316878 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.318392 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.319788 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.321285 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.322785 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.324534 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.326606 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.328680 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.330752 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.332830 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.335035 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.337244 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.339154 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.341055 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.343106 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.344937 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.347352 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.349798 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.351782 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.354459 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.357483 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.360345 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.363825 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.367426 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.374421 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.381411 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.388406 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.395389 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.403220 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.411042 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.504368 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.505569 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.506810 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.508024 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.509267 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.510525 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.511754 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.512377 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.513091 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.513597 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.514416 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.514862 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.515773 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.516098 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.517252 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.517418 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.518816 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.518888 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.520072 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.520433 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.521416 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.522158 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.522745 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.524221 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.524301 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.525650 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.526130 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.527108 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.527988 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.528646 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.530475 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.530560 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.532571 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.533411 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.534393 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.536224 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.536595 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.538584 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.541487 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.544692 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.548486 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.550000 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.551468 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.553010 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.554411 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.555910 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.556668 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.557408 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.558186 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.559167 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.559657 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.561328 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.561395 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.562751 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.563495 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.564261 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.565641 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.565821 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.567630 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.567798 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.569729 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.570040 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.571828 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.572279 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.573937 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.574225 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.576147 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.576254 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.578462 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.578539 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.580330 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.580794 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.582851 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.582919 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.584790 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.585374 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.586880 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.587384 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.588745 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.590067 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.591183 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.593120 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.593629 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.595629 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.596009 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.598326 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.599531 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.601385 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.603178 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.604281 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.607798 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.610240 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.611474 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.617307 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.618566 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.624362 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.625585 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.631419 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.632606 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.639346 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.639620 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.647270 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.647481 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697635.655347 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.701641 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.703074 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.704514 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.705993 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.707554 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.709419 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.711527 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.713527 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.715798 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.721572 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.724682 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.727705 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.734045 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.742187 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.757027 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.757850 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.758635 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.759409 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.760257 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.761057 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.761817 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.762651 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.763488 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.764414 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.765553 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.766447 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.767456 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.768583 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.769686 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.773252 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.776901 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.780378 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.787122 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.790503 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.928391 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.929825 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.931270 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.932744 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.934303 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.936177 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.938287 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.940299 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.942590 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.946039 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.947490 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.948442 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.948968 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.950471 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.951449 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.951616 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.952062 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.952304 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.953168 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.954154 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.954176 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.954671 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.955010 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.955849 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.956311 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.956718 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.957570 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.958480 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.958590 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.959503 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.960407 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.960865 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.961053 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.961424 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.962545 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.963589 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.964697 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.965921 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.966726 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.967302 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.969059 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.969347 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.969916 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.973182 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.977742 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.978758 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.979743 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.979862 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.980805 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.981839 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.982958 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.984199 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.984307 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.985254 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.985355 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.986054 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.986405 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.986851 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.987675 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.987778 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.988161 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.988599 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.988896 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.989379 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.990357 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.990369 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.991213 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.991685 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.992158 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.993380 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.993474 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.994380 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.994762 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.995405 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.996193 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.996548 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.997868 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.997879 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697636.999299 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.000832 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.001485 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.002371 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.003143 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.004085 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.004204 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.004898 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.005176 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.005704 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.006677 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.006778 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.007597 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.008371 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.008705 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.009232 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.010267 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.010361 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.011231 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.012378 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.013274 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.014032 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.014297 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.015573 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.015659 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.016693 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.017704 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.019084 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.020286 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.021371 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.023961 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.025046 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.027473 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.029123 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.033173 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.034276 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.037637 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.181295 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.182117 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.182983 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.183822 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.184634 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.185465 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.186321 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.187179 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.188053 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.188962 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.189867 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.190879 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.191996 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.193046 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.194157 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.195389 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.196772 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.198536 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.199109 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.199932 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.200794 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.201632 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.202588 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.203444 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.204301 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.205160 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.206091 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.206993 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.207122 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.207895 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.208125 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.208971 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.209138 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.210212 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.210229 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.211388 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.211453 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.212643 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.212741 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.214022 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.214096 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.215076 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.215473 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.216125 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.217370 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.217442 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.218661 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.219933 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.221282 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.222417 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.223788 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.225197 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.225963 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.226620 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.226951 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.227942 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.228105 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.228891 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.229647 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.229919 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.231079 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.231268 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.232318 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.232993 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.233368 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.234396 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.235319 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.235569 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.236762 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.238024 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.238931 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.239342 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.240413 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.241768 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.242591 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.243178 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.244587 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.245998 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.246272 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.247526 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.249030 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.249947 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.250740 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.253025 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.253619 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.256577 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.257703 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.260205 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.261785 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.263830 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.267443 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.271051 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.275097 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.279128 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.595614 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.596579 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.597539 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.598512 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.599708 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.600961 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.602024 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.603343 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.604463 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.606564 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.609916 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.611635 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.613382 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.617322 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.620844 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.625544 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.637638 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.638208 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.638737 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.639281 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.639825 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.640341 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.640907 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.641463 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.642027 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.642617 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.643328 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.643982 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.644563 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.645283 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.645967 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.648048 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.650130 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.652165 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.655728 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.657682 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.738707 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.739292 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.739876 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.740434 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.740980 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.741547 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.742127 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.742706 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.743295 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.743894 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.744480 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.745125 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.745832 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.746535 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.747272 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.748056 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.748958 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.750005 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.756799 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.757506 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.758210 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.759003 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.759762 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.760571 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.761410 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.762281 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.763039 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.763794 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.764477 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.765346 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.766213 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.767246 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.768457 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.769427 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.770395 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.771714 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.773039 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.774468 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.775899 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.777835 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.779774 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.781708 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.783642 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.785778 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.787909 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.790303 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.792544 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.821964 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.822925 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.823892 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.824862 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.826066 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.827318 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.828389 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.829711 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.830842 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.832992 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.836424 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.838196 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.839616 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.839964 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.840607 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.841586 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.842567 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.843833 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.844003 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.845125 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.846212 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.847679 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.847697 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.848848 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.851048 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.852436 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.854478 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.856266 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.858010 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.861994 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.864410 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.864992 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.865660 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.865731 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.866215 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.866757 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.867276 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.867846 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.868405 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.868971 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.869564 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.870296 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.870530 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.870964 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.871546 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.872259 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.872952 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.875048 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.877186 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.879262 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.882504 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.882856 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.883095 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.883628 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.884168 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.884747 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.884925 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.885279 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.885843 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.886401 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.886955 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.887544 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.888256 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.888908 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.889492 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.890211 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.890898 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.892977 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.895083 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.897151 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.900729 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.902663 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.966908 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.967495 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.968078 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.968638 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.969184 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.969746 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.970327 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.970900 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.971489 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.972082 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.972674 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.973324 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.974039 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.974741 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.975472 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.976256 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.977159 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.978211 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.984283 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.984870 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.984952 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.985496 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.985701 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.986075 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.986414 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.986649 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.987350 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.987432 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.987943 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.988201 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.988536 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.989066 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.989232 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.989964 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.990045 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.990570 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.990919 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.991228 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.991690 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.991951 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.992473 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.992670 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.993176 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.993421 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.994103 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.994261 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.995032 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.995198 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.996128 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.996297 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.997368 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.998340 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697637.999324 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.000646 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.001972 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.003007 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.003411 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.003723 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.004417 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.004866 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.005215 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.005964 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.006909 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.006975 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.007755 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.008610 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.008946 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.009387 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.010144 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.010908 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.011004 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.011797 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.012663 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.012969 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.013711 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.014934 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.015156 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.015912 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.016888 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.017321 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.018221 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.019544 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.019752 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.020995 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.022004 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.022450 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.024389 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.026326 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.028272 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.030227 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.032378 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.034518 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.036919 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.039159 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.046005 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.046717 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.047446 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.048246 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.049009 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.049808 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.050628 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.051457 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.052343 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.054339 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.055568 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.057172 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.058879 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.061023 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.063997 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.067583 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.081651 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.082160 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.082619 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.083135 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.083655 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.084145 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.084621 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.085141 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.085596 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.086145 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.086680 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.087265 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.087746 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.088296 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.088895 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.089474 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.090696 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.091918 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.093119 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.094565 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.098111 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.139355 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.139830 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.140281 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.140745 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.141207 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.141745 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.142271 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.142781 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.143360 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.143901 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.144459 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.145022 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.145562 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.146209 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.146824 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.147427 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.148209 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.148896 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.150139 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.155817 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.156530 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.157127 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.157659 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.158283 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.158924 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.159569 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.160158 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.160699 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.161312 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.161902 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.162607 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.163327 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.163956 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.164571 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.165181 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.165940 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.166702 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.167557 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.168369 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.169190 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.170120 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.171056 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.172152 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.173250 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.174354 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.175454 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.177110 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.178302 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.179502 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.180817 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.273989 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.274703 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.275424 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.276230 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.277002 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.277793 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.278615 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.279446 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.280339 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.282358 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.283604 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.285170 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.286197 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.286998 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.287016 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.287591 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.288179 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.289046 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.289152 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.289632 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.290110 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.290367 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.290956 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.291072 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.291708 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.292050 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.292408 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.292580 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.293350 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.293577 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.294158 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.295155 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.295177 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.295551 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.296004 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.296838 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.297006 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.298201 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.299005 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.300238 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.301966 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.303632 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.305666 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.305704 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.306175 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.306571 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.306961 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.307337 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.307697 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.308042 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.308394 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.308442 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.308597 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.308992 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.309097 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.309513 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.309629 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.309934 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.310266 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.310377 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.311035 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.311048 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.311716 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.311727 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.312482 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.312552 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.312566 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.313120 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.313226 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.313683 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.313985 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.314243 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.314942 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.315020 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.315528 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.316028 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.316144 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.316695 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.317020 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.317299 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.317863 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.318973 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.319146 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.320361 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.321576 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.323209 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.325102 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.325612 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.326064 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.326624 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.326795 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.327154 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.327631 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.328097 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.328608 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.329058 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.329597 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.330126 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.330696 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.331174 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.331717 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.332309 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.332873 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.334074 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.335277 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.336478 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.337898 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.339724 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.340102 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.340472 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.340829 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.341194 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.341420 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.341620 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.342045 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.342483 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.342907 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.343313 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.343727 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.344153 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.344584 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.345060 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.345549 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.346027 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.346844 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.351686 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.352188 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.352639 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.353102 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.353596 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.354103 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.354610 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.355126 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.355659 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.356184 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.356625 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.357130 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.357615 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.358105 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.358593 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.359084 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.359585 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.360104 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.360631 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.361404 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.362129 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.362854 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.363880 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.364907 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.365933 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.366965 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.368371 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.368843 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.369301 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.369759 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.370222 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.370757 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.371285 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.371805 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.372381 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.372925 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.373481 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.374048 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.374590 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.375236 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.375860 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.376463 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.377244 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.377940 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.379196 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.382543 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.383021 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.383465 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.383919 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.384375 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.384830 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.384914 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.385504 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.385672 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.386035 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.386288 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.386629 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.386840 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.387193 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.387488 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.387762 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.388157 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.388351 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.388954 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.389024 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.389597 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.389761 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.390166 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.390395 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.390805 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.391005 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.391412 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.391790 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.392143 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.392484 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.392881 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.393504 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.393733 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.394131 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.394749 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.395532 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.396295 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.397152 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.397979 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.398805 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.399311 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.399738 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.400035 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.400762 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.400834 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.401306 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.402056 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.402123 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.402708 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.403285 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.403448 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.404037 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.404405 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.404590 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.405196 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.405528 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.405803 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.406502 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.407301 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.407379 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.407998 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.408547 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.408713 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.409319 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.409742 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.410100 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.410856 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.411069 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.411730 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.412538 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.413349 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.414283 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.415218 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.415987 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.416445 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.416564 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.416974 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.417473 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.417629 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.417978 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.418406 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.418745 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.418951 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.419521 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.419980 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.420095 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.420866 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.421844 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.421867 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.422915 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.423157 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.424038 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.424355 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.425470 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.425619 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.434323 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.434776 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.435267 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.435756 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.436310 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.436867 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.437412 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.437969 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.438522 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.439074 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.439622 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.440172 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.440798 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.441426 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.441977 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.442607 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.443160 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.443711 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.444337 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.444889 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.445426 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.445982 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.446534 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.447087 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.447630 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.448181 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.448736 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.449240 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.449734 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.452219 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.452712 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.453242 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.453794 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.454902 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.455498 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.456013 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.456685 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.457501 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.458251 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.462271 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.463040 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.516191 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.516767 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.517332 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.517912 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.518684 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.519249 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.519967 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.520514 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.521813 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.522965 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.524442 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.526043 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.527385 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.531441 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.532017 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.532587 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.533178 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.533950 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.534518 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.534691 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.535264 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.535380 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.535643 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.536035 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.536135 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.536513 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.536866 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.537263 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.537428 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.537645 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.538040 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.538481 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.538640 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.538901 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.539270 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.539723 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.540258 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.540328 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.540760 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.541188 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.541917 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.542091 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.542976 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.543276 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.543881 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.544867 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.546797 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.550636 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.551089 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.551451 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.551834 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.552212 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.552572 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.552945 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.553310 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.553703 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.554112 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.554508 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.554878 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.555331 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.555749 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.556184 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.556617 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.557469 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.558354 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.559237 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.560215 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.562128 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.567737 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.568110 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.568482 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.568831 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.569195 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.569599 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.570012 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.570451 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.570878 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.571281 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.571688 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.572110 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.572534 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.573000 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.573490 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.573964 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.574782 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.579483 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.579979 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.580434 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.580898 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.581391 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.581888 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.582402 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.583055 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.583061 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.583483 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.583642 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.583872 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.584313 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.584419 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.584901 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.584998 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.585546 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.585612 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.586019 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.586186 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.586460 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.586703 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.586905 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.587270 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.587383 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.587904 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.587983 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.588544 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.588623 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.589031 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.589190 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.589511 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.589734 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.590019 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.590622 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.590686 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.591536 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.591617 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.592272 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.593319 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.594353 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.595377 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.596361 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.596405 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.596875 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.597336 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.597803 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.598300 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.598798 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.599308 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.599827 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.600354 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.600883 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.601321 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.601868 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.602353 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.602841 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.603332 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.603826 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.604327 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.604838 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.605369 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.606147 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.606869 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.607593 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.608624 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.609654 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.610686 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.611714 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.645914 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.646410 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.646815 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.647277 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.647759 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.648177 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.648702 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.649267 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.649774 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.650546 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.651403 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.652465 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.653571 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.654955 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.661359 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.661469 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.661986 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.662055 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.662459 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.662611 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.662975 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.663138 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.663477 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.663723 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.663907 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.664338 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.664503 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.664950 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.665109 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.665551 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.665717 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.666121 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.666539 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.666727 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.667317 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.667486 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.667877 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.668623 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.668694 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.669263 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.669934 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.669956 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.670573 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.671126 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.671372 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.671689 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.672322 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.672999 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.673563 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.674137 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.674695 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.675247 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.675796 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.676351 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.676911 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.677931 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.677995 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.678566 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.678588 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.679083 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.679592 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.680155 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.680714 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.681082 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.681289 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.681612 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.681858 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.682159 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.682435 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.682731 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.683160 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.683395 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.683728 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.683993 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.684291 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.684530 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.684936 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.685212 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.685578 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.686045 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.686221 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.686901 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.686971 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.688729 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.689039 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.689372 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.689841 1798459 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.690000 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.690556 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.691106 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.691652 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.692212 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.692767 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.693314 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.693869 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.694427 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.694920 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.695414 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.697909 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.698406 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.698934 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.699487 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.700145 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.700737 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.701256 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.701923 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.702734 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.703486 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.705627 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697638.706365 1798430 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0852"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:33:59.833559: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-10-23 15:33:59.833700: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "2024-10-23 15:33:59.833812: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "W0000 00:00:1729697639.864666 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.864780 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.864855 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.865652 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.865675 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.865813 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.866534 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.866541 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.866668 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.867387 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.867394 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.867515 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.868220 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.868310 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.868333 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.869047 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.869062 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.869199 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.869690 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.869830 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.869960 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.870570 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.870576 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.870699 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.871432 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.871439 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.871559 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.872295 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.872301 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.872424 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.873162 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.873169 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.873307 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.873905 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.873966 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.874044 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.874677 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.874715 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.874793 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.875463 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.875501 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.875591 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.876278 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.876316 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.876388 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.877137 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.877179 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.877215 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.877902 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.877964 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.878044 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.878761 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.878787 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.878819 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.879617 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.879646 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.879677 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.880497 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.880526 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.880559 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.881369 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.881396 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.881428 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.882231 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.882257 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.882292 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.883264 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.883292 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.883321 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.884040 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.884067 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.884100 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.884832 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.884859 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.884889 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.885699 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.885724 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.885759 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.886609 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.886683 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.886717 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.887497 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.887568 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.887594 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.888354 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.888421 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.888447 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.889273 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.889350 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.889372 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.890215 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.890249 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.890282 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.891039 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.891099 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.891178 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.891925 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.891962 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.892023 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.892704 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.893026 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.893046 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.893453 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.893991 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.894045 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.894280 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.894721 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.894946 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.895029 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.895765 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.896044 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.896075 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.896740 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.897114 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.897318 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.913543 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.913963 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.913960 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.914187 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.914519 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.914704 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.914963 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.915322 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.915404 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.915613 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.916222 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.916235 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.916362 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.917018 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.917023 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.917172 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.917656 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.917793 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.918024 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.918440 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.918465 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.918656 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.919089 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.919216 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.919361 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.919948 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.919954 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.920072 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.920631 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.920667 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.920977 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.921364 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.921430 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.921699 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.922109 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.922143 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.922527 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.922859 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.922871 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.923690 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.923691 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.923816 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.924250 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.924371 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.924946 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.924960 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.925081 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.925565 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.925713 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.925900 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.926273 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.926298 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.927373 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.927407 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.927657 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.928271 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.928496 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.928585 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.929018 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.929266 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.929481 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.929757 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.929869 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.930295 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.930410 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.930841 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.931035 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.931497 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.931615 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.932038 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.932402 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.932824 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.938056 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.938404 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.938745 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.939087 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.939396 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.939704 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.940021 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.940338 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.940650 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.941158 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.941541 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.941892 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.942223 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.942561 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.942990 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.943327 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.943675 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.944105 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.944573 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.947641 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.947999 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.948299 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.948547 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.948634 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.949143 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.949153 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.949698 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.949711 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.950266 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.950286 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.950814 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.950827 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.950948 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.951410 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.951443 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.951527 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.952117 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.952191 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.952206 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.952702 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.952886 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.953007 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.953191 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.953329 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.953553 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.953780 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.953858 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.954403 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.954604 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.954608 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.954850 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.955023 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.955501 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.955630 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.955708 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.956018 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.956481 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.956603 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.956743 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.956919 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.957587 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.957927 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.958033 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.958260 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.958864 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.959148 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.959426 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.959699 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.959975 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.960251 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.960748 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.960856 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.961445 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.961798 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.962287 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.963218 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.977357 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.977671 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.977988 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.978302 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.978694 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.978785 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.979262 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.979279 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.979823 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.979879 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.980139 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.980460 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.980494 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.980626 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.981166 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.981197 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.981280 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.981869 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.981950 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.981965 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.982412 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.982594 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.982716 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.982852 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.983395 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.983467 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.983480 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.983886 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.984047 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.984151 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.984554 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.984652 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.984773 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.985248 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.985269 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.985376 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.985779 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.986004 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.986048 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.986250 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.986432 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.986752 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.987110 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.987131 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.987256 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.987839 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.987877 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.987953 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.988354 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.988930 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.988948 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.989026 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.989599 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.989645 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.989819 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.990583 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.990663 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.990678 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.991214 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.991451 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.991557 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.991862 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.992102 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.992206 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.992434 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.992714 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.993266 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.993344 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.994026 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.994718 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.998460 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.998871 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.999234 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.999591 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697639.999780 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.000039 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.000331 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.000434 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.000825 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.000855 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.000924 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.001491 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.001678 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.001694 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.002061 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.002264 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.002352 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.002501 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.002793 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.003126 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.003164 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.003335 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.003945 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.003955 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.004059 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.004695 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.004707 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.004808 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.005319 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.005398 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.006048 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.006073 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.006101 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.006647 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.006721 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.007258 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.007280 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.007845 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.007922 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.009071 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.009155 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.009348 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.010145 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.010686 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.011252 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.012264 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.012596 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.012872 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.013610 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.014228 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.014815 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.015933 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.016075 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.016235 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.017443 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.017809 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.018534 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.048751 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.049125 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.049516 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.049881 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.050256 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.050624 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.051209 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.051233 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.051575 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.051900 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.051921 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.052040 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.052698 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.052709 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.052818 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.053446 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.053455 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.053559 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.054235 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.054247 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.054348 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.054808 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.054949 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.055086 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.055291 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.055690 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.055823 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.055903 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.056508 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.056583 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.056597 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.057111 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.057329 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.057341 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.057551 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.057960 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.058077 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.058181 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.058405 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.058754 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.058822 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.058926 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.059335 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.059683 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.059700 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.059913 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.060220 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.060433 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.060758 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.060932 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.061049 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.061543 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.061663 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.061871 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.062167 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.062333 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.063105 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.063328 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.063337 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.064082 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.064658 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.064668 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.065187 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.066011 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.066299 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.067104 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.071708 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.072180 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.072611 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.073097 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.073156 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.073610 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.073710 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.073922 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.074231 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.074362 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.074493 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.074776 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.075085 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.075262 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.075395 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.075607 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.075894 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.076049 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.076320 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.076548 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.076680 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.076890 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.077306 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.077327 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.077451 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.077936 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.078078 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.078185 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.078627 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.078733 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.079293 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.079475 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.079708 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.079853 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.080030 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.080326 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.080789 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.081761 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.081781 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.082345 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.083772 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.083867 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.084262 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.085974 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.086094 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.086199 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.088167 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.088510 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.088521 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.090264 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.090623 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.092141 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.093879 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.094263 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.095810 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.097575 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.097970 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.161168 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.161653 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.162112 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.162424 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.162605 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.163056 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.163151 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.163651 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.163812 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.163970 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.164191 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.164400 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.164661 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.164876 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.165106 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.165246 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.165419 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.165906 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.165940 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.166057 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.166586 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.166708 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.166812 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.167105 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.167451 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.167573 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.167690 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.168345 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.168480 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.168504 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.169059 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.169247 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.169256 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.170071 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.170094 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.170114 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.170802 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.170891 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.171632 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.171706 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.171933 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.172293 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.172675 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.172986 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.173586 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.173687 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.174539 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.174676 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.174841 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.175637 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.175762 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.175834 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.176708 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.176786 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.177062 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.177701 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.177722 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.178843 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.178867 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.178991 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.180402 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.180483 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.180882 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.182349 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.182425 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.184390 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.184466 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.188454 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.189094 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.189712 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.190415 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.191003 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.191573 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.192113 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.192242 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.192301 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.192817 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.193221 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.193231 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.193461 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.194060 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.194139 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.194245 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.195055 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.195130 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.195143 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.195925 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.196093 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.196104 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.196519 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.197008 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.197016 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.197242 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.197791 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.198017 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.198447 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.198668 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.199090 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.199313 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.199905 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.200113 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.200211 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.200568 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.200872 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.203372 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.203779 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.203878 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.206929 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.207228 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.207439 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.210396 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.210910 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.211184 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.214362 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.214845 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.215183 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.218388 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.218493 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.218836 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.221599 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.221931 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.225334 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.228577 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.228836 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.355457 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.356136 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.356764 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.357394 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.358116 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.358182 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.358985 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.358994 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.359948 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.359974 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.360131 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.360991 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.361072 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.361089 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.361851 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.362076 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.362094 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.362596 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.362893 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.362992 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.363309 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.363589 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.363875 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.364038 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.364280 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.364767 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.364899 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.365074 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.365789 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.365914 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.365997 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.366944 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.367148 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.367162 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.367766 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.367980 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.368637 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.368840 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.369689 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.369854 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.370318 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.370556 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.371439 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.371688 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.372585 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.373011 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.374043 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.374152 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.374851 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.375427 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.375539 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.375979 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.376764 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.377133 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.378205 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.378491 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.379736 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.379930 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.384473 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.385418 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.386358 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.387249 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.388126 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.388682 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.388850 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.388983 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.389703 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.389905 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.390106 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.390687 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.390898 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.391237 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.391639 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.391841 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.392247 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.392543 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.392740 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.393130 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.393443 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.393645 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.394144 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.394550 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.394750 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.395179 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.395698 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.395892 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.396722 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.396927 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.397627 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.397821 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.398690 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.398860 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.399781 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.399953 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.400457 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.405136 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.405309 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.407189 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.411965 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.412149 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.413744 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.417679 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.418763 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.419414 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.424279 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.424488 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.426130 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.430964 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.431258 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.432967 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.437914 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.438183 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.446509 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.451967 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.452259 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.706141 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.707151 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.708106 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.709069 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.710113 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.711062 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.711222 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.712095 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.712347 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.713072 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.713430 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.714060 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.714606 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.715240 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.715262 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.715948 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.716428 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.716504 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.717570 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.717582 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.717698 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.718573 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.718975 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.718986 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.719648 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.720150 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.720405 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.720740 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.721489 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.721867 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.722330 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.722993 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.723077 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.724387 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.724459 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.725792 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.725958 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.727177 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.727895 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.728116 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.728493 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.729934 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.730112 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.731868 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.732126 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.733736 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.734467 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.735676 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.737820 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.737901 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.739826 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.740140 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.741821 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.742708 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.742724 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.743392 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.744118 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.744226 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.744856 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.745646 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.746403 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.747167 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.750538 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.751317 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.752001 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.752531 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.752625 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.753255 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.753418 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.753872 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.754152 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.754640 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.754899 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.754995 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.755369 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.755755 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.756141 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.756894 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.758433 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.759167 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.760302 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.761843 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.763389 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.764520 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.765312 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.766945 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.768080 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.768592 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.770384 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.771529 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.773871 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.775037 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.775280 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.777182 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.778343 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.783934 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.785088 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.894624 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.895265 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.895904 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.896499 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.897090 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.897771 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.898469 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.899101 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.899719 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.900387 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.901049 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.901747 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.902507 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.903320 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.903576 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.904325 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.904343 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.904980 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.905402 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.905721 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.905787 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.906547 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.906794 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.906804 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.907262 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.907476 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.908348 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.908425 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.908438 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.909120 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.909192 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.909934 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.910046 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.910122 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.910820 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.910926 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.911642 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.911711 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.912716 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.912730 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.912745 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.913536 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.913613 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.914254 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.914425 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.914953 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.915345 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.915735 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.916007 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.916405 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.916583 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.917573 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.917643 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.918699 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.918860 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.919885 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.920018 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.920188 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.921132 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.921621 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.922420 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.924087 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.924893 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.927354 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.928157 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.931156 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.931975 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.936523 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.936901 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.937227 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.937545 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.937920 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.938390 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.938862 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.939635 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.940424 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.941343 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.942277 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.943468 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.945017 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.946116 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.948018 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.948397 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.948547 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.948798 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.949012 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.949223 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.949392 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.949653 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.949817 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.950122 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.950282 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.950746 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.951347 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.951362 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.951827 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.952200 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.952368 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.953054 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.953372 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.953399 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.953728 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.954368 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.954376 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.954478 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.954701 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.955032 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.955665 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.955677 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.955774 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.956020 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.956367 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.956903 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.957032 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.957103 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.957299 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.957630 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.958006 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.958339 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.958453 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.958782 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.958885 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.959234 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.959653 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.960047 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.960136 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.960235 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.960710 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.961074 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.961800 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.962948 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.964276 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.966043 1798440 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.967419 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.967493 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.967887 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.967965 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.968344 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.968423 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.968813 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.968881 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.969286 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.969361 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.969760 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.969836 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.970236 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.970313 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.970711 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.970787 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.971197 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.971274 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.971883 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.971958 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.972372 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.972454 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.972895 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.972970 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.973406 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.973483 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.974211 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.974294 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.974752 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.974826 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.975164 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.975326 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.975622 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.975789 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.976059 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.976290 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.976595 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.976757 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.977478 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.977943 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.978626 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.978735 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.980082 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.980410 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.981134 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.981865 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.982290 1798423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.988173 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.988714 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.989153 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.989607 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.989987 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.990369 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.990740 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.991101 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.991479 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.991859 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.992245 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.992662 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.993404 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.994134 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.994853 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.995292 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.995723 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.996057 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.996148 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.996451 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.996810 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.997148 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.997241 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.997543 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.997844 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.998165 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.998484 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.998821 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.999174 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697640.999848 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.000517 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.001180 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.002069 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.002871 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.003815 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.004203 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.004594 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.004966 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.005365 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.005741 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.006128 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.006569 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.006943 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.007352 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.007732 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.008124 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.008484 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.008845 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.009000 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.009292 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.009933 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.010023 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.010067 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.010589 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.010702 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.010818 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.011243 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.011267 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.011429 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.011810 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.011885 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.012063 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.012510 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.012563 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.012871 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.013067 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.013134 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.013720 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.013742 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.013826 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.014261 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.014423 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.014661 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.014967 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.015400 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.015520 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.015683 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.015838 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.016341 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.016388 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.016669 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.017149 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.017470 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.017543 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.017649 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.017967 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.018377 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.018482 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.018820 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.019359 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.019362 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.019739 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.020181 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.020404 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.021267 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.021553 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.023269 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.027985 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.028368 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.028984 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.029387 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.029784 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.030160 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.030542 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.030970 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.031340 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.031754 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.032134 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.032290 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.032564 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.032805 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.032993 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.033116 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.033266 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.033675 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.033695 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.033863 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.034344 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.034442 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.034489 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.034972 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.035184 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.035226 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.035594 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.035796 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.035836 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.036228 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.036424 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.036460 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.036845 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.037043 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.037084 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.037431 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.037564 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.037738 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.038174 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.038185 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.038336 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.038867 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.038988 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.039392 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.039756 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.039788 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.039898 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.040403 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.040496 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.041114 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.041152 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.041849 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.041859 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.041897 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.042446 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.042562 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.042996 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.043136 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.043488 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.043712 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.043898 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.044301 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.044392 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.045008 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.045050 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.046035 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.046157 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.046928 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.047119 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.048339 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.048585 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.049755 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.050050 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.051164 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.051505 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.052562 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.052951 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.055360 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.055726 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.056050 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.056400 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.056732 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.057088 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.057425 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.057753 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.058119 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.058622 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.058994 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.059376 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.059759 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.060154 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.060501 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.060899 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.061295 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.061720 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.062104 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.062515 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.062905 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.063781 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.064615 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.066022 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.067437 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.068836 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.070239 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.080500 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.080967 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.081464 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.081552 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.082043 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.082063 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.082588 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.082597 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.083086 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.083104 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.083557 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.083581 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.084053 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.084076 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.084596 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.084614 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.085055 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.085153 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.085460 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.085630 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.085864 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.086409 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.086432 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.086806 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.087044 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.087439 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.088207 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.088850 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.095375 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.096032 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.096262 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.096644 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.096927 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.097267 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.097546 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.097888 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.098173 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.098493 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.098877 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.098880 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.099109 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.099379 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.099582 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.099853 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.099869 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.100278 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.100390 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.100570 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.100784 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.100975 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.101195 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.101357 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.101685 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.101759 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.102130 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.102195 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.102609 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.102614 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.102913 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.103108 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.103281 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.103505 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.104123 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.104200 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.104593 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.105731 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.106014 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.106946 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.108577 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.109762 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.111419 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.112578 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.112678 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.113325 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.113937 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.114260 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.114559 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.115171 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.115369 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.115768 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.116370 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.116959 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.117716 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.117787 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.118531 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.118702 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.119154 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.119897 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.122721 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.125545 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.128368 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.131194 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.134503 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.236632 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.237340 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.237577 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.237924 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.238244 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.238791 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.238905 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.239446 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.239661 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.240135 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.240330 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.240754 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.240993 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.241537 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.241657 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.242294 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.242402 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.243115 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.243134 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.243891 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.243991 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.244612 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.244772 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.245352 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.245513 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.246073 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.246235 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.246783 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.247104 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.247652 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.247877 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.248422 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.248708 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.249265 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.249539 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.250106 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.250405 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.250966 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.251424 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.252009 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.253895 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.254486 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.254488 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.255110 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.255677 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.256418 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.257076 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.257725 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.258331 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.258995 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.259619 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.260255 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.260922 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.261234 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.261612 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.261980 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.262016 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.262297 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.262975 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.263055 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.263145 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.263922 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.264007 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.264100 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.264945 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.264957 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.265046 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.265914 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.266063 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.266090 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.266684 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.266963 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.267128 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.267716 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.267897 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.268096 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.268663 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.268957 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.269122 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.269618 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.270126 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.270638 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.271101 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.271432 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.271621 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.272092 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.272628 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.273088 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.273631 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.274055 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.274603 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.274923 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.275470 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.275841 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.276395 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.276658 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.277219 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.277517 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.278096 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.278323 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.279185 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.279247 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.279671 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.279893 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.280297 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.280751 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.280822 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.281335 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.281530 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.281837 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.282329 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.283353 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.284290 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.284857 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.285360 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.285437 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.286375 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.287344 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.288476 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.288547 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.288880 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.289543 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.290515 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.291374 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.292055 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.292329 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.292489 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.293141 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.294006 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.295702 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.295781 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.296094 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.296755 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.297771 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.299366 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.299705 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.301261 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.302947 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.303303 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.304733 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.308370 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.312003 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.315641 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.319263 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.595718 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.596386 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.597036 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.597746 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.598597 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.598651 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.599278 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.599505 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.599947 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.600450 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.600680 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.601509 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.601608 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.602391 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.602656 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.603352 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.603704 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.604322 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.604892 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.605381 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.605748 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.606453 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.607637 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.608499 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.608719 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.611477 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.614953 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.615681 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.616334 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.617050 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.617128 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.617752 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.618094 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.618633 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.619029 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.619604 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.619971 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.620137 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.620585 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.620990 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.621167 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.621649 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.622256 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.622284 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.622722 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.623339 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.623360 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.623931 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.624457 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.624555 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.624794 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.625496 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.625659 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.626402 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.626788 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.627425 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.627971 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.628056 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.628454 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.629057 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.629591 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.630005 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.630785 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.631262 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.631796 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.632872 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.632891 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.634132 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.635568 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.636482 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.637438 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.638070 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.638364 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.639299 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.640255 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.640805 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.641263 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.642158 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.643173 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.643414 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.644206 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.645325 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.646180 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.646474 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.647473 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.648605 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.648687 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.649886 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.651496 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.651506 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.654925 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.656785 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.657690 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.660640 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.662206 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.663354 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.665996 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.667335 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.668667 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.673595 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.679303 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.684654 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.922585 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.923558 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.924596 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.925553 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.926556 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.927290 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.927549 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.928274 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.928592 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.929327 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.929660 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.930304 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.930743 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.931325 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.931834 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.932315 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.932978 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.933355 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.934161 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.934423 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.935593 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.935614 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.936709 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.936935 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.937865 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.938388 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.939049 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.939836 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.940307 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.941280 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.941666 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.943283 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.943300 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.944740 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.945335 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.945588 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.946199 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.946579 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.947623 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.947997 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.948108 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.948601 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.949612 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.950125 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.950613 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.951647 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.952879 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.952888 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.953975 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.955076 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.956218 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.957387 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.958124 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.958747 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.959335 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.960104 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.960500 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.961715 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.961795 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.963080 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.963246 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.963416 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.964359 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.964853 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.964857 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.965632 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.966020 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.966700 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.966964 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.967201 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.968393 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.968537 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.968743 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.969955 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.970049 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.971368 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.971498 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.971666 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.972712 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.973334 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.974030 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.974791 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.975547 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.976743 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.977208 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.978330 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.978893 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.979953 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.980359 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.981898 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.982324 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.983125 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.983925 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.984302 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.984995 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.985621 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.985712 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.986588 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.986894 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.988176 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.988496 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.989463 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.990439 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.990950 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.991043 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.992381 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.992400 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.992662 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.993923 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.994582 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.995294 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.995481 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.996533 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.997170 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.997786 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.998366 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697641.998650 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.000377 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.000624 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.001285 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.002223 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.003929 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.004023 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.006263 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.006545 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.009161 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.010770 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.012406 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.012634 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.012796 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.014754 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.016588 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.018607 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.018879 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.019525 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.022026 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.024549 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.024822 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.024921 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.030178 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.030628 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.030794 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.035819 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.036283 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.037052 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.041930 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.043290 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.048967 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.054657 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.060360 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.701124 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.702202 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.703291 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.704426 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.705569 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.707004 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.708547 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.710175 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.711939 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.713816 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.714183 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.715266 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.716143 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.716372 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.717517 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.718714 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.718884 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.720180 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.721735 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.723378 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.725337 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.725349 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.727252 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.729577 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.732220 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.735784 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.735809 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.736466 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.736935 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.737117 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.737737 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.738053 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.738415 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.738580 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.739019 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.739225 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.739672 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.740439 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.740520 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.741101 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.741774 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.741996 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.742498 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.743170 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.743577 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.743800 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.744595 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.745244 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.745475 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.747049 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.748319 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.748973 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.749398 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.750052 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.750647 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.751602 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.751671 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.751686 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.752300 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.752876 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.753512 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.754175 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.754502 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.754578 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.754838 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.755518 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.756149 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.756842 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.757455 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.757673 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.758288 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.759150 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.760999 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.761076 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.762016 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.763939 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.764946 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.767749 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.770820 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.771475 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.772117 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.772721 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.773342 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.774070 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.774182 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.774665 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.775301 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.775944 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.776585 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.777019 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.777278 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.777905 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.778605 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.779206 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.779973 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.780834 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.783713 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.786647 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.789465 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.792552 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.795852 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.798706 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.892607 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.893272 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.893939 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.894572 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.895219 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.895855 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.896508 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.897192 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.897878 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.898569 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.899278 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.900005 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.900772 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.901608 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.902572 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.903439 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.904321 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.905427 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.906398 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.906752 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.907080 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.907748 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.908214 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.908396 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.909041 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.909680 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.910334 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.911010 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.911704 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.912398 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.913106 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.913831 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.914644 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.915483 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.915792 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.916491 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.916670 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.917507 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.917609 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.918502 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.918520 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.919256 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.919646 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.920009 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.920733 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.920981 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.921601 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.922413 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.922626 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.923626 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.924610 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.925779 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.926824 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.927879 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.928787 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.929342 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.929713 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.930039 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.930245 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.930868 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.930948 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.931125 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.931587 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.931979 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.932000 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.932263 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.932919 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.933107 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.933217 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.933936 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.933941 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.934368 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.934793 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.934877 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.935362 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.935649 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.935756 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.936355 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.936771 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.936789 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.937086 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.938066 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.938111 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.938228 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.938968 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.939132 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.939530 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.939823 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.940138 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.940799 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.941241 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.941264 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.941678 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.942334 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.942587 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.942828 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.943413 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.943716 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.944340 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.945057 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.945270 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.945763 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.946303 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.946496 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.947221 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.948350 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.948698 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.949613 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.950565 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.951750 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.951860 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.953218 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.954036 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.954535 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.954774 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.954904 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.955652 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.956087 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.956466 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.957213 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.957670 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.958068 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.958173 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.958818 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.959679 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.960867 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.960876 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.961448 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.961915 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.962916 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.964062 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.964072 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.965138 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.966210 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.967147 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.967247 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.968168 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.969171 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.970321 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.970334 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.971470 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.972612 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.973786 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.973802 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.975040 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.976408 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.977095 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.977719 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.979268 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.980862 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.983833 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.986806 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.989775 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.992755 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.996068 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697642.999382 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.290251 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.290997 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.291711 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.292430 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.293174 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.294034 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.294990 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.295903 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.296927 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.299490 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.300819 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.302117 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.304673 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.307982 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.310255 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.311003 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.311856 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.312581 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.313331 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.314203 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.315167 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.316091 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.317121 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.317456 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.317987 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.318452 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.318919 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.319414 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.319710 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.319894 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.320374 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.321008 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.321122 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.321547 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.322067 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.322482 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.322641 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.323262 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.323849 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.324419 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.325207 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.325301 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.326907 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.328670 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.328694 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.330245 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.332416 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.333073 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.333238 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.333966 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.334742 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.334926 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.335502 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.336364 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.337325 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.338254 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.338328 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.338851 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.339465 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.339552 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.340018 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.340509 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.340968 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.341443 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.342041 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.342144 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.342577 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.343101 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.343646 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.343740 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.344361 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.345171 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.345183 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.345755 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.346423 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.347787 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.348039 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.349620 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.351412 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.351420 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.354173 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.355967 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.360541 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.361065 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.361535 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.361990 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.362485 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.362939 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.363420 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.363940 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.364471 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.364987 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.365481 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.366102 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.366695 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.367263 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.367930 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.369547 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.371142 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.372717 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.375492 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.377280 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.399854 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.400357 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.400894 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.401408 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.401888 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.402380 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.402907 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.403391 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.403895 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.404397 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.404902 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.405493 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.406095 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.406665 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.407262 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.407887 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.408587 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.409432 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.415485 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.416084 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.416600 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.417133 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.417698 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.418311 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.418868 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.419432 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.420074 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.420742 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.420903 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.421500 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.421523 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.422106 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.422262 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.422643 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.423084 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.423201 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.423727 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.423892 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.424267 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.424743 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.424862 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.425412 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.425577 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.425929 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.426439 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.426552 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.427095 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.427211 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.427931 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.428032 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.428514 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.428800 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.429129 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.429758 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.429874 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.430597 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.430827 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.431458 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.432424 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.434036 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.435640 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.437239 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.437676 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.438307 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.438964 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.439059 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.439512 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.440085 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.440731 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.440875 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.441312 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.441876 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.442691 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.442873 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.442940 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.443464 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.443575 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.444354 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.444365 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.444989 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.445095 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.445477 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.445914 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.446022 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.446698 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.446783 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.447190 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.447505 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.447706 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.448425 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.448438 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.448944 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.449168 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.449548 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.449774 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.450153 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.450663 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.450762 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.451599 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.451615 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.452239 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.452462 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.452955 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.453534 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.453818 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.455145 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.456770 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.458384 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.459767 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.460005 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.460369 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.460897 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.461451 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.461631 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.462036 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.462645 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.463230 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.463412 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.463811 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.464464 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.465194 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.465299 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.465857 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.466537 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.467235 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.467950 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.468666 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.469387 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.470122 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.470714 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.471476 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.472246 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.473088 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.474145 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.475749 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.477369 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.478983 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.480604 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.482227 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.484009 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.485785 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.595022 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.595559 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.596086 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.596623 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.597219 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.597837 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.598397 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.599047 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.599621 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.600569 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.602115 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.602911 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.603732 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.605385 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.606877 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.608830 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.616539 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.616939 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.617303 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.617664 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.618064 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.618459 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.618823 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.619196 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.619747 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.619783 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.620217 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.620392 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.620605 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.621076 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.621168 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.621712 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.621738 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.622108 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.622379 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.622572 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.623166 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.623187 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.623714 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.623829 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.624175 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.624532 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.624699 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.625122 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.625786 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.626100 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.626309 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.626872 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.627689 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.627880 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.628508 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.629350 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.631017 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.632518 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.632529 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.633017 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.633486 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.633971 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.634454 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.634565 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.634955 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.635457 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.635896 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.636351 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.636796 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.637322 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.637811 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.638248 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.638810 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.639445 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.639975 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.640653 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.640671 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.641255 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.641418 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.641791 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.642110 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.642348 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.642546 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.643232 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.643304 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.643315 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.643691 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.644263 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.644286 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.644309 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.644813 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.644912 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.645353 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.645476 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.645761 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.645863 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.646356 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.646531 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.646559 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.646759 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.647155 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.647886 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.647916 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.647922 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.648309 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.648738 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.648893 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.649132 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.649746 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.649754 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.649934 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.650201 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.650811 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.650850 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.650999 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.651314 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.651798 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.651895 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.652105 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.653018 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.653173 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.653725 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.653736 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.654305 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.655488 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.655497 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.657492 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.660237 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.660742 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.661210 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.661695 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.662130 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.662617 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.663067 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.663560 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.664027 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.664474 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.664968 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.665106 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.665609 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.665716 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.666276 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.666293 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.666672 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.666853 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.667083 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.667705 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.667723 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.668106 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.668294 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.668498 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.669086 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.669094 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.669494 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.669919 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.670001 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.670382 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.670729 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.670825 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.671205 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.671460 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.671666 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.672240 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.672333 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.672674 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.673218 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.673313 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.673681 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.674250 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.674771 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.675420 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.675434 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.675992 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.676357 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.676985 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.677375 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.678382 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.679481 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.680509 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.681533 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.682034 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.682511 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.683001 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.683434 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.683933 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.684379 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.684887 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.685354 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.685804 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.686298 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.686789 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.687216 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.687784 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.688430 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.688966 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.689504 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.690194 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.690874 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.691587 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.692308 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.693245 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.694185 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.695122 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.696054 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.697056 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.698059 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.699163 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.700197 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.725968 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.726410 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.726862 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.727301 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.727744 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.728193 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.728648 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.729109 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.729590 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.730552 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.731146 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.731906 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.732679 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.733625 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.734886 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.736367 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.744456 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.744842 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.745189 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.745521 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.745843 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.746210 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.746537 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.746887 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.747242 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.747613 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.747964 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.748317 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.748716 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.749074 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.749465 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.749833 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.750198 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.750649 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.751040 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.751429 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.751871 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.752292 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.753017 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.753642 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.754027 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.754619 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.755103 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.755535 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.755979 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.756428 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.756881 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.757342 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.757820 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.757865 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.758328 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.758880 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.758904 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.759259 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.759550 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.759713 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.760087 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.760359 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.760519 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.760888 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.761185 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.761340 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.761725 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.762275 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.762370 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.762812 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.763205 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.763678 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.763776 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.764173 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.764660 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.765183 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.765294 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.765654 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.766111 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.766630 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.767141 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.767607 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.768089 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.768674 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.769256 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.769840 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.770419 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.771213 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.771838 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.772453 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.773108 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.773622 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.774022 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.774400 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.774765 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.774821 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.775370 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.775385 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.775853 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.775965 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.776202 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.776529 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.776631 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.777126 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.777222 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.777628 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.777718 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.777997 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.778311 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.778418 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.779016 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.779026 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.779484 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.779595 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.779894 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.780260 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.780815 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.780825 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.781382 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.781487 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.781793 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.782230 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.782401 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.782698 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.783252 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.783353 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.783996 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.784320 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.784637 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.785591 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.787080 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.788813 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.789284 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.789846 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.790207 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.790610 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.791014 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.791415 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.791785 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.792194 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.792582 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.793014 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.793457 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.793850 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.794239 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.794641 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.795137 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.795275 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.795595 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.795788 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0849"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1729697643.796297 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.796310 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.796748 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.796850 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.797086 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.797621 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.797632 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.797987 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.798282 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.798388 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.798978 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.798989 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.799469 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.799568 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.799841 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.800412 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.800422 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.800819 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.801126 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.801231 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.801722 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.801819 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.802107 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.802660 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.802672 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.803116 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.803705 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.803722 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.804115 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.804372 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.804583 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.805207 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.805222 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.806072 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.806092 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.806734 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.807708 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.808082 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.808531 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.808890 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.809318 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.809692 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.810069 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.810482 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.810896 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.811214 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.811383 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.811908 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.811968 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.812282 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.812767 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.812848 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.813225 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.813629 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.813736 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.814102 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.814405 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.814565 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.814952 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.815545 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.815977 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.816367 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.816759 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.817162 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.817654 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.818061 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.818513 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.818967 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.819483 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.820002 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.820478 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.820950 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.821538 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.821608 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.821973 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.822210 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.822359 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.822709 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.822890 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.823067 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.823408 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.823600 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.823772 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.824084 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.824503 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.824569 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.824825 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.825160 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.825343 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.825520 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.825881 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.826061 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.826239 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.826611 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.826794 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.826960 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.827446 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.827939 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.828448 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.828987 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.829873 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.838313 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.838595 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.838881 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.839168 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.839472 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.839785 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.840092 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.840400 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.840721 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.841087 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.841322 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.841495 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.841745 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.841916 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.842345 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.842442 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.842860 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.842959 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.843440 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.843540 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.843963 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.844071 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.844487 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.844587 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.845038 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.845139 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.845608 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.845784 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.846141 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.846400 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.847084 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.847862 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.848581 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.850443 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.850825 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.851171 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.851516 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.851860 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.852193 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.852548 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.852903 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.853260 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.853614 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.853932 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.854281 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.854625 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.854973 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.855241 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.855338 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.855621 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.855906 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.856030 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.856456 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.856471 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.856897 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.857009 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.857245 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.857527 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.857640 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.858062 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.858156 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.858387 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.858773 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.858800 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.859144 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.859415 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.859529 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.859884 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.860165 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.860281 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.860643 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.860814 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.861015 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.861467 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.861559 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.861849 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.862321 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.862431 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.862453 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.862951 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.862957 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.863562 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.863579 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.864175 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.864185 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.864845 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.864857 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.865264 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.865442 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.865661 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.866047 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.866152 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.866618 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.866846 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.867444 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.868126 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.868890 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.869616 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.876062 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.876413 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.876711 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.876999 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.877292 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.877582 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.877881 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.877902 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.878354 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.878433 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.878950 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.878961 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.879584 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.879591 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.879698 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.880290 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.880299 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.880405 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.880994 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.881003 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.881101 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.881704 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.881720 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.881820 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.882399 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.882408 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.882512 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.883004 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.883093 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.883103 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.883526 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.883716 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.883822 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.883965 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.884255 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.884544 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.884579 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.884765 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.885005 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.885373 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.885492 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.885576 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.886291 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.886372 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.886388 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.886672 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.887161 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.887285 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.887360 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.888146 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.888179 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.888247 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.888796 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.889025 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.889127 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.889368 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.889876 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.893603 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.893943 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.894291 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.894647 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.895041 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.895446 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.895834 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.896194 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.896583 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.896973 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.897364 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.897900 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.898302 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.898704 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.899087 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.899489 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.899877 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.900261 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.900652 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.900907 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.901043 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.901340 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.901518 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.901718 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.901978 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.902140 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.902422 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.902590 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.902890 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.903008 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.903428 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.903501 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.903930 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.904004 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.904460 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.904532 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.904904 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.905070 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.905306 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.905536 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.906040 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.906428 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.906684 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.906849 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.907274 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.907911 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.908616 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.909419 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.909586 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.909930 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.910280 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.910399 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.910706 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.910820 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.911193 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.911357 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.911553 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.911935 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.912049 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.912439 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.912964 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.913070 1798455 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.913404 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.913780 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.914171 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.914575 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.914966 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.915356 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.915744 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.916144 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.916538 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.916941 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.917333 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.917723 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.918115 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.918514 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.918913 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.919304 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.919694 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.920082 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.920447 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.920838 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.921226 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.921623 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.922740 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.923121 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.925775 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.926124 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.926483 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.926928 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.927504 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.927948 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.928908 1798433 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.929940 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.930306 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.930651 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.930998 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.931390 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.931775 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.932164 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.932550 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.932907 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.933304 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.933689 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.934097 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.934485 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.934879 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.935273 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.935665 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.936052 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.936435 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.936816 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.937194 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.937583 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.937966 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.938355 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.938735 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.939119 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.939474 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.939858 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.940245 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.940626 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.941754 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.942136 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.944806 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.945150 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.945507 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.945879 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.946457 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.946901 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697643.947839 1798445 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "2024-10-23 15:34:04.811933: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "W0000 00:00:1729697644.835294 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.835761 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.835836 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.835866 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.836748 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.836757 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.836791 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.837636 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.837661 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.837694 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.838488 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.838511 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.838545 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.839337 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.839361 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.839399 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.840211 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.840237 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.840278 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.841082 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.841087 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.841118 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.841925 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.841946 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.841982 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.842817 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.842836 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.842865 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.843635 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.843715 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.843741 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.844435 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.844454 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.844576 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.845234 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.845320 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.845337 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.846034 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.846126 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.846139 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.846878 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.846957 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.846976 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.847757 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.847837 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.847865 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.848616 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.848637 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.848765 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.849385 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.849439 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.849553 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.850325 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.850344 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.850466 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.851119 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.851140 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.851261 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.852037 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.852107 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.852137 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.853003 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.853084 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.853099 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.853787 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.853843 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.853980 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.854370 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.855057 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.855127 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.855143 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.855902 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.855972 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.855991 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.856589 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.856671 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.856802 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.857577 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.857657 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.857688 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.858440 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.858608 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.858644 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.859285 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.859493 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.859525 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.860240 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.860281 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.860324 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.861066 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.861145 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.861273 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.861957 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.861978 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.862183 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.862870 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.863217 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.863259 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.863449 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.863770 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.864122 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.864527 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.864565 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.865023 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.865646 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.865722 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.865912 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.866286 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.866734 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.866762 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.867389 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.867583 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.867798 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.868679 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.868822 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.869017 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.869918 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.883067 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.883509 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.883876 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.884243 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.884348 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.884689 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.884963 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.885155 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.885439 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.885591 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.885685 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.886035 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.886372 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.886396 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.886760 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.887116 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.887146 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.887331 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.887728 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.888008 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.888086 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.888227 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.888940 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.888974 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.888997 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.889591 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.889672 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.889822 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.890189 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.890220 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.890861 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.891064 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.891134 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.891410 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.892000 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.892135 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.892247 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.893130 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.893252 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.893339 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.894100 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.894276 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.894457 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.895315 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.895431 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.895554 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.896302 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.896637 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.896642 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.897459 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.897495 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.898549 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.898586 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.899527 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.909284 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.909593 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.909908 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.910229 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.910564 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.910906 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.911336 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.911402 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.911743 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.911888 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.912296 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.912406 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.912586 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.912731 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.912862 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.913315 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.913324 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.913427 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.913985 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.914019 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.914100 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.914664 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.914697 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.914771 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.915315 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.915332 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.915366 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.915959 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.915981 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.916061 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.916355 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.916735 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.916834 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.916960 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.917185 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.917594 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.917682 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.917790 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.918175 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.918306 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.918400 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.919044 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.919115 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.919133 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.919608 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.919789 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.919823 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.920042 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.920274 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.920791 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.920885 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.921235 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.921398 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.921660 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.922121 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.922216 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.922913 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.926293 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.926672 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.927003 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.927329 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.927677 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.928029 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.928363 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.928677 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.928722 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.929197 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.929272 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.929492 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.929585 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.929914 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.930079 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.930184 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.930591 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.930644 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.930743 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.931301 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.931336 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.931416 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.931802 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.931911 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.932402 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.932531 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.932710 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.932839 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.933181 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.933323 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.933657 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.933826 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.933846 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.934385 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.934405 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.934924 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.935035 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.935345 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.935456 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.935966 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.936377 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.936978 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.936997 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.937267 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.938021 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.938563 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.938817 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.939084 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.940121 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.940301 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.940418 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.941394 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.941516 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.942509 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.942624 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.943507 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.943609 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.965080 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.965432 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.965787 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.966144 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.966505 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.966850 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.967210 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.967591 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.967977 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.968692 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.968697 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.968711 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.969412 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.969420 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.969439 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.970107 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.970123 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.970145 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.970801 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.970815 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.970841 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.971464 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.971594 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.971614 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.971867 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.972274 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.972363 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.972480 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.972694 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.973044 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.973244 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.973421 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.973537 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.973944 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.974090 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.974361 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.974644 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.974676 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.974884 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.975274 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.975350 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.975459 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.975875 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.975903 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.976516 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.976706 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.976719 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.977357 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.977541 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.977561 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.978367 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.978460 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.978496 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.978892 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.979640 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.979686 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.979852 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.980204 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.980369 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.980845 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.981020 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.981663 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.981832 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.982285 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.982449 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.983012 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.983189 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.983957 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.984127 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.986222 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.986676 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.987082 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.987529 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.987965 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.988360 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.988786 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.989186 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.989611 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.990165 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.990674 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.990709 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.990723 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.991447 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.991527 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.991539 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.992039 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.992062 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.992672 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.992692 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.993420 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.993443 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.993463 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.994037 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.994056 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.994648 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.994669 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.995225 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.995407 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.995427 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.996021 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.996041 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.996863 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.996938 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.996954 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.997555 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.997576 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.998306 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.998326 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697644.999887 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.000047 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.000067 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.001885 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.001894 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.001995 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.003370 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.003389 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.004749 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.006263 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.006283 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.006664 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.008363 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.008383 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.011217 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.011316 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.013299 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.013399 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.056166 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.056613 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.057046 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.057484 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.057925 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.058373 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.058822 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.059277 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.059775 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.060282 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.060783 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.061298 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.061838 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.062684 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.062702 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.063147 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.063326 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.063421 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.063782 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.063881 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.064397 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.064417 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.065142 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.065165 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.065187 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.065993 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.066073 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.066096 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.066623 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.066750 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.066848 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.067215 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.067336 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.067681 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.067828 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.067938 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.068482 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.068779 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.068789 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.069019 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.069298 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.069538 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.069935 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.070153 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.070226 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.070505 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.070786 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.071118 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.071401 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.071909 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.071958 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.072122 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.073478 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.073691 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.074145 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.074369 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.074842 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.075072 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.075577 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.075807 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.076387 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.076617 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.077577 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.077819 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.079091 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.079339 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.079453 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.080036 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.080879 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.081431 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.081951 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.082514 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.083132 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.083659 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.084262 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.084784 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.085351 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.085931 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.086893 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.087015 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.087512 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.087687 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.088236 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.088423 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.088443 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.088791 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.089011 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.089338 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.089548 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.089921 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.090128 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.090578 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.090766 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.091334 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.091458 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.091534 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.091984 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.092181 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.092529 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.092718 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.093137 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.093334 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.093741 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.093972 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.094144 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.096037 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.096314 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.096507 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.098741 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.099038 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.099497 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.101373 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.101698 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.102503 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.103681 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.104026 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.106620 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.106991 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.107791 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.109609 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.110013 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.114852 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.115305 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.205819 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.206436 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.207039 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.207604 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.208199 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.208812 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.209450 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.210057 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.210764 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.211560 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.211961 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.212284 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.212553 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.213153 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.213320 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.213584 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.214024 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.214188 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.214288 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.214953 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.215149 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.215161 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.215612 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.215776 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.216358 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.216467 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.216550 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.217333 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.217447 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.217527 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.218192 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.218284 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.219075 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.219096 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.220139 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.220210 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.220226 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.221031 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.221050 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.221324 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.221944 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.221965 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.222878 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.222904 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.223029 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.223659 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.224242 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.224251 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.224574 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.225276 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.225553 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.226379 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.226586 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.227613 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.228686 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.228977 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.229155 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.230121 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.230220 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.231317 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.231530 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.232717 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.233417 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.234810 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.236135 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.237550 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.237553 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.238394 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.239211 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.240089 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.240902 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.241847 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.242614 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.243397 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.244375 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.244616 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.245150 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.245457 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.245972 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.246046 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.246273 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.246869 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.247159 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.247264 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.247703 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.248076 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.248584 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.249024 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.249399 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.249806 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.250352 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.250598 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.251275 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.251361 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.251587 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.252070 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.252369 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.253078 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.253278 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.253862 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.254181 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.254767 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.255787 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.255806 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.258206 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.259856 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.260970 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.262472 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.264163 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.266006 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.267610 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.269334 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.271736 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.272611 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.274368 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.277535 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.278298 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.280079 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.284074 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.285879 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.287878 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.294285 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.296138 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.484666 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.485521 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.486368 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.487180 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.488064 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.489163 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.489198 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.490199 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.490300 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.491177 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.491287 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.491844 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.492005 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.492376 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.492858 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.492974 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.493320 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.493854 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.493976 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.494438 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.494699 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.494978 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.495730 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.495906 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.496030 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.497094 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.497176 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.497284 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.498223 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.498334 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.498708 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.499135 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.499437 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.500346 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.500525 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.500632 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.501296 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.501815 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.502114 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.502401 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.503382 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.503546 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.504719 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.504964 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.506357 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.506449 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.506637 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.508059 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.508259 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.509628 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.510414 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.510716 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.512658 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.513738 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.514797 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.515628 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.517776 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.517899 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.519161 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.520456 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.521680 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.522366 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.522939 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.523622 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.524527 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.524909 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.525317 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.525714 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.526152 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.526594 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.527161 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.527415 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.527904 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.528729 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.529037 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.529212 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.529978 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.530222 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.531132 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.531372 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.531666 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.532854 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.532936 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.533218 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.534048 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.534466 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.535500 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.535848 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.537057 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.537287 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.538319 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.539703 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.540772 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.541155 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.545039 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.548301 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.548984 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.552509 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.556493 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.558431 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.562460 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.566545 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.568260 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.572104 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.576364 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.578257 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.581920 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.586369 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.588395 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.591922 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.596547 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.609906 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.613447 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697645.618040 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.001601 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.003034 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.003215 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.004391 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.004586 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.005856 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.005963 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.007434 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.007525 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.009039 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.009244 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.009381 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.010533 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.010859 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.010961 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.012392 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.012510 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.012592 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.014012 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.014111 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.014394 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.015561 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.015908 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.016006 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.017065 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.017468 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.017890 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.018685 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.019331 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.019792 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.020159 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.021214 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.021835 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.022011 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.023203 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.023569 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.024574 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.025438 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.025976 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.027445 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.027521 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.028694 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.029523 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.030279 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.031530 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.032276 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.034999 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.037863 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.038070 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.039136 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.041489 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.042529 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.045607 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.045693 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.046467 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.049123 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.053126 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.055102 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.055920 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.055996 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.056873 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.057004 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.057748 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.057855 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.058551 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.058723 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.059588 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.059687 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.060642 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.060818 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.061654 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.062852 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.063664 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.064452 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.065208 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.065951 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.066338 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.067147 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.067170 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.068163 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.072281 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.073028 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.073606 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.077947 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.078494 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.079619 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.082334 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.082838 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.085143 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.087668 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.088138 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.089517 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.093093 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.093519 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.094869 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.100289 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.102976 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.103337 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.110180 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 296ms/step - loss: 0.0846 - val_loss: 0.0653 - learning_rate: 1.0000e-04\n",
      "Epoch 2/3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1729697646.283910 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.284437 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.284719 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.285237 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.285528 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.286035 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.286337 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.286825 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.287154 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.287630 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.288010 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.288483 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.288879 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.289339 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.289776 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.290217 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.290679 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.291226 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.291495 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.291641 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.292140 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.292359 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.292565 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.293090 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.293265 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.293459 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.294057 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.294155 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.294486 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.295207 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.295231 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.295513 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.296188 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.296307 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.296672 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.297061 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.297452 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.298041 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.298148 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.298985 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.299080 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.299757 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.299954 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.300589 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.300860 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.301180 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.301750 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.302014 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.302775 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.303790 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.304931 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.306320 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.307904 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.309320 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.315073 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.315752 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.319278 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.319920 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.321078 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.321698 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.323234 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.323330 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.323696 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.327533 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.329308 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.331304 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.334579 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.335036 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.335218 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.335437 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.335631 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.335940 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.336050 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.336561 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.336575 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.337192 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.337203 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.337909 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.337920 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.338399 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.339178 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.339650 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.340242 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.340715 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.341332 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.341800 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.342512 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.343037 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.343107 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.343576 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.343594 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.343945 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.344361 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.344519 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.344962 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.345087 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.345471 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.345880 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.346440 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.346740 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.347028 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.347585 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.347814 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.348885 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.350517 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.351880 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.353221 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.354352 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.358453 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.358822 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.359122 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.359217 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.359701 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.359713 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.360270 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.360275 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.360849 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.360859 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.361427 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.361438 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.361923 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.362004 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.362416 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.362513 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.362879 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.362978 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.363348 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.363450 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.363845 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.363944 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.364366 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.364467 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.364787 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.364968 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.365185 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.365507 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.365649 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.365912 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.366115 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.366355 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.366493 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.366728 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.366954 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.367098 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.367384 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.367619 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.367717 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.368057 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.368228 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.368249 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.368692 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.368806 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.369052 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.369393 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.369870 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.369893 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.370248 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.370531 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.370806 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.370890 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.371316 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.371432 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.371719 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.372100 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.372508 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.372914 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.373218 1798460 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.373381 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.373728 1798416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.373896 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.374387 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.376064 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.376910 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729697646.379177 1798453 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0652"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:34:07.793258: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0652 - val_loss: 0.0642 - learning_rate: 1.0000e-04\n",
      "Epoch 3/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0594 - val_loss: 0.0482 - learning_rate: 1.0000e-04\n",
      "Epoch 4/3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:34:09.652845: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0449 - val_loss: 0.0373 - learning_rate: 1.0000e-04\n",
      "Epoch 5/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0348 - val_loss: 0.0251 - learning_rate: 1.0000e-04\n",
      "Epoch 6/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0261"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:34:14.161702: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0261 - val_loss: 0.0225 - learning_rate: 1.0000e-04\n",
      "Epoch 7/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0226 - val_loss: 0.0201 - learning_rate: 1.0000e-04\n",
      "Epoch 8/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0207 - val_loss: 0.0187 - learning_rate: 1.0000e-04\n",
      "Epoch 9/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0195 - val_loss: 0.0176 - learning_rate: 1.0000e-04\n",
      "Epoch 10/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0184 - val_loss: 0.0165 - learning_rate: 1.0000e-04\n",
      "Epoch 11/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0173 - val_loss: 0.0162 - learning_rate: 1.0000e-04\n",
      "Epoch 12/3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:34:22.460521: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0166 - val_loss: 0.0148 - learning_rate: 1.0000e-04\n",
      "Epoch 13/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0158 - val_loss: 0.0140 - learning_rate: 1.0000e-04\n",
      "Epoch 14/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0150 - val_loss: 0.0134 - learning_rate: 1.0000e-04\n",
      "Epoch 15/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0142 - val_loss: 0.0128 - learning_rate: 1.0000e-04\n",
      "Epoch 16/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0135 - val_loss: 0.0116 - learning_rate: 1.0000e-04\n",
      "Epoch 17/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0129 - val_loss: 0.0117 - learning_rate: 1.0000e-04\n",
      "Epoch 18/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0122 - val_loss: 0.0106 - learning_rate: 1.0000e-04\n",
      "Epoch 19/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0117 - val_loss: 0.0096 - learning_rate: 1.0000e-04\n",
      "Epoch 20/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0111 - val_loss: 0.0098 - learning_rate: 1.0000e-04\n",
      "Epoch 21/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0107 - val_loss: 0.0093 - learning_rate: 1.0000e-04\n",
      "Epoch 22/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0101"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:34:40.141209: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0101 - val_loss: 0.0090 - learning_rate: 1.0000e-04\n",
      "Epoch 23/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0097 - val_loss: 0.0086 - learning_rate: 1.0000e-04\n",
      "Epoch 24/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0094 - val_loss: 0.0080 - learning_rate: 1.0000e-04\n",
      "Epoch 25/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0089 - val_loss: 0.0074 - learning_rate: 1.0000e-04\n",
      "Epoch 26/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0085 - val_loss: 0.0076 - learning_rate: 1.0000e-04\n",
      "Epoch 27/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0082 - val_loss: 0.0071 - learning_rate: 1.0000e-04\n",
      "Epoch 28/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0079 - val_loss: 0.0069 - learning_rate: 1.0000e-04\n",
      "Epoch 29/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0076 - val_loss: 0.0066 - learning_rate: 1.0000e-04\n",
      "Epoch 30/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0073 - val_loss: 0.0061 - learning_rate: 1.0000e-04\n",
      "Epoch 31/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0072 - val_loss: 0.0062 - learning_rate: 1.0000e-04\n",
      "Epoch 32/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0068 - val_loss: 0.0056 - learning_rate: 1.0000e-04\n",
      "Epoch 33/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0067 - val_loss: 0.0056 - learning_rate: 1.0000e-04\n",
      "Epoch 34/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0063 - val_loss: 0.0051 - learning_rate: 1.0000e-04\n",
      "Epoch 35/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0061 - val_loss: 0.0052 - learning_rate: 1.0000e-04\n",
      "Epoch 36/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0060 - val_loss: 0.0051 - learning_rate: 1.0000e-04\n",
      "Epoch 37/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0058 - val_loss: 0.0049 - learning_rate: 1.0000e-04\n",
      "Epoch 38/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0057 - val_loss: 0.0046 - learning_rate: 1.0000e-04\n",
      "Epoch 39/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0055 - val_loss: 0.0049 - learning_rate: 1.0000e-04\n",
      "Epoch 40/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0053 - val_loss: 0.0045 - learning_rate: 1.0000e-04\n",
      "Epoch 41/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0052 - val_loss: 0.0042 - learning_rate: 1.0000e-04\n",
      "Epoch 42/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0050 - val_loss: 0.0049 - learning_rate: 1.0000e-04\n",
      "Epoch 43/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0049 - val_loss: 0.0043 - learning_rate: 1.0000e-04\n",
      "Epoch 44/3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:35:13.965809: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0048 - val_loss: 0.0040 - learning_rate: 1.0000e-04\n",
      "Epoch 45/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0046 - val_loss: 0.0041 - learning_rate: 1.0000e-04\n",
      "Epoch 46/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0046 - val_loss: 0.0041 - learning_rate: 1.0000e-04\n",
      "Epoch 47/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0045 - val_loss: 0.0041 - learning_rate: 1.0000e-04\n",
      "Epoch 48/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0043 - val_loss: 0.0040 - learning_rate: 1.0000e-04\n",
      "Epoch 49/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0042 - val_loss: 0.0042 - learning_rate: 1.0000e-04\n",
      "Epoch 50/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0041 - val_loss: 0.0037 - learning_rate: 1.0000e-04\n",
      "Epoch 51/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0040 - val_loss: 0.0037 - learning_rate: 1.0000e-04\n",
      "Epoch 52/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0039 - val_loss: 0.0035 - learning_rate: 1.0000e-04\n",
      "Epoch 53/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0038 - val_loss: 0.0036 - learning_rate: 1.0000e-04\n",
      "Epoch 54/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0038 - val_loss: 0.0035 - learning_rate: 1.0000e-04\n",
      "Epoch 55/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0036 - val_loss: 0.0032 - learning_rate: 1.0000e-04\n",
      "Epoch 56/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0036 - val_loss: 0.0034 - learning_rate: 1.0000e-04\n",
      "Epoch 57/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0035 - val_loss: 0.0033 - learning_rate: 1.0000e-04\n",
      "Epoch 58/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0035 - val_loss: 0.0030 - learning_rate: 1.0000e-04\n",
      "Epoch 59/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0034 - val_loss: 0.0031 - learning_rate: 1.0000e-04\n",
      "Epoch 60/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0033 - val_loss: 0.0030 - learning_rate: 1.0000e-04\n",
      "Epoch 61/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0032 - val_loss: 0.0029 - learning_rate: 1.0000e-04\n",
      "Epoch 62/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0032 - val_loss: 0.0032 - learning_rate: 1.0000e-04\n",
      "Epoch 63/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0031 - val_loss: 0.0030 - learning_rate: 1.0000e-04\n",
      "Epoch 64/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0030 - val_loss: 0.0029 - learning_rate: 1.0000e-04\n",
      "Epoch 65/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0030 - val_loss: 0.0027 - learning_rate: 1.0000e-04\n",
      "Epoch 66/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0029 - val_loss: 0.0027 - learning_rate: 1.0000e-04\n",
      "Epoch 67/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0029 - val_loss: 0.0028 - learning_rate: 1.0000e-04\n",
      "Epoch 68/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0029 - val_loss: 0.0026 - learning_rate: 1.0000e-04\n",
      "Epoch 69/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0028 - val_loss: 0.0026 - learning_rate: 1.0000e-04\n",
      "Epoch 70/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0028 - val_loss: 0.0027 - learning_rate: 1.0000e-04\n",
      "Epoch 71/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0027 - val_loss: 0.0026 - learning_rate: 1.0000e-04\n",
      "Epoch 72/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0027 - val_loss: 0.0025 - learning_rate: 1.0000e-04\n",
      "Epoch 73/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0026 - val_loss: 0.0023 - learning_rate: 1.0000e-04\n",
      "Epoch 74/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0026 - val_loss: 0.0025 - learning_rate: 1.0000e-04\n",
      "Epoch 75/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0025 - val_loss: 0.0025 - learning_rate: 1.0000e-04\n",
      "Epoch 76/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0025 - val_loss: 0.0025 - learning_rate: 1.0000e-04\n",
      "Epoch 77/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 137ms/step - loss: 0.0024 - val_loss: 0.0024 - learning_rate: 1.0000e-04\n",
      "Epoch 78/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0024 - val_loss: 0.0023 - learning_rate: 1.0000e-04\n",
      "Epoch 79/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0024 - val_loss: 0.0023 - learning_rate: 1.0000e-04\n",
      "Epoch 80/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0023 - val_loss: 0.0023 - learning_rate: 1.0000e-04\n",
      "Epoch 81/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0023 - val_loss: 0.0023 - learning_rate: 1.0000e-04\n",
      "Epoch 82/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0022 - val_loss: 0.0021 - learning_rate: 1.0000e-04\n",
      "Epoch 83/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0022 - val_loss: 0.0023 - learning_rate: 1.0000e-04\n",
      "Epoch 84/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0022 - val_loss: 0.0025 - learning_rate: 1.0000e-04\n",
      "Epoch 85/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0022 - val_loss: 0.0022 - learning_rate: 1.0000e-04\n",
      "Epoch 86/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0021"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:36:26.803406: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0021 - val_loss: 0.0023 - learning_rate: 1.0000e-04\n",
      "Epoch 87/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0021 - val_loss: 0.0019 - learning_rate: 1.0000e-04\n",
      "Epoch 88/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0020 - val_loss: 0.0020 - learning_rate: 1.0000e-04\n",
      "Epoch 89/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0020 - val_loss: 0.0020 - learning_rate: 1.0000e-04\n",
      "Epoch 90/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0020 - val_loss: 0.0020 - learning_rate: 1.0000e-04\n",
      "Epoch 91/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0020 - val_loss: 0.0019 - learning_rate: 1.0000e-04\n",
      "Epoch 92/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0019 - val_loss: 0.0022 - learning_rate: 1.0000e-04\n",
      "Epoch 93/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0019 - val_loss: 0.0020 - learning_rate: 1.0000e-04\n",
      "Epoch 94/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0019 - val_loss: 0.0019 - learning_rate: 1.0000e-04\n",
      "Epoch 95/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0018 - val_loss: 0.0021 - learning_rate: 1.0000e-04\n",
      "Epoch 96/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0018 - val_loss: 0.0019 - learning_rate: 1.0000e-04\n",
      "Epoch 97/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0018\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 8.999999772640876e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0018 - val_loss: 0.0020 - learning_rate: 1.0000e-04\n",
      "Epoch 98/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0018 - val_loss: 0.0019 - learning_rate: 9.0000e-05\n",
      "Epoch 99/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0018 - val_loss: 0.0019 - learning_rate: 9.0000e-05\n",
      "Epoch 100/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0017 - val_loss: 0.0018 - learning_rate: 9.0000e-05\n",
      "Epoch 101/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0017 - val_loss: 0.0019 - learning_rate: 9.0000e-05\n",
      "Epoch 102/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0017 - val_loss: 0.0019 - learning_rate: 9.0000e-05\n",
      "Epoch 103/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0017 - val_loss: 0.0019 - learning_rate: 9.0000e-05\n",
      "Epoch 104/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0017 - val_loss: 0.0018 - learning_rate: 9.0000e-05\n",
      "Epoch 105/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0016 - val_loss: 0.0018 - learning_rate: 9.0000e-05\n",
      "Epoch 106/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0016 - val_loss: 0.0018 - learning_rate: 9.0000e-05\n",
      "Epoch 107/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0016\n",
      "Epoch 107: ReduceLROnPlateau reducing learning rate to 8.100000122794882e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0016 - val_loss: 0.0018 - learning_rate: 9.0000e-05\n",
      "Epoch 108/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0016 - val_loss: 0.0018 - learning_rate: 8.1000e-05\n",
      "Epoch 109/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0015 - val_loss: 0.0019 - learning_rate: 8.1000e-05\n",
      "Epoch 110/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0016 - val_loss: 0.0019 - learning_rate: 8.1000e-05\n",
      "Epoch 111/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0015 - val_loss: 0.0018 - learning_rate: 8.1000e-05\n",
      "Epoch 112/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.0014 - val_loss: 0.0018 - learning_rate: 8.1000e-05\n",
      "Epoch 113/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0015 - val_loss: 0.0016 - learning_rate: 8.1000e-05\n",
      "Epoch 114/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0015 - val_loss: 0.0016 - learning_rate: 8.1000e-05\n",
      "Epoch 115/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - loss: 0.0014 - val_loss: 0.0017 - learning_rate: 8.1000e-05\n",
      "Epoch 116/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0014 - val_loss: 0.0016 - learning_rate: 8.1000e-05\n",
      "Epoch 117/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0014 - val_loss: 0.0015 - learning_rate: 8.1000e-05\n",
      "Epoch 118/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0014 - val_loss: 0.0017 - learning_rate: 8.1000e-05\n",
      "Epoch 119/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0014 - val_loss: 0.0016 - learning_rate: 8.1000e-05\n",
      "Epoch 120/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0014 - val_loss: 0.0015 - learning_rate: 8.1000e-05\n",
      "Epoch 121/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0014 - val_loss: 0.0014 - learning_rate: 8.1000e-05\n",
      "Epoch 122/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0014 - val_loss: 0.0017 - learning_rate: 8.1000e-05\n",
      "Epoch 123/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0013 - val_loss: 0.0015 - learning_rate: 8.1000e-05\n",
      "Epoch 124/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0013 - val_loss: 0.0017 - learning_rate: 8.1000e-05\n",
      "Epoch 125/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0013 - val_loss: 0.0014 - learning_rate: 8.1000e-05\n",
      "Epoch 126/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0013 - val_loss: 0.0016 - learning_rate: 8.1000e-05\n",
      "Epoch 127/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0013\n",
      "Epoch 127: ReduceLROnPlateau reducing learning rate to 7.289999848580919e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0013 - val_loss: 0.0015 - learning_rate: 8.1000e-05\n",
      "Epoch 128/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0013 - val_loss: 0.0015 - learning_rate: 7.2900e-05\n",
      "Epoch 129/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0013 - val_loss: 0.0015 - learning_rate: 7.2900e-05\n",
      "Epoch 130/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0013 - val_loss: 0.0014 - learning_rate: 7.2900e-05\n",
      "Epoch 131/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0012 - val_loss: 0.0017 - learning_rate: 7.2900e-05\n",
      "Epoch 132/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0012 - val_loss: 0.0015 - learning_rate: 7.2900e-05\n",
      "Epoch 133/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0012 - val_loss: 0.0014 - learning_rate: 7.2900e-05\n",
      "Epoch 134/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0012 - val_loss: 0.0015 - learning_rate: 7.2900e-05\n",
      "Epoch 135/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0012 - val_loss: 0.0013 - learning_rate: 7.2900e-05\n",
      "Epoch 136/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0012 - val_loss: 0.0014 - learning_rate: 7.2900e-05\n",
      "Epoch 137/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0012 - val_loss: 0.0015 - learning_rate: 7.2900e-05\n",
      "Epoch 138/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0012 - val_loss: 0.0013 - learning_rate: 7.2900e-05\n",
      "Epoch 139/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0012 - val_loss: 0.0015 - learning_rate: 7.2900e-05\n",
      "Epoch 140/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0011 - val_loss: 0.0012 - learning_rate: 7.2900e-05\n",
      "Epoch 141/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0011 - val_loss: 0.0015 - learning_rate: 7.2900e-05\n",
      "Epoch 142/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0011 - val_loss: 0.0013 - learning_rate: 7.2900e-05\n",
      "Epoch 143/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0011 - val_loss: 0.0014 - learning_rate: 7.2900e-05\n",
      "Epoch 144/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0011 - val_loss: 0.0013 - learning_rate: 7.2900e-05\n",
      "Epoch 145/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0011 - val_loss: 0.0012 - learning_rate: 7.2900e-05\n",
      "Epoch 146/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0011 - val_loss: 0.0014 - learning_rate: 7.2900e-05\n",
      "Epoch 147/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0011 - val_loss: 0.0013 - learning_rate: 7.2900e-05\n",
      "Epoch 148/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0011 - val_loss: 0.0013 - learning_rate: 7.2900e-05\n",
      "Epoch 149/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0011 - val_loss: 0.0013 - learning_rate: 7.2900e-05\n",
      "Epoch 150/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0011\n",
      "Epoch 150: ReduceLROnPlateau reducing learning rate to 6.56100019114092e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0011 - val_loss: 0.0013 - learning_rate: 7.2900e-05\n",
      "Epoch 151/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0011 - val_loss: 0.0012 - learning_rate: 6.5610e-05\n",
      "Epoch 152/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0010 - val_loss: 0.0014 - learning_rate: 6.5610e-05\n",
      "Epoch 153/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0010 - val_loss: 0.0012 - learning_rate: 6.5610e-05\n",
      "Epoch 154/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0010 - val_loss: 0.0013 - learning_rate: 6.5610e-05\n",
      "Epoch 155/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0010 - val_loss: 0.0013 - learning_rate: 6.5610e-05\n",
      "Epoch 156/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0010 - val_loss: 0.0015 - learning_rate: 6.5610e-05\n",
      "Epoch 157/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 9.9009e-04 - val_loss: 0.0012 - learning_rate: 6.5610e-05\n",
      "Epoch 158/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 9.7428e-04 - val_loss: 0.0012 - learning_rate: 6.5610e-05\n",
      "Epoch 159/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 9.9218e-04 - val_loss: 0.0013 - learning_rate: 6.5610e-05\n",
      "Epoch 160/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 9.5586e-04\n",
      "Epoch 160: ReduceLROnPlateau reducing learning rate to 5.904900172026828e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 9.5581e-04 - val_loss: 0.0013 - learning_rate: 6.5610e-05\n",
      "Epoch 161/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 9.6984e-04 - val_loss: 0.0013 - learning_rate: 5.9049e-05\n",
      "Epoch 162/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 9.5898e-04 - val_loss: 0.0015 - learning_rate: 5.9049e-05\n",
      "Epoch 163/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 9.5078e-04 - val_loss: 0.0011 - learning_rate: 5.9049e-05\n",
      "Epoch 164/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 9.4702e-04 - val_loss: 0.0013 - learning_rate: 5.9049e-05\n",
      "Epoch 165/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 9.3135e-04 - val_loss: 0.0012 - learning_rate: 5.9049e-05\n",
      "Epoch 166/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 9.2870e-04 - val_loss: 0.0012 - learning_rate: 5.9049e-05\n",
      "Epoch 167/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 9.2178e-04 - val_loss: 0.0013 - learning_rate: 5.9049e-05\n",
      "Epoch 168/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 9.4205e-04 - val_loss: 0.0012 - learning_rate: 5.9049e-05\n",
      "Epoch 169/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 9.0400e-04 - val_loss: 0.0013 - learning_rate: 5.9049e-05\n",
      "Epoch 170/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 8.8367e-04\n",
      "Epoch 170: ReduceLROnPlateau reducing learning rate to 5.314410154824145e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 8.8394e-04 - val_loss: 0.0013 - learning_rate: 5.9049e-05\n",
      "Epoch 171/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 9.0241e-04 - val_loss: 0.0011 - learning_rate: 5.3144e-05\n",
      "Epoch 172/3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:38:48.409846: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 9.0010e-04 - val_loss: 0.0012 - learning_rate: 5.3144e-05\n",
      "Epoch 173/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 8.9153e-04 - val_loss: 0.0012 - learning_rate: 5.3144e-05\n",
      "Epoch 174/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 8.7984e-04 - val_loss: 0.0013 - learning_rate: 5.3144e-05\n",
      "Epoch 175/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 8.8326e-04 - val_loss: 0.0013 - learning_rate: 5.3144e-05\n",
      "Epoch 176/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 8.8250e-04 - val_loss: 0.0012 - learning_rate: 5.3144e-05\n",
      "Epoch 177/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 8.6561e-04 - val_loss: 0.0011 - learning_rate: 5.3144e-05\n",
      "Epoch 178/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 8.7071e-04 - val_loss: 0.0012 - learning_rate: 5.3144e-05\n",
      "Epoch 179/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 8.4313e-04 - val_loss: 0.0012 - learning_rate: 5.3144e-05\n",
      "Epoch 180/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 8.4437e-04 - val_loss: 0.0013 - learning_rate: 5.3144e-05\n",
      "Epoch 181/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 8.3619e-04\n",
      "Epoch 181: ReduceLROnPlateau reducing learning rate to 4.7829690083744934e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 8.3678e-04 - val_loss: 0.0011 - learning_rate: 5.3144e-05\n",
      "Epoch 182/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 8.4781e-04 - val_loss: 0.0012 - learning_rate: 4.7830e-05\n",
      "Epoch 183/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 8.3667e-04 - val_loss: 0.0011 - learning_rate: 4.7830e-05\n",
      "Epoch 184/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 8.2399e-04 - val_loss: 0.0012 - learning_rate: 4.7830e-05\n",
      "Epoch 185/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 8.2337e-04 - val_loss: 0.0010 - learning_rate: 4.7830e-05\n",
      "Epoch 186/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 8.2859e-04 - val_loss: 0.0012 - learning_rate: 4.7830e-05\n",
      "Epoch 187/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 8.1610e-04 - val_loss: 0.0012 - learning_rate: 4.7830e-05\n",
      "Epoch 188/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 8.1043e-04 - val_loss: 0.0011 - learning_rate: 4.7830e-05\n",
      "Epoch 189/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 8.0641e-04 - val_loss: 0.0012 - learning_rate: 4.7830e-05\n",
      "Epoch 190/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 7.8632e-04 - val_loss: 0.0012 - learning_rate: 4.7830e-05\n",
      "Epoch 191/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 8.1174e-04 - val_loss: 0.0011 - learning_rate: 4.7830e-05\n",
      "Epoch 192/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 8.1528e-04 - val_loss: 0.0011 - learning_rate: 4.7830e-05\n",
      "Epoch 193/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 7.9798e-04 - val_loss: 0.0013 - learning_rate: 4.7830e-05\n",
      "Epoch 194/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 7.9391e-04 - val_loss: 0.0011 - learning_rate: 4.7830e-05\n",
      "Epoch 195/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 7.7727e-04\n",
      "Epoch 195: ReduceLROnPlateau reducing learning rate to 4.304672074795235e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 7.7750e-04 - val_loss: 0.0012 - learning_rate: 4.7830e-05\n",
      "Epoch 196/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 7.9200e-04 - val_loss: 0.0012 - learning_rate: 4.3047e-05\n",
      "Epoch 197/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 7.7217e-04 - val_loss: 0.0011 - learning_rate: 4.3047e-05\n",
      "Epoch 198/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 7.6045e-04 - val_loss: 0.0012 - learning_rate: 4.3047e-05\n",
      "Epoch 199/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 7.6983e-04 - val_loss: 0.0012 - learning_rate: 4.3047e-05\n",
      "Epoch 200/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 7.5807e-04 - val_loss: 9.6671e-04 - learning_rate: 4.3047e-05\n",
      "Epoch 201/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 7.6534e-04 - val_loss: 0.0012 - learning_rate: 4.3047e-05\n",
      "Epoch 202/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 7.5358e-04 - val_loss: 0.0011 - learning_rate: 4.3047e-05\n",
      "Epoch 203/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 7.5428e-04 - val_loss: 0.0011 - learning_rate: 4.3047e-05\n",
      "Epoch 204/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 7.5685e-04 - val_loss: 0.0011 - learning_rate: 4.3047e-05\n",
      "Epoch 205/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 7.5058e-04\n",
      "Epoch 205: ReduceLROnPlateau reducing learning rate to 3.8742047036066654e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 7.5015e-04 - val_loss: 0.0011 - learning_rate: 4.3047e-05\n",
      "Epoch 206/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 7.4671e-04 - val_loss: 0.0010 - learning_rate: 3.8742e-05\n",
      "Epoch 207/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 7.3636e-04 - val_loss: 0.0011 - learning_rate: 3.8742e-05\n",
      "Epoch 208/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 7.4107e-04 - val_loss: 0.0011 - learning_rate: 3.8742e-05\n",
      "Epoch 209/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 7.2203e-04 - val_loss: 0.0011 - learning_rate: 3.8742e-05\n",
      "Epoch 210/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 7.2451e-04 - val_loss: 0.0011 - learning_rate: 3.8742e-05\n",
      "Epoch 211/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 7.3942e-04 - val_loss: 0.0012 - learning_rate: 3.8742e-05\n",
      "Epoch 212/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 7.2709e-04 - val_loss: 0.0010 - learning_rate: 3.8742e-05\n",
      "Epoch 213/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 7.2712e-04 - val_loss: 0.0011 - learning_rate: 3.8742e-05\n",
      "Epoch 214/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 7.2234e-04 - val_loss: 0.0011 - learning_rate: 3.8742e-05\n",
      "Epoch 215/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 7.1713e-04\n",
      "Epoch 215: ReduceLROnPlateau reducing learning rate to 3.4867842987296176e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 7.1719e-04 - val_loss: 0.0011 - learning_rate: 3.8742e-05\n",
      "Epoch 216/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 7.1372e-04 - val_loss: 0.0011 - learning_rate: 3.4868e-05\n",
      "Epoch 217/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 7.0330e-04 - val_loss: 0.0012 - learning_rate: 3.4868e-05\n",
      "Epoch 218/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 7.2147e-04 - val_loss: 0.0011 - learning_rate: 3.4868e-05\n",
      "Epoch 219/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 7.0283e-04 - val_loss: 0.0010 - learning_rate: 3.4868e-05\n",
      "Epoch 220/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 7.0180e-04 - val_loss: 9.4568e-04 - learning_rate: 3.4868e-05\n",
      "Epoch 221/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 7.0782e-04 - val_loss: 0.0011 - learning_rate: 3.4868e-05\n",
      "Epoch 222/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.8495e-04 - val_loss: 9.8182e-04 - learning_rate: 3.4868e-05\n",
      "Epoch 223/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.9399e-04 - val_loss: 0.0010 - learning_rate: 3.4868e-05\n",
      "Epoch 224/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.8074e-04 - val_loss: 0.0010 - learning_rate: 3.4868e-05\n",
      "Epoch 225/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 6.9381e-04\n",
      "Epoch 225: ReduceLROnPlateau reducing learning rate to 3.138105967082083e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.9364e-04 - val_loss: 0.0012 - learning_rate: 3.4868e-05\n",
      "Epoch 226/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 6.8081e-04 - val_loss: 0.0011 - learning_rate: 3.1381e-05\n",
      "Epoch 227/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.7528e-04 - val_loss: 9.8581e-04 - learning_rate: 3.1381e-05\n",
      "Epoch 228/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.7923e-04 - val_loss: 0.0010 - learning_rate: 3.1381e-05\n",
      "Epoch 229/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.6660e-04 - val_loss: 0.0012 - learning_rate: 3.1381e-05\n",
      "Epoch 230/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 6.7533e-04 - val_loss: 0.0011 - learning_rate: 3.1381e-05\n",
      "Epoch 231/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.6762e-04 - val_loss: 0.0012 - learning_rate: 3.1381e-05\n",
      "Epoch 232/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.6858e-04 - val_loss: 9.3829e-04 - learning_rate: 3.1381e-05\n",
      "Epoch 233/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.7444e-04 - val_loss: 0.0010 - learning_rate: 3.1381e-05\n",
      "Epoch 234/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 6.6377e-04 - val_loss: 0.0011 - learning_rate: 3.1381e-05\n",
      "Epoch 235/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 6.5381e-04\n",
      "Epoch 235: ReduceLROnPlateau reducing learning rate to 2.824295370373875e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.5393e-04 - val_loss: 9.6751e-04 - learning_rate: 3.1381e-05\n",
      "Epoch 236/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 6.5664e-04 - val_loss: 0.0010 - learning_rate: 2.8243e-05\n",
      "Epoch 237/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.5963e-04 - val_loss: 0.0010 - learning_rate: 2.8243e-05\n",
      "Epoch 238/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 6.4780e-04 - val_loss: 9.7960e-04 - learning_rate: 2.8243e-05\n",
      "Epoch 239/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 6.4607e-04 - val_loss: 9.8907e-04 - learning_rate: 2.8243e-05\n",
      "Epoch 240/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.4933e-04 - val_loss: 0.0010 - learning_rate: 2.8243e-05\n",
      "Epoch 241/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 6.5158e-04 - val_loss: 9.3291e-04 - learning_rate: 2.8243e-05\n",
      "Epoch 242/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 6.5361e-04 - val_loss: 9.7491e-04 - learning_rate: 2.8243e-05\n",
      "Epoch 243/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 6.4254e-04 - val_loss: 9.9807e-04 - learning_rate: 2.8243e-05\n",
      "Epoch 244/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.4742e-04 - val_loss: 9.9970e-04 - learning_rate: 2.8243e-05\n",
      "Epoch 245/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 6.2905e-04\n",
      "Epoch 245: ReduceLROnPlateau reducing learning rate to 2.5418658333364876e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.2905e-04 - val_loss: 9.1773e-04 - learning_rate: 2.8243e-05\n",
      "Epoch 246/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.3175e-04 - val_loss: 0.0011 - learning_rate: 2.5419e-05\n",
      "Epoch 247/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.3471e-04 - val_loss: 0.0010 - learning_rate: 2.5419e-05\n",
      "Epoch 248/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.2444e-04 - val_loss: 0.0010 - learning_rate: 2.5419e-05\n",
      "Epoch 249/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.3322e-04 - val_loss: 9.5614e-04 - learning_rate: 2.5419e-05\n",
      "Epoch 250/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.2927e-04 - val_loss: 9.4710e-04 - learning_rate: 2.5419e-05\n",
      "Epoch 251/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 6.2261e-04 - val_loss: 0.0011 - learning_rate: 2.5419e-05\n",
      "Epoch 252/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 6.2862e-04 - val_loss: 0.0010 - learning_rate: 2.5419e-05\n",
      "Epoch 253/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 6.1909e-04 - val_loss: 9.9179e-04 - learning_rate: 2.5419e-05\n",
      "Epoch 254/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 6.1950e-04 - val_loss: 0.0011 - learning_rate: 2.5419e-05\n",
      "Epoch 255/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 6.1750e-04\n",
      "Epoch 255: ReduceLROnPlateau reducing learning rate to 2.2876792172610294e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 6.1678e-04 - val_loss: 0.0011 - learning_rate: 2.5419e-05\n",
      "Epoch 256/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.1953e-04 - val_loss: 0.0011 - learning_rate: 2.2877e-05\n",
      "Epoch 257/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.1378e-04 - val_loss: 9.7665e-04 - learning_rate: 2.2877e-05\n",
      "Epoch 258/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.1267e-04 - val_loss: 9.6339e-04 - learning_rate: 2.2877e-05\n",
      "Epoch 259/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.2343e-04 - val_loss: 0.0011 - learning_rate: 2.2877e-05\n",
      "Epoch 260/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.1751e-04 - val_loss: 8.6187e-04 - learning_rate: 2.2877e-05\n",
      "Epoch 261/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.0706e-04 - val_loss: 9.8068e-04 - learning_rate: 2.2877e-05\n",
      "Epoch 262/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.1213e-04 - val_loss: 0.0010 - learning_rate: 2.2877e-05\n",
      "Epoch 263/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.0619e-04 - val_loss: 9.0866e-04 - learning_rate: 2.2877e-05\n",
      "Epoch 264/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.9635e-04 - val_loss: 0.0011 - learning_rate: 2.2877e-05\n",
      "Epoch 265/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.0505e-04 - val_loss: 9.8777e-04 - learning_rate: 2.2877e-05\n",
      "Epoch 266/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.0292e-04 - val_loss: 0.0011 - learning_rate: 2.2877e-05\n",
      "Epoch 267/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 6.0056e-04 - val_loss: 9.7335e-04 - learning_rate: 2.2877e-05\n",
      "Epoch 268/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.9954e-04 - val_loss: 0.0011 - learning_rate: 2.2877e-05\n",
      "Epoch 269/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.9680e-04 - val_loss: 0.0011 - learning_rate: 2.2877e-05\n",
      "Epoch 270/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 5.9580e-04\n",
      "Epoch 270: ReduceLROnPlateau reducing learning rate to 2.0589113773894496e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.9526e-04 - val_loss: 9.6959e-04 - learning_rate: 2.2877e-05\n",
      "Epoch 271/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.9349e-04 - val_loss: 8.7165e-04 - learning_rate: 2.0589e-05\n",
      "Epoch 272/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 6.0290e-04 - val_loss: 9.1459e-04 - learning_rate: 2.0589e-05\n",
      "Epoch 273/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.8651e-04 - val_loss: 0.0010 - learning_rate: 2.0589e-05\n",
      "Epoch 274/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.8842e-04 - val_loss: 0.0011 - learning_rate: 2.0589e-05\n",
      "Epoch 275/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.8838e-04 - val_loss: 9.6175e-04 - learning_rate: 2.0589e-05\n",
      "Epoch 276/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.7875e-04 - val_loss: 9.3119e-04 - learning_rate: 2.0589e-05\n",
      "Epoch 277/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.7547e-04 - val_loss: 8.4552e-04 - learning_rate: 2.0589e-05\n",
      "Epoch 278/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.8827e-04 - val_loss: 0.0010 - learning_rate: 2.0589e-05\n",
      "Epoch 279/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.7530e-04 - val_loss: 0.0010 - learning_rate: 2.0589e-05\n",
      "Epoch 280/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 5.8238e-04\n",
      "Epoch 280: ReduceLROnPlateau reducing learning rate to 1.8530202396505047e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.8234e-04 - val_loss: 8.9209e-04 - learning_rate: 2.0589e-05\n",
      "Epoch 281/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.7540e-04 - val_loss: 0.0010 - learning_rate: 1.8530e-05\n",
      "Epoch 282/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.7178e-04 - val_loss: 9.1321e-04 - learning_rate: 1.8530e-05\n",
      "Epoch 283/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.8235e-04 - val_loss: 0.0010 - learning_rate: 1.8530e-05\n",
      "Epoch 284/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.6937e-04 - val_loss: 0.0010 - learning_rate: 1.8530e-05\n",
      "Epoch 285/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.7142e-04 - val_loss: 9.8115e-04 - learning_rate: 1.8530e-05\n",
      "Epoch 286/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.6537e-04 - val_loss: 9.3425e-04 - learning_rate: 1.8530e-05\n",
      "Epoch 287/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.6780e-04 - val_loss: 9.5410e-04 - learning_rate: 1.8530e-05\n",
      "Epoch 288/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.6817e-04 - val_loss: 9.8774e-04 - learning_rate: 1.8530e-05\n",
      "Epoch 289/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 5.6936e-04 - val_loss: 9.2309e-04 - learning_rate: 1.8530e-05\n",
      "Epoch 290/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 5.6122e-04\n",
      "Epoch 290: ReduceLROnPlateau reducing learning rate to 1.667718133830931e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.6098e-04 - val_loss: 0.0011 - learning_rate: 1.8530e-05\n",
      "Epoch 291/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.6737e-04 - val_loss: 0.0010 - learning_rate: 1.6677e-05\n",
      "Epoch 292/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.6573e-04 - val_loss: 0.0010 - learning_rate: 1.6677e-05\n",
      "Epoch 293/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.6183e-04 - val_loss: 9.7129e-04 - learning_rate: 1.6677e-05\n",
      "Epoch 294/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.5281e-04 - val_loss: 9.5489e-04 - learning_rate: 1.6677e-05\n",
      "Epoch 295/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.6242e-04 - val_loss: 8.6292e-04 - learning_rate: 1.6677e-05\n",
      "Epoch 296/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.5878e-04 - val_loss: 9.4348e-04 - learning_rate: 1.6677e-05\n",
      "Epoch 297/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.7381e-04 - val_loss: 9.2931e-04 - learning_rate: 1.6677e-05\n",
      "Epoch 298/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.6436e-04 - val_loss: 9.6600e-04 - learning_rate: 1.6677e-05\n",
      "Epoch 299/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.5911e-04 - val_loss: 9.8628e-04 - learning_rate: 1.6677e-05\n",
      "Epoch 300/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 5.4807e-04\n",
      "Epoch 300: ReduceLROnPlateau reducing learning rate to 1.5009462549642194e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.4824e-04 - val_loss: 9.0357e-04 - learning_rate: 1.6677e-05\n",
      "Epoch 301/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.5370e-04 - val_loss: 8.9520e-04 - learning_rate: 1.5009e-05\n",
      "Epoch 302/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.4850e-04 - val_loss: 8.9308e-04 - learning_rate: 1.5009e-05\n",
      "Epoch 303/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.5228e-04 - val_loss: 9.4338e-04 - learning_rate: 1.5009e-05\n",
      "Epoch 304/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.6388e-04 - val_loss: 8.5048e-04 - learning_rate: 1.5009e-05\n",
      "Epoch 305/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.5407e-04 - val_loss: 9.5473e-04 - learning_rate: 1.5009e-05\n",
      "Epoch 306/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.5635e-04 - val_loss: 8.6638e-04 - learning_rate: 1.5009e-05\n",
      "Epoch 307/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.4121e-04 - val_loss: 0.0010 - learning_rate: 1.5009e-05\n",
      "Epoch 308/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.4550e-04 - val_loss: 9.2828e-04 - learning_rate: 1.5009e-05\n",
      "Epoch 309/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.4609e-04 - val_loss: 9.7099e-04 - learning_rate: 1.5009e-05\n",
      "Epoch 310/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 5.4556e-04\n",
      "Epoch 310: ReduceLROnPlateau reducing learning rate to 1.3508516622096067e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.4514e-04 - val_loss: 8.9057e-04 - learning_rate: 1.5009e-05\n",
      "Epoch 311/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.5180e-04 - val_loss: 9.6460e-04 - learning_rate: 1.3509e-05\n",
      "Epoch 312/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.3635e-04 - val_loss: 0.0011 - learning_rate: 1.3509e-05\n",
      "Epoch 313/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.3098e-04 - val_loss: 9.3280e-04 - learning_rate: 1.3509e-05\n",
      "Epoch 314/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.3553e-04 - val_loss: 8.6991e-04 - learning_rate: 1.3509e-05\n",
      "Epoch 315/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.4732e-04 - val_loss: 8.4485e-04 - learning_rate: 1.3509e-05\n",
      "Epoch 316/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.3936e-04 - val_loss: 9.1571e-04 - learning_rate: 1.3509e-05\n",
      "Epoch 317/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.3158e-04 - val_loss: 9.9873e-04 - learning_rate: 1.3509e-05\n",
      "Epoch 318/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.3913e-04 - val_loss: 0.0010 - learning_rate: 1.3509e-05\n",
      "Epoch 319/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.3882e-04 - val_loss: 8.3833e-04 - learning_rate: 1.3509e-05\n",
      "Epoch 320/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 5.2489e-04\n",
      "Epoch 320: ReduceLROnPlateau reducing learning rate to 1.2157664878031938e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.2473e-04 - val_loss: 8.3806e-04 - learning_rate: 1.3509e-05\n",
      "Epoch 321/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.3829e-04 - val_loss: 0.0010 - learning_rate: 1.2158e-05\n",
      "Epoch 322/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.3136e-04 - val_loss: 0.0010 - learning_rate: 1.2158e-05\n",
      "Epoch 323/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.3327e-04 - val_loss: 8.8698e-04 - learning_rate: 1.2158e-05\n",
      "Epoch 324/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.3312e-04 - val_loss: 9.0025e-04 - learning_rate: 1.2158e-05\n",
      "Epoch 325/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.2481e-04 - val_loss: 9.5273e-04 - learning_rate: 1.2158e-05\n",
      "Epoch 326/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.3043e-04 - val_loss: 9.3015e-04 - learning_rate: 1.2158e-05\n",
      "Epoch 327/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.2523e-04 - val_loss: 9.4211e-04 - learning_rate: 1.2158e-05\n",
      "Epoch 328/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.2511e-04 - val_loss: 9.2703e-04 - learning_rate: 1.2158e-05\n",
      "Epoch 329/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.3024e-04 - val_loss: 9.2402e-04 - learning_rate: 1.2158e-05\n",
      "Epoch 330/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 5.2677e-04\n",
      "Epoch 330: ReduceLROnPlateau reducing learning rate to 1.0941898472083266e-05.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.2667e-04 - val_loss: 9.1627e-04 - learning_rate: 1.2158e-05\n",
      "Epoch 331/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.3250e-04 - val_loss: 8.5305e-04 - learning_rate: 1.0942e-05\n",
      "Epoch 332/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.2387e-04 - val_loss: 9.4925e-04 - learning_rate: 1.0942e-05\n",
      "Epoch 333/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.1989e-04 - val_loss: 0.0010 - learning_rate: 1.0942e-05\n",
      "Epoch 334/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.1656e-04 - val_loss: 9.8467e-04 - learning_rate: 1.0942e-05\n",
      "Epoch 335/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.2026e-04 - val_loss: 7.8391e-04 - learning_rate: 1.0942e-05\n",
      "Epoch 336/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.1847e-04 - val_loss: 8.8658e-04 - learning_rate: 1.0942e-05\n",
      "Epoch 337/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.2572e-04 - val_loss: 8.8891e-04 - learning_rate: 1.0942e-05\n",
      "Epoch 338/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.2070e-04 - val_loss: 9.6622e-04 - learning_rate: 1.0942e-05\n",
      "Epoch 339/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.1686e-04 - val_loss: 9.3915e-04 - learning_rate: 1.0942e-05\n",
      "Epoch 340/3000\n",
      "\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 5.1482e-04\n",
      "Epoch 340: ReduceLROnPlateau reducing learning rate to 9.847708952293033e-06.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.1481e-04 - val_loss: 9.1470e-04 - learning_rate: 1.0942e-05\n",
      "Epoch 341/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.2237e-04 - val_loss: 9.4679e-04 - learning_rate: 9.8477e-06\n",
      "Epoch 342/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 5.1952e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:43:24.916252: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.1944e-04 - val_loss: 9.6205e-04 - learning_rate: 9.8477e-06\n",
      "Epoch 343/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.1384e-04 - val_loss: 8.8371e-04 - learning_rate: 9.8477e-06\n",
      "Epoch 344/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.1406e-04 - val_loss: 9.5081e-04 - learning_rate: 9.8477e-06\n",
      "Epoch 345/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.1225e-04 - val_loss: 8.9999e-04 - learning_rate: 9.8477e-06\n",
      "Epoch 346/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.2408e-04 - val_loss: 8.5628e-04 - learning_rate: 9.8477e-06\n",
      "Epoch 347/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.1504e-04 - val_loss: 9.7888e-04 - learning_rate: 9.8477e-06\n",
      "Epoch 348/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.1381e-04 - val_loss: 8.6644e-04 - learning_rate: 9.8477e-06\n",
      "Epoch 349/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.1418e-04 - val_loss: 0.0011 - learning_rate: 9.8477e-06\n",
      "Epoch 350/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 5.1560e-04\n",
      "Epoch 350: ReduceLROnPlateau reducing learning rate to 8.862937647791114e-06.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.1562e-04 - val_loss: 8.9522e-04 - learning_rate: 9.8477e-06\n",
      "Epoch 351/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.1754e-04 - val_loss: 9.1564e-04 - learning_rate: 8.8629e-06\n",
      "Epoch 352/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.1524e-04 - val_loss: 9.4798e-04 - learning_rate: 8.8629e-06\n",
      "Epoch 353/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.1677e-04 - val_loss: 8.7966e-04 - learning_rate: 8.8629e-06\n",
      "Epoch 354/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.0265e-04 - val_loss: 9.7639e-04 - learning_rate: 8.8629e-06\n",
      "Epoch 355/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.1110e-04 - val_loss: 9.3605e-04 - learning_rate: 8.8629e-06\n",
      "Epoch 356/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.1340e-04 - val_loss: 9.2312e-04 - learning_rate: 8.8629e-06\n",
      "Epoch 357/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.0923e-04 - val_loss: 8.5324e-04 - learning_rate: 8.8629e-06\n",
      "Epoch 358/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.0265e-04 - val_loss: 9.8848e-04 - learning_rate: 8.8629e-06\n",
      "Epoch 359/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.0038e-04 - val_loss: 8.6628e-04 - learning_rate: 8.8629e-06\n",
      "Epoch 360/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 5.0722e-04\n",
      "Epoch 360: ReduceLROnPlateau reducing learning rate to 7.976643883012003e-06.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.0702e-04 - val_loss: 9.7758e-04 - learning_rate: 8.8629e-06\n",
      "Epoch 361/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.0843e-04 - val_loss: 8.3470e-04 - learning_rate: 7.9766e-06\n",
      "Epoch 362/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.0467e-04 - val_loss: 0.0010 - learning_rate: 7.9766e-06\n",
      "Epoch 363/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.0347e-04 - val_loss: 0.0011 - learning_rate: 7.9766e-06\n",
      "Epoch 364/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.0922e-04 - val_loss: 8.5535e-04 - learning_rate: 7.9766e-06\n",
      "Epoch 365/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.0647e-04 - val_loss: 9.7467e-04 - learning_rate: 7.9766e-06\n",
      "Epoch 366/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.0526e-04 - val_loss: 8.1329e-04 - learning_rate: 7.9766e-06\n",
      "Epoch 367/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.0340e-04 - val_loss: 8.4164e-04 - learning_rate: 7.9766e-06\n",
      "Epoch 368/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.9394e-04 - val_loss: 8.2630e-04 - learning_rate: 7.9766e-06\n",
      "Epoch 369/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.0219e-04 - val_loss: 8.5229e-04 - learning_rate: 7.9766e-06\n",
      "Epoch 370/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 5.0286e-04\n",
      "Epoch 370: ReduceLROnPlateau reducing learning rate to 7.178979740274372e-06.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 5.0261e-04 - val_loss: 9.2725e-04 - learning_rate: 7.9766e-06\n",
      "Epoch 371/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.0602e-04 - val_loss: 7.5829e-04 - learning_rate: 7.1790e-06\n",
      "Epoch 372/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 5.0319e-04 - val_loss: 8.4141e-04 - learning_rate: 7.1790e-06\n",
      "Epoch 373/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.9912e-04 - val_loss: 9.9889e-04 - learning_rate: 7.1790e-06\n",
      "Epoch 374/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.9627e-04 - val_loss: 8.9372e-04 - learning_rate: 7.1790e-06\n",
      "Epoch 375/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.9905e-04 - val_loss: 9.0017e-04 - learning_rate: 7.1790e-06\n",
      "Epoch 376/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.9792e-04 - val_loss: 8.3440e-04 - learning_rate: 7.1790e-06\n",
      "Epoch 377/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.9981e-04 - val_loss: 8.7681e-04 - learning_rate: 7.1790e-06\n",
      "Epoch 378/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.9775e-04 - val_loss: 8.9476e-04 - learning_rate: 7.1790e-06\n",
      "Epoch 379/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.0086e-04 - val_loss: 8.4195e-04 - learning_rate: 7.1790e-06\n",
      "Epoch 380/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.9716e-04 - val_loss: 7.8942e-04 - learning_rate: 7.1790e-06\n",
      "Epoch 381/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 4.9166e-04\n",
      "Epoch 381: ReduceLROnPlateau reducing learning rate to 7e-06.\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.9128e-04 - val_loss: 9.1638e-04 - learning_rate: 7.1790e-06\n",
      "Epoch 382/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.0115e-04 - val_loss: 8.7085e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 383/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.9448e-04 - val_loss: 9.3854e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 384/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.9618e-04 - val_loss: 7.9328e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 385/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.9883e-04 - val_loss: 8.8739e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 386/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.9396e-04 - val_loss: 9.0220e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 387/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.9146e-04 - val_loss: 9.5582e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 388/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.9446e-04 - val_loss: 0.0010 - learning_rate: 7.0000e-06\n",
      "Epoch 389/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 5.0184e-04 - val_loss: 8.6805e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 390/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.8757e-04 - val_loss: 8.1182e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 391/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.9534e-04 - val_loss: 8.6612e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 392/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.9175e-04 - val_loss: 7.9942e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 393/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.8940e-04 - val_loss: 7.9740e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 394/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.8893e-04 - val_loss: 9.0403e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 395/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.8737e-04 - val_loss: 8.9545e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 396/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.9792e-04 - val_loss: 8.1261e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 397/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.8968e-04 - val_loss: 8.5620e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 398/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.9487e-04 - val_loss: 8.0034e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 399/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.9881e-04 - val_loss: 8.3212e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 400/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.8571e-04 - val_loss: 0.0010 - learning_rate: 7.0000e-06\n",
      "Epoch 401/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.9476e-04 - val_loss: 8.8435e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 402/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.8136e-04 - val_loss: 9.0096e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 403/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.8267e-04 - val_loss: 8.9658e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 404/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.9220e-04 - val_loss: 8.5766e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 405/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.8910e-04 - val_loss: 8.6558e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 406/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.8589e-04 - val_loss: 9.0076e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 407/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.8997e-04 - val_loss: 8.2428e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 408/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.8412e-04 - val_loss: 9.1416e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 409/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.9378e-04 - val_loss: 8.7544e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 410/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.7945e-04 - val_loss: 8.3487e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 411/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.8870e-04 - val_loss: 8.4060e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 412/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.8800e-04 - val_loss: 9.2445e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 413/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.8005e-04 - val_loss: 8.8128e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 414/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.8754e-04 - val_loss: 8.9978e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 415/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.8658e-04 - val_loss: 8.5946e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 416/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.8629e-04 - val_loss: 9.2411e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 417/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.9008e-04 - val_loss: 8.6009e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 418/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.8344e-04 - val_loss: 9.5341e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 419/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.8127e-04 - val_loss: 8.7502e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 420/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.8288e-04 - val_loss: 0.0011 - learning_rate: 7.0000e-06\n",
      "Epoch 421/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.8916e-04 - val_loss: 9.4870e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 422/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.8282e-04 - val_loss: 9.5529e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 423/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.8509e-04 - val_loss: 9.2502e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 424/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.7984e-04 - val_loss: 9.2946e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 425/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.9203e-04 - val_loss: 9.1040e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 426/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.7629e-04 - val_loss: 8.4202e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 427/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.7982e-04 - val_loss: 8.8438e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 428/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.8038e-04 - val_loss: 8.4388e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 429/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.8274e-04 - val_loss: 9.0811e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 430/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.8010e-04 - val_loss: 8.9730e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 431/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.7175e-04 - val_loss: 7.8220e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 432/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.8049e-04 - val_loss: 7.7774e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 433/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.8175e-04 - val_loss: 8.6253e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 434/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.7002e-04 - val_loss: 9.4490e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 435/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.7081e-04 - val_loss: 8.4556e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 436/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.8032e-04 - val_loss: 7.7439e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 437/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.8189e-04 - val_loss: 8.9573e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 438/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.7544e-04 - val_loss: 8.9628e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 439/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.7859e-04 - val_loss: 7.8972e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 440/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.7689e-04 - val_loss: 8.6348e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 441/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.7639e-04 - val_loss: 8.0421e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 442/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.7883e-04 - val_loss: 9.7230e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 443/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.7613e-04 - val_loss: 7.9480e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 444/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.7050e-04 - val_loss: 8.3062e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 445/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.7052e-04 - val_loss: 8.9035e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 446/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6918e-04 - val_loss: 9.2024e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 447/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.7184e-04 - val_loss: 7.8248e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 448/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.7446e-04 - val_loss: 7.7863e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 449/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.7505e-04 - val_loss: 8.9345e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 450/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.7594e-04 - val_loss: 8.8812e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 451/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.7097e-04 - val_loss: 9.7418e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 452/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.7427e-04 - val_loss: 6.8048e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 453/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6769e-04 - val_loss: 8.7375e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 454/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6970e-04 - val_loss: 8.2656e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 455/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6731e-04 - val_loss: 8.7089e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 456/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6984e-04 - val_loss: 8.7668e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 457/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6427e-04 - val_loss: 8.1920e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 458/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.7222e-04 - val_loss: 8.7535e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 459/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6536e-04 - val_loss: 8.5766e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 460/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.6945e-04 - val_loss: 7.8719e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 461/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6890e-04 - val_loss: 8.5385e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 462/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6984e-04 - val_loss: 7.7587e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 463/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6476e-04 - val_loss: 9.0118e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 464/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6675e-04 - val_loss: 9.3781e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 465/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6924e-04 - val_loss: 8.3401e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 466/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.7085e-04 - val_loss: 9.2007e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 467/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.7007e-04 - val_loss: 8.4757e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 468/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.7045e-04 - val_loss: 9.2007e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 469/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6083e-04 - val_loss: 9.7615e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 470/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.6317e-04 - val_loss: 9.2982e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 471/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.7116e-04 - val_loss: 8.1144e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 472/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6513e-04 - val_loss: 9.8639e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 473/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6287e-04 - val_loss: 8.3479e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 474/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 4.6153e-04 - val_loss: 8.8209e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 475/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6240e-04 - val_loss: 7.9759e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 476/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6369e-04 - val_loss: 9.9280e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 477/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6749e-04 - val_loss: 9.3697e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 478/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6301e-04 - val_loss: 9.4603e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 479/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6247e-04 - val_loss: 8.3104e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 480/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6168e-04 - val_loss: 8.0725e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 481/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6303e-04 - val_loss: 8.0558e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 482/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.6053e-04 - val_loss: 9.1394e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 483/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.5942e-04 - val_loss: 9.1675e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 484/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5865e-04 - val_loss: 8.9669e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 485/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5967e-04 - val_loss: 8.8605e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 486/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.6937e-04 - val_loss: 8.9417e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 487/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6151e-04 - val_loss: 8.7044e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 488/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6057e-04 - val_loss: 9.3069e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 489/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5888e-04 - val_loss: 7.5062e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 490/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6401e-04 - val_loss: 8.6376e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 491/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6451e-04 - val_loss: 8.2128e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 492/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6017e-04 - val_loss: 8.7449e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 493/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5617e-04 - val_loss: 9.3667e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 494/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5673e-04 - val_loss: 7.9763e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 495/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5787e-04 - val_loss: 8.7637e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 496/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.6012e-04 - val_loss: 8.8694e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 497/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5089e-04 - val_loss: 8.0054e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 498/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5778e-04 - val_loss: 7.5539e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 499/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5751e-04 - val_loss: 9.2881e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 500/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5948e-04 - val_loss: 8.0729e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 501/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5966e-04 - val_loss: 7.7173e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 502/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5417e-04 - val_loss: 8.8552e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 503/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5438e-04 - val_loss: 9.1305e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 504/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5068e-04 - val_loss: 8.0345e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 505/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5537e-04 - val_loss: 8.4532e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 506/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5967e-04 - val_loss: 7.6916e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 507/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5292e-04 - val_loss: 9.3835e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 508/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 4.5488e-04 - val_loss: 9.4898e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 509/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5392e-04 - val_loss: 8.6421e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 510/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5746e-04 - val_loss: 8.9797e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 511/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5236e-04 - val_loss: 8.4578e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 512/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 4.5198e-04 - val_loss: 8.5308e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 513/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5269e-04 - val_loss: 8.5420e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 514/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5215e-04 - val_loss: 8.4442e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 515/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.4924e-04 - val_loss: 8.7996e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 516/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5760e-04 - val_loss: 8.4940e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 517/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.4946e-04 - val_loss: 8.5582e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 518/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5114e-04 - val_loss: 8.0308e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 519/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.4850e-04 - val_loss: 8.8516e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 520/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5053e-04 - val_loss: 8.6906e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 521/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5066e-04 - val_loss: 9.0469e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 522/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.5740e-04 - val_loss: 7.8945e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 523/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.4850e-04 - val_loss: 8.5033e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 524/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.4235e-04 - val_loss: 7.9869e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 525/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.4569e-04 - val_loss: 6.7687e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 526/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.4609e-04 - val_loss: 8.1506e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 527/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.4422e-04 - val_loss: 8.4585e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 528/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.4700e-04 - val_loss: 7.3341e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 529/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.4173e-04 - val_loss: 7.3208e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 530/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.4462e-04 - val_loss: 9.4598e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 531/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.4584e-04 - val_loss: 8.9067e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 532/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.4602e-04 - val_loss: 6.8240e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 533/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.4176e-04 - val_loss: 9.0600e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 534/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.4537e-04 - val_loss: 9.7581e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 535/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.4574e-04 - val_loss: 9.0324e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 536/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.4652e-04 - val_loss: 8.0763e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 537/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.4997e-04 - val_loss: 6.9800e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 538/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.4414e-04 - val_loss: 9.2409e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 539/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.5143e-04 - val_loss: 8.7228e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 540/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.4793e-04 - val_loss: 8.1596e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 541/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.3758e-04 - val_loss: 7.3269e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 542/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.4674e-04 - val_loss: 8.4266e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 543/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.4403e-04 - val_loss: 7.8593e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 544/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.5122e-04 - val_loss: 8.6282e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 545/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.4238e-04 - val_loss: 9.0569e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 546/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.4432e-04 - val_loss: 8.3430e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 547/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.4319e-04 - val_loss: 8.8779e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 548/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.4080e-04 - val_loss: 8.2001e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 549/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3820e-04 - val_loss: 9.0765e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 550/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.4100e-04 - val_loss: 8.9147e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 551/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3400e-04 - val_loss: 9.4575e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 552/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3680e-04 - val_loss: 8.4929e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 553/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.3901e-04 - val_loss: 8.6694e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 554/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.3841e-04 - val_loss: 8.3125e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 555/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3437e-04 - val_loss: 7.1457e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 556/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.4344e-04 - val_loss: 9.2120e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 557/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.3979e-04 - val_loss: 7.5124e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 558/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.3871e-04 - val_loss: 8.1713e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 559/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3550e-04 - val_loss: 8.9028e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 560/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3895e-04 - val_loss: 8.8772e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 561/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3783e-04 - val_loss: 9.2455e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 562/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3255e-04 - val_loss: 8.8348e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 563/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3751e-04 - val_loss: 9.1504e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 564/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3705e-04 - val_loss: 9.3597e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 565/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3700e-04 - val_loss: 9.3999e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 566/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3741e-04 - val_loss: 9.2915e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 567/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3471e-04 - val_loss: 8.7135e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 568/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3999e-04 - val_loss: 7.1889e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 569/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3670e-04 - val_loss: 8.2297e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 570/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3892e-04 - val_loss: 8.8443e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 571/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.4003e-04 - val_loss: 8.0211e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 572/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3490e-04 - val_loss: 7.7261e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 573/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3544e-04 - val_loss: 7.5686e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 574/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3725e-04 - val_loss: 8.2178e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 575/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3225e-04 - val_loss: 8.2722e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 576/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3360e-04 - val_loss: 9.3400e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 577/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3421e-04 - val_loss: 8.5702e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 578/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3114e-04 - val_loss: 7.8908e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 579/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3522e-04 - val_loss: 9.3352e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 580/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3287e-04 - val_loss: 8.8409e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 581/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2995e-04 - val_loss: 7.9810e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 582/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2988e-04 - val_loss: 8.5152e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 583/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.3077e-04 - val_loss: 8.0824e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 584/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2652e-04 - val_loss: 8.0605e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 585/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3188e-04 - val_loss: 9.5326e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 586/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3347e-04 - val_loss: 7.3428e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 587/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3126e-04 - val_loss: 8.1903e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 588/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3231e-04 - val_loss: 8.8710e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 589/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.3018e-04 - val_loss: 7.8565e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 590/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3167e-04 - val_loss: 8.9397e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 591/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2735e-04 - val_loss: 8.6248e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 592/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3383e-04 - val_loss: 8.6603e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 593/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2701e-04 - val_loss: 8.9027e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 594/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3010e-04 - val_loss: 8.7313e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 595/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3163e-04 - val_loss: 8.0790e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 596/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2611e-04 - val_loss: 7.8012e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 597/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3121e-04 - val_loss: 8.4389e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 598/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.2695e-04 - val_loss: 9.1413e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 599/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 4.2479e-04 - val_loss: 9.0994e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 600/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1988e-04 - val_loss: 8.7445e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 601/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2557e-04 - val_loss: 8.8882e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 602/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2249e-04 - val_loss: 7.9404e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 603/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2505e-04 - val_loss: 8.0074e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 604/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.2688e-04 - val_loss: 8.0942e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 605/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2120e-04 - val_loss: 7.8164e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 606/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 4.2826e-04 - val_loss: 7.6909e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 607/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.3184e-04 - val_loss: 8.6373e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 608/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2214e-04 - val_loss: 8.3923e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 609/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2496e-04 - val_loss: 7.7607e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 610/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2720e-04 - val_loss: 7.5306e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 611/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2358e-04 - val_loss: 8.5658e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 612/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 4.2501e-04 - val_loss: 9.7089e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 613/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2309e-04 - val_loss: 7.8958e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 614/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2707e-04 - val_loss: 7.9772e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 615/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2011e-04 - val_loss: 8.4054e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 616/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2024e-04 - val_loss: 9.2822e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 617/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2800e-04 - val_loss: 8.4119e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 618/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2045e-04 - val_loss: 7.3295e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 619/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2095e-04 - val_loss: 8.9738e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 620/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1636e-04 - val_loss: 7.8769e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 621/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2034e-04 - val_loss: 7.0450e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 622/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1797e-04 - val_loss: 9.1117e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 623/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2432e-04 - val_loss: 8.2755e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 624/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2493e-04 - val_loss: 7.6860e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 625/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2439e-04 - val_loss: 8.9874e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 626/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1896e-04 - val_loss: 0.0010 - learning_rate: 7.0000e-06\n",
      "Epoch 627/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1512e-04 - val_loss: 7.0781e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 628/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2068e-04 - val_loss: 7.5828e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 629/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2300e-04 - val_loss: 8.5396e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 630/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.2020e-04 - val_loss: 8.2438e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 631/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1711e-04 - val_loss: 9.1400e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 632/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1839e-04 - val_loss: 9.5122e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 633/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1465e-04 - val_loss: 7.7383e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 634/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2121e-04 - val_loss: 8.4430e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 635/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1710e-04 - val_loss: 8.1947e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 636/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2088e-04 - val_loss: 7.7247e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 637/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2250e-04 - val_loss: 8.3107e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 638/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1869e-04 - val_loss: 8.3519e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 639/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1884e-04 - val_loss: 7.6921e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 640/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2654e-04 - val_loss: 8.7440e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 641/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1777e-04 - val_loss: 7.3107e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 642/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1504e-04 - val_loss: 7.0375e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 643/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1312e-04 - val_loss: 8.3989e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 644/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.1627e-04 - val_loss: 8.0331e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 645/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1922e-04 - val_loss: 7.9491e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 646/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1692e-04 - val_loss: 0.0011 - learning_rate: 7.0000e-06\n",
      "Epoch 647/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1184e-04 - val_loss: 8.7265e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 648/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1201e-04 - val_loss: 9.1621e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 649/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1355e-04 - val_loss: 6.9544e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 650/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1749e-04 - val_loss: 7.9569e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 651/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.1522e-04 - val_loss: 8.8049e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 652/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1769e-04 - val_loss: 8.6891e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 653/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0993e-04 - val_loss: 8.8222e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 654/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.2260e-04 - val_loss: 8.5012e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 655/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1092e-04 - val_loss: 7.2710e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 656/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1009e-04 - val_loss: 7.7074e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 657/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.1279e-04 - val_loss: 7.7055e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 658/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.0968e-04 - val_loss: 9.1257e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 659/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.1413e-04 - val_loss: 7.6737e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 660/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 4.1056e-04 - val_loss: 8.7532e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 661/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 4.1411e-04 - val_loss: 7.7354e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 662/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.1055e-04 - val_loss: 7.6222e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 663/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1605e-04 - val_loss: 7.1023e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 664/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1226e-04 - val_loss: 9.4659e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 665/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0845e-04 - val_loss: 8.0081e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 666/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1127e-04 - val_loss: 8.4116e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 667/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.1355e-04 - val_loss: 7.0615e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 668/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0953e-04 - val_loss: 9.6615e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 669/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0568e-04 - val_loss: 8.2373e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 670/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0550e-04 - val_loss: 8.0804e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 671/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1237e-04 - val_loss: 7.3296e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 672/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0757e-04 - val_loss: 8.8958e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 673/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0829e-04 - val_loss: 8.2871e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 674/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0738e-04 - val_loss: 9.2022e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 675/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1033e-04 - val_loss: 9.1324e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 676/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0496e-04 - val_loss: 7.9709e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 677/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1223e-04 - val_loss: 8.3132e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 678/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.1337e-04 - val_loss: 6.8079e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 679/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0455e-04 - val_loss: 9.1629e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 680/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0746e-04 - val_loss: 7.7178e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 681/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0827e-04 - val_loss: 7.1756e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 682/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0927e-04 - val_loss: 7.4631e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 683/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0836e-04 - val_loss: 8.5859e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 684/3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 15:52:34.805255: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0260e-04 - val_loss: 8.0034e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 685/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0507e-04 - val_loss: 8.3516e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 686/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0149e-04 - val_loss: 9.0749e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 687/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9745e-04 - val_loss: 7.8565e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 688/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0029e-04 - val_loss: 8.3187e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 689/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0607e-04 - val_loss: 8.9844e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 690/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.0662e-04 - val_loss: 8.7497e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 691/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.0249e-04 - val_loss: 7.4026e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 692/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.0567e-04 - val_loss: 8.0722e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 693/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0707e-04 - val_loss: 6.2559e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 694/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.0553e-04 - val_loss: 8.6011e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 695/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0224e-04 - val_loss: 7.9233e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 696/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9972e-04 - val_loss: 6.9550e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 697/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0794e-04 - val_loss: 7.1372e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 698/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0244e-04 - val_loss: 8.4046e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 699/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9852e-04 - val_loss: 8.0215e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 700/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9995e-04 - val_loss: 8.5423e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 701/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0364e-04 - val_loss: 7.1776e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 702/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0528e-04 - val_loss: 8.5585e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 703/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0622e-04 - val_loss: 7.6974e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 704/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9847e-04 - val_loss: 7.8844e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 705/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9533e-04 - val_loss: 8.0017e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 706/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0706e-04 - val_loss: 8.6253e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 707/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 4.0055e-04 - val_loss: 8.4078e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 708/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9903e-04 - val_loss: 8.0518e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 709/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9911e-04 - val_loss: 7.9917e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 710/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9957e-04 - val_loss: 8.0204e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 711/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 4.0172e-04 - val_loss: 7.2936e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 712/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 4.0148e-04 - val_loss: 7.3070e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 713/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9405e-04 - val_loss: 9.3378e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 714/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 4.0437e-04 - val_loss: 8.6951e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 715/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9604e-04 - val_loss: 8.3304e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 716/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.9698e-04 - val_loss: 8.1227e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 717/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9901e-04 - val_loss: 8.2421e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 718/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.9757e-04 - val_loss: 8.0708e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 719/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9494e-04 - val_loss: 7.0574e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 720/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9736e-04 - val_loss: 8.2949e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 721/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9294e-04 - val_loss: 7.2896e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 722/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9510e-04 - val_loss: 8.8193e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 723/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9709e-04 - val_loss: 8.2100e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 724/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9916e-04 - val_loss: 7.3926e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 725/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9803e-04 - val_loss: 7.9532e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 726/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.9236e-04 - val_loss: 7.6153e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 727/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.8774e-04 - val_loss: 8.4364e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 728/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9673e-04 - val_loss: 8.2146e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 729/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.9922e-04 - val_loss: 6.4089e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 730/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8695e-04 - val_loss: 8.5640e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 731/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.9897e-04 - val_loss: 8.2249e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 732/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.9903e-04 - val_loss: 7.7581e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 733/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.9726e-04 - val_loss: 7.2787e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 734/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.9481e-04 - val_loss: 7.8151e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 735/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.8929e-04 - val_loss: 9.6157e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 736/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8966e-04 - val_loss: 7.9048e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 737/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9666e-04 - val_loss: 7.8980e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 738/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.9176e-04 - val_loss: 7.8751e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 739/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.8699e-04 - val_loss: 9.0833e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 740/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.8959e-04 - val_loss: 7.7420e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 741/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9384e-04 - val_loss: 8.0034e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 742/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9553e-04 - val_loss: 8.1575e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 743/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.9432e-04 - val_loss: 7.6235e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 744/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.8956e-04 - val_loss: 7.6304e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 745/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9477e-04 - val_loss: 7.1732e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 746/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.9158e-04 - val_loss: 7.4864e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 747/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8905e-04 - val_loss: 7.9859e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 748/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9454e-04 - val_loss: 8.1007e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 749/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9556e-04 - val_loss: 8.2138e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 750/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.9207e-04 - val_loss: 7.3423e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 751/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.8837e-04 - val_loss: 7.8330e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 752/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8961e-04 - val_loss: 7.1943e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 753/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9087e-04 - val_loss: 7.3424e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 754/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9336e-04 - val_loss: 8.8443e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 755/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8877e-04 - val_loss: 7.5668e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 756/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.8905e-04 - val_loss: 8.9154e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 757/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9204e-04 - val_loss: 7.5498e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 758/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.9366e-04 - val_loss: 7.7834e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 759/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 3.8829e-04 - val_loss: 7.2793e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 760/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.9356e-04 - val_loss: 7.5330e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 761/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8864e-04 - val_loss: 8.8929e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 762/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8916e-04 - val_loss: 7.8709e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 763/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8997e-04 - val_loss: 8.0142e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 764/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8577e-04 - val_loss: 7.7639e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 765/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8336e-04 - val_loss: 8.3797e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 766/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.8679e-04 - val_loss: 6.8676e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 767/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8766e-04 - val_loss: 7.7227e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 768/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8331e-04 - val_loss: 8.2573e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 769/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8739e-04 - val_loss: 8.9129e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 770/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 3.8129e-04 - val_loss: 6.9113e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 771/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8322e-04 - val_loss: 7.4646e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 772/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8580e-04 - val_loss: 7.8201e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 773/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8975e-04 - val_loss: 7.0782e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 774/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.8373e-04 - val_loss: 8.2211e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 775/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.8674e-04 - val_loss: 8.0979e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 776/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8418e-04 - val_loss: 8.2930e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 777/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8043e-04 - val_loss: 7.9716e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 778/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8181e-04 - val_loss: 8.6027e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 779/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8141e-04 - val_loss: 9.1659e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 780/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8378e-04 - val_loss: 7.3677e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 781/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8563e-04 - val_loss: 6.7252e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 782/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8733e-04 - val_loss: 8.4474e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 783/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8100e-04 - val_loss: 7.7512e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 784/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8332e-04 - val_loss: 8.1217e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 785/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7959e-04 - val_loss: 7.7607e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 786/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8079e-04 - val_loss: 7.3508e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 787/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8602e-04 - val_loss: 8.2089e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 788/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.8229e-04 - val_loss: 7.7997e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 789/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.8534e-04 - val_loss: 8.7962e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 790/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7806e-04 - val_loss: 8.4033e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 791/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7863e-04 - val_loss: 7.8315e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 792/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8503e-04 - val_loss: 6.2634e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 793/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 3.8123e-04 - val_loss: 7.7367e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 794/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8020e-04 - val_loss: 8.1249e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 795/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7856e-04 - val_loss: 9.0038e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 796/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7825e-04 - val_loss: 7.1604e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 797/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8245e-04 - val_loss: 8.6158e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 798/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8161e-04 - val_loss: 7.5354e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 799/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7473e-04 - val_loss: 6.8523e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 800/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7851e-04 - val_loss: 8.5392e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 801/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8239e-04 - val_loss: 6.9249e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 802/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 3.7683e-04 - val_loss: 7.5078e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 803/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7825e-04 - val_loss: 8.9107e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 804/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8188e-04 - val_loss: 8.3731e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 805/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8044e-04 - val_loss: 7.7190e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 806/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8073e-04 - val_loss: 8.0392e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 807/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7921e-04 - val_loss: 6.9347e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 808/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7648e-04 - val_loss: 8.7633e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 809/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7320e-04 - val_loss: 8.4771e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 810/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7504e-04 - val_loss: 6.7042e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 811/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 3.7552e-04 - val_loss: 8.4866e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 812/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8141e-04 - val_loss: 6.9312e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 813/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7956e-04 - val_loss: 7.7958e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 814/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7813e-04 - val_loss: 7.2418e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 815/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7814e-04 - val_loss: 7.7004e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 816/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7242e-04 - val_loss: 8.9689e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 817/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7038e-04 - val_loss: 6.0587e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 818/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7351e-04 - val_loss: 7.5245e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 819/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.8063e-04 - val_loss: 7.5329e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 820/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7691e-04 - val_loss: 8.5915e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 821/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7309e-04 - val_loss: 7.8389e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 822/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.7340e-04 - val_loss: 6.9665e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 823/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7572e-04 - val_loss: 6.9935e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 824/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7438e-04 - val_loss: 8.6137e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 825/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7362e-04 - val_loss: 7.3057e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 826/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7662e-04 - val_loss: 8.6266e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 827/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7184e-04 - val_loss: 8.3308e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 828/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7787e-04 - val_loss: 8.9373e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 829/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7121e-04 - val_loss: 8.1772e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 830/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7519e-04 - val_loss: 7.2663e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 831/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7154e-04 - val_loss: 6.6733e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 832/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.7048e-04 - val_loss: 7.0593e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 833/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.7272e-04 - val_loss: 7.7645e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 834/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7367e-04 - val_loss: 8.9643e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 835/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7256e-04 - val_loss: 6.7056e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 836/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7272e-04 - val_loss: 9.7455e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 837/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7334e-04 - val_loss: 8.2468e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 838/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7729e-04 - val_loss: 8.7582e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 839/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 3.7393e-04 - val_loss: 8.2517e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 840/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.7265e-04 - val_loss: 7.6692e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 841/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7468e-04 - val_loss: 7.3081e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 842/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7222e-04 - val_loss: 9.0719e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 843/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6874e-04 - val_loss: 8.3473e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 844/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6639e-04 - val_loss: 8.9571e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 845/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6910e-04 - val_loss: 8.7420e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 846/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.7187e-04 - val_loss: 8.0765e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 847/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6951e-04 - val_loss: 6.9252e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 848/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6841e-04 - val_loss: 7.9955e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 849/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.6742e-04 - val_loss: 8.0353e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 850/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.7411e-04 - val_loss: 7.2498e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 851/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6469e-04 - val_loss: 6.6452e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 852/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6807e-04 - val_loss: 8.2108e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 853/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.6324e-04 - val_loss: 7.8564e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 854/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6544e-04 - val_loss: 7.6352e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 855/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.7222e-04 - val_loss: 7.6724e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 856/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6444e-04 - val_loss: 7.9616e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 857/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7822e-04 - val_loss: 7.6741e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 858/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.6308e-04 - val_loss: 6.7092e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 859/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6675e-04 - val_loss: 6.7753e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 860/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6662e-04 - val_loss: 6.9680e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 861/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6652e-04 - val_loss: 8.3395e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 862/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6296e-04 - val_loss: 7.4095e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 863/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6479e-04 - val_loss: 7.7010e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 864/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7177e-04 - val_loss: 9.0452e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 865/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.7590e-04 - val_loss: 7.5035e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 866/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5924e-04 - val_loss: 7.6838e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 867/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.6590e-04 - val_loss: 9.0034e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 868/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6436e-04 - val_loss: 9.0691e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 869/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6190e-04 - val_loss: 7.8841e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 870/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6269e-04 - val_loss: 8.1925e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 871/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.6407e-04 - val_loss: 7.7236e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 872/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.6112e-04 - val_loss: 8.2720e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 873/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6675e-04 - val_loss: 7.7583e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 874/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.6295e-04 - val_loss: 8.6316e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 875/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 3.6433e-04 - val_loss: 8.5973e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 876/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.6417e-04 - val_loss: 7.9604e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 877/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5886e-04 - val_loss: 6.3068e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 878/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6539e-04 - val_loss: 8.3573e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 879/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6392e-04 - val_loss: 8.5772e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 880/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.6698e-04 - val_loss: 7.5273e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 881/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.6345e-04 - val_loss: 6.5839e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 882/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.6754e-04 - val_loss: 7.9954e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 883/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.6425e-04 - val_loss: 7.5498e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 884/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6711e-04 - val_loss: 7.1683e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 885/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5845e-04 - val_loss: 7.8530e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 886/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6442e-04 - val_loss: 8.6365e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 887/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6848e-04 - val_loss: 7.6943e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 888/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.6602e-04 - val_loss: 7.6019e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 889/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6420e-04 - val_loss: 6.6177e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 890/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5833e-04 - val_loss: 8.0010e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 891/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6588e-04 - val_loss: 9.1528e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 892/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6776e-04 - val_loss: 8.4192e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 893/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6734e-04 - val_loss: 7.2590e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 894/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5807e-04 - val_loss: 7.1310e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 895/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6019e-04 - val_loss: 6.7821e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 896/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5834e-04 - val_loss: 8.3845e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 897/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.5977e-04 - val_loss: 8.7800e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 898/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5898e-04 - val_loss: 7.2739e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 899/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6146e-04 - val_loss: 7.9701e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 900/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.5583e-04 - val_loss: 7.1647e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 901/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6038e-04 - val_loss: 8.3872e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 902/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5308e-04 - val_loss: 7.0630e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 903/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5860e-04 - val_loss: 6.8646e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 904/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5983e-04 - val_loss: 8.1927e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 905/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.6045e-04 - val_loss: 7.7418e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 906/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5507e-04 - val_loss: 8.4710e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 907/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6327e-04 - val_loss: 7.2456e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 908/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6167e-04 - val_loss: 6.8701e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 909/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5722e-04 - val_loss: 7.8998e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 910/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5724e-04 - val_loss: 8.6664e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 911/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.6024e-04 - val_loss: 7.4185e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 912/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5703e-04 - val_loss: 7.8356e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 913/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5958e-04 - val_loss: 7.6425e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 914/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5602e-04 - val_loss: 8.1711e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 915/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5877e-04 - val_loss: 8.0147e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 916/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.5799e-04 - val_loss: 6.5539e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 917/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.5926e-04 - val_loss: 7.7352e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 918/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.5741e-04 - val_loss: 7.8811e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 919/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5538e-04 - val_loss: 7.5843e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 920/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5145e-04 - val_loss: 6.9789e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 921/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5776e-04 - val_loss: 7.1264e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 922/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5388e-04 - val_loss: 7.3637e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 923/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5126e-04 - val_loss: 7.4439e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 924/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5930e-04 - val_loss: 7.0079e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 925/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5248e-04 - val_loss: 6.5200e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 926/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5890e-04 - val_loss: 7.7619e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 927/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5544e-04 - val_loss: 7.4483e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 928/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.5448e-04 - val_loss: 6.6938e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 929/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5672e-04 - val_loss: 8.1813e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 930/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5347e-04 - val_loss: 6.7454e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 931/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.5113e-04 - val_loss: 7.1896e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 932/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5469e-04 - val_loss: 6.8867e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 933/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5228e-04 - val_loss: 7.7266e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 934/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5846e-04 - val_loss: 6.2951e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 935/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5377e-04 - val_loss: 6.6879e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 936/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5446e-04 - val_loss: 8.0993e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 937/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5250e-04 - val_loss: 8.1073e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 938/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5172e-04 - val_loss: 7.7913e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 939/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.5262e-04 - val_loss: 8.2249e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 940/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5638e-04 - val_loss: 8.0725e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 941/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5232e-04 - val_loss: 8.3056e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 942/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4548e-04 - val_loss: 8.6712e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 943/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5244e-04 - val_loss: 8.2040e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 944/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5339e-04 - val_loss: 7.2290e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 945/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.5365e-04 - val_loss: 6.3047e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 946/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5686e-04 - val_loss: 8.5895e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 947/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5167e-04 - val_loss: 7.7999e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 948/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5044e-04 - val_loss: 8.1413e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 949/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.5440e-04 - val_loss: 6.8883e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 950/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.5145e-04 - val_loss: 7.3344e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 951/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5263e-04 - val_loss: 6.9279e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 952/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.5112e-04 - val_loss: 6.9878e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 953/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4872e-04 - val_loss: 8.3843e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 954/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.4841e-04 - val_loss: 7.0074e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 955/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5312e-04 - val_loss: 6.6453e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 956/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5041e-04 - val_loss: 7.7035e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 957/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4709e-04 - val_loss: 8.2000e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 958/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4766e-04 - val_loss: 7.8996e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 959/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4324e-04 - val_loss: 6.4355e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 960/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5132e-04 - val_loss: 7.4512e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 961/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5328e-04 - val_loss: 7.9968e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 962/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4748e-04 - val_loss: 8.2333e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 963/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4581e-04 - val_loss: 7.6945e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 964/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.5441e-04 - val_loss: 6.7561e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 965/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4907e-04 - val_loss: 8.5747e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 966/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5149e-04 - val_loss: 6.9349e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 967/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5039e-04 - val_loss: 7.0503e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 968/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5512e-04 - val_loss: 7.3317e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 969/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4764e-04 - val_loss: 6.5252e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 970/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 3.4466e-04 - val_loss: 8.4030e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 971/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4051e-04 - val_loss: 6.7410e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 972/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4710e-04 - val_loss: 8.6694e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 973/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4686e-04 - val_loss: 7.2818e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 974/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4892e-04 - val_loss: 7.5399e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 975/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4612e-04 - val_loss: 9.1949e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 976/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4469e-04 - val_loss: 7.0232e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 977/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4536e-04 - val_loss: 7.4252e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 978/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4857e-04 - val_loss: 7.5263e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 979/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.5015e-04 - val_loss: 7.7256e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 980/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4807e-04 - val_loss: 8.7433e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 981/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4502e-04 - val_loss: 8.2754e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 982/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4400e-04 - val_loss: 8.1672e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 983/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4646e-04 - val_loss: 8.1721e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 984/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4174e-04 - val_loss: 7.9678e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 985/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4786e-04 - val_loss: 8.2152e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 986/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4855e-04 - val_loss: 7.4131e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 987/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4771e-04 - val_loss: 7.5623e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 988/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4536e-04 - val_loss: 6.5878e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 989/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4596e-04 - val_loss: 7.2370e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 990/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4840e-04 - val_loss: 7.0847e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 991/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4295e-04 - val_loss: 6.2752e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 992/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3884e-04 - val_loss: 6.8648e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 993/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4511e-04 - val_loss: 7.6295e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 994/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4948e-04 - val_loss: 7.8619e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 995/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4632e-04 - val_loss: 6.6289e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 996/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4363e-04 - val_loss: 5.8053e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 997/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4155e-04 - val_loss: 8.6327e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 998/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4109e-04 - val_loss: 6.7965e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 999/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4569e-04 - val_loss: 7.0658e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1000/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4302e-04 - val_loss: 7.4294e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1001/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.4364e-04 - val_loss: 6.9134e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1002/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4279e-04 - val_loss: 6.6991e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1003/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4140e-04 - val_loss: 7.1198e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1004/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4319e-04 - val_loss: 6.8744e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1005/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4477e-04 - val_loss: 7.0635e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1006/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4318e-04 - val_loss: 6.4544e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1007/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4689e-04 - val_loss: 7.7544e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1008/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4626e-04 - val_loss: 8.1983e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1009/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3990e-04 - val_loss: 7.5112e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1010/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3903e-04 - val_loss: 7.1321e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1011/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3808e-04 - val_loss: 8.0941e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1012/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3656e-04 - val_loss: 6.9829e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1013/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 3.4086e-04 - val_loss: 6.4794e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1014/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4390e-04 - val_loss: 7.5428e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1015/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4738e-04 - val_loss: 7.2691e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1016/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3508e-04 - val_loss: 8.7743e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1017/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3596e-04 - val_loss: 7.2827e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1018/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3834e-04 - val_loss: 8.1183e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1019/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4341e-04 - val_loss: 7.0940e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1020/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4146e-04 - val_loss: 7.3158e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1021/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3653e-04 - val_loss: 8.5205e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1022/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3942e-04 - val_loss: 7.1266e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1023/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.4001e-04 - val_loss: 7.4156e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1024/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3976e-04 - val_loss: 8.4180e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1025/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3818e-04 - val_loss: 7.6675e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1026/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3740e-04 - val_loss: 7.1041e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1027/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3791e-04 - val_loss: 7.9064e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1028/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.3956e-04 - val_loss: 7.8957e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1029/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3543e-04 - val_loss: 7.6571e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1030/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3704e-04 - val_loss: 8.3357e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1031/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3888e-04 - val_loss: 7.1658e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1032/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3693e-04 - val_loss: 8.0085e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1033/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.3789e-04 - val_loss: 6.8214e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1034/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3658e-04 - val_loss: 8.0121e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1035/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3576e-04 - val_loss: 6.9832e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1036/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3517e-04 - val_loss: 7.9887e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1037/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3990e-04 - val_loss: 6.3746e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1038/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3432e-04 - val_loss: 7.7616e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1039/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3330e-04 - val_loss: 6.3532e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1040/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3665e-04 - val_loss: 7.6804e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1041/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3549e-04 - val_loss: 7.2492e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1042/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.3343e-04 - val_loss: 6.6288e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1043/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.3356e-04 - val_loss: 7.3142e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1044/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3750e-04 - val_loss: 8.4811e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1045/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3454e-04 - val_loss: 7.0694e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1046/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.3469e-04 - val_loss: 6.3729e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1047/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.3439e-04 - val_loss: 7.2528e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1048/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3879e-04 - val_loss: 7.5890e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1049/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.3197e-04 - val_loss: 8.5119e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1050/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3060e-04 - val_loss: 6.8917e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1051/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3198e-04 - val_loss: 7.1160e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1052/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3056e-04 - val_loss: 6.5045e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1053/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.3849e-04 - val_loss: 7.0086e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1054/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3630e-04 - val_loss: 7.2620e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1055/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3521e-04 - val_loss: 7.3366e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1056/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.3108e-04 - val_loss: 9.2124e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1057/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.3472e-04 - val_loss: 7.2199e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1058/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.3967e-04 - val_loss: 7.3341e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1059/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3682e-04 - val_loss: 7.7365e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1060/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3073e-04 - val_loss: 7.4908e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1061/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3276e-04 - val_loss: 7.5767e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1062/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3173e-04 - val_loss: 7.3244e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1063/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3468e-04 - val_loss: 8.2173e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1064/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3095e-04 - val_loss: 8.6541e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1065/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3265e-04 - val_loss: 7.5964e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1066/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3219e-04 - val_loss: 6.9309e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1067/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3192e-04 - val_loss: 6.2289e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1068/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.3328e-04 - val_loss: 7.2497e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1069/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3402e-04 - val_loss: 7.3697e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1070/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.3250e-04 - val_loss: 6.9198e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1071/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3001e-04 - val_loss: 7.5361e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1072/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.3117e-04 - val_loss: 7.2034e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1073/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.2944e-04 - val_loss: 8.3931e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1074/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2852e-04 - val_loss: 8.1176e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1075/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.2811e-04 - val_loss: 8.6478e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1076/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.3648e-04 - val_loss: 7.7957e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1077/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.3064e-04 - val_loss: 8.1896e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1078/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.3245e-04 - val_loss: 7.5234e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1079/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.2990e-04 - val_loss: 7.8721e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1080/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2970e-04 - val_loss: 7.5990e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1081/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2874e-04 - val_loss: 7.9775e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1082/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2653e-04 - val_loss: 7.1065e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1083/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.2955e-04 - val_loss: 6.6480e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1084/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2899e-04 - val_loss: 9.0259e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1085/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.2831e-04 - val_loss: 7.0472e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1086/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2735e-04 - val_loss: 8.1355e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1087/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.2900e-04 - val_loss: 7.2260e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1088/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3044e-04 - val_loss: 8.8098e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1089/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2685e-04 - val_loss: 8.5926e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1090/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3089e-04 - val_loss: 7.7846e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1091/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3027e-04 - val_loss: 8.6729e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1092/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2760e-04 - val_loss: 8.1350e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1093/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2828e-04 - val_loss: 7.7050e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1094/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.2922e-04 - val_loss: 8.4942e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1095/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2981e-04 - val_loss: 7.0145e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1096/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2532e-04 - val_loss: 6.5284e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1097/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.3243e-04 - val_loss: 7.9009e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1098/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.2788e-04 - val_loss: 6.6810e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1099/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.2596e-04 - val_loss: 7.9161e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1100/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2933e-04 - val_loss: 7.1166e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1101/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2712e-04 - val_loss: 7.1615e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1102/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2672e-04 - val_loss: 8.0991e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1103/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2745e-04 - val_loss: 8.0166e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1104/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.3057e-04 - val_loss: 6.5479e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1105/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2666e-04 - val_loss: 7.7723e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1106/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2444e-04 - val_loss: 7.9322e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1107/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2411e-04 - val_loss: 6.3008e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1108/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2317e-04 - val_loss: 7.9005e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1109/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2624e-04 - val_loss: 7.0615e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1110/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2939e-04 - val_loss: 5.8432e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1111/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2547e-04 - val_loss: 7.8370e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1112/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.3156e-04 - val_loss: 8.1122e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1113/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.2439e-04 - val_loss: 7.0413e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1114/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2305e-04 - val_loss: 8.0253e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1115/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2404e-04 - val_loss: 7.2833e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1116/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2597e-04 - val_loss: 7.6332e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1117/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2458e-04 - val_loss: 6.9337e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1118/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2334e-04 - val_loss: 7.1383e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1119/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2576e-04 - val_loss: 7.1981e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1120/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2601e-04 - val_loss: 7.5035e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1121/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2216e-04 - val_loss: 7.0550e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1122/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2232e-04 - val_loss: 7.6139e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1123/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2495e-04 - val_loss: 7.2985e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1124/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2433e-04 - val_loss: 7.6708e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1125/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2119e-04 - val_loss: 8.2259e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1126/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 3.2529e-04 - val_loss: 7.9602e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1127/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2468e-04 - val_loss: 6.8801e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1128/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2236e-04 - val_loss: 6.3162e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1129/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1992e-04 - val_loss: 7.4653e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1130/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2354e-04 - val_loss: 7.2822e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1131/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2829e-04 - val_loss: 7.1273e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1132/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2383e-04 - val_loss: 7.0900e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1133/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.2264e-04 - val_loss: 8.1746e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1134/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2103e-04 - val_loss: 6.8342e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1135/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2024e-04 - val_loss: 6.4069e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1136/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2227e-04 - val_loss: 7.1379e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1137/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2098e-04 - val_loss: 8.1569e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1138/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.2130e-04 - val_loss: 6.5622e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1139/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.2009e-04 - val_loss: 6.8060e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1140/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.1972e-04 - val_loss: 7.3987e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1141/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2085e-04 - val_loss: 6.9156e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1142/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1975e-04 - val_loss: 6.7921e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1143/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.2278e-04 - val_loss: 6.6557e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1144/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1946e-04 - val_loss: 6.7103e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1145/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2089e-04 - val_loss: 7.7372e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1146/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2112e-04 - val_loss: 7.5709e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1147/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1764e-04 - val_loss: 7.2192e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1148/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2031e-04 - val_loss: 8.5300e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1149/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1968e-04 - val_loss: 6.5479e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1150/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2037e-04 - val_loss: 7.3851e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1151/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1503e-04 - val_loss: 7.1331e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1152/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1954e-04 - val_loss: 7.7927e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1153/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1684e-04 - val_loss: 7.8160e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1154/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2252e-04 - val_loss: 6.0383e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1155/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1927e-04 - val_loss: 6.5515e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1156/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1931e-04 - val_loss: 6.6345e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1157/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1902e-04 - val_loss: 7.8953e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1158/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1663e-04 - val_loss: 7.5378e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1159/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2243e-04 - val_loss: 7.7206e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1160/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1729e-04 - val_loss: 6.8995e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1161/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2076e-04 - val_loss: 8.1659e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1162/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1826e-04 - val_loss: 8.1828e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1163/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.2073e-04 - val_loss: 7.9598e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1164/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1709e-04 - val_loss: 6.8014e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1165/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1777e-04 - val_loss: 7.7548e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1166/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.1911e-04 - val_loss: 6.0163e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1167/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.1786e-04 - val_loss: 6.2862e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1168/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.1746e-04 - val_loss: 8.3595e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1169/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1823e-04 - val_loss: 8.2818e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1170/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.1860e-04 - val_loss: 7.5070e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1171/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.1546e-04 - val_loss: 7.4354e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1172/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.1627e-04 - val_loss: 6.7797e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1173/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.1790e-04 - val_loss: 6.7089e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1174/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.1615e-04 - val_loss: 6.9738e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1175/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1767e-04 - val_loss: 7.2437e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1176/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1502e-04 - val_loss: 7.1331e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1177/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1621e-04 - val_loss: 5.9137e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1178/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1753e-04 - val_loss: 7.0180e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1179/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.1689e-04 - val_loss: 7.2528e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1180/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1343e-04 - val_loss: 6.9042e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1181/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1501e-04 - val_loss: 6.8855e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1182/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1868e-04 - val_loss: 7.9791e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1183/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1594e-04 - val_loss: 5.9720e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1184/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1351e-04 - val_loss: 7.4504e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1185/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1641e-04 - val_loss: 6.9147e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1186/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1679e-04 - val_loss: 7.4563e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1187/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.1726e-04 - val_loss: 6.9419e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1188/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1616e-04 - val_loss: 5.5334e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1189/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1360e-04 - val_loss: 6.9396e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1190/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1632e-04 - val_loss: 7.4045e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1191/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1491e-04 - val_loss: 7.6861e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1192/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1332e-04 - val_loss: 6.2520e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1193/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1322e-04 - val_loss: 5.8455e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1194/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1023e-04 - val_loss: 9.4912e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1195/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1546e-04 - val_loss: 7.6156e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1196/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1297e-04 - val_loss: 7.4251e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1197/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1304e-04 - val_loss: 7.7791e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1198/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1498e-04 - val_loss: 8.0556e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1199/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1322e-04 - val_loss: 6.8423e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1200/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1467e-04 - val_loss: 7.2919e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1201/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1197e-04 - val_loss: 6.8950e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1202/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1396e-04 - val_loss: 7.4902e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1203/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1295e-04 - val_loss: 5.9448e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1204/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0920e-04 - val_loss: 7.9363e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1205/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.1121e-04 - val_loss: 5.7832e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1206/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1239e-04 - val_loss: 7.1881e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1207/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1011e-04 - val_loss: 7.8180e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1208/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0960e-04 - val_loss: 7.3582e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1209/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1402e-04 - val_loss: 6.0863e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1210/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1828e-04 - val_loss: 6.5910e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1211/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1431e-04 - val_loss: 8.2887e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1212/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1403e-04 - val_loss: 6.6261e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1213/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 3.1174e-04 - val_loss: 7.3114e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1214/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0902e-04 - val_loss: 5.6202e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1215/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1054e-04 - val_loss: 5.9781e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1216/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1136e-04 - val_loss: 6.6336e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1217/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0797e-04 - val_loss: 7.8417e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1218/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1618e-04 - val_loss: 6.2837e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1219/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1082e-04 - val_loss: 6.6133e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1220/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1017e-04 - val_loss: 7.1623e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1221/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0932e-04 - val_loss: 6.1224e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1222/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1155e-04 - val_loss: 7.2161e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1223/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0942e-04 - val_loss: 6.7266e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1224/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1249e-04 - val_loss: 8.9707e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1225/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1167e-04 - val_loss: 7.8455e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1226/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.1373e-04 - val_loss: 6.6988e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1227/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1119e-04 - val_loss: 7.3278e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1228/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1025e-04 - val_loss: 6.2754e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1229/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1000e-04 - val_loss: 6.1699e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1230/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1117e-04 - val_loss: 8.0175e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1231/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0997e-04 - val_loss: 8.2432e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1232/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0526e-04 - val_loss: 6.7711e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1233/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0822e-04 - val_loss: 7.7256e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1234/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0434e-04 - val_loss: 7.1735e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1235/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0488e-04 - val_loss: 7.3163e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1236/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1000e-04 - val_loss: 7.0113e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1237/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0798e-04 - val_loss: 7.2363e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1238/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0855e-04 - val_loss: 6.5337e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1239/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0694e-04 - val_loss: 8.3337e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1240/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0854e-04 - val_loss: 7.7517e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1241/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0601e-04 - val_loss: 6.4311e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1242/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0544e-04 - val_loss: 7.0405e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1243/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0822e-04 - val_loss: 6.9198e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1244/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0995e-04 - val_loss: 7.6106e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1245/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0464e-04 - val_loss: 6.5260e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1246/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 3.0615e-04 - val_loss: 6.4782e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1247/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0311e-04 - val_loss: 8.4809e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1248/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 3.0321e-04 - val_loss: 6.9622e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1249/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.1120e-04 - val_loss: 6.3857e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1250/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0798e-04 - val_loss: 6.2732e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1251/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 3.0261e-04 - val_loss: 7.0383e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1252/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 3.0730e-04 - val_loss: 7.4959e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1253/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 3.1049e-04 - val_loss: 5.7425e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1254/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0667e-04 - val_loss: 7.4734e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1255/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0283e-04 - val_loss: 6.4305e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1256/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0846e-04 - val_loss: 6.5606e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1257/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0813e-04 - val_loss: 6.1063e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1258/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0850e-04 - val_loss: 7.2380e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1259/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0313e-04 - val_loss: 6.4088e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1260/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0696e-04 - val_loss: 6.2993e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1261/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0391e-04 - val_loss: 7.3146e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1262/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0476e-04 - val_loss: 7.0650e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1263/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0373e-04 - val_loss: 7.2870e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1264/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0053e-04 - val_loss: 6.1297e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1265/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0125e-04 - val_loss: 7.2810e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1266/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0348e-04 - val_loss: 7.1671e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1267/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0748e-04 - val_loss: 6.1559e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1268/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0515e-04 - val_loss: 8.0712e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1269/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0373e-04 - val_loss: 7.2917e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1270/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0584e-04 - val_loss: 6.9618e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1271/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0179e-04 - val_loss: 7.4801e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1272/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0300e-04 - val_loss: 7.0874e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1273/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.0650e-04 - val_loss: 5.8428e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1274/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0382e-04 - val_loss: 7.9325e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1275/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 3.0335e-04 - val_loss: 6.6979e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1276/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0516e-04 - val_loss: 7.9231e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1277/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0908e-04 - val_loss: 7.1582e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1278/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0342e-04 - val_loss: 7.0179e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1279/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.9895e-04 - val_loss: 7.3273e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1280/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0557e-04 - val_loss: 7.8805e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1281/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0465e-04 - val_loss: 6.8401e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1282/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0348e-04 - val_loss: 6.4529e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1283/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.0495e-04 - val_loss: 7.3961e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1284/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0150e-04 - val_loss: 7.6374e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1285/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.0184e-04 - val_loss: 7.9360e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1286/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.0806e-04 - val_loss: 6.8957e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1287/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9691e-04 - val_loss: 7.0176e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1288/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9943e-04 - val_loss: 7.9764e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1289/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0341e-04 - val_loss: 8.1585e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1290/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0173e-04 - val_loss: 7.3892e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1291/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0108e-04 - val_loss: 7.7896e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1292/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0514e-04 - val_loss: 7.9209e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1293/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9764e-04 - val_loss: 7.2253e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1294/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9796e-04 - val_loss: 7.1597e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1295/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9806e-04 - val_loss: 8.1465e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1296/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9629e-04 - val_loss: 6.6553e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1297/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0060e-04 - val_loss: 7.1194e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1298/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0097e-04 - val_loss: 6.6391e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1299/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9991e-04 - val_loss: 6.5564e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1300/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 3.0127e-04 - val_loss: 6.2900e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1301/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0102e-04 - val_loss: 7.0785e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1302/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0050e-04 - val_loss: 7.6019e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1303/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9691e-04 - val_loss: 7.0658e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1304/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 3.0277e-04 - val_loss: 6.9527e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1305/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0236e-04 - val_loss: 7.8756e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1306/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0261e-04 - val_loss: 6.5903e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1307/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9856e-04 - val_loss: 7.4120e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1308/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9980e-04 - val_loss: 7.0970e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1309/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9964e-04 - val_loss: 6.9032e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1310/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.0184e-04 - val_loss: 7.3004e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1311/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9895e-04 - val_loss: 6.9880e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1312/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0208e-04 - val_loss: 6.6306e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1313/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.0053e-04 - val_loss: 6.7555e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1314/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 3.0133e-04 - val_loss: 6.9868e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1315/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 3.0225e-04 - val_loss: 8.1299e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1316/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9827e-04 - val_loss: 7.6386e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1317/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9891e-04 - val_loss: 6.2153e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1318/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.9967e-04 - val_loss: 7.2803e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1319/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9964e-04 - val_loss: 6.9818e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1320/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9788e-04 - val_loss: 6.7660e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1321/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9256e-04 - val_loss: 6.4697e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1322/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.9589e-04 - val_loss: 7.2699e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1323/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9953e-04 - val_loss: 7.4147e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1324/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.9957e-04 - val_loss: 6.9513e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1325/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.9688e-04 - val_loss: 6.5517e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1326/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9871e-04 - val_loss: 6.9485e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1327/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9742e-04 - val_loss: 7.2214e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1328/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0052e-04 - val_loss: 7.7412e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1329/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9340e-04 - val_loss: 6.6525e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1330/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9756e-04 - val_loss: 6.6209e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1331/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9977e-04 - val_loss: 6.4953e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1332/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9681e-04 - val_loss: 7.3467e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1333/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.9655e-04 - val_loss: 6.9630e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1334/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9859e-04 - val_loss: 6.3455e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1335/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9473e-04 - val_loss: 8.1204e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1336/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9911e-04 - val_loss: 6.5310e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1337/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9547e-04 - val_loss: 6.9562e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1338/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9776e-04 - val_loss: 6.0556e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1339/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9469e-04 - val_loss: 7.5983e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1340/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9897e-04 - val_loss: 6.7806e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1341/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9214e-04 - val_loss: 7.3679e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1342/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9708e-04 - val_loss: 7.6101e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1343/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9756e-04 - val_loss: 7.6227e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1344/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9512e-04 - val_loss: 7.9096e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1345/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 2.9087e-04 - val_loss: 7.5514e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1346/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.9565e-04 - val_loss: 7.4783e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1347/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9590e-04 - val_loss: 6.6490e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1348/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9757e-04 - val_loss: 7.6020e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1349/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9744e-04 - val_loss: 7.4199e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1350/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.9394e-04 - val_loss: 7.1444e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1351/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9137e-04 - val_loss: 7.1387e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1352/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9348e-04 - val_loss: 6.0808e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1353/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9623e-04 - val_loss: 6.5270e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1354/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9229e-04 - val_loss: 7.7790e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1355/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9263e-04 - val_loss: 6.5369e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1356/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.8980e-04 - val_loss: 7.5238e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1357/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 3.0004e-04 - val_loss: 6.4414e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1358/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8933e-04 - val_loss: 6.3901e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1359/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9408e-04 - val_loss: 6.1997e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1360/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9599e-04 - val_loss: 6.8335e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1361/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9027e-04 - val_loss: 7.6367e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1362/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9572e-04 - val_loss: 6.3787e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1363/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.9318e-04 - val_loss: 6.6716e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1364/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9298e-04 - val_loss: 5.6231e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1365/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9172e-04 - val_loss: 7.2852e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1366/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9582e-04 - val_loss: 6.2163e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1367/3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:10:56.263735: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.9354e-04 - val_loss: 7.7277e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1368/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9073e-04 - val_loss: 7.5442e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1369/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9018e-04 - val_loss: 7.1768e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1370/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9283e-04 - val_loss: 6.8561e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1371/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9113e-04 - val_loss: 7.4248e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1372/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8947e-04 - val_loss: 7.1551e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1373/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8993e-04 - val_loss: 6.6482e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1374/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8980e-04 - val_loss: 6.0989e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1375/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8912e-04 - val_loss: 6.8854e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1376/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8980e-04 - val_loss: 5.8577e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1377/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9349e-04 - val_loss: 6.2824e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1378/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8963e-04 - val_loss: 6.9595e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1379/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9156e-04 - val_loss: 7.3731e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1380/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9087e-04 - val_loss: 7.8970e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1381/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9220e-04 - val_loss: 6.4749e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1382/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.9066e-04 - val_loss: 8.0896e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1383/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8781e-04 - val_loss: 6.4713e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1384/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.9126e-04 - val_loss: 7.6989e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1385/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9023e-04 - val_loss: 6.5970e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1386/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.9083e-04 - val_loss: 6.5754e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1387/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.9337e-04 - val_loss: 7.2745e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1388/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 2.8684e-04 - val_loss: 6.4603e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1389/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.9027e-04 - val_loss: 6.9702e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1390/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8669e-04 - val_loss: 5.6812e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1391/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.9141e-04 - val_loss: 5.9908e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1392/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8594e-04 - val_loss: 7.4029e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1393/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8955e-04 - val_loss: 6.5299e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1394/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8854e-04 - val_loss: 6.6508e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1395/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8883e-04 - val_loss: 7.0123e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1396/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8569e-04 - val_loss: 7.7684e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1397/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8878e-04 - val_loss: 6.1149e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1398/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8646e-04 - val_loss: 6.6976e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1399/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8837e-04 - val_loss: 7.4414e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1400/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8908e-04 - val_loss: 7.5672e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1401/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8623e-04 - val_loss: 6.3775e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1402/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.8795e-04 - val_loss: 6.7070e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1403/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8647e-04 - val_loss: 7.1907e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1404/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8965e-04 - val_loss: 6.1218e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1405/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8519e-04 - val_loss: 6.5647e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1406/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9163e-04 - val_loss: 6.8964e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1407/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8410e-04 - val_loss: 6.3451e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1408/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8776e-04 - val_loss: 6.3418e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1409/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8889e-04 - val_loss: 6.8543e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1410/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9344e-04 - val_loss: 7.0756e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1411/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8921e-04 - val_loss: 7.2382e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1412/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.8769e-04 - val_loss: 6.1295e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1413/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8565e-04 - val_loss: 6.8993e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1414/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8616e-04 - val_loss: 6.2841e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1415/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.9239e-04 - val_loss: 6.8145e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1416/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8862e-04 - val_loss: 6.5747e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1417/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8711e-04 - val_loss: 7.4911e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1418/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8540e-04 - val_loss: 7.8672e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1419/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.8812e-04 - val_loss: 7.1369e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1420/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8804e-04 - val_loss: 7.4027e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1421/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8752e-04 - val_loss: 6.8727e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1422/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8851e-04 - val_loss: 5.9023e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1423/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8518e-04 - val_loss: 6.1658e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1424/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8377e-04 - val_loss: 6.2715e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1425/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 2.8683e-04 - val_loss: 7.0168e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1426/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8349e-04 - val_loss: 7.0665e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1427/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8621e-04 - val_loss: 7.1005e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1428/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8758e-04 - val_loss: 7.2370e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1429/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8330e-04 - val_loss: 7.5046e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1430/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8491e-04 - val_loss: 7.4035e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1431/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8622e-04 - val_loss: 7.0232e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1432/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8608e-04 - val_loss: 6.9310e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1433/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8442e-04 - val_loss: 6.8043e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1434/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8827e-04 - val_loss: 6.5450e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1435/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8703e-04 - val_loss: 6.6963e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1436/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8467e-04 - val_loss: 7.4042e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1437/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8322e-04 - val_loss: 7.3945e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1438/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8599e-04 - val_loss: 7.7480e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1439/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8360e-04 - val_loss: 7.4116e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1440/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8227e-04 - val_loss: 7.3469e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1441/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8235e-04 - val_loss: 7.4747e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1442/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8245e-04 - val_loss: 6.0147e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1443/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.8484e-04 - val_loss: 6.2301e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1444/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8837e-04 - val_loss: 6.7139e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1445/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.8276e-04 - val_loss: 7.4118e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1446/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8779e-04 - val_loss: 6.2983e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1447/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.8509e-04 - val_loss: 7.1160e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1448/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8343e-04 - val_loss: 6.0450e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1449/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.8193e-04 - val_loss: 6.3030e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1450/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8126e-04 - val_loss: 6.6587e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1451/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8231e-04 - val_loss: 6.2805e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1452/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.8060e-04 - val_loss: 6.4887e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1453/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7912e-04 - val_loss: 7.3655e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1454/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8182e-04 - val_loss: 6.6750e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1455/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8176e-04 - val_loss: 5.7446e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1456/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8123e-04 - val_loss: 7.5121e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1457/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7869e-04 - val_loss: 7.3312e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1458/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8041e-04 - val_loss: 7.0820e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1459/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.8017e-04 - val_loss: 6.4008e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1460/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8339e-04 - val_loss: 6.5677e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1461/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 2.8080e-04 - val_loss: 6.7538e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1462/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8123e-04 - val_loss: 6.8770e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1463/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8178e-04 - val_loss: 7.5130e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1464/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8264e-04 - val_loss: 6.7066e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1465/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7921e-04 - val_loss: 5.5188e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1466/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7770e-04 - val_loss: 6.0676e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1467/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8113e-04 - val_loss: 6.4562e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1468/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7795e-04 - val_loss: 6.4189e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1469/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8077e-04 - val_loss: 7.7019e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1470/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8065e-04 - val_loss: 7.8165e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1471/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8039e-04 - val_loss: 6.0625e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1472/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8172e-04 - val_loss: 6.7840e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1473/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8018e-04 - val_loss: 6.2189e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1474/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7656e-04 - val_loss: 6.9522e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1475/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8078e-04 - val_loss: 6.2101e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1476/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8128e-04 - val_loss: 7.6630e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1477/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8140e-04 - val_loss: 6.5933e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1478/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8102e-04 - val_loss: 7.1397e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1479/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7969e-04 - val_loss: 5.9081e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1480/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8120e-04 - val_loss: 6.9550e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1481/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8002e-04 - val_loss: 5.9902e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1482/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7943e-04 - val_loss: 7.5343e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1483/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7803e-04 - val_loss: 6.5557e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1484/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7803e-04 - val_loss: 7.2525e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1485/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.7854e-04 - val_loss: 7.2933e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1486/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7902e-04 - val_loss: 5.8762e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1487/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7775e-04 - val_loss: 6.5865e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1488/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8001e-04 - val_loss: 6.3313e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1489/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7933e-04 - val_loss: 7.1281e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1490/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7724e-04 - val_loss: 7.1629e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1491/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7886e-04 - val_loss: 6.9164e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1492/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7659e-04 - val_loss: 7.4955e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1493/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.7667e-04 - val_loss: 7.2372e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1494/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7728e-04 - val_loss: 5.5767e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1495/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8209e-04 - val_loss: 8.5431e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1496/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7577e-04 - val_loss: 6.2716e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1497/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.8134e-04 - val_loss: 7.5366e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1498/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.8021e-04 - val_loss: 6.4646e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1499/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.8050e-04 - val_loss: 7.2647e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1500/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7646e-04 - val_loss: 5.8945e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1501/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7616e-04 - val_loss: 6.4422e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1502/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7707e-04 - val_loss: 6.5716e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1503/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7793e-04 - val_loss: 7.3668e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1504/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7779e-04 - val_loss: 7.9354e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1505/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.7485e-04 - val_loss: 7.1137e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1506/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7462e-04 - val_loss: 6.4932e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1507/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7738e-04 - val_loss: 5.9514e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1508/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7632e-04 - val_loss: 6.1566e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1509/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7470e-04 - val_loss: 6.2498e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1510/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7716e-04 - val_loss: 6.6375e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1511/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7591e-04 - val_loss: 7.3050e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1512/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7493e-04 - val_loss: 6.5660e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1513/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7448e-04 - val_loss: 7.0038e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1514/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.7144e-04 - val_loss: 6.0901e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1515/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.7520e-04 - val_loss: 6.8343e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1516/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7988e-04 - val_loss: 7.1139e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1517/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7701e-04 - val_loss: 6.7478e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1518/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7846e-04 - val_loss: 6.7871e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1519/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7684e-04 - val_loss: 5.7808e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1520/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7372e-04 - val_loss: 8.0627e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1521/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7594e-04 - val_loss: 8.2260e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1522/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.7311e-04 - val_loss: 6.3139e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1523/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.7935e-04 - val_loss: 6.5561e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1524/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7437e-04 - val_loss: 6.8533e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1525/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7547e-04 - val_loss: 7.0368e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1526/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7743e-04 - val_loss: 7.7143e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1527/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7728e-04 - val_loss: 6.7489e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1528/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7604e-04 - val_loss: 6.6007e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1529/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.7067e-04 - val_loss: 7.9530e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1530/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7548e-04 - val_loss: 6.4723e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1531/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7765e-04 - val_loss: 6.6261e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1532/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.7637e-04 - val_loss: 6.9084e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1533/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7515e-04 - val_loss: 7.8693e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1534/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7358e-04 - val_loss: 6.7286e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1535/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7845e-04 - val_loss: 6.3159e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1536/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7653e-04 - val_loss: 7.0664e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1537/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7448e-04 - val_loss: 6.8736e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1538/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7748e-04 - val_loss: 5.2817e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1539/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7296e-04 - val_loss: 6.4392e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1540/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7725e-04 - val_loss: 7.2808e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1541/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7434e-04 - val_loss: 7.3998e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1542/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7776e-04 - val_loss: 6.5209e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1543/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.7278e-04 - val_loss: 7.4342e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1544/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.7474e-04 - val_loss: 6.0709e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1545/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7469e-04 - val_loss: 7.1393e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1546/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7253e-04 - val_loss: 7.9626e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1547/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7328e-04 - val_loss: 6.2795e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1548/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7092e-04 - val_loss: 7.1467e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1549/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7354e-04 - val_loss: 5.2593e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1550/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7308e-04 - val_loss: 7.8557e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1551/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7198e-04 - val_loss: 5.5706e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1552/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7616e-04 - val_loss: 6.9639e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1553/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6891e-04 - val_loss: 6.9045e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1554/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7279e-04 - val_loss: 6.7565e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1555/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7253e-04 - val_loss: 5.7996e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1556/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7275e-04 - val_loss: 6.7806e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1557/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7317e-04 - val_loss: 6.4733e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1558/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6819e-04 - val_loss: 6.3976e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1559/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7066e-04 - val_loss: 7.0284e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1560/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7166e-04 - val_loss: 6.1028e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1561/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7048e-04 - val_loss: 5.9606e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1562/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7363e-04 - val_loss: 5.6681e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1563/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6713e-04 - val_loss: 5.7349e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1564/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7362e-04 - val_loss: 6.5491e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1565/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7018e-04 - val_loss: 7.1401e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1566/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6988e-04 - val_loss: 7.0188e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1567/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6848e-04 - val_loss: 6.6983e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1568/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.7128e-04 - val_loss: 5.4456e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1569/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6959e-04 - val_loss: 6.5393e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1570/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6899e-04 - val_loss: 6.9500e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1571/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6905e-04 - val_loss: 6.7045e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1572/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7159e-04 - val_loss: 6.0368e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1573/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6887e-04 - val_loss: 7.1294e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1574/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7063e-04 - val_loss: 6.0896e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1575/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6931e-04 - val_loss: 7.3063e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1576/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6868e-04 - val_loss: 7.0143e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1577/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6984e-04 - val_loss: 7.0983e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1578/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6999e-04 - val_loss: 7.1287e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1579/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.7046e-04 - val_loss: 6.6297e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1580/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7711e-04 - val_loss: 7.2856e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1581/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6864e-04 - val_loss: 7.1993e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1582/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6924e-04 - val_loss: 7.3130e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1583/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6585e-04 - val_loss: 7.3706e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1584/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.7086e-04 - val_loss: 6.7085e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1585/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7039e-04 - val_loss: 6.9173e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1586/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6645e-04 - val_loss: 7.1995e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1587/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.7033e-04 - val_loss: 4.9002e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1588/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6823e-04 - val_loss: 7.2751e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1589/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6906e-04 - val_loss: 5.9388e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1590/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6886e-04 - val_loss: 6.5239e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1591/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6762e-04 - val_loss: 6.0175e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1592/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6871e-04 - val_loss: 6.6653e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1593/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6829e-04 - val_loss: 6.2614e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1594/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6857e-04 - val_loss: 5.4887e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1595/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6292e-04 - val_loss: 6.4926e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1596/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6854e-04 - val_loss: 7.3046e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1597/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7148e-04 - val_loss: 6.8971e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1598/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6966e-04 - val_loss: 6.5146e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1599/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6795e-04 - val_loss: 6.2993e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1600/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6916e-04 - val_loss: 6.6124e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1601/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6599e-04 - val_loss: 7.3673e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1602/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6841e-04 - val_loss: 5.8922e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1603/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6682e-04 - val_loss: 7.8689e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1604/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6806e-04 - val_loss: 5.8545e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1605/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6863e-04 - val_loss: 5.8422e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1606/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6743e-04 - val_loss: 5.8788e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1607/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6763e-04 - val_loss: 7.4157e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1608/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6910e-04 - val_loss: 7.1421e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1609/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6702e-04 - val_loss: 6.0487e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1610/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6332e-04 - val_loss: 8.0078e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1611/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.6496e-04 - val_loss: 6.6015e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1612/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6542e-04 - val_loss: 7.6417e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1613/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6416e-04 - val_loss: 6.7008e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1614/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6855e-04 - val_loss: 6.8478e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1615/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6316e-04 - val_loss: 6.2810e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1616/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6785e-04 - val_loss: 6.6314e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1617/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6637e-04 - val_loss: 6.9859e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1618/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6962e-04 - val_loss: 7.2242e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1619/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6761e-04 - val_loss: 7.4069e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1620/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6766e-04 - val_loss: 8.0335e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1621/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6815e-04 - val_loss: 6.6998e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1622/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.7089e-04 - val_loss: 7.4306e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1623/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6527e-04 - val_loss: 6.6293e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1624/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6679e-04 - val_loss: 6.3019e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1625/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6546e-04 - val_loss: 7.2269e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1626/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6402e-04 - val_loss: 6.8262e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1627/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6589e-04 - val_loss: 6.6661e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1628/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6521e-04 - val_loss: 7.0922e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1629/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6961e-04 - val_loss: 7.1971e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1630/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6706e-04 - val_loss: 7.0969e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1631/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6737e-04 - val_loss: 6.2915e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1632/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6744e-04 - val_loss: 7.1066e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1633/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6233e-04 - val_loss: 6.3711e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1634/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6406e-04 - val_loss: 6.6943e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1635/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6591e-04 - val_loss: 5.9263e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1636/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6255e-04 - val_loss: 7.7001e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1637/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6664e-04 - val_loss: 8.5400e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1638/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6828e-04 - val_loss: 6.3127e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1639/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6260e-04 - val_loss: 6.5237e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1640/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6132e-04 - val_loss: 6.4541e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1641/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6751e-04 - val_loss: 6.0756e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1642/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6392e-04 - val_loss: 7.5343e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1643/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6533e-04 - val_loss: 6.4312e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1644/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6442e-04 - val_loss: 6.8189e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1645/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6385e-04 - val_loss: 6.5775e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1646/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6096e-04 - val_loss: 7.1061e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1647/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6389e-04 - val_loss: 6.4384e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1648/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6505e-04 - val_loss: 6.1765e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1649/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.5971e-04 - val_loss: 7.2484e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1650/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6395e-04 - val_loss: 6.9023e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1651/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6408e-04 - val_loss: 6.8799e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1652/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6120e-04 - val_loss: 6.4805e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1653/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5994e-04 - val_loss: 6.8903e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1654/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6018e-04 - val_loss: 6.6630e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1655/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6063e-04 - val_loss: 6.5898e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1656/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6584e-04 - val_loss: 6.6486e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1657/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5992e-04 - val_loss: 6.3714e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1658/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6430e-04 - val_loss: 6.9576e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1659/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6520e-04 - val_loss: 7.6595e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1660/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6106e-04 - val_loss: 6.6041e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1661/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6142e-04 - val_loss: 7.0410e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1662/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.5959e-04 - val_loss: 7.1508e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1663/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6006e-04 - val_loss: 7.1879e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1664/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6685e-04 - val_loss: 6.0011e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1665/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5895e-04 - val_loss: 7.3608e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1666/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6284e-04 - val_loss: 7.5908e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1667/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6066e-04 - val_loss: 6.4155e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1668/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6026e-04 - val_loss: 6.1097e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1669/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6453e-04 - val_loss: 7.0754e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1670/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6222e-04 - val_loss: 5.6095e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1671/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6561e-04 - val_loss: 6.0093e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1672/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6134e-04 - val_loss: 7.3331e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1673/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6177e-04 - val_loss: 6.1503e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1674/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6483e-04 - val_loss: 7.2625e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1675/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5810e-04 - val_loss: 7.1468e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1676/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.5919e-04 - val_loss: 6.3708e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1677/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5785e-04 - val_loss: 6.9205e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1678/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.5858e-04 - val_loss: 5.3183e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1679/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6100e-04 - val_loss: 7.0202e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1680/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6107e-04 - val_loss: 6.8303e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1681/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6014e-04 - val_loss: 6.1019e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1682/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6138e-04 - val_loss: 6.7683e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1683/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5652e-04 - val_loss: 6.9046e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1684/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5870e-04 - val_loss: 7.2222e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1685/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.5883e-04 - val_loss: 6.3679e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1686/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6262e-04 - val_loss: 6.1514e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1687/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5763e-04 - val_loss: 5.6204e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1688/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.6013e-04 - val_loss: 6.4651e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1689/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5775e-04 - val_loss: 6.7771e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1690/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5927e-04 - val_loss: 7.6464e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1691/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.6128e-04 - val_loss: 6.0459e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1692/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5992e-04 - val_loss: 7.9780e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1693/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.5944e-04 - val_loss: 5.2286e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1694/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6031e-04 - val_loss: 6.9962e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1695/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.5954e-04 - val_loss: 6.5010e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1696/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6122e-04 - val_loss: 6.9919e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1697/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5902e-04 - val_loss: 5.8899e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1698/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6013e-04 - val_loss: 7.6970e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1699/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.6012e-04 - val_loss: 5.7307e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1700/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5711e-04 - val_loss: 6.8525e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1701/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5940e-04 - val_loss: 6.9984e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1702/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 2.5774e-04 - val_loss: 7.4459e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1703/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5878e-04 - val_loss: 6.0119e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1704/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5844e-04 - val_loss: 6.6373e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1705/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5929e-04 - val_loss: 6.7906e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1706/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5823e-04 - val_loss: 5.8738e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1707/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.5410e-04 - val_loss: 6.4650e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1708/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5937e-04 - val_loss: 6.8412e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1709/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5833e-04 - val_loss: 5.8709e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1710/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.5485e-04 - val_loss: 6.7811e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1711/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5703e-04 - val_loss: 6.9487e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1712/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.5542e-04 - val_loss: 7.0871e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1713/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5838e-04 - val_loss: 6.0127e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1714/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5726e-04 - val_loss: 7.0994e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1715/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5390e-04 - val_loss: 6.9020e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1716/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5903e-04 - val_loss: 7.4722e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1717/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5740e-04 - val_loss: 6.7617e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1718/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5470e-04 - val_loss: 7.2824e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1719/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5616e-04 - val_loss: 7.4011e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1720/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5859e-04 - val_loss: 6.2154e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1721/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5638e-04 - val_loss: 7.1824e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1722/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5484e-04 - val_loss: 6.6841e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1723/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5703e-04 - val_loss: 6.3690e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1724/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5303e-04 - val_loss: 6.6975e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1725/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5725e-04 - val_loss: 6.4075e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1726/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5491e-04 - val_loss: 6.7077e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1727/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5755e-04 - val_loss: 6.6125e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1728/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5596e-04 - val_loss: 6.4086e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1729/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.5805e-04 - val_loss: 7.3693e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1730/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5632e-04 - val_loss: 6.0910e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1731/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5530e-04 - val_loss: 7.4311e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1732/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5484e-04 - val_loss: 6.0336e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1733/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5543e-04 - val_loss: 5.9749e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1734/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5716e-04 - val_loss: 6.4525e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1735/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5369e-04 - val_loss: 7.4660e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1736/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.5575e-04 - val_loss: 6.1973e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1737/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5250e-04 - val_loss: 6.2574e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1738/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5722e-04 - val_loss: 6.7263e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1739/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5596e-04 - val_loss: 7.0646e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1740/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5562e-04 - val_loss: 7.5382e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1741/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5624e-04 - val_loss: 5.5859e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1742/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5497e-04 - val_loss: 7.4230e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1743/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.5422e-04 - val_loss: 6.1904e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1744/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5426e-04 - val_loss: 5.6619e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1745/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5235e-04 - val_loss: 6.0517e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1746/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5318e-04 - val_loss: 6.9985e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1747/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.5418e-04 - val_loss: 6.9177e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1748/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5229e-04 - val_loss: 5.7668e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1749/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5131e-04 - val_loss: 6.1878e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1750/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5592e-04 - val_loss: 5.4093e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1751/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5394e-04 - val_loss: 7.4771e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1752/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5466e-04 - val_loss: 6.3022e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1753/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5592e-04 - val_loss: 6.5009e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1754/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5216e-04 - val_loss: 5.7459e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1755/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5620e-04 - val_loss: 6.5493e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1756/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4926e-04 - val_loss: 6.1213e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1757/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5411e-04 - val_loss: 6.4869e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1758/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5338e-04 - val_loss: 5.6833e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1759/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5507e-04 - val_loss: 5.4472e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1760/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5174e-04 - val_loss: 6.0209e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1761/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5541e-04 - val_loss: 7.2868e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1762/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.5637e-04 - val_loss: 6.0114e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1763/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.5473e-04 - val_loss: 6.3972e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1764/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.5405e-04 - val_loss: 5.3869e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1765/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.5634e-04 - val_loss: 6.4355e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1766/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5282e-04 - val_loss: 7.5284e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1767/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5440e-04 - val_loss: 6.7836e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1768/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5160e-04 - val_loss: 6.4401e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1769/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.5283e-04 - val_loss: 6.4951e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1770/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5060e-04 - val_loss: 6.8331e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1771/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.5367e-04 - val_loss: 8.4954e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1772/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5143e-04 - val_loss: 5.9635e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1773/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4951e-04 - val_loss: 5.6026e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1774/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5812e-04 - val_loss: 6.9245e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1775/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5253e-04 - val_loss: 5.3044e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1776/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5166e-04 - val_loss: 6.6216e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1777/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5411e-04 - val_loss: 6.6778e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1778/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4996e-04 - val_loss: 6.0885e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1779/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5467e-04 - val_loss: 6.2243e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1780/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5443e-04 - val_loss: 6.7447e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1781/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5173e-04 - val_loss: 6.9172e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1782/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5131e-04 - val_loss: 5.4843e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1783/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5086e-04 - val_loss: 5.9354e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1784/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5160e-04 - val_loss: 6.1561e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1785/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5210e-04 - val_loss: 6.9327e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1786/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.5059e-04 - val_loss: 7.1767e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1787/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4962e-04 - val_loss: 7.1790e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1788/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4932e-04 - val_loss: 6.7126e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1789/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4882e-04 - val_loss: 6.8081e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1790/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5267e-04 - val_loss: 6.5391e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1791/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4965e-04 - val_loss: 6.4430e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1792/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5004e-04 - val_loss: 8.5678e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1793/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4774e-04 - val_loss: 7.8016e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1794/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5067e-04 - val_loss: 6.8491e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1795/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4706e-04 - val_loss: 6.3193e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1796/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.5282e-04 - val_loss: 6.7187e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1797/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.5177e-04 - val_loss: 6.6500e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1798/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4950e-04 - val_loss: 6.1435e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1799/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4986e-04 - val_loss: 7.5148e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1800/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4815e-04 - val_loss: 7.2437e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1801/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5138e-04 - val_loss: 5.8719e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1802/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.5045e-04 - val_loss: 7.9562e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1803/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.4670e-04 - val_loss: 6.8678e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1804/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5262e-04 - val_loss: 6.3545e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1805/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5127e-04 - val_loss: 6.1800e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1806/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4838e-04 - val_loss: 6.2493e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1807/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4853e-04 - val_loss: 6.4156e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1808/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.4728e-04 - val_loss: 6.7093e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1809/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4722e-04 - val_loss: 6.0637e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1810/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4874e-04 - val_loss: 6.4520e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1811/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4956e-04 - val_loss: 5.8592e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1812/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.4972e-04 - val_loss: 5.6519e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1813/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.4914e-04 - val_loss: 7.2853e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1814/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5084e-04 - val_loss: 5.7105e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1815/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.5113e-04 - val_loss: 6.7300e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1816/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5314e-04 - val_loss: 5.4931e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1817/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4783e-04 - val_loss: 5.8962e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1818/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5081e-04 - val_loss: 7.3570e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1819/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4649e-04 - val_loss: 6.1067e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1820/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5156e-04 - val_loss: 6.1157e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1821/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4714e-04 - val_loss: 6.2675e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1822/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4907e-04 - val_loss: 7.6350e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1823/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.5196e-04 - val_loss: 6.7047e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1824/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4656e-04 - val_loss: 7.0114e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1825/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4899e-04 - val_loss: 6.9577e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1826/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4697e-04 - val_loss: 5.7008e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1827/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4877e-04 - val_loss: 6.1497e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1828/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4871e-04 - val_loss: 4.9170e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1829/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4735e-04 - val_loss: 5.7361e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1830/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4783e-04 - val_loss: 6.5115e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1831/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.4722e-04 - val_loss: 6.3708e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1832/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 2.4426e-04 - val_loss: 7.6104e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1833/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.4638e-04 - val_loss: 6.7710e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1834/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4674e-04 - val_loss: 5.8360e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1835/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4680e-04 - val_loss: 5.9364e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1836/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4613e-04 - val_loss: 6.4164e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1837/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.4584e-04 - val_loss: 5.5377e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1838/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.4416e-04 - val_loss: 6.3712e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1839/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4786e-04 - val_loss: 6.8720e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1840/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4902e-04 - val_loss: 6.3725e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1841/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4698e-04 - val_loss: 5.2945e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1842/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4605e-04 - val_loss: 6.3154e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1843/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4608e-04 - val_loss: 6.3953e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1844/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4532e-04 - val_loss: 5.8086e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1845/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4473e-04 - val_loss: 7.2265e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1846/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4605e-04 - val_loss: 6.5532e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1847/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4492e-04 - val_loss: 6.5164e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1848/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4575e-04 - val_loss: 5.6751e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1849/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4428e-04 - val_loss: 6.0588e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1850/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.4847e-04 - val_loss: 6.0430e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1851/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4811e-04 - val_loss: 6.5237e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1852/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4196e-04 - val_loss: 5.8112e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1853/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4936e-04 - val_loss: 5.2574e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1854/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4625e-04 - val_loss: 5.4634e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1855/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4611e-04 - val_loss: 6.7117e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1856/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4426e-04 - val_loss: 7.1424e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1857/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4238e-04 - val_loss: 7.0995e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1858/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.4574e-04 - val_loss: 6.9399e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1859/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4364e-04 - val_loss: 5.9330e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1860/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4749e-04 - val_loss: 6.5725e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1861/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4416e-04 - val_loss: 5.6296e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1862/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4363e-04 - val_loss: 7.3632e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1863/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4802e-04 - val_loss: 6.9404e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1864/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4836e-04 - val_loss: 6.7746e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1865/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4423e-04 - val_loss: 6.0652e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1866/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.4371e-04 - val_loss: 7.4458e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1867/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.4360e-04 - val_loss: 6.1564e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1868/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4887e-04 - val_loss: 6.0054e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1869/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4542e-04 - val_loss: 6.0290e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1870/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4347e-04 - val_loss: 5.8521e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1871/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4531e-04 - val_loss: 6.0013e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1872/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4536e-04 - val_loss: 5.6988e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1873/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4098e-04 - val_loss: 6.1733e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1874/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4477e-04 - val_loss: 5.6219e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1875/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4488e-04 - val_loss: 5.6145e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1876/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4476e-04 - val_loss: 6.6127e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1877/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4347e-04 - val_loss: 7.1543e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1878/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4336e-04 - val_loss: 7.2399e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1879/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4160e-04 - val_loss: 6.5004e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1880/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4099e-04 - val_loss: 6.0104e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1881/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4143e-04 - val_loss: 6.3143e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1882/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.4372e-04 - val_loss: 5.6539e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1883/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4566e-04 - val_loss: 7.0178e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1884/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4487e-04 - val_loss: 6.0407e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1885/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4449e-04 - val_loss: 5.6364e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1886/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 2.4782e-04 - val_loss: 5.6062e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1887/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4174e-04 - val_loss: 6.4350e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1888/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4748e-04 - val_loss: 6.0409e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1889/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4221e-04 - val_loss: 6.1953e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1890/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4278e-04 - val_loss: 5.0792e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1891/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4533e-04 - val_loss: 6.2851e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1892/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4262e-04 - val_loss: 6.7076e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1893/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4304e-04 - val_loss: 6.2908e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1894/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4306e-04 - val_loss: 6.5161e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1895/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.4105e-04 - val_loss: 6.7576e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1896/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4475e-04 - val_loss: 6.0788e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1897/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3976e-04 - val_loss: 5.2866e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1898/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4473e-04 - val_loss: 7.2015e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1899/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.4041e-04 - val_loss: 6.1852e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1900/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4357e-04 - val_loss: 6.4072e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1901/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4078e-04 - val_loss: 5.7526e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1902/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4247e-04 - val_loss: 6.7021e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1903/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.4434e-04 - val_loss: 6.7601e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1904/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.4033e-04 - val_loss: 6.4499e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1905/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4441e-04 - val_loss: 5.8569e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1906/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4477e-04 - val_loss: 6.9238e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1907/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4394e-04 - val_loss: 6.7273e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1908/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4173e-04 - val_loss: 5.5370e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1909/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.4206e-04 - val_loss: 6.6080e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1910/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3967e-04 - val_loss: 5.4568e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1911/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4112e-04 - val_loss: 6.4070e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1912/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3937e-04 - val_loss: 6.5160e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1913/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4274e-04 - val_loss: 6.5771e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1914/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3979e-04 - val_loss: 7.7171e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1915/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4061e-04 - val_loss: 5.5630e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1916/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4325e-04 - val_loss: 5.5695e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1917/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4261e-04 - val_loss: 5.8479e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1918/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4013e-04 - val_loss: 6.1654e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1919/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4304e-04 - val_loss: 5.9827e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1920/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.4664e-04 - val_loss: 6.0588e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1921/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4233e-04 - val_loss: 5.9231e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1922/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4048e-04 - val_loss: 5.3097e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1923/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4141e-04 - val_loss: 6.4431e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1924/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4142e-04 - val_loss: 7.2167e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1925/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4236e-04 - val_loss: 5.8880e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1926/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4137e-04 - val_loss: 6.2455e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1927/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4195e-04 - val_loss: 4.9829e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1928/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.3555e-04 - val_loss: 5.9395e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1929/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3932e-04 - val_loss: 6.3520e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1930/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4089e-04 - val_loss: 7.1646e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1931/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 2.3882e-04 - val_loss: 7.5821e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1932/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4142e-04 - val_loss: 6.1082e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1933/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4001e-04 - val_loss: 4.8748e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1934/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3884e-04 - val_loss: 6.9078e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1935/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3958e-04 - val_loss: 6.8636e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1936/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3994e-04 - val_loss: 7.2758e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1937/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4043e-04 - val_loss: 5.7417e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1938/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.4218e-04 - val_loss: 5.9852e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1939/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3800e-04 - val_loss: 6.9826e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1940/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3960e-04 - val_loss: 6.9766e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1941/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4133e-04 - val_loss: 6.6392e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1942/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4082e-04 - val_loss: 6.0670e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1943/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3460e-04 - val_loss: 6.1109e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1944/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3566e-04 - val_loss: 7.5861e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1945/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4030e-04 - val_loss: 6.7198e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1946/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4310e-04 - val_loss: 6.7685e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1947/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3647e-04 - val_loss: 6.2455e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1948/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3911e-04 - val_loss: 6.1028e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1949/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3817e-04 - val_loss: 6.8818e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1950/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3799e-04 - val_loss: 6.1353e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1951/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3781e-04 - val_loss: 6.7861e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1952/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4145e-04 - val_loss: 5.6060e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1953/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3827e-04 - val_loss: 7.1170e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1954/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3911e-04 - val_loss: 5.2414e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1955/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3768e-04 - val_loss: 6.2002e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1956/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3536e-04 - val_loss: 6.6181e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1957/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3936e-04 - val_loss: 5.8301e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1958/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.3719e-04 - val_loss: 6.6003e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1959/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.3623e-04 - val_loss: 5.4389e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1960/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3837e-04 - val_loss: 6.8431e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1961/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3769e-04 - val_loss: 4.9211e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1962/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3624e-04 - val_loss: 7.3878e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1963/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3640e-04 - val_loss: 6.6738e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1964/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.3799e-04 - val_loss: 5.7367e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1965/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3728e-04 - val_loss: 7.1332e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1966/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.4134e-04 - val_loss: 5.6923e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1967/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.3963e-04 - val_loss: 6.1014e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1968/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.3760e-04 - val_loss: 5.7381e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1969/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3814e-04 - val_loss: 5.8684e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1970/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3954e-04 - val_loss: 5.7490e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1971/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.3498e-04 - val_loss: 5.9241e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1972/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3765e-04 - val_loss: 6.8287e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1973/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3850e-04 - val_loss: 5.9852e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1974/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 2.3841e-04 - val_loss: 5.5868e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1975/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3867e-04 - val_loss: 6.8765e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1976/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3580e-04 - val_loss: 5.0842e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1977/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3875e-04 - val_loss: 6.4450e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1978/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3596e-04 - val_loss: 6.3927e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1979/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3651e-04 - val_loss: 6.0052e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1980/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.3804e-04 - val_loss: 6.4859e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1981/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3934e-04 - val_loss: 5.4999e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1982/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3939e-04 - val_loss: 6.1990e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1983/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3704e-04 - val_loss: 7.2702e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1984/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.3519e-04 - val_loss: 6.2378e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1985/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3790e-04 - val_loss: 5.5138e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1986/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3504e-04 - val_loss: 6.7715e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1987/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3602e-04 - val_loss: 6.4807e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1988/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3412e-04 - val_loss: 5.7684e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1989/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3611e-04 - val_loss: 6.6692e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1990/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3559e-04 - val_loss: 6.4580e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1991/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3363e-04 - val_loss: 5.4521e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1992/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3352e-04 - val_loss: 5.7630e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1993/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3694e-04 - val_loss: 6.4557e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1994/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3206e-04 - val_loss: 5.5805e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1995/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.3642e-04 - val_loss: 7.2091e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1996/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3789e-04 - val_loss: 6.3318e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1997/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3660e-04 - val_loss: 7.1341e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1998/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3466e-04 - val_loss: 6.1619e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 1999/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3529e-04 - val_loss: 6.0348e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2000/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3498e-04 - val_loss: 8.5788e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2001/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3482e-04 - val_loss: 6.6394e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2002/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3761e-04 - val_loss: 6.8658e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2003/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3236e-04 - val_loss: 6.0507e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2004/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3524e-04 - val_loss: 6.7946e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2005/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3454e-04 - val_loss: 6.8367e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2006/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.3097e-04 - val_loss: 6.1238e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2007/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3572e-04 - val_loss: 4.9954e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2008/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.3320e-04 - val_loss: 7.3689e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2009/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3527e-04 - val_loss: 6.8723e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2010/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3174e-04 - val_loss: 6.4708e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2011/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 2.3405e-04 - val_loss: 5.4063e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2012/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3474e-04 - val_loss: 6.5962e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2013/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3555e-04 - val_loss: 6.6999e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2014/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3599e-04 - val_loss: 5.6502e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2015/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3546e-04 - val_loss: 6.5275e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2016/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.3794e-04 - val_loss: 6.1049e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2017/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3263e-04 - val_loss: 5.9482e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2018/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3335e-04 - val_loss: 6.9797e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2019/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3226e-04 - val_loss: 6.0049e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2020/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3566e-04 - val_loss: 6.5031e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2021/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3348e-04 - val_loss: 5.6313e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2022/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3362e-04 - val_loss: 6.0297e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2023/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3202e-04 - val_loss: 5.7865e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2024/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3351e-04 - val_loss: 6.1072e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2025/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3285e-04 - val_loss: 5.1012e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2026/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3069e-04 - val_loss: 6.6973e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2027/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3435e-04 - val_loss: 6.3558e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2028/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3093e-04 - val_loss: 6.4697e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2029/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.3461e-04 - val_loss: 6.7383e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2030/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3154e-04 - val_loss: 4.7200e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2031/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3546e-04 - val_loss: 5.0990e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2032/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2970e-04 - val_loss: 6.7924e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2033/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3141e-04 - val_loss: 5.5996e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2034/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3197e-04 - val_loss: 5.7926e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2035/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3124e-04 - val_loss: 5.5968e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2036/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3245e-04 - val_loss: 6.3223e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2037/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3150e-04 - val_loss: 6.6774e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2038/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.3556e-04 - val_loss: 5.6025e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2039/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3381e-04 - val_loss: 6.5129e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2040/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3252e-04 - val_loss: 6.2173e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2041/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3121e-04 - val_loss: 6.6473e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2042/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2905e-04 - val_loss: 6.0836e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2043/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3387e-04 - val_loss: 6.0161e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2044/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3235e-04 - val_loss: 7.1282e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2045/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3497e-04 - val_loss: 6.3040e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2046/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3384e-04 - val_loss: 5.2933e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2047/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 2.3205e-04 - val_loss: 6.1209e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2048/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.3556e-04 - val_loss: 6.7855e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2049/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2921e-04 - val_loss: 6.2047e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2050/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3166e-04 - val_loss: 6.5920e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2051/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3104e-04 - val_loss: 7.3165e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2052/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2906e-04 - val_loss: 6.4267e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2053/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3067e-04 - val_loss: 6.8229e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2054/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3255e-04 - val_loss: 6.7635e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2055/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3026e-04 - val_loss: 5.8968e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2056/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3258e-04 - val_loss: 6.0836e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2057/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3156e-04 - val_loss: 6.1311e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2058/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2690e-04 - val_loss: 6.2511e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2059/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3150e-04 - val_loss: 4.9998e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2060/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3156e-04 - val_loss: 7.2872e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2061/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3284e-04 - val_loss: 6.1222e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2062/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3079e-04 - val_loss: 6.6620e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2063/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3013e-04 - val_loss: 6.1073e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2064/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3141e-04 - val_loss: 5.9912e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2065/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3108e-04 - val_loss: 6.5610e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2066/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3297e-04 - val_loss: 6.4846e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2067/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3098e-04 - val_loss: 5.3642e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2068/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3294e-04 - val_loss: 6.5717e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2069/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3172e-04 - val_loss: 5.4114e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2070/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.3103e-04 - val_loss: 6.3006e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2071/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3231e-04 - val_loss: 6.4100e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2072/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2738e-04 - val_loss: 7.0505e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2073/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3078e-04 - val_loss: 6.3993e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2074/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3149e-04 - val_loss: 6.2386e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2075/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2971e-04 - val_loss: 6.0522e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2076/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3077e-04 - val_loss: 5.7245e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2077/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3032e-04 - val_loss: 5.7933e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2078/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2753e-04 - val_loss: 6.3593e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2079/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2659e-04 - val_loss: 6.6940e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2080/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3152e-04 - val_loss: 7.1246e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2081/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2916e-04 - val_loss: 6.0746e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2082/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3444e-04 - val_loss: 6.6406e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2083/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2846e-04 - val_loss: 6.8633e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2084/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3005e-04 - val_loss: 6.4289e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2085/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2770e-04 - val_loss: 6.5478e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2086/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2810e-04 - val_loss: 5.7166e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2087/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3388e-04 - val_loss: 6.4397e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2088/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3063e-04 - val_loss: 6.6260e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2089/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3099e-04 - val_loss: 5.1737e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2090/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.2871e-04 - val_loss: 6.0322e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2091/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3200e-04 - val_loss: 7.3219e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2092/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.2716e-04 - val_loss: 5.8730e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2093/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2930e-04 - val_loss: 5.6021e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2094/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3023e-04 - val_loss: 8.4602e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2095/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.2724e-04 - val_loss: 6.8818e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2096/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2851e-04 - val_loss: 5.3413e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2097/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2713e-04 - val_loss: 6.1596e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2098/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2727e-04 - val_loss: 6.7281e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2099/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2798e-04 - val_loss: 5.6542e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2100/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2530e-04 - val_loss: 6.6333e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2101/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2746e-04 - val_loss: 5.8360e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2102/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2898e-04 - val_loss: 6.9493e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2103/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2969e-04 - val_loss: 5.7610e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2104/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2831e-04 - val_loss: 7.7946e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2105/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2644e-04 - val_loss: 8.3423e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2106/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2678e-04 - val_loss: 5.9730e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2107/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2665e-04 - val_loss: 6.9592e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2108/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2657e-04 - val_loss: 6.3146e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2109/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2914e-04 - val_loss: 6.1421e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2110/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2905e-04 - val_loss: 6.2530e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2111/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2555e-04 - val_loss: 6.9074e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2112/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2742e-04 - val_loss: 6.7965e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2113/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2869e-04 - val_loss: 6.6827e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2114/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2923e-04 - val_loss: 7.5142e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2115/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2711e-04 - val_loss: 6.1150e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2116/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2517e-04 - val_loss: 7.2740e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2117/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2439e-04 - val_loss: 6.3057e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2118/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2584e-04 - val_loss: 5.7607e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2119/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3005e-04 - val_loss: 5.5931e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2120/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.2575e-04 - val_loss: 4.9429e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2121/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2577e-04 - val_loss: 5.0527e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2122/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.2780e-04 - val_loss: 6.3730e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2123/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2628e-04 - val_loss: 5.2314e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2124/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2647e-04 - val_loss: 6.6008e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2125/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.2433e-04 - val_loss: 6.5909e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2126/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2657e-04 - val_loss: 6.5341e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2127/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2844e-04 - val_loss: 5.7424e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2128/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2746e-04 - val_loss: 6.5771e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2129/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2404e-04 - val_loss: 6.1557e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2130/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2553e-04 - val_loss: 6.8307e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2131/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2583e-04 - val_loss: 6.5266e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2132/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2612e-04 - val_loss: 7.7751e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2133/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2771e-04 - val_loss: 6.7363e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2134/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2906e-04 - val_loss: 6.2481e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2135/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.2642e-04 - val_loss: 5.0863e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2136/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2725e-04 - val_loss: 5.5122e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2137/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2711e-04 - val_loss: 5.1336e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2138/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2590e-04 - val_loss: 6.3141e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2139/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2421e-04 - val_loss: 6.9942e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2140/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2204e-04 - val_loss: 5.4771e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2141/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2650e-04 - val_loss: 7.2515e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2142/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2808e-04 - val_loss: 6.2965e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2143/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2392e-04 - val_loss: 6.7745e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2144/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2479e-04 - val_loss: 6.2855e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2145/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.3005e-04 - val_loss: 6.1237e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2146/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2686e-04 - val_loss: 6.1434e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2147/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2423e-04 - val_loss: 6.5359e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2148/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2502e-04 - val_loss: 5.1008e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2149/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2404e-04 - val_loss: 6.2409e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2150/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2205e-04 - val_loss: 7.2051e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2151/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2980e-04 - val_loss: 6.4237e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2152/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2681e-04 - val_loss: 5.7413e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2153/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2690e-04 - val_loss: 7.3509e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2154/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2655e-04 - val_loss: 4.8901e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2155/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2262e-04 - val_loss: 6.9147e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2156/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2630e-04 - val_loss: 6.1408e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2157/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2686e-04 - val_loss: 5.7771e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2158/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2175e-04 - val_loss: 6.2939e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2159/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2594e-04 - val_loss: 6.5144e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2160/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2683e-04 - val_loss: 5.9643e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2161/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2412e-04 - val_loss: 6.0893e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2162/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.2488e-04 - val_loss: 6.5154e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2163/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2361e-04 - val_loss: 5.7874e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2164/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2547e-04 - val_loss: 6.5369e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2165/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2177e-04 - val_loss: 5.2613e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2166/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2147e-04 - val_loss: 6.5163e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2167/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2675e-04 - val_loss: 6.1933e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2168/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.2695e-04 - val_loss: 5.6532e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2169/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2493e-04 - val_loss: 5.6287e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2170/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.2338e-04 - val_loss: 6.0867e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2171/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.2354e-04 - val_loss: 5.5655e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2172/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2291e-04 - val_loss: 6.6761e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2173/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2427e-04 - val_loss: 5.5700e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2174/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2184e-04 - val_loss: 6.4932e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2175/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2358e-04 - val_loss: 6.7149e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2176/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2331e-04 - val_loss: 7.0051e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2177/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2247e-04 - val_loss: 7.2647e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2178/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2364e-04 - val_loss: 6.9322e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2179/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2348e-04 - val_loss: 6.6920e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2180/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2182e-04 - val_loss: 6.6476e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2181/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2220e-04 - val_loss: 6.0147e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2182/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2389e-04 - val_loss: 5.8052e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2183/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2436e-04 - val_loss: 6.8596e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2184/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2417e-04 - val_loss: 6.6852e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2185/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2435e-04 - val_loss: 6.9284e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2186/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2275e-04 - val_loss: 5.3847e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2187/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2137e-04 - val_loss: 7.6108e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2188/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1849e-04 - val_loss: 5.8942e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2189/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.2297e-04 - val_loss: 6.9713e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2190/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2364e-04 - val_loss: 7.2188e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2191/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.2320e-04 - val_loss: 6.7117e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2192/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2406e-04 - val_loss: 5.5803e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2193/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2365e-04 - val_loss: 5.8676e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2194/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.2106e-04 - val_loss: 5.4618e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2195/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2344e-04 - val_loss: 6.4450e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2196/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2024e-04 - val_loss: 6.9454e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2197/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2095e-04 - val_loss: 5.2272e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2198/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2301e-04 - val_loss: 5.5002e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2199/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.2175e-04 - val_loss: 5.3922e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2200/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2189e-04 - val_loss: 5.5247e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2201/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1912e-04 - val_loss: 4.4473e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2202/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2113e-04 - val_loss: 5.4894e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2203/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2448e-04 - val_loss: 6.5202e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2204/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2397e-04 - val_loss: 7.2788e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2205/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2378e-04 - val_loss: 6.1419e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2206/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1960e-04 - val_loss: 6.7370e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2207/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2464e-04 - val_loss: 5.9137e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2208/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1914e-04 - val_loss: 5.7627e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2209/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2259e-04 - val_loss: 5.1583e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2210/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2017e-04 - val_loss: 5.1087e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2211/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2166e-04 - val_loss: 6.8340e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2212/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.2119e-04 - val_loss: 5.7170e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2213/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1991e-04 - val_loss: 5.7074e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2214/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2077e-04 - val_loss: 5.9416e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2215/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2084e-04 - val_loss: 5.9875e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2216/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.2140e-04 - val_loss: 5.9032e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2217/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1829e-04 - val_loss: 5.8118e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2218/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2281e-04 - val_loss: 5.9260e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2219/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2168e-04 - val_loss: 5.2957e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2220/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2043e-04 - val_loss: 6.3832e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2221/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.1759e-04 - val_loss: 6.3740e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2222/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1805e-04 - val_loss: 5.1162e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2223/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.1985e-04 - val_loss: 6.0134e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2224/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2196e-04 - val_loss: 6.4851e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2225/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1896e-04 - val_loss: 6.3196e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2226/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1956e-04 - val_loss: 7.0977e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2227/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1935e-04 - val_loss: 6.4442e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2228/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2146e-04 - val_loss: 6.6064e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2229/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2001e-04 - val_loss: 5.9499e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2230/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.1977e-04 - val_loss: 5.3575e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2231/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2135e-04 - val_loss: 6.1812e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2232/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2237e-04 - val_loss: 5.0627e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2233/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.2011e-04 - val_loss: 6.1894e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2234/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.1912e-04 - val_loss: 6.9656e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2235/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2181e-04 - val_loss: 7.1359e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2236/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1947e-04 - val_loss: 6.0119e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2237/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1849e-04 - val_loss: 6.5547e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2238/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.2328e-04 - val_loss: 5.9126e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2239/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.1839e-04 - val_loss: 6.8118e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2240/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.1795e-04 - val_loss: 5.9627e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2241/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2093e-04 - val_loss: 5.9017e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2242/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1935e-04 - val_loss: 5.1968e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2243/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1809e-04 - val_loss: 4.9017e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2244/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2080e-04 - val_loss: 6.8023e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2245/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.2149e-04 - val_loss: 6.4189e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2246/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1816e-04 - val_loss: 6.6708e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2247/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1800e-04 - val_loss: 6.6853e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2248/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2059e-04 - val_loss: 5.9751e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2249/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1744e-04 - val_loss: 6.2847e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2250/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1826e-04 - val_loss: 6.6394e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2251/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2140e-04 - val_loss: 5.8147e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2252/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1804e-04 - val_loss: 6.2710e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2253/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1813e-04 - val_loss: 5.4094e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2254/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1871e-04 - val_loss: 6.4760e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2255/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1732e-04 - val_loss: 6.3314e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2256/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1936e-04 - val_loss: 6.7825e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2257/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2121e-04 - val_loss: 6.3221e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2258/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1974e-04 - val_loss: 6.1947e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2259/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1887e-04 - val_loss: 5.0689e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2260/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1789e-04 - val_loss: 5.4089e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2261/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1599e-04 - val_loss: 5.8980e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2262/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1650e-04 - val_loss: 5.5001e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2263/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1612e-04 - val_loss: 5.8780e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2264/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1858e-04 - val_loss: 6.4324e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2265/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1873e-04 - val_loss: 6.1672e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2266/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1596e-04 - val_loss: 6.8791e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2267/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2021e-04 - val_loss: 6.2319e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2268/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1803e-04 - val_loss: 7.5250e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2269/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1975e-04 - val_loss: 5.7135e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2270/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1712e-04 - val_loss: 6.1925e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2271/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1720e-04 - val_loss: 6.1850e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2272/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1667e-04 - val_loss: 5.8737e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2273/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1642e-04 - val_loss: 5.9876e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2274/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1614e-04 - val_loss: 6.5209e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2275/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1651e-04 - val_loss: 6.6023e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2276/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1457e-04 - val_loss: 6.0632e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2277/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1800e-04 - val_loss: 6.1207e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2278/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.2003e-04 - val_loss: 5.8845e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2279/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1975e-04 - val_loss: 6.4869e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2280/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1675e-04 - val_loss: 5.1694e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2281/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1589e-04 - val_loss: 5.5041e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2282/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1766e-04 - val_loss: 5.8619e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2283/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.1436e-04 - val_loss: 6.3515e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2284/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1805e-04 - val_loss: 5.5151e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2285/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1583e-04 - val_loss: 6.5386e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2286/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1339e-04 - val_loss: 5.2243e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2287/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1727e-04 - val_loss: 6.5636e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2288/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1766e-04 - val_loss: 6.1148e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2289/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1366e-04 - val_loss: 5.2082e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2290/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1505e-04 - val_loss: 5.8589e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2291/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1784e-04 - val_loss: 5.2531e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2292/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1594e-04 - val_loss: 5.8648e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2293/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1714e-04 - val_loss: 5.7729e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2294/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.1753e-04 - val_loss: 7.6338e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2295/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.2029e-04 - val_loss: 5.8704e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2296/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1725e-04 - val_loss: 7.2806e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2297/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1732e-04 - val_loss: 4.8662e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2298/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1673e-04 - val_loss: 5.5525e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2299/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1802e-04 - val_loss: 5.9246e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2300/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1778e-04 - val_loss: 4.6303e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2301/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1764e-04 - val_loss: 5.8600e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2302/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1451e-04 - val_loss: 5.5191e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2303/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.1382e-04 - val_loss: 5.8348e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2304/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1363e-04 - val_loss: 6.4541e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2305/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.1512e-04 - val_loss: 5.0386e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2306/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1351e-04 - val_loss: 4.6346e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2307/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1646e-04 - val_loss: 7.2724e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2308/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1924e-04 - val_loss: 6.8319e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2309/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1361e-04 - val_loss: 6.2888e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2310/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1692e-04 - val_loss: 6.6259e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2311/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1259e-04 - val_loss: 6.3904e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2312/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1609e-04 - val_loss: 5.0539e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2313/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.1355e-04 - val_loss: 6.8521e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2314/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1323e-04 - val_loss: 5.0814e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2315/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1499e-04 - val_loss: 5.7537e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2316/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1696e-04 - val_loss: 5.9220e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2317/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1723e-04 - val_loss: 6.9624e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2318/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.1211e-04 - val_loss: 5.8073e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2319/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1611e-04 - val_loss: 5.9505e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2320/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1544e-04 - val_loss: 5.9882e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2321/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.1565e-04 - val_loss: 5.7724e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2322/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1328e-04 - val_loss: 7.2825e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2323/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.1295e-04 - val_loss: 6.2489e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2324/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.1349e-04 - val_loss: 6.2513e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2325/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1413e-04 - val_loss: 5.8736e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2326/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1406e-04 - val_loss: 6.2416e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2327/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.1112e-04 - val_loss: 6.0471e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2328/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1781e-04 - val_loss: 5.9069e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2329/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.1337e-04 - val_loss: 5.8351e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2330/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1430e-04 - val_loss: 5.9553e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2331/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1500e-04 - val_loss: 5.8490e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2332/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1513e-04 - val_loss: 6.0135e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2333/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.1511e-04 - val_loss: 5.3100e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2334/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1360e-04 - val_loss: 6.5824e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2335/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.1258e-04 - val_loss: 5.3952e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2336/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1634e-04 - val_loss: 5.7659e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2337/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1581e-04 - val_loss: 5.6551e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2338/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.1267e-04 - val_loss: 6.3727e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2339/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1381e-04 - val_loss: 5.6361e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2340/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.1723e-04 - val_loss: 6.5745e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2341/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1479e-04 - val_loss: 6.4634e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2342/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1266e-04 - val_loss: 6.2610e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2343/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.1201e-04 - val_loss: 5.4488e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2344/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1175e-04 - val_loss: 5.4120e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2345/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1559e-04 - val_loss: 5.2132e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2346/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1311e-04 - val_loss: 6.4425e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2347/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1472e-04 - val_loss: 6.2302e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2348/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1337e-04 - val_loss: 5.5227e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2349/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1397e-04 - val_loss: 6.6520e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2350/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1037e-04 - val_loss: 6.9877e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2351/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1267e-04 - val_loss: 6.1856e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2352/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1454e-04 - val_loss: 5.5659e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2353/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1355e-04 - val_loss: 5.3927e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2354/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1249e-04 - val_loss: 5.2359e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2355/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1095e-04 - val_loss: 6.6592e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2356/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.1310e-04 - val_loss: 6.5744e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2357/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1327e-04 - val_loss: 6.1751e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2358/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1135e-04 - val_loss: 5.6665e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2359/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.1474e-04 - val_loss: 4.9897e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2360/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1237e-04 - val_loss: 5.5624e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2361/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.1135e-04 - val_loss: 5.3161e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2362/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.1185e-04 - val_loss: 5.2247e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2363/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1082e-04 - val_loss: 6.7236e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2364/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1168e-04 - val_loss: 5.6863e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2365/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1411e-04 - val_loss: 5.0787e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2366/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1022e-04 - val_loss: 5.7010e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2367/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1130e-04 - val_loss: 5.2996e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2368/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1214e-04 - val_loss: 5.5396e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2369/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1287e-04 - val_loss: 7.0123e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2370/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1330e-04 - val_loss: 6.3201e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2371/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1258e-04 - val_loss: 5.7843e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2372/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1373e-04 - val_loss: 5.9877e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2373/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1080e-04 - val_loss: 6.8423e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2374/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1058e-04 - val_loss: 5.8342e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2375/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.0977e-04 - val_loss: 6.2393e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2376/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1303e-04 - val_loss: 5.2782e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2377/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1130e-04 - val_loss: 6.7627e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2378/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1233e-04 - val_loss: 6.2050e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2379/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0972e-04 - val_loss: 4.9871e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2380/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1190e-04 - val_loss: 6.1459e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2381/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1051e-04 - val_loss: 5.3846e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2382/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1145e-04 - val_loss: 5.9417e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2383/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1264e-04 - val_loss: 6.6042e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2384/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1432e-04 - val_loss: 5.8834e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2385/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1036e-04 - val_loss: 5.3572e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2386/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.1329e-04 - val_loss: 5.1611e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2387/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1028e-04 - val_loss: 5.7235e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2388/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0956e-04 - val_loss: 5.4401e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2389/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0989e-04 - val_loss: 6.7701e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2390/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0865e-04 - val_loss: 6.2379e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2391/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1201e-04 - val_loss: 6.5964e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2392/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1066e-04 - val_loss: 4.7453e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2393/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1116e-04 - val_loss: 5.2930e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2394/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1057e-04 - val_loss: 6.2114e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2395/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1122e-04 - val_loss: 6.0173e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2396/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0914e-04 - val_loss: 6.5337e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2397/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1196e-04 - val_loss: 5.6814e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2398/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1067e-04 - val_loss: 6.6276e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2399/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1000e-04 - val_loss: 5.6119e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2400/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1115e-04 - val_loss: 6.0752e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2401/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0982e-04 - val_loss: 4.8230e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2402/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.1094e-04 - val_loss: 5.9281e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2403/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1109e-04 - val_loss: 5.4780e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2404/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1176e-04 - val_loss: 5.2227e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2405/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0741e-04 - val_loss: 5.5448e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2406/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1087e-04 - val_loss: 6.6404e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2407/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1163e-04 - val_loss: 5.9839e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2408/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0807e-04 - val_loss: 5.6325e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2409/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.1059e-04 - val_loss: 5.8512e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2410/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1133e-04 - val_loss: 5.9587e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2411/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1187e-04 - val_loss: 4.8631e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2412/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0613e-04 - val_loss: 5.1713e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2413/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0876e-04 - val_loss: 5.7712e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2414/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.0935e-04 - val_loss: 6.4491e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2415/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0760e-04 - val_loss: 5.5551e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2416/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0901e-04 - val_loss: 6.1790e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2417/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0897e-04 - val_loss: 5.9204e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2418/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 2.0733e-04 - val_loss: 5.8124e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2419/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0804e-04 - val_loss: 4.9132e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2420/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1012e-04 - val_loss: 5.5574e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2421/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0799e-04 - val_loss: 5.0738e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2422/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0810e-04 - val_loss: 5.0851e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2423/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1000e-04 - val_loss: 7.9691e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2424/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0930e-04 - val_loss: 6.4533e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2425/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.0738e-04 - val_loss: 7.4398e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2426/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0718e-04 - val_loss: 5.8194e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2427/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0973e-04 - val_loss: 5.1450e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2428/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1234e-04 - val_loss: 6.6500e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2429/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0783e-04 - val_loss: 5.0944e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2430/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0906e-04 - val_loss: 5.4151e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2431/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0813e-04 - val_loss: 4.2775e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2432/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1037e-04 - val_loss: 5.7987e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2433/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.1019e-04 - val_loss: 5.8363e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2434/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0772e-04 - val_loss: 6.5182e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2435/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.0904e-04 - val_loss: 5.2406e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2436/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.0666e-04 - val_loss: 6.1141e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2437/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.0836e-04 - val_loss: 6.5088e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2438/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0877e-04 - val_loss: 5.9234e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2439/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0833e-04 - val_loss: 5.8411e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2440/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0844e-04 - val_loss: 5.8862e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2441/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0502e-04 - val_loss: 5.3530e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2442/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0834e-04 - val_loss: 6.5877e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2443/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.1166e-04 - val_loss: 5.2544e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2444/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0791e-04 - val_loss: 5.6535e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2445/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0671e-04 - val_loss: 6.1376e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2446/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0730e-04 - val_loss: 4.6283e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2447/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0697e-04 - val_loss: 6.8432e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2448/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0846e-04 - val_loss: 5.6869e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2449/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0944e-04 - val_loss: 7.2033e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2450/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0633e-04 - val_loss: 5.2188e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2451/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0905e-04 - val_loss: 5.6998e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2452/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0640e-04 - val_loss: 5.6877e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2453/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0847e-04 - val_loss: 6.1818e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2454/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.0612e-04 - val_loss: 6.2373e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2455/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0529e-04 - val_loss: 6.4200e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2456/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0876e-04 - val_loss: 5.5923e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2457/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0756e-04 - val_loss: 6.3118e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2458/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0611e-04 - val_loss: 6.6758e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2459/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0682e-04 - val_loss: 5.3518e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2460/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0488e-04 - val_loss: 6.3730e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2461/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0628e-04 - val_loss: 5.6488e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2462/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0791e-04 - val_loss: 6.1604e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2463/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.0785e-04 - val_loss: 5.6513e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2464/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0718e-04 - val_loss: 5.8066e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2465/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0501e-04 - val_loss: 5.9126e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2466/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0608e-04 - val_loss: 6.1545e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2467/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0496e-04 - val_loss: 7.3406e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2468/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0446e-04 - val_loss: 6.7399e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2469/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0813e-04 - val_loss: 6.0209e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2470/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0572e-04 - val_loss: 5.8401e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2471/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0957e-04 - val_loss: 5.2743e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2472/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 2.0647e-04 - val_loss: 5.7188e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2473/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0777e-04 - val_loss: 5.7103e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2474/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0602e-04 - val_loss: 5.5509e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2475/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0616e-04 - val_loss: 7.1846e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2476/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0553e-04 - val_loss: 5.5743e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2477/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0479e-04 - val_loss: 5.2511e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2478/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.0362e-04 - val_loss: 5.4199e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2479/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0659e-04 - val_loss: 5.3089e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2480/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0685e-04 - val_loss: 6.4600e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2481/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0519e-04 - val_loss: 6.3391e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2482/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0586e-04 - val_loss: 4.8182e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2483/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0540e-04 - val_loss: 6.3696e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2484/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0434e-04 - val_loss: 5.0727e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2485/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0632e-04 - val_loss: 6.1293e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2486/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0615e-04 - val_loss: 5.7211e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2487/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0697e-04 - val_loss: 5.6473e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2488/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0447e-04 - val_loss: 6.4730e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2489/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0271e-04 - val_loss: 4.9097e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2490/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0432e-04 - val_loss: 5.0692e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2491/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0753e-04 - val_loss: 5.3094e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2492/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0763e-04 - val_loss: 6.3094e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2493/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.0323e-04 - val_loss: 5.1240e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2494/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0632e-04 - val_loss: 6.0395e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2495/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0605e-04 - val_loss: 6.5352e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2496/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0272e-04 - val_loss: 6.1245e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2497/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0225e-04 - val_loss: 6.2481e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2498/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.0717e-04 - val_loss: 5.7718e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2499/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.0684e-04 - val_loss: 5.1158e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2500/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0425e-04 - val_loss: 5.3192e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2501/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0386e-04 - val_loss: 6.0276e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2502/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0535e-04 - val_loss: 6.9920e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2503/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0521e-04 - val_loss: 6.1534e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2504/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0661e-04 - val_loss: 5.7557e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2505/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0376e-04 - val_loss: 6.1668e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2506/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0415e-04 - val_loss: 6.7988e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2507/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.0458e-04 - val_loss: 6.5177e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2508/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0389e-04 - val_loss: 5.7289e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2509/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0245e-04 - val_loss: 5.5266e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2510/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0647e-04 - val_loss: 5.3298e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2511/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0245e-04 - val_loss: 6.5930e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2512/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0761e-04 - val_loss: 5.5591e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2513/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0419e-04 - val_loss: 6.4649e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2514/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0617e-04 - val_loss: 5.6837e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2515/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0339e-04 - val_loss: 6.2742e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2516/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0461e-04 - val_loss: 5.7968e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2517/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 2.0347e-04 - val_loss: 6.2408e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2518/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0683e-04 - val_loss: 6.6193e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2519/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.0470e-04 - val_loss: 5.4296e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2520/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0394e-04 - val_loss: 5.5255e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2521/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0467e-04 - val_loss: 6.0556e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2522/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0533e-04 - val_loss: 4.5890e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2523/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0243e-04 - val_loss: 5.6038e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2524/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0572e-04 - val_loss: 5.8376e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2525/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0245e-04 - val_loss: 5.9686e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2526/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0136e-04 - val_loss: 6.0422e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2527/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0153e-04 - val_loss: 5.7916e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2528/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0220e-04 - val_loss: 5.1558e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2529/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0403e-04 - val_loss: 5.8567e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2530/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0396e-04 - val_loss: 6.0667e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2531/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0225e-04 - val_loss: 6.5024e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2532/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0388e-04 - val_loss: 5.7277e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2533/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0536e-04 - val_loss: 5.5732e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2534/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0221e-04 - val_loss: 5.7608e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2535/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0668e-04 - val_loss: 5.3286e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2536/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.0198e-04 - val_loss: 6.5269e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2537/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0598e-04 - val_loss: 5.2544e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2538/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0180e-04 - val_loss: 5.3542e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2539/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.0193e-04 - val_loss: 5.6758e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2540/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0188e-04 - val_loss: 5.3157e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2541/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0174e-04 - val_loss: 7.1731e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2542/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0355e-04 - val_loss: 6.5518e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2543/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0237e-04 - val_loss: 5.3785e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2544/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0211e-04 - val_loss: 6.9184e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2545/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0352e-04 - val_loss: 5.2531e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2546/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0101e-04 - val_loss: 7.1862e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2547/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0348e-04 - val_loss: 5.6642e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2548/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0434e-04 - val_loss: 6.6152e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2549/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.0039e-04 - val_loss: 6.2460e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2550/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0143e-04 - val_loss: 6.0855e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2551/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0130e-04 - val_loss: 6.2633e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2552/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.0511e-04 - val_loss: 6.2322e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2553/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0308e-04 - val_loss: 6.3087e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2554/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.0415e-04 - val_loss: 5.6882e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2555/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9970e-04 - val_loss: 6.8152e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2556/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0259e-04 - val_loss: 7.4742e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2557/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.0382e-04 - val_loss: 5.2830e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2558/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0390e-04 - val_loss: 5.9766e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2559/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.0279e-04 - val_loss: 6.0424e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2560/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 2.0289e-04 - val_loss: 5.3440e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2561/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0053e-04 - val_loss: 6.6106e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2562/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0009e-04 - val_loss: 5.5009e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2563/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9931e-04 - val_loss: 5.6834e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2564/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0083e-04 - val_loss: 4.8533e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2565/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9938e-04 - val_loss: 6.0337e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2566/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.0128e-04 - val_loss: 5.9911e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2567/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0295e-04 - val_loss: 5.8606e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2568/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9945e-04 - val_loss: 4.5574e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2569/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0009e-04 - val_loss: 6.3362e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2570/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0083e-04 - val_loss: 5.5287e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2571/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0036e-04 - val_loss: 6.9661e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2572/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9986e-04 - val_loss: 5.3588e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2573/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 1.9944e-04 - val_loss: 5.8796e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2574/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0166e-04 - val_loss: 5.8539e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2575/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0258e-04 - val_loss: 6.7770e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2576/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.0256e-04 - val_loss: 6.4993e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2577/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0036e-04 - val_loss: 5.9245e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2578/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0036e-04 - val_loss: 6.1983e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2579/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 1.9877e-04 - val_loss: 4.9625e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2580/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.0163e-04 - val_loss: 5.8654e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2581/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0171e-04 - val_loss: 5.5331e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2582/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0393e-04 - val_loss: 4.9523e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2583/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0114e-04 - val_loss: 5.5486e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2584/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0364e-04 - val_loss: 6.4214e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2585/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 1.9862e-04 - val_loss: 5.0764e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2586/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9964e-04 - val_loss: 5.5113e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2587/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0203e-04 - val_loss: 6.2792e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2588/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9960e-04 - val_loss: 6.2113e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2589/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0143e-04 - val_loss: 6.2212e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2590/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9939e-04 - val_loss: 5.7203e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2591/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0013e-04 - val_loss: 5.0310e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2592/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9877e-04 - val_loss: 4.4892e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2593/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0172e-04 - val_loss: 7.2834e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2594/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9913e-04 - val_loss: 7.0208e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2595/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0073e-04 - val_loss: 6.3654e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2596/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9957e-04 - val_loss: 5.1755e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2597/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 1.9949e-04 - val_loss: 5.2279e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2598/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9793e-04 - val_loss: 6.0841e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2599/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9659e-04 - val_loss: 5.5704e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2600/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9843e-04 - val_loss: 6.4427e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2601/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9724e-04 - val_loss: 5.8569e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2602/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 1.9936e-04 - val_loss: 5.2208e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2603/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0044e-04 - val_loss: 4.9777e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2604/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0130e-04 - val_loss: 5.9621e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2605/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9891e-04 - val_loss: 5.6903e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2606/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 2.0100e-04 - val_loss: 5.4355e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2607/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0023e-04 - val_loss: 5.4597e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2608/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9883e-04 - val_loss: 5.7542e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2609/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0178e-04 - val_loss: 6.0965e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2610/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9995e-04 - val_loss: 5.5482e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2611/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9950e-04 - val_loss: 5.1675e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2612/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9952e-04 - val_loss: 6.2552e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2613/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 1.9797e-04 - val_loss: 5.4043e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2614/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0040e-04 - val_loss: 5.6231e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2615/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0018e-04 - val_loss: 5.3806e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2616/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0048e-04 - val_loss: 5.6847e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2617/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9742e-04 - val_loss: 6.4182e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2618/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9768e-04 - val_loss: 5.1287e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2619/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9928e-04 - val_loss: 6.2641e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2620/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9991e-04 - val_loss: 6.2015e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2621/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9933e-04 - val_loss: 5.5335e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2622/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9579e-04 - val_loss: 5.9068e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2623/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9934e-04 - val_loss: 5.4844e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2624/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9719e-04 - val_loss: 6.9378e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2625/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9861e-04 - val_loss: 5.3031e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2626/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9939e-04 - val_loss: 5.7825e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2627/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9930e-04 - val_loss: 4.6460e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2628/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9877e-04 - val_loss: 5.5695e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2629/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9963e-04 - val_loss: 7.1351e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2630/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 2.0056e-04 - val_loss: 5.1515e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2631/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9728e-04 - val_loss: 6.2360e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2632/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9713e-04 - val_loss: 5.5695e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2633/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 2.0197e-04 - val_loss: 7.0528e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2634/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9922e-04 - val_loss: 5.1277e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2635/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9677e-04 - val_loss: 6.2538e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2636/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9720e-04 - val_loss: 5.0188e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2637/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9783e-04 - val_loss: 4.1255e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2638/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9711e-04 - val_loss: 5.2636e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2639/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 1.9688e-04 - val_loss: 5.4957e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2640/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9957e-04 - val_loss: 4.6411e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2641/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9826e-04 - val_loss: 5.9868e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2642/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9577e-04 - val_loss: 6.0627e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2643/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9924e-04 - val_loss: 5.4060e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2644/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9701e-04 - val_loss: 4.9891e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2645/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9746e-04 - val_loss: 6.3730e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2646/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9797e-04 - val_loss: 6.6632e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2647/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9666e-04 - val_loss: 5.4172e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2648/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9723e-04 - val_loss: 4.9801e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2649/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9844e-04 - val_loss: 5.1448e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2650/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9817e-04 - val_loss: 6.1210e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2651/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9816e-04 - val_loss: 6.1404e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2652/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9741e-04 - val_loss: 6.2178e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2653/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9722e-04 - val_loss: 6.3198e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2654/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9932e-04 - val_loss: 6.3383e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2655/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9833e-04 - val_loss: 5.4251e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2656/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9994e-04 - val_loss: 6.9664e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2657/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9719e-04 - val_loss: 4.8877e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2658/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9969e-04 - val_loss: 5.9290e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2659/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9376e-04 - val_loss: 5.3896e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2660/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9748e-04 - val_loss: 6.5888e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2661/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9483e-04 - val_loss: 5.4531e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2662/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0072e-04 - val_loss: 5.2753e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2663/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9558e-04 - val_loss: 4.9617e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2664/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9699e-04 - val_loss: 6.1916e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2665/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9658e-04 - val_loss: 6.6485e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2666/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9675e-04 - val_loss: 6.1122e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2667/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9726e-04 - val_loss: 5.2520e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2668/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9518e-04 - val_loss: 6.5680e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2669/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9574e-04 - val_loss: 6.5045e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2670/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9576e-04 - val_loss: 5.5784e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2671/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 1.9931e-04 - val_loss: 5.8236e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2672/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9756e-04 - val_loss: 6.9445e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2673/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9804e-04 - val_loss: 6.1181e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2674/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9724e-04 - val_loss: 5.8877e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2675/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 1.9896e-04 - val_loss: 6.1614e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2676/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9702e-04 - val_loss: 6.2683e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2677/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9684e-04 - val_loss: 5.7854e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2678/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9705e-04 - val_loss: 4.8792e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2679/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9759e-04 - val_loss: 5.5893e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2680/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9378e-04 - val_loss: 5.4926e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2681/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9575e-04 - val_loss: 5.0819e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2682/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 2.0003e-04 - val_loss: 5.4816e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2683/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9691e-04 - val_loss: 4.8780e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2684/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9591e-04 - val_loss: 5.8711e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2685/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9590e-04 - val_loss: 4.8127e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2686/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9758e-04 - val_loss: 5.4251e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2687/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9818e-04 - val_loss: 5.1796e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2688/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9709e-04 - val_loss: 4.6666e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2689/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9490e-04 - val_loss: 5.1638e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2690/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9785e-04 - val_loss: 6.1318e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2691/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9580e-04 - val_loss: 7.0213e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2692/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9597e-04 - val_loss: 5.5393e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2693/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9648e-04 - val_loss: 5.5582e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2694/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9654e-04 - val_loss: 6.4036e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2695/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9449e-04 - val_loss: 5.0444e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2696/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9611e-04 - val_loss: 5.9194e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2697/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9717e-04 - val_loss: 7.3203e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2698/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9411e-04 - val_loss: 5.7993e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2699/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9317e-04 - val_loss: 6.1757e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2700/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9510e-04 - val_loss: 6.1614e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2701/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9356e-04 - val_loss: 5.5356e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2702/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9569e-04 - val_loss: 6.1105e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2703/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9595e-04 - val_loss: 5.9309e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2704/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9510e-04 - val_loss: 5.2286e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2705/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9395e-04 - val_loss: 4.3143e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2706/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9376e-04 - val_loss: 5.4553e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2707/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9629e-04 - val_loss: 5.1290e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2708/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9304e-04 - val_loss: 5.6720e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2709/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9744e-04 - val_loss: 6.9626e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2710/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9411e-04 - val_loss: 5.4810e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2711/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9444e-04 - val_loss: 4.7897e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2712/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9191e-04 - val_loss: 4.8678e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2713/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9541e-04 - val_loss: 6.0617e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2714/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9433e-04 - val_loss: 5.6609e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2715/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9293e-04 - val_loss: 5.6345e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2716/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9471e-04 - val_loss: 6.5013e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2717/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9245e-04 - val_loss: 4.8820e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2718/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9436e-04 - val_loss: 5.3830e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2719/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9317e-04 - val_loss: 6.3216e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2720/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9355e-04 - val_loss: 5.5858e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2721/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9512e-04 - val_loss: 5.8842e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2722/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9468e-04 - val_loss: 6.5924e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2723/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9298e-04 - val_loss: 5.5707e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2724/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9615e-04 - val_loss: 6.3731e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2725/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9351e-04 - val_loss: 5.5157e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2726/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9411e-04 - val_loss: 5.8155e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2727/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9153e-04 - val_loss: 6.1913e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2728/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9292e-04 - val_loss: 6.1166e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2729/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9741e-04 - val_loss: 5.9220e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2730/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9214e-04 - val_loss: 5.8696e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2731/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9515e-04 - val_loss: 6.0623e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2732/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9385e-04 - val_loss: 5.5134e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2733/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.9290e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:47:45.387912: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9285e-04 - val_loss: 6.3128e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2734/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9168e-04 - val_loss: 5.6944e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2735/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9568e-04 - val_loss: 5.6536e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2736/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9391e-04 - val_loss: 5.7226e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2737/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9455e-04 - val_loss: 5.3224e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2738/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9279e-04 - val_loss: 6.6992e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2739/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9487e-04 - val_loss: 5.5400e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2740/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9396e-04 - val_loss: 5.9886e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2741/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9576e-04 - val_loss: 6.0352e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2742/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9287e-04 - val_loss: 5.8847e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2743/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9129e-04 - val_loss: 5.7831e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2744/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 1.9284e-04 - val_loss: 4.5682e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2745/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9460e-04 - val_loss: 5.6780e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2746/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9245e-04 - val_loss: 5.0853e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2747/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9376e-04 - val_loss: 5.1834e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2748/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9193e-04 - val_loss: 4.7989e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2749/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9392e-04 - val_loss: 4.5376e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2750/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9572e-04 - val_loss: 6.2137e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2751/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9203e-04 - val_loss: 6.0292e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2752/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9411e-04 - val_loss: 5.1927e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2753/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9300e-04 - val_loss: 5.7032e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2754/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9276e-04 - val_loss: 5.1401e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2755/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9310e-04 - val_loss: 5.3653e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2756/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9145e-04 - val_loss: 5.4465e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2757/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9091e-04 - val_loss: 6.5346e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2758/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9407e-04 - val_loss: 5.2092e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2759/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9204e-04 - val_loss: 5.9188e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2760/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9531e-04 - val_loss: 5.6314e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2761/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9336e-04 - val_loss: 5.1216e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2762/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9081e-04 - val_loss: 4.7765e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2763/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9273e-04 - val_loss: 7.6042e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2764/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9427e-04 - val_loss: 6.7674e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2765/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9241e-04 - val_loss: 6.8877e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2766/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9318e-04 - val_loss: 5.8500e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2767/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9237e-04 - val_loss: 5.0555e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2768/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9134e-04 - val_loss: 5.5119e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2769/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9272e-04 - val_loss: 5.6712e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2770/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9257e-04 - val_loss: 5.6403e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2771/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9328e-04 - val_loss: 6.4760e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2772/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9334e-04 - val_loss: 6.1699e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2773/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9290e-04 - val_loss: 5.5474e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2774/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9417e-04 - val_loss: 5.5867e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2775/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9136e-04 - val_loss: 5.8599e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2776/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9078e-04 - val_loss: 5.5138e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2777/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9342e-04 - val_loss: 4.7015e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2778/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9211e-04 - val_loss: 5.6020e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2779/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9146e-04 - val_loss: 5.8568e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2780/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9004e-04 - val_loss: 5.9638e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2781/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8963e-04 - val_loss: 5.8772e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2782/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9037e-04 - val_loss: 5.5892e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2783/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9225e-04 - val_loss: 6.3169e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2784/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9097e-04 - val_loss: 5.4179e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2785/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9064e-04 - val_loss: 4.5968e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2786/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9222e-04 - val_loss: 5.6086e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2787/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9117e-04 - val_loss: 6.1683e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2788/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8985e-04 - val_loss: 4.7962e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2789/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9015e-04 - val_loss: 5.5141e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2790/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9109e-04 - val_loss: 5.4150e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2791/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8898e-04 - val_loss: 7.1955e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2792/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8928e-04 - val_loss: 6.1262e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2793/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9118e-04 - val_loss: 5.4333e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2794/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8910e-04 - val_loss: 5.0413e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2795/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9115e-04 - val_loss: 5.3487e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2796/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9225e-04 - val_loss: 6.0364e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2797/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9183e-04 - val_loss: 5.6449e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2798/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9418e-04 - val_loss: 5.5933e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2799/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.8972e-04 - val_loss: 5.5355e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2800/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9033e-04 - val_loss: 6.1981e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2801/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9211e-04 - val_loss: 5.2600e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2802/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9093e-04 - val_loss: 6.1492e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2803/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8867e-04 - val_loss: 4.4820e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2804/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8892e-04 - val_loss: 5.2405e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2805/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9234e-04 - val_loss: 5.7893e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2806/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9235e-04 - val_loss: 5.5370e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2807/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.8939e-04 - val_loss: 6.0072e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2808/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.8829e-04 - val_loss: 4.3522e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2809/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9000e-04 - val_loss: 6.0861e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2810/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9115e-04 - val_loss: 6.4533e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2811/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8837e-04 - val_loss: 6.4024e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2812/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9044e-04 - val_loss: 5.1505e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2813/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9048e-04 - val_loss: 6.0617e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2814/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8823e-04 - val_loss: 5.1499e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2815/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9013e-04 - val_loss: 5.4676e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2816/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8914e-04 - val_loss: 5.6942e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2817/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9191e-04 - val_loss: 6.6056e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2818/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9043e-04 - val_loss: 5.5592e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2819/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9028e-04 - val_loss: 6.6223e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2820/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9049e-04 - val_loss: 7.3151e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2821/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8802e-04 - val_loss: 5.2967e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2822/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8922e-04 - val_loss: 5.8098e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2823/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8990e-04 - val_loss: 6.6964e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2824/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.8869e-04 - val_loss: 6.1530e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2825/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9100e-04 - val_loss: 6.2277e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2826/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9020e-04 - val_loss: 7.4889e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2827/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8841e-04 - val_loss: 5.8256e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2828/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8833e-04 - val_loss: 5.5561e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2829/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8878e-04 - val_loss: 5.1138e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2830/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9207e-04 - val_loss: 4.7109e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2831/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9173e-04 - val_loss: 6.0412e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2832/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.8874e-04 - val_loss: 5.2268e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2833/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8815e-04 - val_loss: 5.1305e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2834/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9100e-04 - val_loss: 5.1358e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2835/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.8918e-04 - val_loss: 6.3690e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2836/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.8883e-04 - val_loss: 5.8098e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2837/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.8878e-04 - val_loss: 4.5624e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2838/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8779e-04 - val_loss: 5.8037e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2839/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8610e-04 - val_loss: 6.4728e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2840/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8891e-04 - val_loss: 5.1157e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2841/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.8787e-04 - val_loss: 4.9771e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2842/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.8986e-04 - val_loss: 4.8574e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2843/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8957e-04 - val_loss: 6.3986e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2844/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8946e-04 - val_loss: 5.0416e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2845/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8901e-04 - val_loss: 5.7808e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2846/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.9018e-04 - val_loss: 6.4836e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2847/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8734e-04 - val_loss: 6.0864e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2848/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.8765e-04 - val_loss: 6.0647e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2849/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8871e-04 - val_loss: 4.5625e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2850/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.8762e-04 - val_loss: 5.2751e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2851/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8869e-04 - val_loss: 5.8758e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2852/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8977e-04 - val_loss: 6.0861e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2853/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8899e-04 - val_loss: 6.8574e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2854/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8854e-04 - val_loss: 6.8224e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2855/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8964e-04 - val_loss: 6.2559e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2856/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8732e-04 - val_loss: 5.6278e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2857/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8916e-04 - val_loss: 5.2396e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2858/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8789e-04 - val_loss: 4.5024e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2859/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8740e-04 - val_loss: 5.8224e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2860/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8893e-04 - val_loss: 5.4393e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2861/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8573e-04 - val_loss: 5.8204e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2862/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8759e-04 - val_loss: 6.1742e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2863/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9049e-04 - val_loss: 5.8380e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2864/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8757e-04 - val_loss: 5.8890e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2865/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.8784e-04 - val_loss: 6.3288e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2866/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8478e-04 - val_loss: 5.2908e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2867/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8982e-04 - val_loss: 5.0611e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2868/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.8699e-04 - val_loss: 5.0634e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2869/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8748e-04 - val_loss: 6.1922e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2870/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8813e-04 - val_loss: 4.4397e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2871/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.9026e-04 - val_loss: 5.5199e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2872/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8905e-04 - val_loss: 5.1466e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2873/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8867e-04 - val_loss: 6.8886e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2874/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8526e-04 - val_loss: 5.7635e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2875/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8972e-04 - val_loss: 6.3341e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2876/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8739e-04 - val_loss: 6.5604e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2877/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8814e-04 - val_loss: 6.0630e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2878/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8946e-04 - val_loss: 5.0226e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2879/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8849e-04 - val_loss: 3.9837e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2880/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8939e-04 - val_loss: 5.6806e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2881/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8715e-04 - val_loss: 7.2811e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2882/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8822e-04 - val_loss: 5.8180e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2883/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8438e-04 - val_loss: 5.7258e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2884/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8548e-04 - val_loss: 5.8860e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2885/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8343e-04 - val_loss: 5.7328e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2886/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8486e-04 - val_loss: 4.5377e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2887/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8688e-04 - val_loss: 5.7099e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2888/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8665e-04 - val_loss: 6.2459e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2889/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8844e-04 - val_loss: 6.1202e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2890/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8449e-04 - val_loss: 5.8709e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2891/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8339e-04 - val_loss: 4.9260e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2892/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8731e-04 - val_loss: 5.6375e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2893/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8783e-04 - val_loss: 6.4736e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2894/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8572e-04 - val_loss: 5.7776e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2895/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8550e-04 - val_loss: 4.9177e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2896/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8443e-04 - val_loss: 5.2419e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2897/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8704e-04 - val_loss: 5.3936e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2898/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8773e-04 - val_loss: 4.7973e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2899/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8707e-04 - val_loss: 5.0300e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2900/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8724e-04 - val_loss: 5.3196e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2901/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8931e-04 - val_loss: 6.1928e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2902/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 1.8766e-04 - val_loss: 6.1967e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2903/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 1.8629e-04 - val_loss: 5.4057e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2904/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8603e-04 - val_loss: 4.9192e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2905/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8564e-04 - val_loss: 4.9817e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2906/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8508e-04 - val_loss: 6.2088e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2907/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8643e-04 - val_loss: 5.4208e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2908/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8670e-04 - val_loss: 4.5416e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2909/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8716e-04 - val_loss: 5.5824e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2910/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8669e-04 - val_loss: 5.9310e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2911/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8727e-04 - val_loss: 4.2704e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2912/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8730e-04 - val_loss: 7.5684e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2913/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8561e-04 - val_loss: 4.9027e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2914/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8494e-04 - val_loss: 6.2659e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2915/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8464e-04 - val_loss: 6.0153e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2916/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8559e-04 - val_loss: 5.3407e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2917/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8542e-04 - val_loss: 4.8905e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2918/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.8840e-04 - val_loss: 6.5039e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2919/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8537e-04 - val_loss: 5.5042e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2920/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8602e-04 - val_loss: 5.0763e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2921/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8525e-04 - val_loss: 5.4300e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2922/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8745e-04 - val_loss: 5.5318e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2923/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.8558e-04 - val_loss: 5.9660e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2924/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.8454e-04 - val_loss: 6.8909e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2925/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8638e-04 - val_loss: 4.5340e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2926/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.8440e-04 - val_loss: 6.3819e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2927/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.8620e-04 - val_loss: 5.2181e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2928/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8377e-04 - val_loss: 5.7380e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2929/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8712e-04 - val_loss: 4.8333e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2930/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8680e-04 - val_loss: 5.4339e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2931/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8501e-04 - val_loss: 5.9994e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2932/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8678e-04 - val_loss: 4.9187e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2933/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8627e-04 - val_loss: 4.3082e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2934/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8650e-04 - val_loss: 5.9027e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2935/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8406e-04 - val_loss: 5.3651e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2936/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8349e-04 - val_loss: 6.0409e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2937/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8384e-04 - val_loss: 5.2548e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2938/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.8643e-04 - val_loss: 5.4021e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2939/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8444e-04 - val_loss: 5.0097e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2940/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8466e-04 - val_loss: 4.9867e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2941/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8552e-04 - val_loss: 4.8505e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2942/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8745e-04 - val_loss: 5.7692e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2943/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8640e-04 - val_loss: 5.1017e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2944/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.8471e-04 - val_loss: 5.5722e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2945/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8298e-04 - val_loss: 6.2168e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2946/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8337e-04 - val_loss: 5.4561e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2947/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8359e-04 - val_loss: 5.3127e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2948/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.8640e-04 - val_loss: 4.8483e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2949/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.8599e-04 - val_loss: 4.9082e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2950/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8326e-04 - val_loss: 4.5264e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2951/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 1.8537e-04 - val_loss: 5.5576e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2952/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8291e-04 - val_loss: 5.2515e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2953/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8705e-04 - val_loss: 4.9584e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2954/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8500e-04 - val_loss: 4.9910e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2955/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8405e-04 - val_loss: 5.5480e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2956/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8219e-04 - val_loss: 6.6007e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2957/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8555e-04 - val_loss: 5.8160e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2958/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8411e-04 - val_loss: 4.1291e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2959/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8339e-04 - val_loss: 4.9218e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2960/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8158e-04 - val_loss: 6.8231e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2961/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8385e-04 - val_loss: 5.5644e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2962/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8349e-04 - val_loss: 5.1463e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2963/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8399e-04 - val_loss: 7.2663e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2964/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8450e-04 - val_loss: 6.1024e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2965/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8428e-04 - val_loss: 5.7810e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2966/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8358e-04 - val_loss: 5.2570e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2967/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8200e-04 - val_loss: 6.9629e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2968/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8279e-04 - val_loss: 5.4166e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2969/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8285e-04 - val_loss: 5.4028e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2970/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8299e-04 - val_loss: 6.5415e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2971/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8148e-04 - val_loss: 6.2219e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2972/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8197e-04 - val_loss: 4.5640e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2973/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 1.8456e-04 - val_loss: 6.5290e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2974/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8166e-04 - val_loss: 5.8872e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2975/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8261e-04 - val_loss: 5.8888e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2976/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8189e-04 - val_loss: 6.0122e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2977/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 1.8296e-04 - val_loss: 4.7676e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2978/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8295e-04 - val_loss: 4.6127e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2979/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8427e-04 - val_loss: 6.5587e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2980/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8150e-04 - val_loss: 5.0279e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2981/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8319e-04 - val_loss: 6.1585e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2982/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8338e-04 - val_loss: 5.7620e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2983/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8170e-04 - val_loss: 6.2733e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2984/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8193e-04 - val_loss: 4.5456e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2985/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8377e-04 - val_loss: 6.8066e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2986/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8320e-04 - val_loss: 5.2353e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2987/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 1.8391e-04 - val_loss: 5.0966e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2988/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8512e-04 - val_loss: 6.0177e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2989/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.7921e-04 - val_loss: 5.6489e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2990/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8154e-04 - val_loss: 6.9735e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2991/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8306e-04 - val_loss: 4.9820e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2992/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 1.8327e-04 - val_loss: 6.9599e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2993/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8347e-04 - val_loss: 4.4868e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2994/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8298e-04 - val_loss: 5.7591e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2995/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8130e-04 - val_loss: 5.4437e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2996/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8032e-04 - val_loss: 4.7877e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2997/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8198e-04 - val_loss: 4.7033e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2998/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8267e-04 - val_loss: 4.3537e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 2999/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8446e-04 - val_loss: 5.5998e-04 - learning_rate: 7.0000e-06\n",
      "Epoch 3000/3000\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 1.8131e-04 - val_loss: 6.3867e-04 - learning_rate: 7.0000e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model with the custom callback\n",
    "history = model_builder.train_model(\n",
    "    train_dataset, \n",
    "    val_dataset, \n",
    "    epochs=3000,\n",
    "    callbacks_list=[lr_scheduler]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Extract the losses from the history object\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "train_loss_x_midpoints = history.history.get('x_midpoints_reshape_loss', train_loss)\n",
    "val_loss_x_midpoints = history.history.get('val_x_midpoints_reshape_loss', val_loss)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2,1)\n",
    "plt.plot(train_loss_x_midpoints, label='Train Loss x_midpoints_reshape')\n",
    "plt.plot(val_loss_x_midpoints, label='Validation Loss x_midpoints_reshape')\n",
    "plt.xlabel('Epochs')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss ')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder.model.save(\"/home/da886/Analysis/33KFixed_Mixed_5_32by32_95index-reg1.keras\")\n",
    "# loaded_model = tf.keras.models.load_model(\n",
    "# \"/home/da886/Analysis/30KFixed_13_SparsespotsrandomSPOTS.keras\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Processing batch 2, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Processing batch 3, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Processing batch 4, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Processing batch 5, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Processing batch 6, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Processing batch 7, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Processing batch 8, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Processing batch 9, batch shape: (200, 32, 32)\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 158ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1729705648.297036 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.297477 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.297788 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.298097 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.298375 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.298662 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.298949 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.299220 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.299340 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.299594 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.299868 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.300045 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.300168 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.300560 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.300732 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.300822 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.301134 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.301414 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.301473 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.301776 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.302043 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.302115 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.302291 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.302704 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.302888 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.302988 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.303177 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.303629 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.303672 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.303882 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.304287 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.304329 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.304595 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.304845 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.304873 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.305186 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.305538 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.305564 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.305808 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.306158 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.306361 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.306492 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.306765 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.307055 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.307100 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.307275 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.307556 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.307815 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.308008 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.308138 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.308317 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.308635 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.308958 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.309023 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.309251 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.309580 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.309720 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.309862 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.310174 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.310484 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.310719 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.310874 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.311186 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.311321 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.311640 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.311776 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.312099 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.312212 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.312909 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.312924 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.313432 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.313528 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.324893 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.325273 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.325571 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.325851 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.326137 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.326402 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.326667 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.326940 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.327216 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.327490 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.327751 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.328022 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.328288 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.328575 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.328626 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.328953 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.329114 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.329174 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.329489 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.329829 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.329895 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.330129 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.330565 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.330623 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.330708 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.331111 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.331295 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.331385 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.331675 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.331951 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.332007 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.332266 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.332548 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.332600 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.332863 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.333141 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.333190 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.333457 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.333766 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.333797 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.334057 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.334394 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.334433 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.334663 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.335014 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.335172 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.335177 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.335560 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.335871 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.335886 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.336149 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.336557 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.336713 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.336879 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.337015 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.337327 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.337679 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.337995 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.338114 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.338414 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.338614 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.338837 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.339117 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.339249 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.339492 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.339718 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.339924 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.340132 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.340353 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.340622 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.340775 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.340999 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.341325 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.341436 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.342044 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.342064 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.342553 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.342671 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.343230 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.343256 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.343637 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.349921 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.350285 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.350572 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.350844 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.351107 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.351368 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.351636 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.351902 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.352177 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.352447 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.352713 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.352975 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.353248 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.353537 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.353818 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.354111 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.354378 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.354609 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.354844 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.355076 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.355309 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.355553 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.355636 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.355875 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.355975 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.356146 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.356493 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.356617 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.356780 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.357225 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.357266 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.357506 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.357761 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.357837 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.358009 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.358385 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.358508 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.358656 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.358878 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.359113 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.359349 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.359538 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.359741 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.360018 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.360159 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.360391 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.360663 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.360810 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.361083 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.361234 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.361499 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.361667 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.361941 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.362065 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.362361 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.362485 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.362791 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.362927 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.363235 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.363351 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.363657 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.363816 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.364076 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.364206 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.364517 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.364670 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.364674 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.365125 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.365233 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.365336 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.365668 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.365780 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.365872 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.366212 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.366349 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.366429 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.366767 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.366883 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.366945 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.367392 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.367512 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.367568 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.368037 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.368049 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.368081 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.368397 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.368687 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.368764 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.368856 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.369363 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.369441 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.369666 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.369919 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.370300 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.370538 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.370780 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.371030 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.371272 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.371528 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.371775 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.372023 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.372287 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.372557 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.372861 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.373145 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.373438 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.373867 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.374281 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.375004 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.375386 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.375624 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.375845 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.376075 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.376301 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.376533 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.376767 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.376995 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.377229 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.377460 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.377710 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.377769 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.378000 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.378252 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.378378 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.378625 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.378748 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.378982 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.379112 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.379341 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.379523 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.379716 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.379901 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.380017 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.380215 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.380453 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.380625 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.380729 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.380772 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.381069 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.381194 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.381307 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.381747 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.381759 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.381943 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.382324 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.382355 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.382443 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.382886 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.382908 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.382931 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.383360 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.383506 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.383588 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.383767 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.383913 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.384363 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.384376 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.384556 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.384772 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.385020 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.385042 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.385183 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.385421 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.385561 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.385800 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.386009 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.386276 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.386413 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.386646 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.386785 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.386953 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.387152 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.387383 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.387528 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.387691 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.387894 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.388043 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.388417 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.388436 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.388678 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.388911 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.389058 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.389321 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.389593 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.390044 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.390364 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.390662 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.391255 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.391621 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.391931 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.392012 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.392241 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.392466 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.392693 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.392925 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.393157 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.393382 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.393629 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.393986 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.394227 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.394477 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.394726 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.394964 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.395222 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.395394 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.395474 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.395802 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.395919 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.396145 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.396341 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.396462 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.396733 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.396827 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.397043 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.397288 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.397468 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.397571 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.397969 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.397980 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.398300 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.398490 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.398600 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.398846 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.399025 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.399075 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.399354 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.399619 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.399659 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.399853 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.399994 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.400336 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.400594 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.400653 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.400854 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.401011 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.401311 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.401526 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.401585 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.401703 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.401922 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.402169 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.402306 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.402552 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.402694 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.402928 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.403068 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.403317 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.403545 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.403848 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.403959 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.404142 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.404345 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.404508 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.404714 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.404877 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.405073 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.405235 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.405629 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.405748 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.405942 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.406345 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.406458 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.406663 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.406990 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.407330 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.407992 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.408735 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.408926 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.409083 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.409331 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.409575 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.409957 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.410027 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.410230 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.410478 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.410737 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.411003 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.411255 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.411506 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.411768 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.412020 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.412301 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.412605 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.412885 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.413191 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.413191 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.413740 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.413774 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.414156 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.414338 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.414444 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.414888 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.414903 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.415278 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.415456 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.415565 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.416034 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.416054 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.416317 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.416659 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.416852 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.416959 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.417217 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.417467 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.417958 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.417968 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.418281 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.418288 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.418774 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.418840 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.419008 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.419261 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.419270 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.419685 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.419703 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.420114 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.420127 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.420549 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.420562 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.420989 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.421006 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.421361 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.421516 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.421684 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.421961 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.422331 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.422448 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.422754 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.423150 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.423275 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.423476 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.423771 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.424198 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.424313 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.424529 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.424848 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.425191 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.425874 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.426304 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.427392 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.427745 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.428103 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.428366 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.428630 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.428922 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.429211 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.429482 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.429759 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.430029 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.430310 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.430609 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.430912 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.431206 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.431633 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.431928 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.432245 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.432562 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.432859 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.432883 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.433299 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.433401 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.433703 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.433903 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.434012 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.434285 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.434738 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.434833 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.435038 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.435518 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.435529 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.435799 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.436071 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.436244 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.436395 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.436818 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.436832 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.437387 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.437420 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.437433 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.437885 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.437904 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.438400 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.438409 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.438883 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.438897 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.439340 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.439359 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.439807 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.439821 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.440265 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.440283 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.440736 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.440755 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.441232 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.441250 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.441552 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.441979 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.442106 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.442374 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.442583 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.442778 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.443146 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.443540 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.443922 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.444270 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.444544 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.444959 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.445433 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.445938 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.447087 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.448200 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.449958 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.450314 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.450609 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.450935 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.451352 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.451723 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.452036 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.452333 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.452804 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.453347 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.453888 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.454474 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.455047 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.456076 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.456931 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.457393 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.457489 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.457591 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.457741 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.458024 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.458167 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.458449 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.458592 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.458865 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.459017 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.459293 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.459438 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.459709 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.459848 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.460029 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.460462 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.460484 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.460732 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.461013 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.461300 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.461319 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.461565 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.461846 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.461985 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.462272 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.462348 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.462815 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.462854 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.463030 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.463204 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.463666 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.463716 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.463830 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.464022 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.464317 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.464986 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.464995 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.465102 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.465326 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.465634 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.465993 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.466595 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.466629 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.466702 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.467014 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.467400 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.467782 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.468221 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.468369 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.468759 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.468829 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.469046 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.469424 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.469446 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.469769 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.470229 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.470241 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.470340 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.470662 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.470771 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.471023 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.471291 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.471638 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.471686 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.471906 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.472018 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.472324 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.472443 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.472768 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.473108 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.473363 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.473474 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.473886 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.473906 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.474330 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.474434 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.474689 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.474972 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.475083 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.475447 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.475561 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.475935 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.476056 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.476435 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.476548 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.477017 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.477038 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.477539 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.477641 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.477939 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.478122 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.478390 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.478692 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.478965 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.479101 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.479512 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.479597 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.479781 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.479886 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.480188 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.480309 1798410 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.480490 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.480873 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.480995 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.481171 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.481661 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.482364 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.482874 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.483465 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.484042 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.485018 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.486274 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.487907 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.487904 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.488277 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.488402 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.488672 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.488867 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.489062 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.489183 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.489400 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.489651 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.489849 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.490052 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.490148 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.490440 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.490552 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.490816 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.490922 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.491440 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.491451 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.491750 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.492189 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.492200 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.492636 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.492741 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.492990 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.493470 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.493567 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.493995 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.494105 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.494372 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.494736 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.495301 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.495312 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.495747 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.496219 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.496566 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.497358 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1729705648.498147 1798454 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.498251 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.498506 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.498763 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.499013 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.499282 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.499777 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.500049 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.500324 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.500605 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.500917 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.501216 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.501502 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.501834 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.502190 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.502556 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.502906 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.503259 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.503621 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.504023 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.504455 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.504916 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.506032 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729705648.506732 1798438 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the function for visualizing midpoints\n",
    "def visualize_midpoints(image, midpoints, title=\"Predicted Midpoint Visualization\"):\n",
    "    \"\"\"\n",
    "    Visualizes midpoints on an image without using a probability vector.\n",
    "\n",
    "    Parameters:\n",
    "    - image: A 3D tensor representing the image.\n",
    "    - midpoints: A 2D tensor representing the midpoint coordinates (x, y).\n",
    "    - title: The title of the plot.\n",
    "\n",
    "    Returns:\n",
    "    None (displays the image with midpoints).\n",
    "    \"\"\"\n",
    "    # Convert to NumPy arrays for easier handling\n",
    "    image_np = image\n",
    "    midpoints_np = midpoints\n",
    "\n",
    "    # Denormalize image if necessary (adjust based on your normalization method)\n",
    "    denormalized_image = image_np  # Modify if normalization was applied during training\n",
    "\n",
    "    # Visualize the image\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(denormalized_image, cmap='gray')\n",
    "    plt.title(title)\n",
    "\n",
    "    # Plot midpoints directly, only if they are not (0, 0)\n",
    "    for i, (x, y) in enumerate(midpoints_np):\n",
    "        if x >= 0 and y >= 0:  # Only plot if the point is not (0, 0)\n",
    "            plt.scatter(x, y, color='red', s=5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Create the validation dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n",
    "val_dataset = val_dataset.batch(800)\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "# train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)\n",
    "# # Initialize lists to collect the data\n",
    "all_images = []\n",
    "all_true_midpoints = []\n",
    "all_pred_midpoints = []\n",
    "\n",
    "# # Loop through each batch in the validation dataset, predict, and collect results\n",
    "for i, (data_batch, midpoints_batch) in enumerate(val_dataset):\n",
    "\n",
    "# for i, (data_batch, midpoints_batch) in enumerate(train_dataset):\n",
    "    print(f\"Processing batch {i + 1}, batch shape: {data_batch.shape}\")\n",
    "    \n",
    "    # Get the model predictions\n",
    "    predictions =model_builder.model.predict(data_batch)\n",
    "\n",
    "    # Extend the lists to store data from each batch\n",
    "    all_images.extend(data_batch.numpy())  # Store all images\n",
    "    all_true_midpoints.extend(midpoints_batch.numpy())  # Store all true midpoints\n",
    "    all_pred_midpoints.extend(predictions)  # Store all predicted midpoints\n",
    "\n",
    "# Convert lists to arrays for easier indexing\n",
    "all_images = np.array(all_images)\n",
    "all_true_midpoints = np.array(all_true_midpoints)\n",
    "all_pred_midpoints = np.array(all_pred_midpoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "# train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6600, 32, 32), (6600, 1, 5, 2), (6600, 1, 5, 2))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images.shape,all_pred_midpoints.shape,all_true_midpoints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWMAAAF2CAYAAAC72fnJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAuaElEQVR4nO3df1RVZb4/8PcB4YAcOIj8TiT8nam0YpIYzSxJQMfRzDU5NV30WpoD5I+aJmsKNe/QWN/UzB9z76yra+b6o2s3ddWYpiY0NuhNkuXojFwlTLsKGjfOAUR+HJ7vH+qpI7+egw9nPwfer7X2CvZ+zt6fs/fh0/Y5z2c/JiGEABERGcrH6ACIiIjJmIhIC0zGREQaYDImItIAkzERkQaYjImINMBkTESkASZjIiINMBkTEWmAyZg67c4778SsWbOcv+fn58NkMiE/P9+wmG51a4yqzZo1C3feeWeH7c6dOweTyYTNmzd3WSxA179f6jpMxl5q8+bNMJlMziUgIABDhgxBdnY2KioqjA7PLXv27MHSpUsNjeHmeXz66adb3f7KK68423z77bcejs4z1q9f3+X/s6C29TI6ALo9y5cvR0JCAq5du4bDhw9jw4YN2LNnD06ePInevXt7NJZx48ahrq4O/v7+br1uz549WLduneEJOSAgAP/1X/+F9evXt3gP27ZtQ0BAAK5du+ay/t/+7d/Q3NzsyTDbVVJSAh+fzt1jrV+/HuHh4byzNgjvjL1cRkYGfvGLX+Dpp5/G5s2bsXDhQpSVlWH37t1tvqa2trZLYvHx8UFAQECnk4HR0tPTYbfb8fHHH7us/+tf/4qysjJMnjy5xWv8/PxgNps9FWKHzGYz/Pz8jA6DOsE7/2qoTQ8//DAAoKysDMD1Pk2LxYLS0lJMmjQJwcHBePLJJwEAzc3NWL16Ne6++24EBAQgKioK8+bNw3fffeeyTyEEVqxYgX79+qF379546KGHcOrUqRbHbqvP+OjRo5g0aRL69OmDoKAgjBo1CmvWrHHGt27dOgBw6Xa5SXWM7bnjjjswbtw4bN261WX9li1bMHLkSIwYMaLFa1rrM66qqsKsWbNgtVoRGhqKzMxMVFVVtfpai8WCr776CmlpaQgKCkJsbCyWL1+OWx+mWFtbi+effx5xcXEwm80YOnQo3nrrrRbtbu0zvtmd9fnnn2Px4sWIiIhAUFAQHn30UVy5csXldadOnUJBQYHzGowfPx4A0NjYiGXLlmHw4MEICAhA3759MXbsWOzfv1/irJIsdlN0M6WlpQCAvn37Otc1NTUhLS0NY8eOxVtvveXsvpg3bx42b96M2bNn47nnnkNZWRneffddHD9+HJ9//rnzDuu1117DihUrMGnSJEyaNAlffvklJk6ciIaGhg7j2b9/P37yk58gJiYGCxYsQHR0NP7xj3/go48+woIFCzBv3jxcvHgR+/fvx5/+9KcWr/dEjD/0xBNPYMGCBaipqYHFYkFTUxN27NiBxYsXt+iiaI0QAlOnTsXhw4fx7LPP4q677sLOnTuRmZnZanuHw4H09HTcf//9WLlyJfbu3Yvc3Fw0NTVh+fLlzn3+9Kc/xaFDhzBnzhzcc8892LdvH371q1/hf//3f7Fq1aoO48rJyUGfPn2Qm5uLc+fOYfXq1cjOzsZ7770HAFi9ejVycnJgsVjwyiuvAACioqIAAEuXLkVeXh6efvppjB49Gna7HceOHcOXX36JRx55ROq8kgRBXmnTpk0CgDhw4IC4cuWKuHDhgti+fbvo27evCAwMFN98840QQojMzEwBQLz00ksur//LX/4iAIgtW7a4rN+7d6/L+suXLwt/f38xefJk0dzc7Gz38ssvCwAiMzPTue7QoUMCgDh06JAQQoimpiaRkJAg4uPjxXfffedynB/uKysrS7T2UeyKGNsCQGRlZYn/+7//E/7+/uJPf/qTEEKIP//5z8JkMolz586J3NxcAUBcuXLF+brMzEwRHx/v/H3Xrl0CgFi5cqVzXVNTk3jggQcEALFp0yaX1wIQOTk5Ludl8uTJwt/f33mcm/tcsWKFS8wzZswQJpNJnD171rkuPj7e5f3e/Jykpqa6nJtFixYJX19fUVVV5Vx39913iwcffLDFuUlMTBSTJ0/u4AzS7WI3hZdLTU1FREQE4uLiMHPmTFgsFuzcuRN33HGHS7v58+e7/L5jxw5YrVY88sgj+Pbbb51LUlISLBYLDh06BAA4cOAAGhoakJOT49J9sHDhwg5jO378OMrKyrBw4UKEhoa6bPvhvtriiRhv1adPH6Snp2Pbtm0AgK1bt+LHP/4x4uPjpV6/Z88e9OrVy+V8+/r6Iicnp83XZGdnO382mUzIzs5GQ0MDDhw44Nynr68vnnvuOZfXPf/88xBCtOjjbs3cuXNdzs0DDzwAh8OBr7/+usPXhoaG4tSpUzhz5kyHbanz2E3h5datW4chQ4agV69eiIqKwtChQ1t8gdarVy/069fPZd2ZM2dgs9kQGRnZ6n4vX74MAM4/1sGDB7tsj4iIQJ8+fdqN7WaXSWt9rTI8EWNrnnjiCTz11FM4f/48du3ahZUrV0q/9uuvv0ZMTAwsFovL+qFDh7ba3sfHBwMGDHBZN2TIEADXxybf3GdsbCyCg4Nd2t11113O7R3p37+/y+83z8utfe+tWb58OaZOnYohQ4ZgxIgRSE9Px1NPPYVRo0Z1+FqSx2Ts5UaPHo0f/ehH7bYxm80tEnRzczMiIyOxZcuWVl8TERGhLMbOMirGn/70pzCbzcjMzER9fT1+9rOfdclxPMnX17fV9UJi1rVx48ahtLQUu3fvxieffII//OEPWLVqFTZu3NjmuGxyH5NxDzVw4EAcOHAAY8aMQWBgYJvtbv7z/MyZMy53cFeuXOnwrmrgwIEAgJMnTyI1NbXNdm11WXgixtYEBgZi2rRp+I//+A9kZGQgPDxc+rXx8fE4ePCg8wvAm0pKSlpt39zcjK+++sp5NwwA//M//wMAzlEa8fHxOHDgAKqrq13ujk+fPu3crkJ7XUdhYWGYPXs2Zs+ejZqaGowbNw5Lly5lMlaIfcY91M9+9jM4HA68/vrrLbY1NTU5h2KlpqbCz88Pa9eudbmLWr16dYfHuPfee5GQkIDVq1e3GNr1w30FBQUBQIs2noixLS+88AJyc3Px6quvuvW6SZMmoampCRs2bHCuczgcWLt2bZuveffdd50/CyHw7rvvws/PDxMmTHDu0+FwuLQDgFWrVsFkMiEjI8OtGNsSFBTU6hC8yspKl98tFgsGDRqE+vp6Jcel63hn3EM9+OCDmDdvHvLy8lBcXIyJEyfCz88PZ86cwY4dO7BmzRrMmDEDEREReOGFF5CXl4ef/OQnmDRpEo4fP46PP/64wztGHx8fbNiwAVOmTME999yD2bNnIyYmBqdPn8apU6ewb98+AEBSUhIA4LnnnkNaWhp8fX0xc+ZMj8TYlsTERCQmJrr9uilTpmDMmDF46aWXcO7cOQwfPhwffPABbDZbq+0DAgKwd+9eZGZmIjk5GR9//DH+/Oc/4+WXX3Z2w0yZMgUPPfQQXnnlFZw7dw6JiYn45JNPsHv3bixcuND5L5DblZSUhA0bNmDFihUYNGgQIiMj8fDDD2P48OEYP348kpKSEBYWhmPHjuH99993+eKRFDByKAd13s0hS1988UW77TIzM0VQUFCb2//1X/9VJCUlicDAQBEcHCxGjhwpXnzxRXHx4kVnG4fDIZYtWyZiYmJEYGCgGD9+vDh58mSLYVS3Dm276fDhw+KRRx4RwcHBIigoSIwaNUqsXbvWub2pqUnk5OSIiIgIYTKZWgxzUxljW3BjaFt7ZIa2CSFEZWWleOqpp0RISIiwWq3iqaeeEsePH291aFtQUJAoLS0VEydOFL179xZRUVEiNzdXOBwOl31WV1eLRYsWidjYWOHn5ycGDx4s3nzzTZfhakK0PbTt1s9Ja9eqvLxcTJ48WQQHBwsAzmFuK1asEKNHjxahoaEiMDBQDBs2TPzLv/yLaGhoaPd8kXtMQkj04BORcrNmzcL777+Pmpoao0MhDbDPmIhIA0zGREQaYDImItIA+4yJiDTAO2MiIg0wGRMRaUC7oo/m5mZcvHgRwcHBUk/2IiLSlRAC1dXViI2N7XAGHO2S8cWLFxEXF2d0GEREyly4cKHFkxNv1WXJeN26dXjzzTdRXl6OxMRErF27FqNHj+7wdbc+JlAnbT356layE1Qa8d2pzGShjY2NUvsyIn6Zfy3xO2lXsp9bGQ6HQ9m+AgICpNrJzLAiOwmuuzO/qCKT17qkz/i9997D4sWLkZubiy+//BKJiYlIS0tzPn+2PTp3TfxwjjYVi7e/B13jJ1e6XnOVx9T5M3szvo50STJ+++238cwzz2D27NkYPnw4Nm7ciN69e+Pf//3fu+JwREReT3kybmhoQFFRkcvza318fJCamorCwsIW7evr62G3210WIqKeRnky/vbbb+FwOJwzy94UFRWF8vLyFu3z8vJgtVqdC7+8I6KeyPBxxkuWLIHNZnMuFy5cMDokIiKPUz6aIjw8HL6+vqioqHBZX1FRgejo6BbtzWYzzGaz6jCIiLyK8jtjf39/JCUl4eDBg851zc3NOHjwIFJSUlQfjoioW+iSccaLFy9GZmYmfvSjH2H06NFYvXo1amtrMXv27K44HBGR1+uSZPz444/jypUreO2111BeXo577rkHe/fubfGlnifIdoHIDGZvamq63XDcJhu/7OSQMu3am4n5h2SKW2TjUv0+PX3MXr3k/pSM+AwZccyOSn8BoK6uTtnxdP6cydLuEZp2ux1Wq1XZ/piM3cdk7P4xdU7GRpBJxrKVqioZlYxtNhtCQkLabWP4aAoiImIyJiLSApMxEZEGmIyJiDTAZExEpAEmYyIiDTAZExFpQLtpl9whM7ZT5XhBi8Ui1a6mpkbZMWWpHOeqcjC+LCMG2as8JscPu/L0GGLZuGSvuRHjpHlnTESkASZjIiINMBkTEWmAyZiISANMxkREGmAyJiLSAJMxEZEGmIyJiDTAZExEpAGvrsBTWfUkU3EjW1knO1OGTKWb6so0mdhkjylTgaR6BgwjKqNk3oPOFXgqz5nKcyv72ZA5puprLrM/mfMqhIDsZEq8MyYi0gCTMRGRBpiMiYg0wGRMRKQBJmMiIg0wGRMRaYDJmIhIA0zGREQa8OqiD5VkBnmrLOYA5Aa9BwcHS+3ru+++k2qnckolmUHvqoshPD2dDyD3HlQXt6hkxDmT+Wz4+vpK7UvXghpOu0RE1A0xGRMRaYDJmIhIA0zGREQaYDImItIAkzERkQaYjImINMBkTESkASZjIiINdPsKPJlKINl2KqvXALnKItnKOpVT2MieMyMqo8xmc4dtVE9VJUPXKjFA/nrKkDn/gOenFFP5HgGDqhZV73Dp0qUwmUwuy7Bhw1QfhoioW+mSO+O7774bBw4c+P4gkndtREQ9VZdkyV69eiE6Orordk1E1C11yRd4Z86cQWxsLAYMGIAnn3wS58+fb7NtfX097Ha7y0JE1NMoT8bJycnYvHkz9u7diw0bNqCsrAwPPPAAqqurW22fl5cHq9XqXOLi4lSHRESkPZMQQnTlAaqqqhAfH4+3334bc+bMabG9vr7e5VtVu92uNCGrHE2h8zfmHE3xPSNGU+hM19EUKuk+msJmsyEkJKTdNl3+zVpoaCiGDBmCs2fPtrrdbDZLX2Aiou6qy4s+ampqUFpaipiYmK4+FBGR11KejF944QUUFBTg3Llz+Otf/4pHH30Uvr6++PnPf676UERE3YbybopvvvkGP//5z1FZWYmIiAiMHTsWR44cQUREhOpDSZHt+1HZR6R6rjwZsv233t7n2tjY2GEbneejU8lisUi1q6mpUXZMT8+hCMj9beo6z58QArJfyylPxtu3b1e9SyKibo8PCiIi0gCTMRGRBpiMiYg0wGRMRKQBJmMiIg0wGRMRaYDJmIhIA9o+9f3mLCHtMWKgt4y2nsNxqzvuuKPDNqoLGHQu6JCh8pqrPLeyz1dRef5VFnPI8vZCDVky19PhcHTYRggh1Q7gnTERkRaYjImINMBkTESkASZjIiINMBkTEWmAydhTmppgWbUKYTNnwrJqFeDlj28kIrW0HdrW3VjWrkXw//t/MAkB8+HDRodDRJrhnbGH+B89CtONh0ybhID/0aMGR0REOmEy9pCG5GSIG0UswmRCQ3KywRERkU5MQnZOEA+x2+2wWq1SbWWqgVRW+dzONDe+AF4GMBbAYQC/BSBXl+N5KqusVFemefu0UTKMmLZL5TVXTaZS0ogptNyZdslmsyEkJKTdtuwz9hAHgNeNDoKItMVuCiIiDTAZExFpgMmYiEgDTMZERBpgMiYi0gCTMRGRBpiMiYg0wGRMRKQBbYs+PD0HnkyVj+ycYyqrzmQro2TJ7E+2mklmXzpXw6meX1AV2c+1yko9nSvwZM6/EfHL/J0LIXDt2jWp/fHOmIhIA0zGREQaYDImItIAkzERkQaYjImINMBkTESkASZjIiINMBkTEWlA26KPm9OVeIrMwHLZaZeuXr0q1U7X6WRkqRxALztov7GxscM2uhZzyJJ5j4D8+Zf53MoWNMny9JRosvuS/Wz4+vp22EbltFdAJ+6MP/vsM0yZMgWxsbEwmUzYtWuXy3YhBF577TXExMQgMDAQqampOHPmjKp4iYi6JbeTcW1tLRITE7Fu3bpWt69cuRLvvPMONm7ciKNHjyIoKAhpaWnSJYFERD2R290UGRkZyMjIaHWbEAKrV6/Gb37zG0ydOhUA8Mc//hFRUVHYtWsXZs6ceXvREhF1U0q/wCsrK0N5eTlSU1Od66xWK5KTk1FYWNjqa+rr62G3210WIqKeRmkyLi8vBwBERUW5rI+KinJuu1VeXh6sVqtziYuLUxkSEZFXMHxo25IlS2Cz2ZzLhQsXjA6JiMjjlCbj6OhoAEBFRYXL+oqKCue2W5nNZoSEhLgsREQ9jdJknJCQgOjoaBw8eNC5zm634+jRo0hJSVF5KCKibsXt0RQ1NTU4e/as8/eysjIUFxcjLCwM/fv3x8KFC7FixQoMHjwYCQkJePXVVxEbG4tp06apjJuIqFtxOxkfO3YMDz30kPP3xYsXAwAyMzOxefNmvPjii6itrcXcuXNRVVWFsWPHYu/evQgICHDrOL6+vkqmXVJZ5eNwOKTayR7TiClsPH1M2SmoVFadyb5HlVP1qHyffn5+UvuSjV+muk7lFE6A5z9nsudCturSiOpMk/BkzbEEu90Oq9WqZTJW/YHtCYxIxrJ6SjKW+Tx6+2db5zn8AMBms3X4fZjhoymIiIjJmIhIC0zGREQaYDImItIAkzERkQaYjImINMBkTESkAW2nXZItsOiIzuMPPT01DSA/HlZGfX29kjbuUHnOZMfzevp9yu5LdgohGbLjvI2g8prL5gNV3Jk+jnfGREQaYDImItIAkzERkQaYjImINMBkTESkASZjIiINMBkTEWmAyZiISANMxkREGtC2Ak9HqquUjKj6k6lsVDnljGyVmOwxVVZjqa4OVEW2SlI2fplzZsQ0Q0ZQ+Tcn89kWQkhXE/POmIhIA0zGREQaYDImItIAkzERkQaYjImINMBkTESkASZjIiINMBkTEWmAyZiISANeXYEnU6mkssqqO1Qpefo9qKysk2VEBZssmQowI+bAk2VE1aiuVP8t8c6YiEgDTMZERBpgMiYi0gCTMRGRBpiMiYg0wGRMRKQBJmMiIg0wGRMRacCriz5UFnSonM5HZZGA7L58fX2l2p07d67DNjExMVL7UnnOVLZTPRhf5piyBRgqiyZk36dMbLJxqZ5GS0ZPKTRxO2t89tlnmDJlCmJjY2EymbBr1y6X7bNmzYLJZHJZ0tPTVcVLRNQtuZ2Ma2trkZiYiHXr1rXZJj09HZcuXXIu27Ztu60giYi6O7e7KTIyMpCRkdFuG7PZjOjo6E4HRUTU03TJF3j5+fmIjIzE0KFDMX/+fFRWVrbZtr6+Hna73WUhIupplCfj9PR0/PGPf8TBgwfxu9/9DgUFBcjIyIDD4Wi1fV5eHqxWq3OJi4tTHRIRkfZMQgjR6RebTNi5cyemTZvWZpuvvvoKAwcOxIEDBzBhwoQW2+vr611GRdjtdkMSMkdTfM+I0RTezohRBrJkYlM5MsOd/fUUNpsNISEh7bbp8qFtAwYMQHh4OM6ePdtqMjabzdLPn6Uu0tSEoHfegf/Ro2hIToYvgNb/HUNEXaXLk/E333yDyspK6bst8rygd96B5a23YBIC/n/5C14G8LrRQRH1MG4n45qaGpw9e9b5e1lZGYqLixEWFoawsDAsW7YMjz32GKKjo1FaWooXX3wRgwYNQlpamtLASR3/o0dhutFbZRICYw2Oh6gncrvPOD8/Hw899FCL9ZmZmdiwYQOmTZuG48ePo6qqCrGxsZg4cSJef/11REVFSe3fbrfDarW6E5ISKqewUdlf5ok+ulcBLMX1b3Obb/zs6TtjlRVsvXv3ltpXTU2NVDuVVPbfqqRzX7DK6dVkv4NRVXUphIDD4eiaPuPx48ejvfy9b98+d3dJBvvtjf+OBXD4B78Tked49bMpSA0H2EdMZDQ+tY2ISANMxkREGmAyJiLSAJMxEZEGmIyJiDTAZExEpAEmYyIiDXj1OGOVlTkyTz2T3ZfKaiYjKp4sFotUu7Yei/pDjY2NUvtSOQfe1atXpfZlBF2r63R+yprKuS5VUn3OeGdMRKQBJmMiIg0wGRMRaYDJmIhIA0zGREQaYDImItIAkzERkQaYjImINKBt0Yevry9MJlO7bVQOBpfZl+ws1iqLQ4wYjK9yOiKV09zIUrkvAAgMDOywTV1dndS+ZM6HbPwqZ1XXuehD5Tnz8/OTamdEoQnvjImINMBkTESkASZjIiINMBkTEWmAyZiISANMxkREGmAyJiLSAJMxEZEGmIyJiDSgbQWezJQ+MlROgaQqJneOqZrKqapUVhAKIaTadVSVCQAhISFS+7Lb7VLtZKvrZKisDjSiSkz270mm0k32vKo8Z7LTgKms+pPFO2MiIg0wGRMRaYDJmIhIA0zGREQaYDIm79DUBCxfjn0AXgXga3Q8RIppO5qCyMVvfwssXYqJAFJvrHrdyHiIFOOdMXmHw4eBG8PffACMNTYaIuWYjMk7jB0L3Bhj3AzgsLHRECnX7bspZIsOZAazKx/kLTklkQzZ2GQHvctQWbQSHh7e7nZfIbAoIAD31tXhMIDfttNWdtoolQVBPYXsudD1nKn8G5YpoBJCoKGhQWp/bmWDvLw83HfffQgODkZkZCSmTZuGkpISlzbXrl1DVlYW+vbtC4vFgsceewwVFRXuHIaoBYfJhLd690YarvcVq62FJDKeW8m4oKAAWVlZOHLkCPbv34/GxkZMnDgRtbW1zjaLFi3Chx9+iB07dqCgoAAXL17E9OnTlQdORNSdmITsQwFaceXKFURGRqKgoADjxo2DzWZDREQEtm7dihkzZgAATp8+jbvuuguFhYW4//77O9yn3W6H1WrtbEidprKbQradEd0URtTcy+jbt69Uu8rKyg7byJ5X2Xa6/pObjOVON4XNZuvwmSm3lQ1sNhsAICwsDABQVFSExsZGpKamOtsMGzYM/fv3R2Fh4e0cioioW+v0F3jNzc1YuHAhxowZgxEjRgAAysvL4e/vj9DQUJe2UVFRKC8vb3U/9fX1Lk+fkn2SFhFRd9LpO+OsrCycPHkS27dvv60A8vLyYLVanUtcXNxt7Y+IyBt1KhlnZ2fjo48+wqFDh9CvXz/n+ujoaDQ0NKCqqsqlfUVFBaKjo1vd15IlS2Cz2ZzLhQsXOhMSEZFXcysZCyGQnZ2NnTt34tNPP0VCQoLL9qSkJPj5+eHgwYPOdSUlJTh//jxSUlJa3afZbEZISIjLQkTU07jVZ5yVlYWtW7di9+7dCA4OdvYDW61WBAYGwmq1Ys6cOVi8eDHCwsIQEhKCnJwcpKSkSI2kICLqqdwa2tbWlDebNm3CrFmzAFwv+nj++eexbds21NfXIy0tDevXr2+zm+JW7gxt8/TQMJXHU31MI4ajqSQzTAgwZqoh+p7FYpFqJ1sFKUPmb0D3YYoyQ9tua5xxV2Ay7twxmYzJE5iMO6fLxxkTEZEaTMZERBpgMiYi0gCTMRGRBpiMiYg0wGRMRKQBJmMiIg0wGRMRacCr58DzdKGDn5+fVDuV88zJvkcjiiZUPqheZVyBgYFS7erq6pQd09vJzgcoW8zh6UIN1blA5nyoLiDhnTERkQaYjImINMBkTESkASZjIiINMBkTEWmAyZiISANMxkREGmAyJo/zBfAqgH03/utrbDhEWvDqmT5kyA5mlxnALTtIXbYAQ9eiA5Uzmnz11Vct1lnXrIF19WqYhIAwmWBbuBB9Vq1SdkyV1xxQW9yi6njukIlN9pypfJ89YXYaIQQaGho40wfpyfzFFzDduAcwCQHzF18YHBGR8ZiMyePq77sP4sbktsJkQv199xkcEZHxvPrZFOSdbFlZAK7fIdffd9/13xV2UxB5IyZj8rxevWBbsMDoKIi0wm4KIiINMBkTEWmAyZiISANMxkREGmAyJiLSgFePppCpVFJZZSVbGSVbWSdTwaNyOiJA7XQyMtMbDR06VGpfKqvmVE+HI1Mp1lF11U12u/12w3FSWcEme85Onz4t1W7YsGG3E47bZP82VZ4zmenV3Clw5p0xEZEGmIyJiDTg1d0URGSQpib0/f3vEVhUhLqkJFTOmwdIdjVR63j2iMhtfX//e/R9912YhEDvwkIAQOWNMnfqHHZTEJHbAouKXJ68F1hUZHBE3o/JmIjcVpeU5PLkvbqkJIMj8n7spiAit1XOmwcArn3GdFuYjInIfb16sY9YMXZTEBFpwK058PLy8vDBBx/g9OnTCAwMxI9//GP87ne/c6myGj9+PAoKClxeN2/ePGzcuFHqGKrnwOspVM/7popMlR6gttJQ9dxqKqszZc6/rteyOzDq3CqfA6+goABZWVk4cuQI9u/fj8bGRkycOBG1tbUu7Z555hlcunTJuaxcudL96ImIehC3+oz37t3r8vvmzZsRGRmJoqIijBs3zrm+d+/eiI6OVhMhEVEPcFt9xjabDQAQFhbmsn7Lli0IDw/HiBEjsGTJEly9evV2DkNE1O11ejRFc3MzFi5ciDFjxmDEiBHO9U888QTi4+MRGxuLEydO4Ne//jVKSkrwwQcftLqf+vp6l/5ClU+1IiLyFp1OxllZWTh58iQOHz7ssn7u3LnOn0eOHImYmBhMmDABpaWlGDhwYIv95OXlYdmyZZ0Ng4ioW+hUN0V2djY++ugjHDp0CP369Wu3bXJyMgDg7NmzrW5fsmQJbDabc7lw4UJnQiIi8mpu3RkLIZCTk4OdO3ciPz8fCQkJHb6muLgYABATE9PqdrPZLPWQdSKi7sytZJyVlYWtW7di9+7dCA4ORnl5OQDAarUiMDAQpaWl2Lp1KyZNmoS+ffvixIkTWLRoEcaNG4dRo0Z1yRsgIuoO3Cr6MN14MMitNm3ahFmzZuHChQv4xS9+gZMnT6K2thZxcXF49NFH8Zvf/MataWm8vehD9k5fZaGDEdPO6MqIgf08/65kin1kpydTyajrJFP04XY3RXvi4uJaVN8REVHH+GwKIiINMBkTEWmAyZiISANMxkREGmAyJiLSAJMxEZEGmIyJiDTAZExEpAFOSHqDTNWWr6+v1L5UVtapruaTqUCSrT5SuS+Vesp0RCorDVVXpqn8G1BJ5wpI3hkTEWmAyZiISANMxkREGmAyJiLSAJMxEZEGmIyJiDTAZExEpAEmYyIiDXh10YfKogOZgfFGFBOoHjyvctC7zL5kpt8BjJmCR5ZM4Y0RRQ6yn0cj4vd0cYUR0ynJHFMI0eEMSc793W5ARER0+5iMiYg0wGRMRKQBJmMiIg0wGRMRaYDJmIhIA0zGREQaYDImItIAkzERkQa0rcAzmUwwmUzttpGpprFYLFLHq6mpkWonw4hqICPITgklQ7ZST6ZSTPV5bWxsVLo/VVROyaVyCicjqL7mMn/Dfn5+HbYRQqChoUHumFKtiIioSzEZExFpgMmYiEgDTMZERBpgMiYi0gCTMRGRBpiMiYg0wGRMRKQBJmMiIh0IN6xfv16MHDlSBAcHi+DgYHH//feLPXv2OLfX1dWJX/7ylyIsLEwEBQWJ6dOni/LycncOIWw2mwDg1UuvXr2kFpXH9PHxkVo8fS7MZrPUomv8qpee8B51Pa/uLKrjs9lsHeY+t+6M+/XrhzfeeANFRUU4duwYHn74YUydOhWnTp0CACxatAgffvghduzYgYKCAly8eBHTp0935xBERD2SSchOXdqGsLAwvPnmm5gxYwYiIiKwdetWzJgxAwBw+vRp3HXXXSgsLMT9998vtT+73Q6r1Xo7IRnOiDp/XZ+HIfv8BNnnP3j78zxUzmhO35P9/MtSfQ1sNhtCQkLabdPpd+BwOLB9+3bU1tYiJSUFRUVFaGxsRGpqqrPNsGHD0L9/fxQWFnb2MEREPYLbT23729/+hpSUFFy7dg0WiwU7d+7E8OHDUVxcDH9/f4SGhrq0j4qKQnl5eZv7q6+vd3mqlN1udzckIiKv5/ad8dChQ1FcXIyjR49i/vz5yMzMxN///vdOB5CXlwer1epc4uLiOr0vIiJv5XYy9vf3x6BBg5CUlIS8vDwkJiZizZo1iI6ORkNDA6qqqlzaV1RUIDo6us39LVmyBDabzblcuHDB7TdBROTtbrvXu7m5GfX19UhKSoKfnx8OHjzo3FZSUoLz588jJSWlzdebzWaEhIS4LEREPY1bfcZLlixBRkYG+vfvj+rqamzduhX5+fnYt28frFYr5syZg8WLFyMsLAwhISHIyclBSkqK9EgKIqKeyq1kfPnyZfzTP/0TLl26BKvVilGjRmHfvn145JFHAACrVq2Cj48PHnvsMdTX1yMtLQ3r16/vVGABAQEdTrvk6Sl4ZIesyUzHAsgNbVM9TE5mf7LnTGY4kcw1kt2XbDsjpuCRPaZMO5XnAlD7OVN5bo3Yl+ohcCrd9jhj1W6OM+4Jybiurk7ZMXVNxrJxqfwj0TkZqzqeO+16QjKWZdR4/C4dZ0xEROowGRMRaYDJmIhIA0zGREQaYDImItIAkzERkQaYjImINOD2U9u62s1hzzLDnz09RFr2eCrjUv0eVZ5Xnd+nSvycdc0xjWBU/DLH1S4ZV1dXA5Cv3PIkh8OhtJ2n96V6fyr3pfMfua7JWNdrqTOjPmfV1dUdTpqhXQVec3MzLl68iODgYGcFnt1uR1xcHC5cuOCVDxJi/Mbz9vfA+I3V2fiFEKiurkZsbGyH1X/a3Rn7+PigX79+rW7z9qe6MX7jeft7YPzG6kz8stPI8Qs8IiINMBkTEWnAK5Kx2WxGbm6u9EzDumH8xvP298D4jeWJ+LX7Ao+IqCfyijtjIqLujsmYiEgDTMZERBpgMiYi0oBXJON169bhzjvvREBAAJKTk/Hf//3fRockZenSpTCZTC7LsGHDjA6rTZ999hmmTJmC2NhYmEwm7Nq1y2W7EAKvvfYaYmJiEBgYiNTUVJw5c8aYYFvRUfyzZs1qcT3S09ONCbYVeXl5uO+++xAcHIzIyEhMmzYNJSUlLm2uXbuGrKws9O3bFxaLBY899hgqKioMitiVTPzjx49vcQ2effZZgyJ2tWHDBowaNcpZ2JGSkoKPP/7Yub2rz732yfi9997D4sWLkZubiy+//BKJiYlIS0vD5cuXjQ5Nyt13341Lly45l8OHDxsdUptqa2uRmJiIdevWtbp95cqVeOedd7Bx40YcPXoUQUFBSEtLw7Vr1zwcaes6ih8A0tPTXa7Htm3bPBhh+woKCpCVlYUjR45g//79aGxsxMSJE1FbW+tss2jRInz44YfYsWMHCgoKcPHiRUyfPt3AqL8nEz8APPPMMy7XYOXKlQZF7Kpfv3544403UFRUhGPHjuHhhx/G1KlTcerUKQAeOPdCc6NHjxZZWVnO3x0Oh4iNjRV5eXkGRiUnNzdXJCYmGh1GpwAQO3fudP7e3NwsoqOjxZtvvulcV1VVJcxms9i2bZsBEbbv1viFECIzM1NMnTrVkHg64/LlywKAKCgoEEJcP99+fn5ix44dzjb/+Mc/BABRWFhoVJhtujV+IYR48MEHxYIFC4wLyk19+vQRf/jDHzxy7rW+M25oaEBRURFSU1Od63x8fJCamorCwkIDI5N35swZxMbGYsCAAXjyySdx/vx5o0PqlLKyMpSXl7tcC6vViuTkZK+5FgCQn5+PyMhIDB06FPPnz0dlZaXRIbXJZrMBAMLCwgAARUVFaGxsdLkGw4YNQ//+/bW8BrfGf9OWLVsQHh6OESNGYMmSJbh69aoR4bXL4XBg+/btqK2tRUpKikfOvXYPCvqhb7/9Fg6HA1FRUS7ro6KicPr0aYOikpecnIzNmzdj6NChuHTpEpYtW4YHHngAJ0+eRHBwsNHhuaW8vBwAWr0WN7fpLj09HdOnT0dCQgJKS0vx8ssvIyMjA4WFhfD19TU6PBfNzc1YuHAhxowZgxEjRgC4fg38/f0RGhrq0lbHa9Ba/ADwxBNPID4+HrGxsThx4gR+/etfo6SkBB988IGB0X7vb3/7G1JSUnDt2jVYLBbs3LkTw4cPR3FxcZefe62TsbfLyMhw/jxq1CgkJycjPj4e//mf/4k5c+YYGFnPNHPmTOfPI0eOxKhRozBw4EDk5+djwoQJBkbWUlZWFk6ePKn1dwztaSv+uXPnOn8eOXIkYmJiMGHCBJSWlmLgwIGeDrOFoUOHori4GDabDe+//z4yMzNRUFDgkWNr3U0RHh4OX1/fFt9YVlRUIDo62qCoOi80NBRDhgzB2bNnjQ7FbTfPd3e5FgAwYMAAhIeHa3c9srOz8dFHH+HQoUMuj5ONjo5GQ0MDqqqqXNrrdg3air81ycnJAKDNNfD398egQYOQlJSEvLw8JCYmYs2aNR4591onY39/fyQlJeHgwYPOdc3NzTh48CBSUlIMjKxzampqUFpaipiYGKNDcVtCQgKio6NdroXdbsfRo0e98loAwDfffIPKykptrocQAtnZ2di5cyc+/fRTJCQkuGxPSkqCn5+fyzUoKSnB+fPntbgGHcXfmuLiYgDQ5hrcqrm5GfX19Z4590q+BuxC27dvF2azWWzevFn8/e9/F3PnzhWhoaGivLzc6NA69Pzzz4v8/HxRVlYmPv/8c5GamirCw8PF5cuXjQ6tVdXV1eL48ePi+PHjAoB4++23xfHjx8XXX38thBDijTfeEKGhoWL37t3ixIkTYurUqSIhIUHU1dUZHPl17cVfXV0tXnjhBVFYWCjKysrEgQMHxL333isGDx4srl27ZnToQggh5s+fL6xWq8jPzxeXLl1yLlevXnW2efbZZ0X//v3Fp59+Ko4dOyZSUlJESkqKgVF/r6P4z549K5YvXy6OHTsmysrKxO7du8WAAQPEuHHjDI78updeekkUFBSIsrIyceLECfHSSy8Jk8kkPvnkEyFE15977ZOxEEKsXbtW9O/fX/j7+4vRo0eLI0eOGB2SlMcff1zExMQIf39/cccdd4jHH39cnD171uiw2nTo0CEBoMWSmZkphLg+vO3VV18VUVFRwmw2iwkTJoiSkhJjg/6B9uK/evWqmDhxooiIiBB+fn4iPj5ePPPMM1r9T7212AGITZs2OdvU1dWJX/7yl6JPnz6id+/e4tFHHxWXLl0yLugf6Cj+8+fPi3HjxomwsDBhNpvFoEGDxK9+9Sths9mMDfyGf/7nfxbx8fHC399fREREiAkTJjgTsRBdf+75CE0iIg1o3WdMRNRTMBkTEWmAyZiISANMxkREGmAyJiLSAJMxEZEGmIyJiDTAZExEpAEmYyIiDTAZExFpgMmYiEgDTMZERBr4/9y5zDwSKXHKAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Select an index to visualize from the entire dataset\n",
    "index_to_visualize = np.random.randint(0, len(all_images))\n",
    "\n",
    "# index_to_visualize = 11548\n",
    "# Visualize the selected image with predicted and true midpoints\n",
    "visualize_midpoints(all_images[index_to_visualize], all_pred_midpoints[index_to_visualize, 0, :, :] * np.max(centers), title=\"Predicted Midpoints\")\n",
    "visualize_midpoints(all_images[index_to_visualize], all_true_midpoints[index_to_visualize, 0, :, :] * np.max(centers), title=\"Ground Truth Midpoints\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0009482383, 30.999704)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(all_pred_midpoints)*np.max(centers),np.max(all_pred_midpoints)*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 31.0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(all_true_midpoints)*np.max(centers),np.max(all_true_midpoints)*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0, 0.0, 31.0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(train_images), np.max(train_images), np.min(train_midpoints)*np.max(centers), np.max(train_midpoints)*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 4.2590027,  3.908059 ],\n",
       "         [27.263153 ,  4.3831873],\n",
       "         [ 5.8743353,  6.6574388],\n",
       "         [14.020337 ,  8.760142 ],\n",
       "         [ 4.1754484, 10.7192545],\n",
       "         [ 4.123699 , 11.2907295],\n",
       "         [22.326601 , 11.401616 ],\n",
       "         [ 7.203351 , 12.493043 ],\n",
       "         [ 5.814977 , 12.613149 ],\n",
       "         [21.202332 , 14.556165 ],\n",
       "         [ 8.0557995, 17.444569 ],\n",
       "         [ 8.055367 , 18.544151 ],\n",
       "         [ 5.2744675, 26.596989 ]]], dtype=float32),\n",
       " array([[[ 4.,  3.],\n",
       "         [28.,  6.],\n",
       "         [ 6.,  7.],\n",
       "         [14.,  9.],\n",
       "         [ 4., 10.],\n",
       "         [ 4., 10.],\n",
       "         [22., 11.],\n",
       "         [ 7., 12.],\n",
       "         [ 6., 14.],\n",
       "         [21., 15.],\n",
       "         [ 8., 17.],\n",
       "         [ 8., 18.],\n",
       "         [ 5., 28.]]], dtype=float32))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pred_midpoints[2]*np.max(centers),all_true_midpoints[2]*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1., 35., 12.],\n",
       "        [ 1., 63., 52.],\n",
       "        [ 1., 11., 43.],\n",
       "        ...,\n",
       "        [ 1., 10., 33.],\n",
       "        [ 1., 11., 48.],\n",
       "        [ 1., 59., 49.]],\n",
       "\n",
       "       [[ 1.,  5., 24.],\n",
       "        [ 1., 34., 55.],\n",
       "        [ 1., 42., 29.],\n",
       "        ...,\n",
       "        [ 1.,  2., 55.],\n",
       "        [ 1., 13., 17.],\n",
       "        [ 1., 45.,  8.]],\n",
       "\n",
       "       [[ 1., 38., 36.],\n",
       "        [ 1., 11., 33.],\n",
       "        [ 1., 40., 40.],\n",
       "        ...,\n",
       "        [ 1., 45.,  5.],\n",
       "        [ 1.,  8.,  7.],\n",
       "        [ 1., 55., 37.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1., 50., 18.],\n",
       "        [ 1., 20., 19.],\n",
       "        [ 1., 63.,  8.],\n",
       "        ...,\n",
       "        [ 1., 32., 44.],\n",
       "        [ 1., 63., 24.],\n",
       "        [ 1., 51., 52.]],\n",
       "\n",
       "       [[ 1.,  6., 33.],\n",
       "        [ 1., 23., 59.],\n",
       "        [ 1., 13., 48.],\n",
       "        ...,\n",
       "        [ 1., 26., 62.],\n",
       "        [ 1., 20., 42.],\n",
       "        [ 1., 53.,  2.]],\n",
       "\n",
       "       [[ 1., 24., 40.],\n",
       "        [ 1., 30., 43.],\n",
       "        [ 1., 38., 55.],\n",
       "        ...,\n",
       "        [ 1., 31., 56.],\n",
       "        [ 1., 21., 50.],\n",
       "        [ 1., 15.,  6.]]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[2],)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize variables to track the min and max MSE\n",
    "min_mse = float('inf')\n",
    "max_mse = float('-inf')\n",
    "min_mse_index = -1\n",
    "max_mse_index = -1\n",
    "\n",
    "# Loop through each prediction to calculate the MSE\n",
    "for i in range(len(all_pred_midpoints)):\n",
    "    mse = np.mean((all_pred_midpoints[i] - all_true_midpoints[i]) **2)\n",
    "    \n",
    "    if mse < min_mse:\n",
    "        min_mse = mse\n",
    "        min_mse_index = i\n",
    "    \n",
    "    if mse > max_mse:\n",
    "        max_mse = mse\n",
    "        max_mse_index = i\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot an image with its centers\n",
    "def plot_image_with_centers(image, true_center, predicted_center, title):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image.squeeze(), cmap='gray')  # Display the image\n",
    "\n",
    "    # Plot the actual center (Groundtruth)\n",
    "    plt.scatter(true_center[:, 0], true_center[:, 1], color='green', label='Groundtruth', s=10)\n",
    "\n",
    "    # Plot the predicted center\n",
    "    plt.scatter(predicted_center[:, 0], predicted_center[:, 1], color='red', label='Predictions', s=10)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the image with the least MSE\n",
    "plot_image_with_centers(all_images[min_mse_index],\n",
    "                        all_true_midpoints[min_mse_index][0] * np.max(centers),  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[min_mse_index][0] * np.max(centers),  # Adjust for scaling if needed\n",
    "                        f'Image with Least MSE. MSE: {min_mse:.4f}')\n",
    "\n",
    "# Plotting the image with the largest MSE\n",
    "plot_image_with_centers(all_images[max_mse_index],\n",
    "                        all_true_midpoints[max_mse_index][0] * np.max(centers),  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[max_mse_index][0] * np.max(centers),  # Adjust for scaling if needed\n",
    "                        f'Image with Largest MSE. MSE: {max_mse:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5266"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_mse_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "objectdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
