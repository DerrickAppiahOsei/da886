{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Set CUDA device order and visible devices\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7,8,9\"\n",
    "\n",
    "# # Set the device\n",
    "# device = '/cpu:0'\n",
    "# if tf.config.experimental.list_physical_devices('GPU'):\n",
    "#     try:\n",
    "#         # Restrict TensorFlow to only use the second GPU\n",
    "#         gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#         if gpus:\n",
    "#             tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "#             device = '/gpu:0'\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)\n",
    "\n",
    "# print(\"device\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 18:05:39.494616: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-21 18:05:39.507376: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-21 18:05:39.520119: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-21 18:05:39.523923: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-21 18:05:39.535001: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-21 18:05:40.253663: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 18:05:41.919059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79196 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:45:00.0, compute capability: 8.0\n",
      "2024-10-21 18:05:41.920600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 79196 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:46:00.0, compute capability: 8.0\n",
      "2024-10-21 18:05:41.921977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 79196 MB memory:  -> device: 2, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:49:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"  # Only GPUs 0 and 1 will be visible to TensorFlow\n",
    "\n",
    "import tensorflow as tf\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\",\"/gpu:2\"])\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# DataLoader Class Definition\n",
    "# -----------------------------\n",
    "class DataLoader:\n",
    "    def __init__(self, h5_filename):\n",
    "        self.h5_filename = h5_filename\n",
    "        self.images, self.centers = self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        with h5py.File(self.h5_filename, 'r') as f:\n",
    "            images = np.array(f['images'])\n",
    "            centers = np.array(f['centers_training'])\n",
    "        return images, centers\n",
    "\n",
    "    def plot_image_with_centers(self, image_index=None):\n",
    "        if image_index is None:\n",
    "            image_index = np.random.randint(0, len(self.images))\n",
    "\n",
    "        image = self.images[image_index]\n",
    "        centers = self.centers[image_index]\n",
    "\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        valid_centers = centers[centers[:, 0] == 1]\n",
    "        for center in valid_centers:\n",
    "            plt.scatter(center[1], center[2], c='red', marker='o',s=5)  # center[1] is x and center[2] is y\n",
    "        plt.title('Image with Valid Centers Marked')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_centers(centers):\n",
    "        return centers[np.lexsort((centers[:, 0], centers[:, 1]))]\n",
    "\n",
    "    def normalize_data(self):\n",
    "        normalized_images = self.images / np.max(self.images)\n",
    "        sorted_centers = np.array([self.sort_centers(image_centers[:, 1:]) for image_centers in self.centers])\n",
    "        normalized_centers = sorted_centers / np.max(centers)\n",
    "\n",
    "        normalized_midpoints = tf.expand_dims(normalized_centers, axis=1)\n",
    "        return normalized_images, normalized_midpoints.numpy()\n",
    "\n",
    "    def split_data(self, train_size=0.8, random_state=42):\n",
    "        normalized_images, normalized_midpoints_np = self.normalize_data()\n",
    "        return train_test_split(normalized_images, normalized_midpoints_np, train_size=train_size, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Utility Function Definition\n",
    "# -----------------------------\n",
    "def plot_transposed_images_with_midpoints(dataset, image_indices=[0, 1, 2, 3]):\n",
    "    \"\"\"\n",
    "    Extracts multiple images and their midpoints from the given dataset, transposes the images, \n",
    "    corrects the midpoints, and plots the transposed images with the corrected midpoints.\n",
    "\n",
    "    Args:\n",
    "    - dataset (tf.data.Dataset): The dataset from which to extract the images and midpoints.\n",
    "    - image_indices (list): The indices of the images in the batch to visualize. Default is [0, 1, 2, 3].\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract a sample image batch and its corresponding midpoints from the dataset\n",
    "    sample_image_batch, sample_midpoints_batch = next(iter(dataset))\n",
    "\n",
    "    # Create a figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(6, 6))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(image_indices):\n",
    "            # Select the specified image and corresponding midpoints from the batch\n",
    "            sample_image = np.array(sample_image_batch[image_indices[i]])\n",
    "            sample_midpoints = np.array(sample_midpoints_batch[image_indices[i]])\n",
    "\n",
    "            # Transpose the image\n",
    "            transposed_image = sample_image.T\n",
    "\n",
    "            # Correct the midpoints by swapping the x and y coordinates\n",
    "            transposed_midpoints_corrected = sample_midpoints[:, :, [1, 0]]\n",
    "\n",
    "            # Plot the transposed image with corrected midpoints\n",
    "            ax.imshow(transposed_image, cmap='gray')\n",
    "            ax.scatter(\n",
    "                transposed_midpoints_corrected[:, :, 0] * 31, \n",
    "                transposed_midpoints_corrected[:, :, 1] * 31, \n",
    "                c='red', marker='o', s=5\n",
    "            )\n",
    "            ax.set_title(f'Image {image_indices[i]} for this batch')\n",
    "        else:\n",
    "            ax.axis('off')  # If fewer than 4 images are requested, hide the unused subplots\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Custom Loss and Callback Definitions\n",
    "# -----------------------------\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def custom_loss(exponent):\n",
    "    def loss(y_true, y_pred):\n",
    "        diff = tf.abs(y_true - y_pred)\n",
    "        powered_diff = tf.pow(diff, exponent)\n",
    "        return tf.reduce_mean(powered_diff)\n",
    "    return loss\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class DynamicExponentCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, initial_exponent, increment, update_frequency):\n",
    "        super().__init__()\n",
    "        self.exponent = initial_exponent\n",
    "        self.increment = increment\n",
    "        self.update_frequency = update_frequency\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.update_frequency == 0:\n",
    "            self.exponent += self.increment\n",
    "            print(f\"\\nEpoch {epoch + 1}: Increasing exponent to {self.exponent}\")\n",
    "            self.model.loss = self.custom_loss(self.exponent)\n",
    "\n",
    "    def custom_loss(self, exponent):\n",
    "        def loss(y_true, y_pred):\n",
    "            diff = tf.abs(y_true - y_pred)\n",
    "            powered_diff = tf.pow(diff, exponent)\n",
    "            return tf.reduce_mean(powered_diff)\n",
    "        return loss\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'initial_exponent': self.exponent,\n",
    "            'increment': self.increment,\n",
    "            'update_frequency': self.update_frequency,\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my NEW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "\n",
    "class ModelBuilder:\n",
    "    def __init__(self, input_shape=(32, 32, 1), num_classes=13, num_coordinates=2, learning_rate=1e-2, weights_path=None,l1_reg=0.001,l2_reg =0.01):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.num_coordinates = num_coordinates\n",
    "        self.learning_rate = learning_rate\n",
    "        self.l1_reg = l1_reg\n",
    "        self.l2_reg = l2_reg\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        # Load weights if a path is provided\n",
    "        if weights_path is not None:\n",
    "            self.model.load_weights(weights_path)\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "        # self.optimizer =tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "    def build_model(self):\n",
    "        \n",
    "        l1 = regularizers.l1(self.l1_reg)\n",
    "        l2 = regularizers.l2(self.l2_reg)\n",
    "\n",
    "    \n",
    "        x_input = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "        \n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x_input)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        \n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        \n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.3)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        # x = layers.MaxPool2D()(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.3)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=5, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        # x = layers.Conv2D(128, kernel_size=5, padding='same', activation='relu')(x)\n",
    "        # # x = layers.MaxPool2D()(x)\n",
    "        # # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Flatten()(x)\n",
    "        \n",
    "        x_midpoints = layers.Dense(self.num_classes * self.num_coordinates, activation='sigmoid', name='x_midpoints')(x)\n",
    "        x_midpoints_reshape = layers.Reshape((-1, self.num_classes, self.num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "        \n",
    "        return tf.keras.models.Model(x_input, x_midpoints_reshape)\n",
    "\n",
    "    def compile_model(self, loss_function):\n",
    "        self.model.compile(optimizer=self.optimizer, loss=loss_function)\n",
    "\n",
    "    def train_model(self, train_dataset, val_dataset, epochs, callbacks_list):\n",
    "        history = self.model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks_list)\n",
    "        return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Main Script Execution\n",
    "# -----------------------------\n",
    "\n",
    "# Load data\n",
    "# h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KFixed_Mixed_13.h5'             \n",
    "h5_filename = '/home/da886/Final Electron counting project/Images and Labels/12KFixed_Mixed_13_32by32_SparsespotsRandomIndex.h5'\n",
    "# h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KFixed_13_SparsespotsRandomIndex.h5'\n",
    "# h5_filename ='/home/da886/Final Electron counting project/Images and Labels/30KFixed-index6_13.h5'\n",
    "data_loader = DataLoader(h5_filename)\n",
    "images, centers = data_loader.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x7f145c145450>, 9780)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l=np.random.randint(0,len(centers))\n",
    "data_loader.plot_image_with_centers(l)\n",
    "plt.imshow(images[l]),l\n",
    "# plt.grid(True),l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sorted_centers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mmax(\u001b[43msorted_centers\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sorted_centers' is not defined"
     ]
    }
   ],
   "source": [
    "np.max(sorted_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x7f40c44766d0>, 5819)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[l]),l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., 11.,  9.],\n",
       "       [ 1.,  8., 26.],\n",
       "       [ 1., 30., 25.],\n",
       "       [ 1.,  4., 15.],\n",
       "       [ 1.,  1., 15.],\n",
       "       [ 1., 24., 21.],\n",
       "       [ 1., 29.,  9.],\n",
       "       [ 1., 16.,  5.],\n",
       "       [ 1.,  2., 18.],\n",
       "       [ 1.,  5., 14.],\n",
       "       [ 1.,  3.,  7.],\n",
       "       [ 1., 21., 23.],\n",
       "       [ 1.,  1., 13.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.random.randint(0,len(centers))\n",
    "centers[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the data and split it into training and validation sets\n",
    "train_images, val_images, train_midpoints, val_midpoints = data_loader.split_data()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0, 0.0, 1.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(train_images), np.max(train_images), np.min(train_midpoints), np.max(train_midpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images: (9600, 32, 32), Train Midpoints: (9600, 1, 13, 2)\n",
      "Validation Images: (2400, 32, 32), Validation Midpoints: (2400, 1, 13, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 400\n",
    "train_dataset = train_dataset.shuffle(buffer_size=8000, reshuffle_each_iteration=True).batch(batch_size)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=8000).batch(batch_size)\n",
    "\n",
    "# Check the shape of the datasets\n",
    "print(f'Train Images: {train_images.shape}, Train Midpoints: {train_midpoints.shape}')\n",
    "print(f'Validation Images: {val_images.shape}, Validation Midpoints: {val_midpoints.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_transposed_images_with_midpoints(train_dataset, image_indices=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set up learning rate scheduler\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.9, patience=10, verbose=1, mode='min', min_lr=7e-6\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,277,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">26,650</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m3,277,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │        \u001b[38;5;34m26,650\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m2\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,348,762</span> (39.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,348,762\u001b[0m (39.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,348,250</span> (39.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,348,250\u001b[0m (39.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# dynamic_exponent_callback = DynamicExponentCallback(2, 1, 400)\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    # Instantiate the model builder\n",
    "    # model_builder = ModelBuilder(weights_path= \"/home/da886/Analysis/30KFixed_13_SparsespotsrandomSPOTS.keras\")\n",
    "    model_builder = ModelBuilder()\n",
    "\n",
    "    # Build the model\n",
    "    model_builder.build_model()\n",
    "\n",
    "    # Display the model architecture\n",
    "    model_builder.model.summary()\n",
    "\n",
    "    # Compile the model using the custom loss function\n",
    "    # model_builder.compile_model(loss_function=dynamic_exponent_callback.custom_loss(2))\n",
    "    model_builder.compile_model(loss_function=tf.keras.losses.MeanSquaredError()) \n",
    "    \n",
    "    # model_builder.compile_model(loss_function=custom_loss(3))e\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 18:06:52.399103: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-21 18:06:52.406750: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1729534012.472124  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.476184  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.516666  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.516758  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.517182  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.517279  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.521678  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.521780  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.534907  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.535002  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.536560  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.536785  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.537356  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.537366  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.537977  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.537987  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.539834  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.539846  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.551670  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.551775  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.552177  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.552276  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.552655  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.552757  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.553194  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.553275  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.553716  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.553796  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.554265  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.554345  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.555850  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.555950  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.557486  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.557581  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.559228  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.559238  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.561069  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.561170  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.562830  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.562930  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.564813  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.564911  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.566246  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.566347  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.571923  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.572019  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.573593  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.573693  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "2024-10-21 18:06:52.634164: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "W0000 00:00:1729534012.665404  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.685291  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.685632  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.686588  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.690171  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.690835  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.691230  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.691578  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.692172  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.695399  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.695762  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.696093  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.696456  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.696814  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.697203  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.697844  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.698434  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.699129  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.699876  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.700655  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.701601  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.702050  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.702633  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.704037  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.704692  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.927496  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.927896  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.928195  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.928488  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.928781  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.929088  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.929398  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.930144  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.930460  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.930789  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.931083  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.931391  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.931700  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.932514  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.932831  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.934123  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.934458  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.936068  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.937421  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.937761  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.938127  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.940927  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.941913  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.942221  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.942513  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.942915  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.943447  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.943446  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.943890  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.944081  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.944377  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.944691  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.944798  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.945365  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.945380  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.945787  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.945894  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.946118  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.946619  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.946629  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.947232  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.947316  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.947877  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.948265  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.948448  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.948875  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.948974  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.949488  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.949974  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.950299  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.950664  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.951418  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.951860  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.952301  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.952787  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.953215  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.953650  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.954129  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.954878  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.955314  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.960725  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.961156  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.961498  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.961808  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.962141  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.962526  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.963162  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.963705  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.964233  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.964835  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.965415  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.965999  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.966505  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.966930  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.967266  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.967577  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.967910  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.968288  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.968849  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.969390  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.969922  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.970765  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.970777  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.971086  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.971627  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.971639  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.971959  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.972478  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.972496  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.972832  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.973161  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.973491  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.973828  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.974194  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.974563  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.975255  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.975624  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.975981  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.976336  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.976714  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.977117  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.977223  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.977468  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.977784  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.977899  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.978356  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.978464  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.978819  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.978917  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.979171  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.979737  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.979750  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.980087  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.980666  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.980681  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.981053  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.981597  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.981614  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.982466  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.982556  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.982931  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.983410  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.983773  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.984150  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.984544  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.984943  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.985358  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.985740  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.986325  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.987018  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.988851  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.989527  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.991756  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.992181  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.992594  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.992958  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.993356  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.993831  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.994802  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.995605  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.996437  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.997249  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.997354  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.997675  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.998097  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.998460  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.998565  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.998969  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.999619  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534012.999634  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.000445  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.001240  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.002059  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.002943  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.003924  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.004816  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.008459  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.008825  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.009194  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.009553  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.009942  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.010320  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.010702  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.011082  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.011468  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.011911  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.012330  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.013497  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.013612  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.014192  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.014205  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.014824  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.014838  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.015442  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.015455  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.015959  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.016057  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.016355  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.016579  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.016766  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.017382  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.017393  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.017895  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.018007  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.018475  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.018576  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.018918  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.019557  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.019975  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.020421  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.020607  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.020875  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.021309  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.021796  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.021898  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.022399  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.023183  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.023198  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.023718  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.024316  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.025288  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.026327  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.027353  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.028467  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.032290  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.032808  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.033230  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.033750  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.034212  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.034747  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.035239  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.035814  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.036340  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.036831  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.037012  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.037450  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.037570  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.037995  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.038463  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.038869  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.039049  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.039606  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.040155  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.040335  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.040671  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.041201  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.041913  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.041927  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.042423  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.043291  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.043779  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.044622  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.044687  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.045233  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.045246  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.045573  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.045996  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.046218  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.046495  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.046604  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.046873  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.047316  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.047932  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.047956  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.048071  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.048397  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.048830  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.049575  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.049590  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.050175  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.051052  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.052510  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.052735  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.053021  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.053318  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.053612  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.053909  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.054217  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.054930  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.055245  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.055582  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.055879  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.056187  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.056502  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.056825  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.057253  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.057572  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.058078  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.058415  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.058946  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.059437  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.059754  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.060996  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.061416  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.061868  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.062331  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.062771  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.063254  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.064656  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.065144  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.065636  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.066132  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.066664  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.067184  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.067760  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.068248  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.068783  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.069149  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.069384  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.069621  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.070142  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.070261  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.070925  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.071021  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.071589  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.071703  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.071911  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.072170  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.072346  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.072828  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.072956  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.072971  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.073289  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.073804  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.073842  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.073913  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.074504  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.074585  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.074691  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.075164  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.075394  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.075512  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.075709  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.076125  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.076350  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.076428  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.076754  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.077048  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.077361  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.077625  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.078342  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.078551  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.078569  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.079278  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.079377  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.080340  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.080352  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.081079  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.081983  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.081995  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.083022  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.083332  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.083953  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.084067  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.084126  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.084420  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.084915  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.084926  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.085256  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.085699  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.086067  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.086117  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.086224  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.086558  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.086915  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.087284  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.087542  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.088043  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.088210  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.088435  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.088802  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.089174  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.089404  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.089599  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.089989  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.090437  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.090854  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.091160  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.091328  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.091749  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.092310  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.093000  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.093191  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.093662  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.094339  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.097308  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.097999  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.098585  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.099217  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.099983  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.100676  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.101286  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.101976  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.102066  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.102109  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.102494  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.103104  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.103148  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.103221  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.103712  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.104051  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.104090  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.104210  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.105045  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.105112  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.105130  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.105963  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.105978  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.106716  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.106891  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.107345  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.107648  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.107818  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.108039  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.108886  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.108900  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.109594  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.109872  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.110111  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.110312  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.110789  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.112523  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.112761  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.115123  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.115236  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.117840  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.117855  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.119444  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.119806  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.120300  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.120553  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.120749  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.120826  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.121224  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.121607  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.121996  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.122388  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.122778  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.123093  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.123280  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.123478  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.123716  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.124757  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.125185  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.125748  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.125847  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.126286  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.126803  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.127288  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.127834  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.128425  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.128526  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.128956  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.129508  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.130477  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.131507  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.132550  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.133659  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.142300  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.142812  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.143289  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.143714  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.144168  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.144690  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.145190  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.145691  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.146218  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.146715  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.147207  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.148567  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.149899  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.151221  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.152580  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.153966  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.155409  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.156642  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.156881  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.157299  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.157986  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.158651  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.159371  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.160085  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.160839  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.161539  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.161629  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.162326  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.162429  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.163018  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.163234  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.163710  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.164103  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.164443  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.165094  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.165205  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.166221  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.166241  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.166928  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.167676  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.167751  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.168538  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.168815  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.169409  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.169973  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.170299  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.171386  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.171401  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.172401  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.172635  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.173386  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.173760  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.173937  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.174433  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.175049  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.175150  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.175470  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.175696  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.176347  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.176448  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.176913  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.177082  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.177349  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.177584  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.178159  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.178333  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.178766  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.179375  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.179984  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.180405  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.180601  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.181517  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.181912  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.182018  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.182246  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.183021  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.183261  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.183757  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.184423  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.186170  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.186801  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.187019  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.187815  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.188693  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.190148  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.191721  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.191973  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.192746  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.193759  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.193841  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.194744  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.196016  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.196096  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.196335  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.197073  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.197361  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.198248  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.198357  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.199565  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.199577  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.200530  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.200777  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.201746  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.201853  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.203043  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.203057  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.204129  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.205076  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.205288  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.205977  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.206172  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.206578  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.207399  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.207420  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.207723  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.208171  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.208859  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.209476  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.210159  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.210899  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.211587  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.212034  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.212465  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.212532  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.214963  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.216557  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.217125  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.217391  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.219796  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.221097  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.221832  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.222289  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.224811  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.225750  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.226583  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.227353  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.230061  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.230447  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.231427  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.235243  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.236526  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.240305  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.262635  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.263284  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.263957  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.264622  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.265346  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.266062  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.266818  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.267515  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.268248  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.269023  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.269880  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.270735  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.271624  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.272852  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.273930  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.275079  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.276235  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.277233  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.280283  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.281647  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.282977  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.284387  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.287862  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.297626  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.298644  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.299525  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.300488  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.301130  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.301705  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.302220  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.302707  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.303206  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.303671  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.304403  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.304503  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.304762  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.305492  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.305852  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.305876  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.306478  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.307091  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.307172  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.307536  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.308227  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.308405  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.308758  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.309673  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.309895  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.310798  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.311063  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.312002  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.312318  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.312884  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.313673  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.313687  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.314877  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.315159  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.316307  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.316667  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.317450  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.317757  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.318340  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.319253  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.320289  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.320916  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.322035  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.322316  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.322831  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.324332  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.324855  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.326918  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.327136  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.327145  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.329707  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.329807  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.331680  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.332122  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.335393  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.336522  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.337679  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.341553  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.347813  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.348510  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.349134  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.349763  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.349893  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.350847  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.350854  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.351720  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.351733  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.352600  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.352614  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.353588  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.353603  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.354345  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.354450  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.355007  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.355296  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.355748  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.356046  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.356502  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.357335  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.358070  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.358580  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.360591  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.361089  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.363089  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.363723  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.365708  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.366565  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.368526  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.369728  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.371666  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.372615  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.374533  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.375624  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.377511  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.405176  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.406243  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.407218  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.408278  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.409091  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.409463  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.409741  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.410358  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.410814  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.410862  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.411058  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.411514  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.411792  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.412097  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.412205  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.412452  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.412894  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.413146  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.413341  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.413604  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.413825  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.414278  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.414600  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.414683  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.414964  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.415391  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.415658  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.415831  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.416310  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.416417  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.417504  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.417512  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.417616  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.418427  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.418539  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.419160  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.419270  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.419564  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.420212  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.420749  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.420830  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.421231  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.422019  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.422285  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.422513  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.423071  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.423552  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.424619  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.424709  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.424806  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.426103  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.426731  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.427028  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.428487  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.428724  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.430803  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.431133  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.432216  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.433688  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.436099  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.441263  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.441759  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.442602  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.451156  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.451633  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.452041  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.452201  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.452604  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.452720  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.453227  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.453313  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.453753  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.454213  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.454217  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.455096  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.455175  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.455760  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.455952  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.456409  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.457237  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.457642  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.457886  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.458408  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.458573  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.459310  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.460067  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.460378  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.460943  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.461134  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.461705  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.463975  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.464085  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.464285  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.466813  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.467868  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.467979  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.469475  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.470709  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.470792  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.472341  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.474110  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.474127  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.475525  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.478432  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.481759  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.481771  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.481801  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.482473  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.482488  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.483178  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.483194  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.483884  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.483895  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.484524  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.484620  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.485251  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.485265  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.486038  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.486052  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.486733  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.486749  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.487501  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.487516  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.488203  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.488216  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.488981  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.488995  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.489761  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.489773  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.490589  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.490602  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.491424  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.491441  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.493228  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.493420  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.493870  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.494078  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.495413  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.495622  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.496285  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.496394  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.497152  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.497325  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.498290  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.498399  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.503959  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.504053  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.505652  408320 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.505665  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.515133  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.515767  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.516388  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.517070  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.517787  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.518449  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.519116  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.519777  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.520470  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.521164  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.521955  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.522755  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.523693  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.524718  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.525758  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.527023  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.528073  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.529381  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.530737  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.533138  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.536857  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.547321  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.557063  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.557520  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.557928  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.558366  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.558809  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.560505  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.562917  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.565628  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.568429  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.572195  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.574868  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.578021  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.585384  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.585834  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.586292  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.586736  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.587211  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.587689  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.588209  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.588649  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.589147  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.589591  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.590111  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.590591  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.591158  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.591729  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.593471  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.594067  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.595595  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.596319  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.597127  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.598127  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.603665  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534013.605104  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.011166  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.012874  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.013330  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.015275  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.015750  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.016178  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.016599  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.017048  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.017491  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.019421  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.019866  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.020318  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.020875  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.021389  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.021947  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.022485  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.023902  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.025882  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.033517  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.035247  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.035662  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.035969  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.036416  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.037125  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.037820  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.037827  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.038251  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.038671  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.039115  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.039553  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.040236  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.040665  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.041115  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.041669  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.042181  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.042712  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.043386  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.045464  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.045451  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.047066  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.054728  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.056731  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.059948  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.060871  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.061519  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.061965  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.062672  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.063130  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.063549  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.063981  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.064437  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.064885  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.065562  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.065998  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.066458  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.066871  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.069796  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.070322  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.070850  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.071359  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.072344  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.072924  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.073046  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.073481  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.073984  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.074597  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.074677  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.077330  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.077790  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.078423  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.078591  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.078908  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.079453  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.080548  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.081482  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.082221  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.082476  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.082849  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.083279  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.083383  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.083841  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.083952  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.084405  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.084522  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.085075  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.085305  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.085539  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.085766  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.086118  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.086353  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.086810  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.087374  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.087857  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.088206  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.089377  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.092250  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.092326  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.092717  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.092943  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.093171  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.093828  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.093842  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.094420  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.094989  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.095680  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.096341  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.096923  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.097544  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.099054  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.102380  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.104625  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.104856  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.105325  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.105754  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.106249  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.106696  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.107440  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.107941  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.108059  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.108612  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.109070  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.109567  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.110354  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.111071  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.111499  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.111931  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.112373  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.112829  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.113394  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.114048  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.114689  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.115280  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.115902  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.120740  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.126239  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.132510  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.132650  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.133036  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.133222  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.134789  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.134871  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.135461  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.135473  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.136150  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.136162  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.136823  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.136835  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.137499  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.137511  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.138236  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.138249  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.138969  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.139018  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.139788  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.139801  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.140484  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.140498  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.141168  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.141180  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.141868  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.141880  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.142551  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.142657  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.143115  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.143293  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.143700  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.143833  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.144341  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.144446  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.145049  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.145061  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.145304  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.145927  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.145959  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.146037  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.146811  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.146833  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.146910  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.147466  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.147614  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.147715  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.147926  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.148158  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.148460  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.148544  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.148720  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.149079  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.149161  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.149538  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.149746  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.149916  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.150611  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.151190  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.151842  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.151866  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.151928  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.152357  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.152804  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.153704  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.154165  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.154768  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.154999  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.155013  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.155300  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.155765  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.156474  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.156589  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.156609  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.157383  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.157982  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.158479  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.158945  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.159736  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.160908  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.161135  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.161227  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.162846  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.164128  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.164504  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.165021  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.167679  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.168005  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.168517  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.171153  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.171456  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.171957  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.174588  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.177962  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.189793  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.189978  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.191163  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.191556  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.191846  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.192191  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.193426  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.193435  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.194604  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.194613  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.195569  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.195573  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.195692  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.197315  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.197758  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.197874  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.198159  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.198725  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.198804  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.198911  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.200005  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.200850  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.200847  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.200956  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.201637  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.201838  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.201940  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.202335  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.202636  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.203333  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.203812  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.204572  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.204713  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.204822  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.205354  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.206703  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.206715  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.207093  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.207752  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.210277  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.210381  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.211136  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.219810  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.220146  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.220226  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.220457  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.220939  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.221023  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.222770  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.222893  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.222978  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.223556  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.223739  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.223757  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.224239  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.224534  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.224613  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.224870  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.225307  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.225390  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.225629  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.226217  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.226393  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.226493  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.227016  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.227425  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.227438  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.227766  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.228401  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.228423  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.228539  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.229406  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.229444  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.229513  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.230411  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.230451  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.230518  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.231418  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.231456  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.231524  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.232409  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.232425  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.232454  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.233421  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.233463  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.233527  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.234314  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.234542  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.234643  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.235220  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.235620  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.235807  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.236267  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.236675  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.236865  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.237320  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.239470  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.239636  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.240097  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.242022  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.242191  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.242645  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.244539  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.244729  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.245173  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.249579  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.249740  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.250205  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.258966  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.259062  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.259537  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.289100  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.289351  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.289728  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.290159  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.290160  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.290529  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.290829  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.291013  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.291212  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.291854  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.291875  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.291998  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.292796  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.292980  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.292996  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.293629  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.293804  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.293820  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.294288  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.294659  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.294675  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.294950  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.295523  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.295604  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.295715  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.296606  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.296681  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.296697  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.297677  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.297751  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.297768  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.298731  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.298752  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.298876  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.299962  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.300038  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.300054  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.300951  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.301167  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.301183  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.301814  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.302188  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.302288  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.302684  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.303112  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.303292  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.303577  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.304013  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.304349  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.304628  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.305078  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.306877  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.307179  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.307642  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.309251  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.309579  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.310051  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.316456  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.316830  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.317226  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.317436  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.317613  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.317960  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.318262  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.318425  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.318716  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.319048  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.319225  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.319495  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.319850  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.320021  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.320267  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.320673  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.320848  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.321040  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.321484  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.321768  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.321883  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.322262  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.322665  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.322770  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.323038  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.323624  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.323663  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.323862  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.324602  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.324674  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.324784  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.325668  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.325694  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.325801  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.326799  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.326815  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.326839  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.327761  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.327984  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.327996  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.328717  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.329179  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.329193  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.329720  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.330232  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.330318  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.330609  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.331391  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.331433  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.331594  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.332571  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.332607  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.332684  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.333823  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.333830  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.333931  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.335047  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.335084  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.335156  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.335985  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.336785  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.336903  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.337625  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.337943  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.338038  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.338636  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.338993  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.339093  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.339567  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.342188  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.342356  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.342764  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.345338  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.345507  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.345914  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.349012  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.349183  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.349593  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.352724  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.352892  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.353309  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.356438  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.356609  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.357024  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.360153  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.360321  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.360736  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.407922  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.408022  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.408843  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.408893  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.409083  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.409730  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.409804  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.409914  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.410848  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.410926  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.410937  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.411902  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.412028  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.412085  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.413125  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.413158  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.413245  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.414375  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.414426  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.414519  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.415700  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.415735  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.415808  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.417098  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.417097  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.417203  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.418471  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.418515  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.418584  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.419761  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.419912  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.419992  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.421017  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.421147  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.421218  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.422109  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.424106  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.424199  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.425141  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.433468  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.433707  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.434297  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.434457  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.434709  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.435328  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.435622  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.435736  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.436291  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.436664  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.436779  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.437276  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.437750  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.437864  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.438312  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.438809  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.438921  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.439312  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.439896  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.440011  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.440355  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.440913  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.441019  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.441301  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.442221  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.442337  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.442446  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.443405  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.443746  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.443759  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.444462  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.444945  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.445028  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.445625  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.446349  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.446362  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.446612  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.447482  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.447581  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.447795  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.448706  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.449010  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.449082  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.449809  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.450123  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.450380  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.451102  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.451425  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.452029  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.452748  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.453081  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.453520  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.454236  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.454578  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.459098  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.459772  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.460154  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.464011  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.464709  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.465147  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.469063  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.469786  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.470285  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.474252  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.475013  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.475573  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.478941  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.479659  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.480273  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.483611  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.484297  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.484959  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.543086  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.544317  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.544360  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.545643  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.545738  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.545845  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.546914  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.547085  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.547105  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.547931  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.548281  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.548362  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.548993  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.549467  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.549486  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.550067  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.550683  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.550756  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.551172  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.551826  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.551941  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.552284  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.552979  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.553158  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.553416  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.554108  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.554351  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.554612  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.555253  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.555572  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.555831  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.556449  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.556865  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.557122  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.557673  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.558259  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.558513  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.558976  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.559756  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.560017  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.560371  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.561242  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.561501  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.561894  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.562719  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.562990  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.563390  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.564565  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.565103  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.565113  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.566591  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.567120  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.567222  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.569022  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.569197  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.569606  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.571598  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.573791  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.574331  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.576370  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.583746  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.584261  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.584979  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.585511  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.586144  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.586338  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.586688  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.587306  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.587591  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.587862  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.588493  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.588773  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.589057  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.589656  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.589953  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.590241  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.590890  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.591161  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.591495  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.592180  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.592378  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.592753  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.593391  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.593683  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.593975  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.594718  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.594963  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.595315  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.596047  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.596220  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.596604  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.597281  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.597569  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.597840  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.598555  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.598879  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.599121  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.600223  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.600402  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.600500  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.601357  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.601871  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.601889  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.602781  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.603418  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.603528  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.603891  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.604651  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.604761  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.605134  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.605901  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.606213  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.606833  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.607338  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.607614  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.608662  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.608744  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.609306  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.610282  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.610473  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.610933  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.611808  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.612179  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.612472  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.613883  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.613969  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.614425  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.615521  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.615837  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.616375  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.617587  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.617607  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.618052  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.619298  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.619587  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.619780  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.621282  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.622987  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.624738  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.625275  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.628517  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.630337  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.630913  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.634212  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.635932  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.636552  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.639904  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.641520  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.642188  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.645597  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.647115  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.647821  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.651285  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.653575  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.654336  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.657858  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.748006  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.749071  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.749394  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.750166  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.750490  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.751307  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.751597  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.752472  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.752742  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.754291  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.754342  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.754355  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.755389  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.755822  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.755996  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.756503  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.757437  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.757727  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.757813  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.759133  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.759242  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.759408  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.760602  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.760892  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.761187  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.762208  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.762682  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.763083  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.763790  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.764585  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.765524  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.765607  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.766929  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.767411  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.768145  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.769331  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.769564  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.771696  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.774468  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.774549  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.775898  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.780860  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.785261  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.785946  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.786579  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.786638  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.787480  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.787492  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.788259  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.788361  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.788966  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.789135  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.789657  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.789850  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.790378  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.790554  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.791090  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.791261  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.791500  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.791722  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.791957  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.792210  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.792431  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.792647  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.792872  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.793161  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.793347  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.793548  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.793848  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.794119  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.794322  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.794518  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.794902  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.795193  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.795299  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.795617  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.796000  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.796104  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.796452  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.796766  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.796875  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.797459  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.797588  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.797768  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.798329  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.798626  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.798740  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.799018  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.799918  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.799933  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.800650  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.801392  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.801635  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.802112  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.803171  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.803180  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.804087  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.804389  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.805082  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.805943  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.807202  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.808093  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.808401  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.809680  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.811090  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.811104  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.812148  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.813588  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.813929  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.814839  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.816056  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.816630  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.818919  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.821638  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.844772  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.845447  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.846153  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.846843  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.846926  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.847652  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.847753  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.848496  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.848596  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.849208  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.849378  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.849900  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.850107  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.850613  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.850851  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.851332  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.851610  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.852305  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.852315  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.852488  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.853266  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.853345  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.853452  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.854122  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.854271  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.854451  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.854811  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.855047  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.855585  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.855821  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.855907  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.856827  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.856850  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.856963  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.857618  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.857917  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.858028  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.858355  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.859083  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.859280  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.859295  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.860282  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.860294  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.860636  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.861078  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.861469  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.862026  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.862113  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.863089  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.863101  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.864114  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.864425  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.864628  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.865036  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.865969  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.866943  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.867159  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.868537  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.869995  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.872519  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.872577  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.873367  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.874110  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.874684  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.874907  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.875606  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.875897  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.876371  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.876629  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.877188  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.877636  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.878057  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.878756  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.878857  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.879800  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.879905  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.880368  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.880844  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.880990  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.881196  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.882331  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.882353  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.882402  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.883493  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.883532  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.883605  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.884518  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.884742  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.884844  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.885267  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.885814  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.886107  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.886308  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.886884  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.887064  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.887315  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.887958  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.888228  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.888329  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.889460  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.889531  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.889548  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.890546  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.890733  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.890748  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.891795  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.892010  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.892090  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.893142  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.893268  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.893348  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.894043  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.894738  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.894816  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.895196  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.895662  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.896177  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.896810  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.896822  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.897387  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.897974  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.898208  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.898819  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.899119  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.899416  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.900140  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.900221  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.900865  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.901290  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.902103  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.902669  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.903080  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.904047  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.904978  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.905264  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.905934  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.906718  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.907893  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.908066  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.908866  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.910956  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.911057  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.911805  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.914146  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.914159  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.915173  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.917145  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.917527  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.918541  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.920124  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.920902  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.923538  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.926932  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.965931  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.966652  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.967355  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.968074  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.968589  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.968828  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.969330  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.969693  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.970050  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.970737  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.970963  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.971823  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.971838  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.972739  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.972910  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.973717  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.974642  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.975123  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.975391  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.975816  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.975914  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.976657  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.976826  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.977405  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.978306  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.978510  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.978524  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.979396  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.980006  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.980022  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.980380  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.981540  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.981549  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.982707  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.982789  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.983092  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.985279  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.985681  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.986049  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.986648  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.987957  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.989029  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.989514  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.992117  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.995493  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.995998  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.996551  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.997038  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.997526  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.998016  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.998513  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.998811  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.999052  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.999616  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534014.999796  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.000127  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.000321  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.000622  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.000868  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.001119  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.001560  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.001677  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.002192  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.002302  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.002910  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.002926  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.003594  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.003610  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.004276  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.004378  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.004947  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.005123  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.005460  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.005593  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.005759  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.006098  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.006215  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.006458  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.006852  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.006951  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.007624  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.007638  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.008373  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.008510  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.008522  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.008891  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.009139  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.009441  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.010002  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.010257  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.010330  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.010781  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.011317  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.011984  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.012100  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.012176  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.012684  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.013340  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.013567  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.013669  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.013947  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.014456  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.015072  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.015249  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.015267  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.015911  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.016965  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.016972  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.017070  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.018488  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.018716  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.020022  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.020203  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.021565  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.023110  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.024627  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.026128  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.032390  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.032883  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.033441  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.033972  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.034467  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.035032  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.035236  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.035556  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.035760  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.036090  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.036325  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.036617  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.036864  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.037152  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.037382  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.037885  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.038004  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.038648  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.038750  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.039210  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.039386  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.039738  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.040012  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.040279  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.040663  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.040905  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.041866  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.041886  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.041890  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.042475  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.042590  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.042759  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.043165  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.043273  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.043708  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.043939  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.044291  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.044372  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.044681  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.044930  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.045670  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.045683  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.046228  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.046743  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.047071  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.047300  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.047905  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.048510  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.049109  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.049723  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.050238  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.050375  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.050831  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.051123  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.051365  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.052003  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.052082  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.052542  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.052901  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.053078  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.053670  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.053778  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.053857  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.054347  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.054516  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.054893  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.055075  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.055686  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.055850  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.056227  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.056529  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.056798  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.057352  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.057462  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.058133  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.058223  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.058940  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.058957  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.059690  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.059787  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.059807  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.060336  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.060641  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.060657  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.060883  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.061693  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.061706  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.061729  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.062544  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.062631  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.062731  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.063099  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.063345  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.063570  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.063737  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.064004  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.064364  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.064435  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.064765  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.064998  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.065207  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.065647  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.065754  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.066397  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.066694  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.066703  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.067593  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.067605  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.067974  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.068482  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.068583  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.069061  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.069928  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.070004  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.070019  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.070667  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.071462  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.071801  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.071817  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.072239  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.073008  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.073572  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.073647  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.073756  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.074592  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.075368  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.075384  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.075662  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.077018  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.077315  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.077387  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.078628  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.079046  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.079204  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.080439  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.080669  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.082478  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.082491  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.084104  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.085921  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.087737  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.103007  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.103512  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.104038  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.104641  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.105266  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.105819  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.106579  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.106666  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.107139  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.107288  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.107692  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.108409  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.108419  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.109049  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.109606  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.109898  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.110271  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.110824  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.110924  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.111596  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.112011  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.112113  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.112624  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.113198  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.113391  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.113548  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.113823  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.114413  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.114582  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.114904  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.115395  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.115406  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.116062  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.116637  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.117069  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.117178  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.117616  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.118697  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.119103  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.119924  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.120764  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.120853  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.122466  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.123996  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.125382  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.125813  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.126155  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.126278  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.126660  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.127046  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.127410  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.127808  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.128189  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.128631  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.129030  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.129239  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.129422  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.129680  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.130014  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.130129  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.130454  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.130570  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.131051  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.131068  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.131573  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.131674  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.132010  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.132179  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.132403  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.132785  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.132891  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.133431  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.133446  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.133826  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.134298  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.134506  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.134538  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.134723  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.134990  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.135213  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.135632  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.135725  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.135824  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.136239  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.136384  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.136687  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.136859  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.136971  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.137240  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.137492  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.137775  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.137855  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.138241  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.138657  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.138838  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.138856  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.139248  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.139606  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.139777  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.139883  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.140349  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.140460  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.140759  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.141183  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.141523  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.141629  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.142072  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.142621  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.142722  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.143196  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.143564  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.144244  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.145053  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.145856  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.146790  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.147806  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.147880  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.148204  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.148615  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.148857  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.149060  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.149435  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.149847  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.150239  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.150632  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.151023  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.151333  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.151497  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.151730  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.151962  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.152158  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.152536  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.152648  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.153150  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.153164  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.153703  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.153804  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.154137  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.154308  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.154545  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.154958  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.155064  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.155585  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.155688  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.156037  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.156711  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.156839  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.156920  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.157288  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.157395  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.158108  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.158153  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.158828  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.158839  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.159332  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.159446  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.159759  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.160095  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.160202  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.160598  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.161161  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.161173  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.161569  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.162011  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.162234  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.162491  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.162699  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.162988  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.163161  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.163507  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.163682  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.164078  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.164186  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.164747  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.164823  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.165393  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.165472  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.165846  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.166212  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.166396  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.166511  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.166743  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.166907  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.167172  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.167454  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.167966  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.168067  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.168406  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.168569  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.168867  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.169052  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.169320  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.169588  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.169777  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.170188  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.170300  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.170805  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.170823  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.171413  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.171430  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.171873  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.172009  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.172114  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.172467  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.172620  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.172728  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.173044  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.173160  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.173393  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.173661  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.173780  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.174014  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.174242  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.174349  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.174849  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.175022  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.175038  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.175296  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.175530  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.175807  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.175986  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.176088  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.176434  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.176643  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.176919  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.177000  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.177265  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.177509  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.178012  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.178134  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.178214  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.178697  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.178866  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.179194  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.179273  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.179515  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.179815  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.180170  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.180452  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.180542  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.180916  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.181236  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.181435  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.181595  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.181958  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.182271  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.182683  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.182700  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.183353  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.183602  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.183705  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.183912  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.184745  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.184842  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.185393  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.185872  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.186341  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.187024  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.187291  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.188234  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.189171  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.190201  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.191232  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.192385  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.195676  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.196137  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.196574  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.197012  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.197465  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.197917  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.198374  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.198852  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.199152  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.199648  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.199808  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.200100  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.200522  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.200634  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.201114  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.201274  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.201575  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.202156  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.202254  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.202655  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.203208  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.203572  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.204169  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.204721  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.204748  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.204935  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.205229  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.205893  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.205904  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.206250  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.206409  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.207093  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.207109  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.207569  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.208028  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.208746  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.208763  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.209681  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.210465  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.210477  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.211187  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.211975  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.213158  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.214141  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.214664  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.214737  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.215030  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.215368  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.215699  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.216073  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.216304  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.216483  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.216845  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.217209  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.217592  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.217956  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.218312  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.218435  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.218874  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.219099  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.219419  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.219537  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.219996  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.220012  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.220466  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.220569  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.220864  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.221155  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.221273  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.221795  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.221811  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.222299  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.222403  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.222722  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.222906  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.223098  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.223539  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.223551  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.224092  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.224104  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.224354  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.224464  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.224885  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.224984  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.225084  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.225475  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.225799  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.225920  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.226018  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.226335  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.226516  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.226745  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.227078  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.227092  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.227747  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.227795  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.228360  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.228375  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.228777  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.228952  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.229295  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.229396  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.229674  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.230157  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.230245  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.230651  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.230989  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.231100  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.231160  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.231742  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.231753  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.232146  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.232762  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.232848  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.233201  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.233381  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.233652  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.233834  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.234106  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.234275  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.234504  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.234794  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.234950  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.235221  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.235386  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.235877  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.235956  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.236256  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.236260  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.236861  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.237035  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.237057  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.237762  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.237838  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.237848  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.238324  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.238344  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.238877  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.238893  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.239393  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.239495  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.239822  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.239979  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.240193  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.240547  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.240663  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.241172  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.241185  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.241612  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.241770  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.241996  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.242116  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.242397  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.242543  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.242755  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.243077  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.243147  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.243262  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.243883  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.243895  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.243924  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.244525  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.244643  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.244715  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.245241  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.245282  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.245433  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.245918  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.245963  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.246131  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.246424  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.246526  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.246860  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.247041  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 5/24\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.1438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1729534015.247136  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.247640  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.247738  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.247842  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.248057  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.248581  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.248713  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.248731  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.249375  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.249449  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.249551  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.249793  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.250168  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.250354  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.250449  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.251010  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.251025  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.251586  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.251690  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.252064  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.252331  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.252601  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.253072  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.253180  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.253760  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.253863  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.254259  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.254682  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.254877  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.255470  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.256067  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.256772  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.256830  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.257143  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.257505  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.257674  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.258073  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.258228  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.258522  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.259025  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.259091  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.259415  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.259953  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.260020  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.260615  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.260921  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.261377  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.261389  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.261843  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.262450  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.262563  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.263002  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.263349  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.263464  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.263845  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.264056  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.264268  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.264947  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.265547  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.266293  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.266393  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.266758  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.267170  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.267285  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.267648  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.267879  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.268089  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.268469  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.269078  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.269498  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.270149  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.270442  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.270890  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.270903  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.271211  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.271635  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.271706  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.271945  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.272242  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.272623  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.272702  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.273008  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.273436  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.273506  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.273766  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.274086  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.274344  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.274441  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.274872  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.274968  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.275242  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.275539  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.275647  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.276040  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.276055  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.276478  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.276581  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.276819  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.277106  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.277218  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.277623  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.277637  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.278091  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.278181  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.278549  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.278657  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.278905  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.279199  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.279308  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.279747  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.279759  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.279875  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.280276  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.280423  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.280454  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.280769  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.281095  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.281116  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.281337  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.281487  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.282013  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.282096  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.282110  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.282756  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.282841  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.282853  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.283327  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.283338  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.283482  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.283926  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.283938  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.284412  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.284502  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.285070  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.285078  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.285515  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.285763  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.286040  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.286431  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.286532  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.287108  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.287117  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.287465  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.287765  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.287875  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.288217  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.288557  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.288930  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.289244  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.289319  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.289874  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.289899  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.290385  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.290403  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.290888  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.290976  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.291291  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.291501  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.291674  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.292145  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.292226  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.292707  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.292784  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.292843  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.293110  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.293607  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.293638  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.293712  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.294115  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.294220  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.294503  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.294791  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.294902  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.295329  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.295343  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.296039  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.296108  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.296498  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.296618  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.296965  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.297086  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.297319  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.297590  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.297763  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.298191  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.298292  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.298787  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.298804  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.298950  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.299187  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.299618  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.299688  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.299799  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.300003  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.300591  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.300660  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.300684  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.301155  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.301333  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.301641  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.301653  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.301935  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.302116  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.302472  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.302650  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.302672  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.303221  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.303384  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.303401  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.303706  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.303954  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.304179  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.304659  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.305252  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.305822  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.306496  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.307332  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.307414  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.307741  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.308223  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.308301  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.308580  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.308924  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.309253  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.309614  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.310205  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.310609  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.310822  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.311191  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.311309  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.312013  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.312024  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.312611  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.313288  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.313960  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.314152  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.314695  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.315015  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.315137  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.315378  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.315726  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.316087  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.316657  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.317355  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.317775  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.317878  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.317972  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.318237  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.318436  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.318591  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.318810  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.319173  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.319749  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.320188  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.321025  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.321991  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.322006  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.322128  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.322361  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.322715  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.323211  408312 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.323325  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.323394  408315 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.324015  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.324467  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.324860  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.325872  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534015.326860  408310 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1466"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 18:06:55.955111: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-10-21 18:06:55.955241: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-10-21 18:06:55.955384: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "W0000 00:00:1729534016.519975  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.520458  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.525909  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.526144  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.526350  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.526413  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.526642  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.527412  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.527598  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.527622  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.528494  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.528483  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.528620  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.529050  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.529198  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.529363  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.529815  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.529891  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.530116  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.530578  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.530587  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.531004  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.531177  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.531180  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.531575  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.531756  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.531886  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.532135  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.532495  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.532570  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.532737  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.533152  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.533208  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.533327  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.533720  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.533924  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.534041  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.534600  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.534592  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.534748  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.535185  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.535373  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.535396  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.535938  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.536104  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.536169  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.536500  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.536703  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.536890  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.537035  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.537276  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.537608  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.537680  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.537867  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.538303  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.538384  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.538528  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.539097  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.539111  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.539224  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.539662  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.539698  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.540070  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.540300  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.540368  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.540498  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.540874  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.541080  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.541181  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.541519  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.541705  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.541787  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.542201  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.542464  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.542475  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.542892  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.543033  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.543107  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.543623  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.543775  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.543823  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.544085  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.544500  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.544723  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.544733  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.545186  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.545358  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.545478  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.545722  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.546050  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.546281  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.546455  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.546814  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.546816  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.547000  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.547451  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.547673  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.547698  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.548390  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.548524  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.548618  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.549276  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.549280  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.549404  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.549954  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.549956  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.550200  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.550779  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.550891  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.551083  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.551854  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.551947  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.552617  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.553326  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.554110  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.576679  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.577067  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.577199  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.577614  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.577700  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.578109  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.578173  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.578178  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.578623  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.578935  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.578978  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.579122  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.579575  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.579755  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.579759  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.580138  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.580381  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.580407  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.580760  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.581003  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.581081  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.581248  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.581596  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.581759  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.581765  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.582137  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.582408  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.582433  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.582566  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.583081  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.583084  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.583193  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.583588  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.583688  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.583847  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.584237  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.584259  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.584392  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.584823  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.584870  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.585224  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.585373  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.585388  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.585829  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.585839  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.586459  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.586529  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.586542  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.587124  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.587175  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.587504  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.587663  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.587899  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.588167  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.588386  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.588600  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.589166  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.589212  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.589319  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.589961  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.589980  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.590100  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.590624  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.590659  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.590791  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.591239  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.591349  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.591797  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.591992  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.592316  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.592775  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.593095  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.599303  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.599588  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.599883  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.600184  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.600487  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.600790  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.601151  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.601630  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.601949  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.602298  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.602623  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.602942  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.603255  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.603590  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.604010  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.604346  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.604692  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.605123  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.605592  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.607660  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.607705  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.608112  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.608198  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.608530  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.608616  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.608945  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.609033  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.609348  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.609424  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.609790  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.609876  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.610220  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.610294  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.610649  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.610726  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.611058  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.611142  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.611518  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.611594  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.611960  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.611988  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.612047  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.612631  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.612653  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.612674  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.612967  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.613528  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.613550  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.613566  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.613863  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.614470  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.614494  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.614506  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.614822  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.615134  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.615445  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.615792  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.615912  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.616011  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.616349  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.616694  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.616993  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.617167  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.617366  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.617923  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.618151  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.618256  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.618780  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.618983  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.619444  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.619729  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.619919  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.620269  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.621480  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.622310  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.623231  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.636555  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.636556  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.636916  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.636920  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.637274  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.637279  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.637692  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.637770  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.638127  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.638206  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.638548  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.638631  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.638975  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.639054  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.639408  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.639484  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.640060  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.640072  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.640189  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.640598  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.640600  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.640713  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.641109  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.641119  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.641226  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.641656  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.641758  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.641844  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.642256  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.642364  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.642440  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.642891  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.642930  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.643040  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.643500  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.643576  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.643595  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.644217  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.644231  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.644256  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.644586  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.645131  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.645208  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.645216  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.645624  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.645742  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.645748  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.645998  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.646510  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.646627  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.646632  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.647030  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.647168  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.647245  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.647461  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.648020  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.648026  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.648130  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.648606  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.648611  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.648879  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.649471  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.649543  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.649551  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.650485  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.650921  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.651508  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.651950  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.652494  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.653170  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.655965  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.656064  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.656472  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.656548  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.656957  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.657035  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.657426  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.657507  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.657922  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.658008  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.658388  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.658467  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.658924  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.659000  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.659293  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.659413  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.659532  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.659980  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.659981  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.660078  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.660491  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.660735  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.660817  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.660934  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.661383  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.661494  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.661574  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.661976  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.662150  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.662169  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.662585  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.663207  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.663289  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.663401  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.663591  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.664064  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.664457  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.664639  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.664657  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.665100  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.666174  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.666557  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.666746  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.667244  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.667902  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.668097  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.669370  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.670095  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.670299  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.670711  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.671472  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.671661  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.673019  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.673144  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.673314  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.674390  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.675462  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.705947  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.706333  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.706510  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.706733  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.706910  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.707102  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.707294  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.707493  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.707665  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.707887  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.708108  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.708395  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.708457  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.708561  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.709031  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.709056  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.709154  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.709720  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.709724  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.709826  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.710390  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.710399  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.710495  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.711041  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.711050  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.711146  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.711701  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.711721  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.711810  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.712391  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.712400  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.712502  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.712917  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.713036  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.713042  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.713343  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.713595  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.713625  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.713792  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.714300  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.714328  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.714409  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.715100  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.715103  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.715108  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.715698  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.715818  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.715893  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.716242  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.716423  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.716918  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.716938  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.717502  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.717580  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.718163  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.718265  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.718614  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.718837  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.719270  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.719460  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.719719  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.720477  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.720570  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.720809  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.721866  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.722990  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.727469  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.727600  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.727973  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.728148  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.728419  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.728592  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.728924  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.729091  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.729356  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.729527  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.729822  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.729826  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.729998  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.730596  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.730603  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.730699  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.731326  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.731333  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.731431  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.732104  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.732118  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.732213  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.732807  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.732813  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.732916  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.733441  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.733573  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.733587  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.734017  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.734196  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.734217  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.734655  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.735166  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.735693  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.735888  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.735968  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.736354  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.736802  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.737590  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.737879  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.738348  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.739439  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.739734  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.740255  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.741491  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.741785  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.742118  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.743576  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.743869  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.744169  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.746244  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.747181  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.747506  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.749863  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.750849  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.751191  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.753557  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.816173  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.816642  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.817274  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.817427  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.817872  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.817993  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.818667  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.818722  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.818742  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.819525  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.819594  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.819604  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.820258  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.820428  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.820440  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.820752  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.821207  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.821220  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.821334  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.822064  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.822142  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.822151  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.822835  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.823006  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.823024  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.823568  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.823736  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.823753  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.824181  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.824499  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.824514  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.824784  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.825166  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.825181  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.825417  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.825888  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.826218  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.826229  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.826517  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.826962  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.827129  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.827806  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.828048  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.829038  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.829051  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.829668  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.830073  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.830091  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.830409  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.831124  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.831213  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.831316  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.832086  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.832299  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.832371  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.832968  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.833252  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.833712  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.834252  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.834430  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.835528  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.835704  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.836224  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.837548  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.837648  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.838129  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.839773  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.845125  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.845722  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.845776  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.846527  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.846621  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.847277  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.847497  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.847510  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.848105  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.848385  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.848398  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.848754  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.849131  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.849216  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.849484  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.850077  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.850156  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.850259  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.850964  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.851106  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.851122  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.852086  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.852164  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.852175  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.853039  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.853043  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.853146  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.853956  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.854030  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.854041  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.854917  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.854937  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.854957  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.855692  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.855709  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.856358  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.857746  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.858505  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.859161  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.861263  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.862062  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.862715  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.864700  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.865533  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.866193  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.868626  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.869492  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.870129  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.872618  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.873509  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.874123  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.875702  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.876618  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.877225  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.882628  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.883623  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534016.884144  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.013079  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.013152  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.013872  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.013967  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.014580  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.014681  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.014984  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.015292  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.015392  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.015687  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.016017  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.016119  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.016335  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.016753  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.017052  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.017130  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.017465  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.017883  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.017976  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.018178  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.018655  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.018866  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.018968  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.019448  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.019730  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.019835  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.020305  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.020506  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.020704  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.021176  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.021457  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.021560  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.021973  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.022416  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.022520  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.022835  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.023277  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.023649  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.024007  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.024174  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.025023  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.026147  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.026795  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.027163  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.027911  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.028267  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.029065  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.029443  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.029522  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.030521  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.030629  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.030850  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.031909  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.032015  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.032282  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.033265  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.033790  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.034700  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.041188  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.042126  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.042634  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.043056  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.043573  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.043875  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.043976  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.044523  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.045056  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.045058  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.045433  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.046196  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.046241  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.046392  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.047289  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.047458  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.047475  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.048194  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.048723  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.048740  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.049065  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.049766  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.049941  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.050167  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.050649  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.050943  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.051301  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.051690  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.051853  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.052314  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.052759  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.052924  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.053197  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.053957  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.054211  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.055236  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.058027  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.059260  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.060552  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.064756  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.066045  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.067349  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.071301  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.071763  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.073953  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.076967  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.078365  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.079659  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.083679  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.085037  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.086422  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.090505  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.091817  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.093313  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.104173  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.105520  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.106982  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.362975  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.363983  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.364264  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.364976  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.365264  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.365948  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.366217  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.367130  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.367244  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.368431  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.368638  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.368683  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.369768  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.370032  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.370034  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.370889  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.371120  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.371215  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.372297  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.372395  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.372500  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.373505  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.373865  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.373882  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.374596  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.375329  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.375332  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.375722  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.376993  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.377075  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.377090  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.378407  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.378636  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.378707  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.379772  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.380052  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.380632  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.381173  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.381977  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.382479  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.383897  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.385812  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.386464  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.387758  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.388383  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.389701  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.390351  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.391901  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.391910  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.392661  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.393835  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.394254  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.395217  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.395850  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.398222  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.402452  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.403136  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.403568  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.403734  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.404242  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.404470  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.404857  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.405192  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.405580  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.405957  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.406304  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.406449  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.406729  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.407217  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.407292  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.408025  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.408108  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.408761  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.409479  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.410226  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.410339  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.411097  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.411523  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.414679  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.414691  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.415743  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.418213  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.418908  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.419291  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.421634  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.422474  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.422720  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.425115  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.425921  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.426210  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.428396  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.429554  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.429626  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.432858  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.435076  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.436365  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.439740  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.554442  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.555094  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.555827  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.555943  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.556457  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.556624  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.557051  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.557275  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.557769  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.557935  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.558604  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.558702  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.559275  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.559435  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.559911  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.560252  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.560386  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.560596  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.560923  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.561207  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.561316  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.561558  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.561990  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.562115  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.562281  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.562598  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.563017  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.563165  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.563271  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 104ms/step - loss: 0.1446 - val_loss: 0.0847 - learning_rate: 0.0100\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1729534017.564011  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.564131  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.564202  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.565208  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.565229  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.565256  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.565899  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.566064  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.566291  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.566546  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.567000  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.567405  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.567487  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.568150  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.568233  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.568722  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.568938  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.569199  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.569705  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.570007  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.570564  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.570644  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.571554  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.571848  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.572588  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.572686  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.573273  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.573740  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.574968  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.575811  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.575914  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.576254  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.578706  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.579074  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.579999  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.581979  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.582917  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.586086  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.595687  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.596159  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.596726  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.597175  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.598043  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.598856  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.599308  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.599803  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.599907  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.600233  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.600643  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.601056  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.601480  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.601741  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.601971  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.602175  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.602778  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.602854  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.603218  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.603661  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.604835  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.604874  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.604934  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.606824  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.606991  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.607007  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.608687  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.608958  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.609764  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.611466  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.611728  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.612796  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.613473  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.615772  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.615781  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.615874  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.619276  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.619611  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.622313  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.622473  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.630573  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.631029  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.631479  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.631921  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.632385  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.633031  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.633502  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.634019  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.634450  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.634895  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.635413  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.635933  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.636461  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.637046  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.637293  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.637596  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.637915  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.637963  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.638126  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.638611  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.638730  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.638829  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.639069  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.639292  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.639564  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.639772  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.640245  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.640620  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.640696  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.640801  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.641098  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.641612  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.641700  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.641800  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.642097  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.642263  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.642769  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.642886  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.642959  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.643544  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.643617  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.643819  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.644206  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.644285  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.644868  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.644940  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.645567  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.645644  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.646290  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.646364  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.647021  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.647100  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.648940  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.649013  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.649351  408301 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.649803  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.649879  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.650854  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.651061  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.651899  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.652181  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.657466  408319 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729534017.657724  408318 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "2024-10-21 18:06:57.687307: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0802"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 18:06:58.545679: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0802 - val_loss: 0.0948 - learning_rate: 0.0100\n",
      "Epoch 3/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0820 - val_loss: 0.0719 - learning_rate: 0.0100\n",
      "Epoch 4/1000\n",
      "\u001b[1m 1/24\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 163ms/step - loss: 0.0748"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 18:06:59.756264: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0884 - val_loss: 0.0774 - learning_rate: 0.0100\n",
      "Epoch 5/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1252 - val_loss: 0.0806 - learning_rate: 0.0100\n",
      "Epoch 6/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1175"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 18:07:02.581772: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1218 - val_loss: 0.0817 - learning_rate: 0.0100\n",
      "Epoch 7/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1230 - val_loss: 0.1127 - learning_rate: 0.0100\n",
      "Epoch 8/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.1211 - val_loss: 0.1432 - learning_rate: 0.0100\n",
      "Epoch 9/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1201 - val_loss: 0.1598 - learning_rate: 0.0100\n",
      "Epoch 10/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1196 - val_loss: 0.1672 - learning_rate: 0.0100\n",
      "Epoch 11/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1173 - val_loss: 0.1791 - learning_rate: 0.0100\n",
      "Epoch 12/1000\n",
      "\u001b[1m 1/24\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 162ms/step - loss: 0.1120"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 18:07:07.832872: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1155 - val_loss: 0.1836 - learning_rate: 0.0100\n",
      "Epoch 13/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1096\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1142 - val_loss: 0.1889 - learning_rate: 0.0100\n",
      "Epoch 14/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1128 - val_loss: 0.1944 - learning_rate: 0.0090\n",
      "Epoch 15/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1103 - val_loss: 0.2035 - learning_rate: 0.0090\n",
      "Epoch 16/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1130 - val_loss: 0.2045 - learning_rate: 0.0090\n",
      "Epoch 17/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1124 - val_loss: 0.2069 - learning_rate: 0.0090\n",
      "Epoch 18/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1098 - val_loss: 0.2080 - learning_rate: 0.0090\n",
      "Epoch 19/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.1083 - val_loss: 0.2204 - learning_rate: 0.0090\n",
      "Epoch 20/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.1085 - val_loss: 0.2210 - learning_rate: 0.0090\n",
      "Epoch 21/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.1116 - val_loss: 0.2167 - learning_rate: 0.0090\n",
      "Epoch 22/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.1019"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 18:07:19.276256: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.1067 - val_loss: 0.2258 - learning_rate: 0.0090\n",
      "Epoch 23/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.1021\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.008099999651312828.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.1069 - val_loss: 0.2222 - learning_rate: 0.0090\n",
      "Epoch 24/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1044 - val_loss: 0.2211 - learning_rate: 0.0081\n",
      "Epoch 25/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1056 - val_loss: 0.2191 - learning_rate: 0.0081\n",
      "Epoch 26/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1042 - val_loss: 0.2189 - learning_rate: 0.0081\n",
      "Epoch 27/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1045 - val_loss: 0.2197 - learning_rate: 0.0081\n",
      "Epoch 28/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1041 - val_loss: 0.2194 - learning_rate: 0.0081\n",
      "Epoch 29/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1046 - val_loss: 0.2218 - learning_rate: 0.0081\n",
      "Epoch 30/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1049 - val_loss: 0.2158 - learning_rate: 0.0081\n",
      "Epoch 31/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1010 - val_loss: 0.2120 - learning_rate: 0.0081\n",
      "Epoch 32/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1008 - val_loss: 0.2041 - learning_rate: 0.0081\n",
      "Epoch 33/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0935\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.007289999350905419.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0976 - val_loss: 0.2009 - learning_rate: 0.0081\n",
      "Epoch 34/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0970 - val_loss: 0.2002 - learning_rate: 0.0073\n",
      "Epoch 35/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0977 - val_loss: 0.1989 - learning_rate: 0.0073\n",
      "Epoch 36/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0968 - val_loss: 0.1995 - learning_rate: 0.0073\n",
      "Epoch 37/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0967 - val_loss: 0.2036 - learning_rate: 0.0073\n",
      "Epoch 38/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0969 - val_loss: 0.1993 - learning_rate: 0.0073\n",
      "Epoch 39/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0967 - val_loss: 0.1980 - learning_rate: 0.0073\n",
      "Epoch 40/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0966 - val_loss: 0.1981 - learning_rate: 0.0073\n",
      "Epoch 41/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0956 - val_loss: 0.1911 - learning_rate: 0.0073\n",
      "Epoch 42/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0930 - val_loss: 0.1910 - learning_rate: 0.0073\n",
      "Epoch 43/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0890\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.006560999248176813.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0928 - val_loss: 0.1794 - learning_rate: 0.0073\n",
      "Epoch 44/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 18:07:41.257065: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0866 - val_loss: 0.1287 - learning_rate: 0.0066\n",
      "Epoch 45/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0553 - val_loss: 0.0797 - learning_rate: 0.0066\n",
      "Epoch 46/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0529 - val_loss: 0.0722 - learning_rate: 0.0066\n",
      "Epoch 47/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0516 - val_loss: 0.1097 - learning_rate: 0.0066\n",
      "Epoch 48/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0498 - val_loss: 0.1273 - learning_rate: 0.0066\n",
      "Epoch 49/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0464 - val_loss: 0.0696 - learning_rate: 0.0066\n",
      "Epoch 50/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0446 - val_loss: 0.0580 - learning_rate: 0.0066\n",
      "Epoch 51/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0438 - val_loss: 0.0634 - learning_rate: 0.0066\n",
      "Epoch 52/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0424 - val_loss: 0.0773 - learning_rate: 0.0066\n",
      "Epoch 53/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0418 - val_loss: 0.0991 - learning_rate: 0.0066\n",
      "Epoch 54/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0413 - val_loss: 0.0983 - learning_rate: 0.0066\n",
      "Epoch 55/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0409 - val_loss: 0.0990 - learning_rate: 0.0066\n",
      "Epoch 56/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0406 - val_loss: 0.1059 - learning_rate: 0.0066\n",
      "Epoch 57/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0404 - val_loss: 0.0978 - learning_rate: 0.0066\n",
      "Epoch 58/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0405 - val_loss: 0.0996 - learning_rate: 0.0066\n",
      "Epoch 59/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0400 - val_loss: 0.0959 - learning_rate: 0.0066\n",
      "Epoch 60/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0401\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.005904899490997195.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0401 - val_loss: 0.0930 - learning_rate: 0.0066\n",
      "Epoch 61/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0396 - val_loss: 0.0960 - learning_rate: 0.0059\n",
      "Epoch 62/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0397 - val_loss: 0.0904 - learning_rate: 0.0059\n",
      "Epoch 63/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0394 - val_loss: 0.0818 - learning_rate: 0.0059\n",
      "Epoch 64/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0393 - val_loss: 0.0770 - learning_rate: 0.0059\n",
      "Epoch 65/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0395 - val_loss: 0.0827 - learning_rate: 0.0059\n",
      "Epoch 66/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0392 - val_loss: 0.0647 - learning_rate: 0.0059\n",
      "Epoch 67/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0395 - val_loss: 0.0746 - learning_rate: 0.0059\n",
      "Epoch 68/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0391 - val_loss: 0.0732 - learning_rate: 0.0059\n",
      "Epoch 69/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0386 - val_loss: 0.0716 - learning_rate: 0.0059\n",
      "Epoch 70/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0386\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.00531440949998796.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0387 - val_loss: 0.0650 - learning_rate: 0.0059\n",
      "Epoch 71/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0384 - val_loss: 0.0724 - learning_rate: 0.0053\n",
      "Epoch 72/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0383 - val_loss: 0.0685 - learning_rate: 0.0053\n",
      "Epoch 73/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0383 - val_loss: 0.0638 - learning_rate: 0.0053\n",
      "Epoch 74/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0377 - val_loss: 0.0659 - learning_rate: 0.0053\n",
      "Epoch 75/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0380 - val_loss: 0.0495 - learning_rate: 0.0053\n",
      "Epoch 76/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0381 - val_loss: 0.0567 - learning_rate: 0.0053\n",
      "Epoch 77/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0378 - val_loss: 0.0561 - learning_rate: 0.0053\n",
      "Epoch 78/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0373 - val_loss: 0.0565 - learning_rate: 0.0053\n",
      "Epoch 79/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0374 - val_loss: 0.0480 - learning_rate: 0.0053\n",
      "Epoch 80/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0372 - val_loss: 0.0613 - learning_rate: 0.0053\n",
      "Epoch 81/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0367 - val_loss: 0.0457 - learning_rate: 0.0053\n",
      "Epoch 82/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0369 - val_loss: 0.0523 - learning_rate: 0.0053\n",
      "Epoch 83/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0366 - val_loss: 0.0422 - learning_rate: 0.0053\n",
      "Epoch 84/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0361 - val_loss: 0.0509 - learning_rate: 0.0053\n",
      "Epoch 85/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0369 - val_loss: 0.0477 - learning_rate: 0.0053\n",
      "Epoch 86/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0361"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 18:08:26.577958: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0363 - val_loss: 0.0420 - learning_rate: 0.0053\n",
      "Epoch 87/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0368 - val_loss: 0.0522 - learning_rate: 0.0053\n",
      "Epoch 88/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0357 - val_loss: 0.0489 - learning_rate: 0.0053\n",
      "Epoch 89/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0350 - val_loss: 0.0646 - learning_rate: 0.0053\n",
      "Epoch 90/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0345 - val_loss: 0.0470 - learning_rate: 0.0053\n",
      "Epoch 91/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0342 - val_loss: 0.0448 - learning_rate: 0.0053\n",
      "Epoch 92/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0340 - val_loss: 0.0421 - learning_rate: 0.0053\n",
      "Epoch 93/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0337 - val_loss: 0.0430 - learning_rate: 0.0053\n",
      "Epoch 94/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0332 - val_loss: 0.0446 - learning_rate: 0.0053\n",
      "Epoch 95/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0329 - val_loss: 0.0433 - learning_rate: 0.0053\n",
      "Epoch 96/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0323\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.004782968759536744.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0326 - val_loss: 0.0508 - learning_rate: 0.0053\n",
      "Epoch 97/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0322 - val_loss: 0.0440 - learning_rate: 0.0048\n",
      "Epoch 98/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0317 - val_loss: 0.0408 - learning_rate: 0.0048\n",
      "Epoch 99/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0312 - val_loss: 0.0438 - learning_rate: 0.0048\n",
      "Epoch 100/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0305 - val_loss: 0.0472 - learning_rate: 0.0048\n",
      "Epoch 101/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0306 - val_loss: 0.0454 - learning_rate: 0.0048\n",
      "Epoch 102/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0297 - val_loss: 0.0429 - learning_rate: 0.0048\n",
      "Epoch 103/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0295 - val_loss: 0.0478 - learning_rate: 0.0048\n",
      "Epoch 104/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0290 - val_loss: 0.0442 - learning_rate: 0.0048\n",
      "Epoch 105/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0286 - val_loss: 0.0425 - learning_rate: 0.0048\n",
      "Epoch 106/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0281 - val_loss: 0.0419 - learning_rate: 0.0048\n",
      "Epoch 107/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0279 - val_loss: 0.0512 - learning_rate: 0.0048\n",
      "Epoch 108/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0269\n",
      "Epoch 108: ReduceLROnPlateau reducing learning rate to 0.0043046717997640375.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0273 - val_loss: 0.0442 - learning_rate: 0.0048\n",
      "Epoch 109/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0269 - val_loss: 0.0472 - learning_rate: 0.0043\n",
      "Epoch 110/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0266 - val_loss: 0.0431 - learning_rate: 0.0043\n",
      "Epoch 111/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0263 - val_loss: 0.0553 - learning_rate: 0.0043\n",
      "Epoch 112/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0259 - val_loss: 0.0503 - learning_rate: 0.0043\n",
      "Epoch 113/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0252 - val_loss: 0.0429 - learning_rate: 0.0043\n",
      "Epoch 114/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0252 - val_loss: 0.0422 - learning_rate: 0.0043\n",
      "Epoch 115/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0248 - val_loss: 0.0485 - learning_rate: 0.0043\n",
      "Epoch 116/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0246 - val_loss: 0.0443 - learning_rate: 0.0043\n",
      "Epoch 117/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0242 - val_loss: 0.0433 - learning_rate: 0.0043\n",
      "Epoch 118/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0230\n",
      "Epoch 118: ReduceLROnPlateau reducing learning rate to 0.0038742044940590858.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0236 - val_loss: 0.0513 - learning_rate: 0.0043\n",
      "Epoch 119/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0232 - val_loss: 0.0421 - learning_rate: 0.0039\n",
      "Epoch 120/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0228 - val_loss: 0.0409 - learning_rate: 0.0039\n",
      "Epoch 121/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0222 - val_loss: 0.0416 - learning_rate: 0.0039\n",
      "Epoch 122/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0221 - val_loss: 0.0448 - learning_rate: 0.0039\n",
      "Epoch 123/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0220 - val_loss: 0.0480 - learning_rate: 0.0039\n",
      "Epoch 124/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0214 - val_loss: 0.0488 - learning_rate: 0.0039\n",
      "Epoch 125/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0214 - val_loss: 0.0461 - learning_rate: 0.0039\n",
      "Epoch 126/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0211 - val_loss: 0.0475 - learning_rate: 0.0039\n",
      "Epoch 127/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0210 - val_loss: 0.0593 - learning_rate: 0.0039\n",
      "Epoch 128/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0198\n",
      "Epoch 128: ReduceLROnPlateau reducing learning rate to 0.003486784128472209.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.0205 - val_loss: 0.0433 - learning_rate: 0.0039\n",
      "Epoch 129/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0203 - val_loss: 0.0514 - learning_rate: 0.0035\n",
      "Epoch 130/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0196 - val_loss: 0.0526 - learning_rate: 0.0035\n",
      "Epoch 131/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0193 - val_loss: 0.0490 - learning_rate: 0.0035\n",
      "Epoch 132/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0192 - val_loss: 0.0510 - learning_rate: 0.0035\n",
      "Epoch 133/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0190 - val_loss: 0.0510 - learning_rate: 0.0035\n",
      "Epoch 134/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0185 - val_loss: 0.0439 - learning_rate: 0.0035\n",
      "Epoch 135/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0184 - val_loss: 0.0512 - learning_rate: 0.0035\n",
      "Epoch 136/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0183 - val_loss: 0.0430 - learning_rate: 0.0035\n",
      "Epoch 137/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0178 - val_loss: 0.0452 - learning_rate: 0.0035\n",
      "Epoch 138/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0169\n",
      "Epoch 138: ReduceLROnPlateau reducing learning rate to 0.003138105757534504.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0176 - val_loss: 0.0480 - learning_rate: 0.0035\n",
      "Epoch 139/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0173 - val_loss: 0.0464 - learning_rate: 0.0031\n",
      "Epoch 140/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0172 - val_loss: 0.0484 - learning_rate: 0.0031\n",
      "Epoch 141/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0168 - val_loss: 0.0508 - learning_rate: 0.0031\n",
      "Epoch 142/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0167 - val_loss: 0.0493 - learning_rate: 0.0031\n",
      "Epoch 143/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0163 - val_loss: 0.0459 - learning_rate: 0.0031\n",
      "Epoch 144/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0162 - val_loss: 0.0487 - learning_rate: 0.0031\n",
      "Epoch 145/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0160 - val_loss: 0.0481 - learning_rate: 0.0031\n",
      "Epoch 146/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0156 - val_loss: 0.0482 - learning_rate: 0.0031\n",
      "Epoch 147/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0156 - val_loss: 0.0464 - learning_rate: 0.0031\n",
      "Epoch 148/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0149\n",
      "Epoch 148: ReduceLROnPlateau reducing learning rate to 0.0028242952656000854.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0156 - val_loss: 0.0486 - learning_rate: 0.0031\n",
      "Epoch 149/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0153 - val_loss: 0.0495 - learning_rate: 0.0028\n",
      "Epoch 150/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0149 - val_loss: 0.0474 - learning_rate: 0.0028\n",
      "Epoch 151/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0149 - val_loss: 0.0507 - learning_rate: 0.0028\n",
      "Epoch 152/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0147 - val_loss: 0.0477 - learning_rate: 0.0028\n",
      "Epoch 153/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0145 - val_loss: 0.0534 - learning_rate: 0.0028\n",
      "Epoch 154/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0142 - val_loss: 0.0499 - learning_rate: 0.0028\n",
      "Epoch 155/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0141 - val_loss: 0.0474 - learning_rate: 0.0028\n",
      "Epoch 156/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0141 - val_loss: 0.0561 - learning_rate: 0.0028\n",
      "Epoch 157/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0138 - val_loss: 0.0500 - learning_rate: 0.0028\n",
      "Epoch 158/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0131\n",
      "Epoch 158: ReduceLROnPlateau reducing learning rate to 0.0025418657809495927.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0139 - val_loss: 0.0503 - learning_rate: 0.0028\n",
      "Epoch 159/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0136 - val_loss: 0.0478 - learning_rate: 0.0025\n",
      "Epoch 160/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0132 - val_loss: 0.0499 - learning_rate: 0.0025\n",
      "Epoch 161/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0132 - val_loss: 0.0499 - learning_rate: 0.0025\n",
      "Epoch 162/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0130 - val_loss: 0.0488 - learning_rate: 0.0025\n",
      "Epoch 163/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0131 - val_loss: 0.0503 - learning_rate: 0.0025\n",
      "Epoch 164/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0124 - val_loss: 0.0507 - learning_rate: 0.0025\n",
      "Epoch 165/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0125 - val_loss: 0.0507 - learning_rate: 0.0025\n",
      "Epoch 166/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0126 - val_loss: 0.0537 - learning_rate: 0.0025\n",
      "Epoch 167/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0120 - val_loss: 0.0525 - learning_rate: 0.0025\n",
      "Epoch 168/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0114\n",
      "Epoch 168: ReduceLROnPlateau reducing learning rate to 0.0022876791190356016.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0121 - val_loss: 0.0502 - learning_rate: 0.0025\n",
      "Epoch 169/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0120 - val_loss: 0.0540 - learning_rate: 0.0023\n",
      "Epoch 170/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0116 - val_loss: 0.0548 - learning_rate: 0.0023\n",
      "Epoch 171/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0116 - val_loss: 0.0513 - learning_rate: 0.0023\n",
      "Epoch 172/1000\n",
      "\u001b[1m 1/24\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - loss: 0.0113"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 18:09:57.211512: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0116 - val_loss: 0.0503 - learning_rate: 0.0023\n",
      "Epoch 173/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0114 - val_loss: 0.0539 - learning_rate: 0.0023\n",
      "Epoch 174/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0112 - val_loss: 0.0521 - learning_rate: 0.0023\n",
      "Epoch 175/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0110 - val_loss: 0.0511 - learning_rate: 0.0023\n",
      "Epoch 176/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0108 - val_loss: 0.0554 - learning_rate: 0.0023\n",
      "Epoch 177/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0106 - val_loss: 0.0574 - learning_rate: 0.0023\n",
      "Epoch 178/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0101\n",
      "Epoch 178: ReduceLROnPlateau reducing learning rate to 0.0020589112071320416.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0107 - val_loss: 0.0590 - learning_rate: 0.0023\n",
      "Epoch 179/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0105 - val_loss: 0.0523 - learning_rate: 0.0021\n",
      "Epoch 180/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0103 - val_loss: 0.0522 - learning_rate: 0.0021\n",
      "Epoch 181/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0101 - val_loss: 0.0570 - learning_rate: 0.0021\n",
      "Epoch 182/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0100 - val_loss: 0.0541 - learning_rate: 0.0021\n",
      "Epoch 183/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0098 - val_loss: 0.0549 - learning_rate: 0.0021\n",
      "Epoch 184/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0098 - val_loss: 0.0615 - learning_rate: 0.0021\n",
      "Epoch 185/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0097 - val_loss: 0.0576 - learning_rate: 0.0021\n",
      "Epoch 186/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0095 - val_loss: 0.0560 - learning_rate: 0.0021\n",
      "Epoch 187/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0092 - val_loss: 0.0593 - learning_rate: 0.0021\n",
      "Epoch 188/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0085\n",
      "Epoch 188: ReduceLROnPlateau reducing learning rate to 0.0018530200235545636.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0091 - val_loss: 0.0557 - learning_rate: 0.0021\n",
      "Epoch 189/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0090 - val_loss: 0.0558 - learning_rate: 0.0019\n",
      "Epoch 190/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0088 - val_loss: 0.0565 - learning_rate: 0.0019\n",
      "Epoch 191/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0085 - val_loss: 0.0565 - learning_rate: 0.0019\n",
      "Epoch 192/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0084 - val_loss: 0.0576 - learning_rate: 0.0019\n",
      "Epoch 193/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0083 - val_loss: 0.0562 - learning_rate: 0.0019\n",
      "Epoch 194/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0083 - val_loss: 0.0603 - learning_rate: 0.0019\n",
      "Epoch 195/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0081 - val_loss: 0.0569 - learning_rate: 0.0019\n",
      "Epoch 196/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0080 - val_loss: 0.0613 - learning_rate: 0.0019\n",
      "Epoch 197/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0079 - val_loss: 0.0572 - learning_rate: 0.0019\n",
      "Epoch 198/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0073\n",
      "Epoch 198: ReduceLROnPlateau reducing learning rate to 0.0016677180421538651.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0077 - val_loss: 0.0590 - learning_rate: 0.0019\n",
      "Epoch 199/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0077 - val_loss: 0.0600 - learning_rate: 0.0017\n",
      "Epoch 200/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0073 - val_loss: 0.0578 - learning_rate: 0.0017\n",
      "Epoch 201/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0072 - val_loss: 0.0588 - learning_rate: 0.0017\n",
      "Epoch 202/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0074 - val_loss: 0.0583 - learning_rate: 0.0017\n",
      "Epoch 203/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0072 - val_loss: 0.0602 - learning_rate: 0.0017\n",
      "Epoch 204/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0070 - val_loss: 0.0599 - learning_rate: 0.0017\n",
      "Epoch 205/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0070 - val_loss: 0.0587 - learning_rate: 0.0017\n",
      "Epoch 206/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0068 - val_loss: 0.0603 - learning_rate: 0.0017\n",
      "Epoch 207/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0068 - val_loss: 0.0607 - learning_rate: 0.0017\n",
      "Epoch 208/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0062\n",
      "Epoch 208: ReduceLROnPlateau reducing learning rate to 0.0015009462484158575.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0065 - val_loss: 0.0623 - learning_rate: 0.0017\n",
      "Epoch 209/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0065 - val_loss: 0.0635 - learning_rate: 0.0015\n",
      "Epoch 210/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0064 - val_loss: 0.0629 - learning_rate: 0.0015\n",
      "Epoch 211/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0063 - val_loss: 0.0618 - learning_rate: 0.0015\n",
      "Epoch 212/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0062 - val_loss: 0.0614 - learning_rate: 0.0015\n",
      "Epoch 213/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0060 - val_loss: 0.0607 - learning_rate: 0.0015\n",
      "Epoch 214/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0060 - val_loss: 0.0612 - learning_rate: 0.0015\n",
      "Epoch 215/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0059 - val_loss: 0.0616 - learning_rate: 0.0015\n",
      "Epoch 216/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0058 - val_loss: 0.0650 - learning_rate: 0.0015\n",
      "Epoch 217/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0056 - val_loss: 0.0622 - learning_rate: 0.0015\n",
      "Epoch 218/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0052\n",
      "Epoch 218: ReduceLROnPlateau reducing learning rate to 0.0013508516130968928.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0056 - val_loss: 0.0632 - learning_rate: 0.0015\n",
      "Epoch 219/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0055 - val_loss: 0.0622 - learning_rate: 0.0014\n",
      "Epoch 220/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0053 - val_loss: 0.0621 - learning_rate: 0.0014\n",
      "Epoch 221/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0053 - val_loss: 0.0651 - learning_rate: 0.0014\n",
      "Epoch 222/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0051 - val_loss: 0.0639 - learning_rate: 0.0014\n",
      "Epoch 223/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0050 - val_loss: 0.0655 - learning_rate: 0.0014\n",
      "Epoch 224/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0051 - val_loss: 0.0647 - learning_rate: 0.0014\n",
      "Epoch 225/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0049 - val_loss: 0.0624 - learning_rate: 0.0014\n",
      "Epoch 226/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0048 - val_loss: 0.0640 - learning_rate: 0.0014\n",
      "Epoch 227/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0048 - val_loss: 0.0644 - learning_rate: 0.0014\n",
      "Epoch 228/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0045\n",
      "Epoch 228: ReduceLROnPlateau reducing learning rate to 0.0012157664517872036.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0048 - val_loss: 0.0652 - learning_rate: 0.0014\n",
      "Epoch 229/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0047 - val_loss: 0.0644 - learning_rate: 0.0012\n",
      "Epoch 230/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0046 - val_loss: 0.0658 - learning_rate: 0.0012\n",
      "Epoch 231/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0045 - val_loss: 0.0663 - learning_rate: 0.0012\n",
      "Epoch 232/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0045 - val_loss: 0.0657 - learning_rate: 0.0012\n",
      "Epoch 233/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0043 - val_loss: 0.0640 - learning_rate: 0.0012\n",
      "Epoch 234/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0043 - val_loss: 0.0674 - learning_rate: 0.0012\n",
      "Epoch 235/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0042 - val_loss: 0.0652 - learning_rate: 0.0012\n",
      "Epoch 236/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0041 - val_loss: 0.0665 - learning_rate: 0.0012\n",
      "Epoch 237/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0041 - val_loss: 0.0658 - learning_rate: 0.0012\n",
      "Epoch 238/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0038\n",
      "Epoch 238: ReduceLROnPlateau reducing learning rate to 0.0010941897751763463.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0041 - val_loss: 0.0666 - learning_rate: 0.0012\n",
      "Epoch 239/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0040 - val_loss: 0.0655 - learning_rate: 0.0011\n",
      "Epoch 240/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0039 - val_loss: 0.0669 - learning_rate: 0.0011\n",
      "Epoch 241/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0039 - val_loss: 0.0665 - learning_rate: 0.0011\n",
      "Epoch 242/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0038 - val_loss: 0.0663 - learning_rate: 0.0011\n",
      "Epoch 243/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0038 - val_loss: 0.0651 - learning_rate: 0.0011\n",
      "Epoch 244/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0037 - val_loss: 0.0687 - learning_rate: 0.0011\n",
      "Epoch 245/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0036 - val_loss: 0.0677 - learning_rate: 0.0011\n",
      "Epoch 246/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0036 - val_loss: 0.0689 - learning_rate: 0.0011\n",
      "Epoch 247/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0036 - val_loss: 0.0665 - learning_rate: 0.0011\n",
      "Epoch 248/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0033\n",
      "Epoch 248: ReduceLROnPlateau reducing learning rate to 0.0009847708395682275.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0035 - val_loss: 0.0675 - learning_rate: 0.0011\n",
      "Epoch 249/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0035 - val_loss: 0.0686 - learning_rate: 9.8477e-04\n",
      "Epoch 250/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0034 - val_loss: 0.0694 - learning_rate: 9.8477e-04\n",
      "Epoch 251/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0034 - val_loss: 0.0665 - learning_rate: 9.8477e-04\n",
      "Epoch 252/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0033 - val_loss: 0.0677 - learning_rate: 9.8477e-04\n",
      "Epoch 253/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0032 - val_loss: 0.0684 - learning_rate: 9.8477e-04\n",
      "Epoch 254/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0033 - val_loss: 0.0670 - learning_rate: 9.8477e-04\n",
      "Epoch 255/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0032 - val_loss: 0.0691 - learning_rate: 9.8477e-04\n",
      "Epoch 256/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0031 - val_loss: 0.0680 - learning_rate: 9.8477e-04\n",
      "Epoch 257/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0031 - val_loss: 0.0677 - learning_rate: 9.8477e-04\n",
      "Epoch 258/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0029\n",
      "Epoch 258: ReduceLROnPlateau reducing learning rate to 0.0008862937451340258.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0031 - val_loss: 0.0705 - learning_rate: 9.8477e-04\n",
      "Epoch 259/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0031 - val_loss: 0.0699 - learning_rate: 8.8629e-04\n",
      "Epoch 260/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0029 - val_loss: 0.0679 - learning_rate: 8.8629e-04\n",
      "Epoch 261/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0029 - val_loss: 0.0696 - learning_rate: 8.8629e-04\n",
      "Epoch 262/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0029 - val_loss: 0.0668 - learning_rate: 8.8629e-04\n",
      "Epoch 263/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0029 - val_loss: 0.0684 - learning_rate: 8.8629e-04\n",
      "Epoch 264/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0028 - val_loss: 0.0691 - learning_rate: 8.8629e-04\n",
      "Epoch 265/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0029 - val_loss: 0.0690 - learning_rate: 8.8629e-04\n",
      "Epoch 266/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0028 - val_loss: 0.0701 - learning_rate: 8.8629e-04\n",
      "Epoch 267/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0028 - val_loss: 0.0717 - learning_rate: 8.8629e-04\n",
      "Epoch 268/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0026\n",
      "Epoch 268: ReduceLROnPlateau reducing learning rate to 0.0007976643915753812.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0027 - val_loss: 0.0696 - learning_rate: 8.8629e-04\n",
      "Epoch 269/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0027 - val_loss: 0.0681 - learning_rate: 7.9766e-04\n",
      "Epoch 270/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0027 - val_loss: 0.0709 - learning_rate: 7.9766e-04\n",
      "Epoch 271/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0027 - val_loss: 0.0692 - learning_rate: 7.9766e-04\n",
      "Epoch 272/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0026 - val_loss: 0.0700 - learning_rate: 7.9766e-04\n",
      "Epoch 273/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0026 - val_loss: 0.0707 - learning_rate: 7.9766e-04\n",
      "Epoch 274/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0026 - val_loss: 0.0690 - learning_rate: 7.9766e-04\n",
      "Epoch 275/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0026 - val_loss: 0.0700 - learning_rate: 7.9766e-04\n",
      "Epoch 276/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0026 - val_loss: 0.0693 - learning_rate: 7.9766e-04\n",
      "Epoch 277/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0025 - val_loss: 0.0704 - learning_rate: 7.9766e-04\n",
      "Epoch 278/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0024\n",
      "Epoch 278: ReduceLROnPlateau reducing learning rate to 0.0007178979576565325.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0025 - val_loss: 0.0692 - learning_rate: 7.9766e-04\n",
      "Epoch 279/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0024 - val_loss: 0.0705 - learning_rate: 7.1790e-04\n",
      "Epoch 280/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0024 - val_loss: 0.0699 - learning_rate: 7.1790e-04\n",
      "Epoch 281/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0024 - val_loss: 0.0690 - learning_rate: 7.1790e-04\n",
      "Epoch 282/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0024 - val_loss: 0.0684 - learning_rate: 7.1790e-04\n",
      "Epoch 283/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0024 - val_loss: 0.0724 - learning_rate: 7.1790e-04\n",
      "Epoch 284/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0023 - val_loss: 0.0714 - learning_rate: 7.1790e-04\n",
      "Epoch 285/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0024 - val_loss: 0.0710 - learning_rate: 7.1790e-04\n",
      "Epoch 286/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0023 - val_loss: 0.0719 - learning_rate: 7.1790e-04\n",
      "Epoch 287/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0023 - val_loss: 0.0716 - learning_rate: 7.1790e-04\n",
      "Epoch 288/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0022\n",
      "Epoch 288: ReduceLROnPlateau reducing learning rate to 0.0006461081618908793.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0023 - val_loss: 0.0717 - learning_rate: 7.1790e-04\n",
      "Epoch 289/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0023 - val_loss: 0.0710 - learning_rate: 6.4611e-04\n",
      "Epoch 290/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0023 - val_loss: 0.0705 - learning_rate: 6.4611e-04\n",
      "Epoch 291/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0022 - val_loss: 0.0710 - learning_rate: 6.4611e-04\n",
      "Epoch 292/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0022 - val_loss: 0.0708 - learning_rate: 6.4611e-04\n",
      "Epoch 293/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0022 - val_loss: 0.0697 - learning_rate: 6.4611e-04\n",
      "Epoch 294/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0022 - val_loss: 0.0714 - learning_rate: 6.4611e-04\n",
      "Epoch 295/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0021 - val_loss: 0.0708 - learning_rate: 6.4611e-04\n",
      "Epoch 296/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0022 - val_loss: 0.0693 - learning_rate: 6.4611e-04\n",
      "Epoch 297/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0021 - val_loss: 0.0715 - learning_rate: 6.4611e-04\n",
      "Epoch 298/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0021\n",
      "Epoch 298: ReduceLROnPlateau reducing learning rate to 0.0005814973614178598.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0022 - val_loss: 0.0711 - learning_rate: 6.4611e-04\n",
      "Epoch 299/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0021 - val_loss: 0.0728 - learning_rate: 5.8150e-04\n",
      "Epoch 300/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0020 - val_loss: 0.0711 - learning_rate: 5.8150e-04\n",
      "Epoch 301/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0021 - val_loss: 0.0712 - learning_rate: 5.8150e-04\n",
      "Epoch 302/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0020 - val_loss: 0.0703 - learning_rate: 5.8150e-04\n",
      "Epoch 303/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0020 - val_loss: 0.0725 - learning_rate: 5.8150e-04\n",
      "Epoch 304/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0020 - val_loss: 0.0711 - learning_rate: 5.8150e-04\n",
      "Epoch 305/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0020 - val_loss: 0.0710 - learning_rate: 5.8150e-04\n",
      "Epoch 306/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0020 - val_loss: 0.0706 - learning_rate: 5.8150e-04\n",
      "Epoch 307/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0020 - val_loss: 0.0711 - learning_rate: 5.8150e-04\n",
      "Epoch 308/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0019\n",
      "Epoch 308: ReduceLROnPlateau reducing learning rate to 0.0005233476462308317.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0020 - val_loss: 0.0711 - learning_rate: 5.8150e-04\n",
      "Epoch 309/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0020 - val_loss: 0.0715 - learning_rate: 5.2335e-04\n",
      "Epoch 310/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0019 - val_loss: 0.0705 - learning_rate: 5.2335e-04\n",
      "Epoch 311/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0019 - val_loss: 0.0718 - learning_rate: 5.2335e-04\n",
      "Epoch 312/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0019 - val_loss: 0.0722 - learning_rate: 5.2335e-04\n",
      "Epoch 313/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0019 - val_loss: 0.0721 - learning_rate: 5.2335e-04\n",
      "Epoch 314/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0019 - val_loss: 0.0714 - learning_rate: 5.2335e-04\n",
      "Epoch 315/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0019 - val_loss: 0.0698 - learning_rate: 5.2335e-04\n",
      "Epoch 316/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0019 - val_loss: 0.0729 - learning_rate: 5.2335e-04\n",
      "Epoch 317/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0019 - val_loss: 0.0726 - learning_rate: 5.2335e-04\n",
      "Epoch 318/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0018\n",
      "Epoch 318: ReduceLROnPlateau reducing learning rate to 0.0004710128763690591.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0019 - val_loss: 0.0714 - learning_rate: 5.2335e-04\n",
      "Epoch 319/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0018 - val_loss: 0.0714 - learning_rate: 4.7101e-04\n",
      "Epoch 320/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0019 - val_loss: 0.0709 - learning_rate: 4.7101e-04\n",
      "Epoch 321/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0018 - val_loss: 0.0712 - learning_rate: 4.7101e-04\n",
      "Epoch 322/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0018 - val_loss: 0.0726 - learning_rate: 4.7101e-04\n",
      "Epoch 323/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0018 - val_loss: 0.0722 - learning_rate: 4.7101e-04\n",
      "Epoch 324/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0018 - val_loss: 0.0714 - learning_rate: 4.7101e-04\n",
      "Epoch 325/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0018 - val_loss: 0.0715 - learning_rate: 4.7101e-04\n",
      "Epoch 326/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0018 - val_loss: 0.0712 - learning_rate: 4.7101e-04\n",
      "Epoch 327/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0018 - val_loss: 0.0727 - learning_rate: 4.7101e-04\n",
      "Epoch 328/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0017\n",
      "Epoch 328: ReduceLROnPlateau reducing learning rate to 0.0004239115834934637.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0017 - val_loss: 0.0710 - learning_rate: 4.7101e-04\n",
      "Epoch 329/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0017 - val_loss: 0.0714 - learning_rate: 4.2391e-04\n",
      "Epoch 330/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0017 - val_loss: 0.0728 - learning_rate: 4.2391e-04\n",
      "Epoch 331/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0017 - val_loss: 0.0723 - learning_rate: 4.2391e-04\n",
      "Epoch 332/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0017 - val_loss: 0.0731 - learning_rate: 4.2391e-04\n",
      "Epoch 333/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0017 - val_loss: 0.0724 - learning_rate: 4.2391e-04\n",
      "Epoch 334/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0017 - val_loss: 0.0710 - learning_rate: 4.2391e-04\n",
      "Epoch 335/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0017 - val_loss: 0.0720 - learning_rate: 4.2391e-04\n",
      "Epoch 336/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0017 - val_loss: 0.0707 - learning_rate: 4.2391e-04\n",
      "Epoch 337/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0017 - val_loss: 0.0736 - learning_rate: 4.2391e-04\n",
      "Epoch 338/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0016\n",
      "Epoch 338: ReduceLROnPlateau reducing learning rate to 0.0003815204225247726.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0017 - val_loss: 0.0733 - learning_rate: 4.2391e-04\n",
      "Epoch 339/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0016 - val_loss: 0.0718 - learning_rate: 3.8152e-04\n",
      "Epoch 340/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0016 - val_loss: 0.0724 - learning_rate: 3.8152e-04\n",
      "Epoch 341/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0017 - val_loss: 0.0718 - learning_rate: 3.8152e-04\n",
      "Epoch 342/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0017 - val_loss: 0.0731 - learning_rate: 3.8152e-04\n",
      "Epoch 343/1000\n",
      "\u001b[1m 1/24\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 162ms/step - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 18:13:00.698020: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0017 - val_loss: 0.0716 - learning_rate: 3.8152e-04\n",
      "Epoch 344/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0016 - val_loss: 0.0726 - learning_rate: 3.8152e-04\n",
      "Epoch 345/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0016 - val_loss: 0.0735 - learning_rate: 3.8152e-04\n",
      "Epoch 346/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0016 - val_loss: 0.0731 - learning_rate: 3.8152e-04\n",
      "Epoch 347/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0016 - val_loss: 0.0736 - learning_rate: 3.8152e-04\n",
      "Epoch 348/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0015\n",
      "Epoch 348: ReduceLROnPlateau reducing learning rate to 0.0003433683828916401.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0016 - val_loss: 0.0728 - learning_rate: 3.8152e-04\n",
      "Epoch 349/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0016 - val_loss: 0.0724 - learning_rate: 3.4337e-04\n",
      "Epoch 350/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0016 - val_loss: 0.0725 - learning_rate: 3.4337e-04\n",
      "Epoch 351/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0016 - val_loss: 0.0741 - learning_rate: 3.4337e-04\n",
      "Epoch 352/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0016 - val_loss: 0.0731 - learning_rate: 3.4337e-04\n",
      "Epoch 353/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0015 - val_loss: 0.0730 - learning_rate: 3.4337e-04\n",
      "Epoch 354/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0016 - val_loss: 0.0734 - learning_rate: 3.4337e-04\n",
      "Epoch 355/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0016 - val_loss: 0.0721 - learning_rate: 3.4337e-04\n",
      "Epoch 356/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0015 - val_loss: 0.0731 - learning_rate: 3.4337e-04\n",
      "Epoch 357/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0015 - val_loss: 0.0735 - learning_rate: 3.4337e-04\n",
      "Epoch 358/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0014\n",
      "Epoch 358: ReduceLROnPlateau reducing learning rate to 0.0003090315498411656.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0015 - val_loss: 0.0729 - learning_rate: 3.4337e-04\n",
      "Epoch 359/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0015 - val_loss: 0.0727 - learning_rate: 3.0903e-04\n",
      "Epoch 360/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0015 - val_loss: 0.0718 - learning_rate: 3.0903e-04\n",
      "Epoch 361/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0015 - val_loss: 0.0728 - learning_rate: 3.0903e-04\n",
      "Epoch 362/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0015 - val_loss: 0.0711 - learning_rate: 3.0903e-04\n",
      "Epoch 363/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0015 - val_loss: 0.0725 - learning_rate: 3.0903e-04\n",
      "Epoch 364/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0015 - val_loss: 0.0720 - learning_rate: 3.0903e-04\n",
      "Epoch 365/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0015 - val_loss: 0.0731 - learning_rate: 3.0903e-04\n",
      "Epoch 366/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0015 - val_loss: 0.0737 - learning_rate: 3.0903e-04\n",
      "Epoch 367/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0015 - val_loss: 0.0735 - learning_rate: 3.0903e-04\n",
      "Epoch 368/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0014\n",
      "Epoch 368: ReduceLROnPlateau reducing learning rate to 0.00027812838961835954.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0015 - val_loss: 0.0745 - learning_rate: 3.0903e-04\n",
      "Epoch 369/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0015 - val_loss: 0.0739 - learning_rate: 2.7813e-04\n",
      "Epoch 370/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0015 - val_loss: 0.0736 - learning_rate: 2.7813e-04\n",
      "Epoch 371/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0015 - val_loss: 0.0735 - learning_rate: 2.7813e-04\n",
      "Epoch 372/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0015 - val_loss: 0.0741 - learning_rate: 2.7813e-04\n",
      "Epoch 373/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0014 - val_loss: 0.0726 - learning_rate: 2.7813e-04\n",
      "Epoch 374/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0014 - val_loss: 0.0717 - learning_rate: 2.7813e-04\n",
      "Epoch 375/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0014 - val_loss: 0.0716 - learning_rate: 2.7813e-04\n",
      "Epoch 376/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0015 - val_loss: 0.0739 - learning_rate: 2.7813e-04\n",
      "Epoch 377/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0014 - val_loss: 0.0736 - learning_rate: 2.7813e-04\n",
      "Epoch 378/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0014\n",
      "Epoch 378: ReduceLROnPlateau reducing learning rate to 0.00025031555851455777.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0014 - val_loss: 0.0735 - learning_rate: 2.7813e-04\n",
      "Epoch 379/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0015 - val_loss: 0.0704 - learning_rate: 2.5032e-04\n",
      "Epoch 380/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0014 - val_loss: 0.0735 - learning_rate: 2.5032e-04\n",
      "Epoch 381/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0014 - val_loss: 0.0725 - learning_rate: 2.5032e-04\n",
      "Epoch 382/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0014 - val_loss: 0.0733 - learning_rate: 2.5032e-04\n",
      "Epoch 383/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0014 - val_loss: 0.0738 - learning_rate: 2.5032e-04\n",
      "Epoch 384/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0014 - val_loss: 0.0738 - learning_rate: 2.5032e-04\n",
      "Epoch 385/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0014 - val_loss: 0.0726 - learning_rate: 2.5032e-04\n",
      "Epoch 386/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0014 - val_loss: 0.0714 - learning_rate: 2.5032e-04\n",
      "Epoch 387/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0014 - val_loss: 0.0718 - learning_rate: 2.5032e-04\n",
      "Epoch 388/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0013\n",
      "Epoch 388: ReduceLROnPlateau reducing learning rate to 0.00022528400004375725.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0014 - val_loss: 0.0721 - learning_rate: 2.5032e-04\n",
      "Epoch 389/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0014 - val_loss: 0.0728 - learning_rate: 2.2528e-04\n",
      "Epoch 390/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0014 - val_loss: 0.0728 - learning_rate: 2.2528e-04\n",
      "Epoch 391/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0014 - val_loss: 0.0714 - learning_rate: 2.2528e-04\n",
      "Epoch 392/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0014 - val_loss: 0.0736 - learning_rate: 2.2528e-04\n",
      "Epoch 393/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0014 - val_loss: 0.0735 - learning_rate: 2.2528e-04\n",
      "Epoch 394/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0725 - learning_rate: 2.2528e-04\n",
      "Epoch 395/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0014 - val_loss: 0.0710 - learning_rate: 2.2528e-04\n",
      "Epoch 396/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0014 - val_loss: 0.0725 - learning_rate: 2.2528e-04\n",
      "Epoch 397/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0014 - val_loss: 0.0734 - learning_rate: 2.2528e-04\n",
      "Epoch 398/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0013\n",
      "Epoch 398: ReduceLROnPlateau reducing learning rate to 0.000202755605278071.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0014 - val_loss: 0.0722 - learning_rate: 2.2528e-04\n",
      "Epoch 399/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0014 - val_loss: 0.0732 - learning_rate: 2.0276e-04\n",
      "Epoch 400/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0014 - val_loss: 0.0724 - learning_rate: 2.0276e-04\n",
      "Epoch 401/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0725 - learning_rate: 2.0276e-04\n",
      "Epoch 402/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0718 - learning_rate: 2.0276e-04\n",
      "Epoch 403/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0723 - learning_rate: 2.0276e-04\n",
      "Epoch 404/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0737 - learning_rate: 2.0276e-04\n",
      "Epoch 405/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0013 - val_loss: 0.0721 - learning_rate: 2.0276e-04\n",
      "Epoch 406/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0014 - val_loss: 0.0725 - learning_rate: 2.0276e-04\n",
      "Epoch 407/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0740 - learning_rate: 2.0276e-04\n",
      "Epoch 408/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0013\n",
      "Epoch 408: ReduceLROnPlateau reducing learning rate to 0.00018248004344059154.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0014 - val_loss: 0.0738 - learning_rate: 2.0276e-04\n",
      "Epoch 409/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0734 - learning_rate: 1.8248e-04\n",
      "Epoch 410/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0741 - learning_rate: 1.8248e-04\n",
      "Epoch 411/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0013 - val_loss: 0.0733 - learning_rate: 1.8248e-04\n",
      "Epoch 412/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0725 - learning_rate: 1.8248e-04\n",
      "Epoch 413/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0723 - learning_rate: 1.8248e-04\n",
      "Epoch 414/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0013 - val_loss: 0.0730 - learning_rate: 1.8248e-04\n",
      "Epoch 415/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0727 - learning_rate: 1.8248e-04\n",
      "Epoch 416/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0751 - learning_rate: 1.8248e-04\n",
      "Epoch 417/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0013 - val_loss: 0.0722 - learning_rate: 1.8248e-04\n",
      "Epoch 418/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0013\n",
      "Epoch 418: ReduceLROnPlateau reducing learning rate to 0.00016423203778686004.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0728 - learning_rate: 1.8248e-04\n",
      "Epoch 419/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0734 - learning_rate: 1.6423e-04\n",
      "Epoch 420/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0724 - learning_rate: 1.6423e-04\n",
      "Epoch 421/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0727 - learning_rate: 1.6423e-04\n",
      "Epoch 422/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0732 - learning_rate: 1.6423e-04\n",
      "Epoch 423/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0722 - learning_rate: 1.6423e-04\n",
      "Epoch 424/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0728 - learning_rate: 1.6423e-04\n",
      "Epoch 425/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0741 - learning_rate: 1.6423e-04\n",
      "Epoch 426/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0725 - learning_rate: 1.6423e-04\n",
      "Epoch 427/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0013 - val_loss: 0.0743 - learning_rate: 1.6423e-04\n",
      "Epoch 428/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0013\n",
      "Epoch 428: ReduceLROnPlateau reducing learning rate to 0.00014780883793719113.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0726 - learning_rate: 1.6423e-04\n",
      "Epoch 429/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0013 - val_loss: 0.0736 - learning_rate: 1.4781e-04\n",
      "Epoch 430/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0731 - learning_rate: 1.4781e-04\n",
      "Epoch 431/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0740 - learning_rate: 1.4781e-04\n",
      "Epoch 432/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0734 - learning_rate: 1.4781e-04\n",
      "Epoch 433/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0733 - learning_rate: 1.4781e-04\n",
      "Epoch 434/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0013 - val_loss: 0.0741 - learning_rate: 1.4781e-04\n",
      "Epoch 435/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0725 - learning_rate: 1.4781e-04\n",
      "Epoch 436/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0732 - learning_rate: 1.4781e-04\n",
      "Epoch 437/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0719 - learning_rate: 1.4781e-04\n",
      "Epoch 438/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0012\n",
      "Epoch 438: ReduceLROnPlateau reducing learning rate to 0.00013302795414347202.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0752 - learning_rate: 1.4781e-04\n",
      "Epoch 439/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0733 - learning_rate: 1.3303e-04\n",
      "Epoch 440/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0757 - learning_rate: 1.3303e-04\n",
      "Epoch 441/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0717 - learning_rate: 1.3303e-04\n",
      "Epoch 442/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0747 - learning_rate: 1.3303e-04\n",
      "Epoch 443/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0725 - learning_rate: 1.3303e-04\n",
      "Epoch 444/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0755 - learning_rate: 1.3303e-04\n",
      "Epoch 445/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0710 - learning_rate: 1.3303e-04\n",
      "Epoch 446/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0733 - learning_rate: 1.3303e-04\n",
      "Epoch 447/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0730 - learning_rate: 1.3303e-04\n",
      "Epoch 448/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0012\n",
      "Epoch 448: ReduceLROnPlateau reducing learning rate to 0.00011972515349043534.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0715 - learning_rate: 1.3303e-04\n",
      "Epoch 449/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0722 - learning_rate: 1.1973e-04\n",
      "Epoch 450/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0739 - learning_rate: 1.1973e-04\n",
      "Epoch 451/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0747 - learning_rate: 1.1973e-04\n",
      "Epoch 452/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0743 - learning_rate: 1.1973e-04\n",
      "Epoch 453/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0746 - learning_rate: 1.1973e-04\n",
      "Epoch 454/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0012 - val_loss: 0.0732 - learning_rate: 1.1973e-04\n",
      "Epoch 455/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0012 - val_loss: 0.0728 - learning_rate: 1.1973e-04\n",
      "Epoch 456/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0012 - val_loss: 0.0728 - learning_rate: 1.1973e-04\n",
      "Epoch 457/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0012 - val_loss: 0.0719 - learning_rate: 1.1973e-04\n",
      "Epoch 458/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0012\n",
      "Epoch 458: ReduceLROnPlateau reducing learning rate to 0.00010775263945106417.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0711 - learning_rate: 1.1973e-04\n",
      "Epoch 459/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0012 - val_loss: 0.0752 - learning_rate: 1.0775e-04\n",
      "Epoch 460/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0013 - val_loss: 0.0725 - learning_rate: 1.0775e-04\n",
      "Epoch 461/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0012 - val_loss: 0.0751 - learning_rate: 1.0775e-04\n",
      "Epoch 462/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0012 - val_loss: 0.0737 - learning_rate: 1.0775e-04\n",
      "Epoch 463/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0012 - val_loss: 0.0729 - learning_rate: 1.0775e-04\n",
      "Epoch 464/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0735 - learning_rate: 1.0775e-04\n",
      "Epoch 465/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0012 - val_loss: 0.0733 - learning_rate: 1.0775e-04\n",
      "Epoch 466/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0735 - learning_rate: 1.0775e-04\n",
      "Epoch 467/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0743 - learning_rate: 1.0775e-04\n",
      "Epoch 468/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0012\n",
      "Epoch 468: ReduceLROnPlateau reducing learning rate to 9.697737550595775e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0735 - learning_rate: 1.0775e-04\n",
      "Epoch 469/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0739 - learning_rate: 9.6977e-05\n",
      "Epoch 470/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0012 - val_loss: 0.0751 - learning_rate: 9.6977e-05\n",
      "Epoch 471/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0738 - learning_rate: 9.6977e-05\n",
      "Epoch 472/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0732 - learning_rate: 9.6977e-05\n",
      "Epoch 473/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0751 - learning_rate: 9.6977e-05\n",
      "Epoch 474/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0727 - learning_rate: 9.6977e-05\n",
      "Epoch 475/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0728 - learning_rate: 9.6977e-05\n",
      "Epoch 476/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0012 - val_loss: 0.0742 - learning_rate: 9.6977e-05\n",
      "Epoch 477/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0733 - learning_rate: 9.6977e-05\n",
      "Epoch 478/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0011\n",
      "Epoch 478: ReduceLROnPlateau reducing learning rate to 8.727963795536197e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0748 - learning_rate: 9.6977e-05\n",
      "Epoch 479/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0734 - learning_rate: 8.7280e-05\n",
      "Epoch 480/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0750 - learning_rate: 8.7280e-05\n",
      "Epoch 481/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0745 - learning_rate: 8.7280e-05\n",
      "Epoch 482/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0738 - learning_rate: 8.7280e-05\n",
      "Epoch 483/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0731 - learning_rate: 8.7280e-05\n",
      "Epoch 484/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0739 - learning_rate: 8.7280e-05\n",
      "Epoch 485/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0741 - learning_rate: 8.7280e-05\n",
      "Epoch 486/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0744 - learning_rate: 8.7280e-05\n",
      "Epoch 487/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0726 - learning_rate: 8.7280e-05\n",
      "Epoch 488/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0012\n",
      "Epoch 488: ReduceLROnPlateau reducing learning rate to 7.85516735049896e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0721 - learning_rate: 8.7280e-05\n",
      "Epoch 489/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0737 - learning_rate: 7.8552e-05\n",
      "Epoch 490/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0738 - learning_rate: 7.8552e-05\n",
      "Epoch 491/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0012 - val_loss: 0.0747 - learning_rate: 7.8552e-05\n",
      "Epoch 492/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0012 - val_loss: 0.0734 - learning_rate: 7.8552e-05\n",
      "Epoch 493/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0747 - learning_rate: 7.8552e-05\n",
      "Epoch 494/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0717 - learning_rate: 7.8552e-05\n",
      "Epoch 495/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0745 - learning_rate: 7.8552e-05\n",
      "Epoch 496/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0736 - learning_rate: 7.8552e-05\n",
      "Epoch 497/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0012 - val_loss: 0.0730 - learning_rate: 7.8552e-05\n",
      "Epoch 498/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0011\n",
      "Epoch 498: ReduceLROnPlateau reducing learning rate to 7.0696507464163e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0717 - learning_rate: 7.8552e-05\n",
      "Epoch 499/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0745 - learning_rate: 7.0697e-05\n",
      "Epoch 500/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0750 - learning_rate: 7.0697e-05\n",
      "Epoch 501/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0729 - learning_rate: 7.0697e-05\n",
      "Epoch 502/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0012 - val_loss: 0.0732 - learning_rate: 7.0697e-05\n",
      "Epoch 503/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0734 - learning_rate: 7.0697e-05\n",
      "Epoch 504/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0732 - learning_rate: 7.0697e-05\n",
      "Epoch 505/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0743 - learning_rate: 7.0697e-05\n",
      "Epoch 506/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0754 - learning_rate: 7.0697e-05\n",
      "Epoch 507/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0727 - learning_rate: 7.0697e-05\n",
      "Epoch 508/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0011\n",
      "Epoch 508: ReduceLROnPlateau reducing learning rate to 6.36268567177467e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0741 - learning_rate: 7.0697e-05\n",
      "Epoch 509/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0749 - learning_rate: 6.3627e-05\n",
      "Epoch 510/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0725 - learning_rate: 6.3627e-05\n",
      "Epoch 511/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0749 - learning_rate: 6.3627e-05\n",
      "Epoch 512/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0718 - learning_rate: 6.3627e-05\n",
      "Epoch 513/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0727 - learning_rate: 6.3627e-05\n",
      "Epoch 514/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0755 - learning_rate: 6.3627e-05\n",
      "Epoch 515/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0715 - learning_rate: 6.3627e-05\n",
      "Epoch 516/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0727 - learning_rate: 6.3627e-05\n",
      "Epoch 517/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0748 - learning_rate: 6.3627e-05\n",
      "Epoch 518/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0011\n",
      "Epoch 518: ReduceLROnPlateau reducing learning rate to 5.726417366531678e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0733 - learning_rate: 6.3627e-05\n",
      "Epoch 519/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0734 - learning_rate: 5.7264e-05\n",
      "Epoch 520/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0740 - learning_rate: 5.7264e-05\n",
      "Epoch 521/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0742 - learning_rate: 5.7264e-05\n",
      "Epoch 522/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0732 - learning_rate: 5.7264e-05\n",
      "Epoch 523/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0734 - learning_rate: 5.7264e-05\n",
      "Epoch 524/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0739 - learning_rate: 5.7264e-05\n",
      "Epoch 525/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0746 - learning_rate: 5.7264e-05\n",
      "Epoch 526/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0726 - learning_rate: 5.7264e-05\n",
      "Epoch 527/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0745 - learning_rate: 5.7264e-05\n",
      "Epoch 528/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0011\n",
      "Epoch 528: ReduceLROnPlateau reducing learning rate to 5.1537755643948914e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0732 - learning_rate: 5.7264e-05\n",
      "Epoch 529/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0736 - learning_rate: 5.1538e-05\n",
      "Epoch 530/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0734 - learning_rate: 5.1538e-05\n",
      "Epoch 531/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0012 - val_loss: 0.0738 - learning_rate: 5.1538e-05\n",
      "Epoch 532/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0749 - learning_rate: 5.1538e-05\n",
      "Epoch 533/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0728 - learning_rate: 5.1538e-05\n",
      "Epoch 534/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0730 - learning_rate: 5.1538e-05\n",
      "Epoch 535/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0750 - learning_rate: 5.1538e-05\n",
      "Epoch 536/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0736 - learning_rate: 5.1538e-05\n",
      "Epoch 537/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0739 - learning_rate: 5.1538e-05\n",
      "Epoch 538/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0011\n",
      "Epoch 538: ReduceLROnPlateau reducing learning rate to 4.638397876988165e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0750 - learning_rate: 5.1538e-05\n",
      "Epoch 539/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0738 - learning_rate: 4.6384e-05\n",
      "Epoch 540/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0735 - learning_rate: 4.6384e-05\n",
      "Epoch 541/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0730 - learning_rate: 4.6384e-05\n",
      "Epoch 542/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0733 - learning_rate: 4.6384e-05\n",
      "Epoch 543/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0745 - learning_rate: 4.6384e-05\n",
      "Epoch 544/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0731 - learning_rate: 4.6384e-05\n",
      "Epoch 545/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0735 - learning_rate: 4.6384e-05\n",
      "Epoch 546/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0742 - learning_rate: 4.6384e-05\n",
      "Epoch 547/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0741 - learning_rate: 4.6384e-05\n",
      "Epoch 548/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0011\n",
      "Epoch 548: ReduceLROnPlateau reducing learning rate to 4.174558089289349e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0740 - learning_rate: 4.6384e-05\n",
      "Epoch 549/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0713 - learning_rate: 4.1746e-05\n",
      "Epoch 550/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0740 - learning_rate: 4.1746e-05\n",
      "Epoch 551/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0730 - learning_rate: 4.1746e-05\n",
      "Epoch 552/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0739 - learning_rate: 4.1746e-05\n",
      "Epoch 553/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0725 - learning_rate: 4.1746e-05\n",
      "Epoch 554/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0746 - learning_rate: 4.1746e-05\n",
      "Epoch 555/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0744 - learning_rate: 4.1746e-05\n",
      "Epoch 556/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0739 - learning_rate: 4.1746e-05\n",
      "Epoch 557/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0744 - learning_rate: 4.1746e-05\n",
      "Epoch 558/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0010\n",
      "Epoch 558: ReduceLROnPlateau reducing learning rate to 3.7571023131022234e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0743 - learning_rate: 4.1746e-05\n",
      "Epoch 559/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0732 - learning_rate: 3.7571e-05\n",
      "Epoch 560/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0752 - learning_rate: 3.7571e-05\n",
      "Epoch 561/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0740 - learning_rate: 3.7571e-05\n",
      "Epoch 562/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0741 - learning_rate: 3.7571e-05\n",
      "Epoch 563/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0725 - learning_rate: 3.7571e-05\n",
      "Epoch 564/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0759 - learning_rate: 3.7571e-05\n",
      "Epoch 565/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0740 - learning_rate: 3.7571e-05\n",
      "Epoch 566/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0746 - learning_rate: 3.7571e-05\n",
      "Epoch 567/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0743 - learning_rate: 3.7571e-05\n",
      "Epoch 568/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0011\n",
      "Epoch 568: ReduceLROnPlateau reducing learning rate to 3.381392016308382e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0747 - learning_rate: 3.7571e-05\n",
      "Epoch 569/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0755 - learning_rate: 3.3814e-05\n",
      "Epoch 570/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0723 - learning_rate: 3.3814e-05\n",
      "Epoch 571/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0743 - learning_rate: 3.3814e-05\n",
      "Epoch 572/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0730 - learning_rate: 3.3814e-05\n",
      "Epoch 573/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0738 - learning_rate: 3.3814e-05\n",
      "Epoch 574/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0721 - learning_rate: 3.3814e-05\n",
      "Epoch 575/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0743 - learning_rate: 3.3814e-05\n",
      "Epoch 576/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0732 - learning_rate: 3.3814e-05\n",
      "Epoch 577/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0724 - learning_rate: 3.3814e-05\n",
      "Epoch 578/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0011\n",
      "Epoch 578: ReduceLROnPlateau reducing learning rate to 3.043252945644781e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0744 - learning_rate: 3.3814e-05\n",
      "Epoch 579/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0733 - learning_rate: 3.0433e-05\n",
      "Epoch 580/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0734 - learning_rate: 3.0433e-05\n",
      "Epoch 581/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0731 - learning_rate: 3.0433e-05\n",
      "Epoch 582/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0733 - learning_rate: 3.0433e-05\n",
      "Epoch 583/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0722 - learning_rate: 3.0433e-05\n",
      "Epoch 584/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0719 - learning_rate: 3.0433e-05\n",
      "Epoch 585/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0731 - learning_rate: 3.0433e-05\n",
      "Epoch 586/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0747 - learning_rate: 3.0433e-05\n",
      "Epoch 587/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0730 - learning_rate: 3.0433e-05\n",
      "Epoch 588/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0010\n",
      "Epoch 588: ReduceLROnPlateau reducing learning rate to 2.738927651080303e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0735 - learning_rate: 3.0433e-05\n",
      "Epoch 589/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0742 - learning_rate: 2.7389e-05\n",
      "Epoch 590/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0736 - learning_rate: 2.7389e-05\n",
      "Epoch 591/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0725 - learning_rate: 2.7389e-05\n",
      "Epoch 592/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0750 - learning_rate: 2.7389e-05\n",
      "Epoch 593/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0735 - learning_rate: 2.7389e-05\n",
      "Epoch 594/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0723 - learning_rate: 2.7389e-05\n",
      "Epoch 595/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0747 - learning_rate: 2.7389e-05\n",
      "Epoch 596/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0724 - learning_rate: 2.7389e-05\n",
      "Epoch 597/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0738 - learning_rate: 2.7389e-05\n",
      "Epoch 598/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0011\n",
      "Epoch 598: ReduceLROnPlateau reducing learning rate to 2.4650348859722725e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0747 - learning_rate: 2.7389e-05\n",
      "Epoch 599/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0759 - learning_rate: 2.4650e-05\n",
      "Epoch 600/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0745 - learning_rate: 2.4650e-05\n",
      "Epoch 601/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0738 - learning_rate: 2.4650e-05\n",
      "Epoch 602/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0735 - learning_rate: 2.4650e-05\n",
      "Epoch 603/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0736 - learning_rate: 2.4650e-05\n",
      "Epoch 604/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0714 - learning_rate: 2.4650e-05\n",
      "Epoch 605/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0732 - learning_rate: 2.4650e-05\n",
      "Epoch 606/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0754 - learning_rate: 2.4650e-05\n",
      "Epoch 607/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0739 - learning_rate: 2.4650e-05\n",
      "Epoch 608/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0010\n",
      "Epoch 608: ReduceLROnPlateau reducing learning rate to 2.218531462858664e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0750 - learning_rate: 2.4650e-05\n",
      "Epoch 609/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0731 - learning_rate: 2.2185e-05\n",
      "Epoch 610/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0732 - learning_rate: 2.2185e-05\n",
      "Epoch 611/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0732 - learning_rate: 2.2185e-05\n",
      "Epoch 612/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0737 - learning_rate: 2.2185e-05\n",
      "Epoch 613/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0749 - learning_rate: 2.2185e-05\n",
      "Epoch 614/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0748 - learning_rate: 2.2185e-05\n",
      "Epoch 615/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0730 - learning_rate: 2.2185e-05\n",
      "Epoch 616/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0731 - learning_rate: 2.2185e-05\n",
      "Epoch 617/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0735 - learning_rate: 2.2185e-05\n",
      "Epoch 618/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0011\n",
      "Epoch 618: ReduceLROnPlateau reducing learning rate to 1.9966783656855114e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0752 - learning_rate: 2.2185e-05\n",
      "Epoch 619/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0749 - learning_rate: 1.9967e-05\n",
      "Epoch 620/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0730 - learning_rate: 1.9967e-05\n",
      "Epoch 621/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0762 - learning_rate: 1.9967e-05\n",
      "Epoch 622/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0744 - learning_rate: 1.9967e-05\n",
      "Epoch 623/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0738 - learning_rate: 1.9967e-05\n",
      "Epoch 624/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0744 - learning_rate: 1.9967e-05\n",
      "Epoch 625/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0732 - learning_rate: 1.9967e-05\n",
      "Epoch 626/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0745 - learning_rate: 1.9967e-05\n",
      "Epoch 627/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0737 - learning_rate: 1.9967e-05\n",
      "Epoch 628/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0011\n",
      "Epoch 628: ReduceLROnPlateau reducing learning rate to 1.7970104636333417e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0726 - learning_rate: 1.9967e-05\n",
      "Epoch 629/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0742 - learning_rate: 1.7970e-05\n",
      "Epoch 630/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0742 - learning_rate: 1.7970e-05\n",
      "Epoch 631/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0724 - learning_rate: 1.7970e-05\n",
      "Epoch 632/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0725 - learning_rate: 1.7970e-05\n",
      "Epoch 633/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0731 - learning_rate: 1.7970e-05\n",
      "Epoch 634/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0737 - learning_rate: 1.7970e-05\n",
      "Epoch 635/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0755 - learning_rate: 1.7970e-05\n",
      "Epoch 636/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0727 - learning_rate: 1.7970e-05\n",
      "Epoch 637/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0735 - learning_rate: 1.7970e-05\n",
      "Epoch 638/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0011\n",
      "Epoch 638: ReduceLROnPlateau reducing learning rate to 1.6173094991245307e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0747 - learning_rate: 1.7970e-05\n",
      "Epoch 639/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0743 - learning_rate: 1.6173e-05\n",
      "Epoch 640/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0749 - learning_rate: 1.6173e-05\n",
      "Epoch 641/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0736 - learning_rate: 1.6173e-05\n",
      "Epoch 642/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0743 - learning_rate: 1.6173e-05\n",
      "Epoch 643/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0736 - learning_rate: 1.6173e-05\n",
      "Epoch 644/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0729 - learning_rate: 1.6173e-05\n",
      "Epoch 645/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0745 - learning_rate: 1.6173e-05\n",
      "Epoch 646/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0755 - learning_rate: 1.6173e-05\n",
      "Epoch 647/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0738 - learning_rate: 1.6173e-05\n",
      "Epoch 648/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0010\n",
      "Epoch 648: ReduceLROnPlateau reducing learning rate to 1.4555785492120777e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0733 - learning_rate: 1.6173e-05\n",
      "Epoch 649/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0740 - learning_rate: 1.4556e-05\n",
      "Epoch 650/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0742 - learning_rate: 1.4556e-05\n",
      "Epoch 651/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0739 - learning_rate: 1.4556e-05\n",
      "Epoch 652/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0738 - learning_rate: 1.4556e-05\n",
      "Epoch 653/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0746 - learning_rate: 1.4556e-05\n",
      "Epoch 654/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0724 - learning_rate: 1.4556e-05\n",
      "Epoch 655/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0740 - learning_rate: 1.4556e-05\n",
      "Epoch 656/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0730 - learning_rate: 1.4556e-05\n",
      "Epoch 657/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0735 - learning_rate: 1.4556e-05\n",
      "Epoch 658/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0010\n",
      "Epoch 658: ReduceLROnPlateau reducing learning rate to 1.3100206615490606e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0011 - val_loss: 0.0746 - learning_rate: 1.4556e-05\n",
      "Epoch 659/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0731 - learning_rate: 1.3100e-05\n",
      "Epoch 660/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0731 - learning_rate: 1.3100e-05\n",
      "Epoch 661/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0728 - learning_rate: 1.3100e-05\n",
      "Epoch 662/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0731 - learning_rate: 1.3100e-05\n",
      "Epoch 663/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0729 - learning_rate: 1.3100e-05\n",
      "Epoch 664/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0746 - learning_rate: 1.3100e-05\n",
      "Epoch 665/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0724 - learning_rate: 1.3100e-05\n",
      "Epoch 666/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0726 - learning_rate: 1.3100e-05\n",
      "Epoch 667/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0720 - learning_rate: 1.3100e-05\n",
      "Epoch 668/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0010\n",
      "Epoch 668: ReduceLROnPlateau reducing learning rate to 1.1790186363214161e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0741 - learning_rate: 1.3100e-05\n",
      "Epoch 669/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0744 - learning_rate: 1.1790e-05\n",
      "Epoch 670/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0755 - learning_rate: 1.1790e-05\n",
      "Epoch 671/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0745 - learning_rate: 1.1790e-05\n",
      "Epoch 672/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0752 - learning_rate: 1.1790e-05\n",
      "Epoch 673/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0731 - learning_rate: 1.1790e-05\n",
      "Epoch 674/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0729 - learning_rate: 1.1790e-05\n",
      "Epoch 675/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0740 - learning_rate: 1.1790e-05\n",
      "Epoch 676/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0736 - learning_rate: 1.1790e-05\n",
      "Epoch 677/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0729 - learning_rate: 1.1790e-05\n",
      "Epoch 678/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0010\n",
      "Epoch 678: ReduceLROnPlateau reducing learning rate to 1.0611167726892746e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0741 - learning_rate: 1.1790e-05\n",
      "Epoch 679/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0728 - learning_rate: 1.0611e-05\n",
      "Epoch 680/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0746 - learning_rate: 1.0611e-05\n",
      "Epoch 681/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0716 - learning_rate: 1.0611e-05\n",
      "Epoch 682/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0742 - learning_rate: 1.0611e-05\n",
      "Epoch 683/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0734 - learning_rate: 1.0611e-05\n",
      "Epoch 684/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 18:19:07.054320: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0738 - learning_rate: 1.0611e-05\n",
      "Epoch 685/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0748 - learning_rate: 1.0611e-05\n",
      "Epoch 686/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0704 - learning_rate: 1.0611e-05\n",
      "Epoch 687/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0749 - learning_rate: 1.0611e-05\n",
      "Epoch 688/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0010\n",
      "Epoch 688: ReduceLROnPlateau reducing learning rate to 9.550050708639902e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0751 - learning_rate: 1.0611e-05\n",
      "Epoch 689/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0739 - learning_rate: 9.5501e-06\n",
      "Epoch 690/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0730 - learning_rate: 9.5501e-06\n",
      "Epoch 691/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0733 - learning_rate: 9.5501e-06\n",
      "Epoch 692/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0739 - learning_rate: 9.5501e-06\n",
      "Epoch 693/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0730 - learning_rate: 9.5501e-06\n",
      "Epoch 694/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0722 - learning_rate: 9.5501e-06\n",
      "Epoch 695/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0745 - learning_rate: 9.5501e-06\n",
      "Epoch 696/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0743 - learning_rate: 9.5501e-06\n",
      "Epoch 697/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0754 - learning_rate: 9.5501e-06\n",
      "Epoch 698/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0010\n",
      "Epoch 698: ReduceLROnPlateau reducing learning rate to 8.595045801484958e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0744 - learning_rate: 9.5501e-06\n",
      "Epoch 699/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0726 - learning_rate: 8.5950e-06\n",
      "Epoch 700/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0732 - learning_rate: 8.5950e-06\n",
      "Epoch 701/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0743 - learning_rate: 8.5950e-06\n",
      "Epoch 702/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0747 - learning_rate: 8.5950e-06\n",
      "Epoch 703/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0734 - learning_rate: 8.5950e-06\n",
      "Epoch 704/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0767 - learning_rate: 8.5950e-06\n",
      "Epoch 705/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0755 - learning_rate: 8.5950e-06\n",
      "Epoch 706/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0743 - learning_rate: 8.5950e-06\n",
      "Epoch 707/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0732 - learning_rate: 8.5950e-06\n",
      "Epoch 708/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0011\n",
      "Epoch 708: ReduceLROnPlateau reducing learning rate to 7.735541385045509e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0734 - learning_rate: 8.5950e-06\n",
      "Epoch 709/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0748 - learning_rate: 7.7355e-06\n",
      "Epoch 710/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0758 - learning_rate: 7.7355e-06\n",
      "Epoch 711/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0736 - learning_rate: 7.7355e-06\n",
      "Epoch 712/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0011 - val_loss: 0.0733 - learning_rate: 7.7355e-06\n",
      "Epoch 713/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0736 - learning_rate: 7.7355e-06\n",
      "Epoch 714/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0738 - learning_rate: 7.7355e-06\n",
      "Epoch 715/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0739 - learning_rate: 7.7355e-06\n",
      "Epoch 716/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0755 - learning_rate: 7.7355e-06\n",
      "Epoch 717/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0748 - learning_rate: 7.7355e-06\n",
      "Epoch 718/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0011\n",
      "Epoch 718: ReduceLROnPlateau reducing learning rate to 7e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0741 - learning_rate: 7.7355e-06\n",
      "Epoch 719/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0761 - learning_rate: 7.0000e-06\n",
      "Epoch 720/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0740 - learning_rate: 7.0000e-06\n",
      "Epoch 721/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0737 - learning_rate: 7.0000e-06\n",
      "Epoch 722/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0738 - learning_rate: 7.0000e-06\n",
      "Epoch 723/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0734 - learning_rate: 7.0000e-06\n",
      "Epoch 724/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0724 - learning_rate: 7.0000e-06\n",
      "Epoch 725/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0747 - learning_rate: 7.0000e-06\n",
      "Epoch 726/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0739 - learning_rate: 7.0000e-06\n",
      "Epoch 727/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0757 - learning_rate: 7.0000e-06\n",
      "Epoch 728/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0741 - learning_rate: 7.0000e-06\n",
      "Epoch 729/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0754 - learning_rate: 7.0000e-06\n",
      "Epoch 730/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0743 - learning_rate: 7.0000e-06\n",
      "Epoch 731/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0735 - learning_rate: 7.0000e-06\n",
      "Epoch 732/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0733 - learning_rate: 7.0000e-06\n",
      "Epoch 733/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0738 - learning_rate: 7.0000e-06\n",
      "Epoch 734/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0743 - learning_rate: 7.0000e-06\n",
      "Epoch 735/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0727 - learning_rate: 7.0000e-06\n",
      "Epoch 736/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0744 - learning_rate: 7.0000e-06\n",
      "Epoch 737/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0738 - learning_rate: 7.0000e-06\n",
      "Epoch 738/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0725 - learning_rate: 7.0000e-06\n",
      "Epoch 739/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0730 - learning_rate: 7.0000e-06\n",
      "Epoch 740/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0731 - learning_rate: 7.0000e-06\n",
      "Epoch 741/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0742 - learning_rate: 7.0000e-06\n",
      "Epoch 742/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0733 - learning_rate: 7.0000e-06\n",
      "Epoch 743/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0732 - learning_rate: 7.0000e-06\n",
      "Epoch 744/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0748 - learning_rate: 7.0000e-06\n",
      "Epoch 745/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0755 - learning_rate: 7.0000e-06\n",
      "Epoch 746/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0746 - learning_rate: 7.0000e-06\n",
      "Epoch 747/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0748 - learning_rate: 7.0000e-06\n",
      "Epoch 748/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0730 - learning_rate: 7.0000e-06\n",
      "Epoch 749/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0736 - learning_rate: 7.0000e-06\n",
      "Epoch 750/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0745 - learning_rate: 7.0000e-06\n",
      "Epoch 751/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0735 - learning_rate: 7.0000e-06\n",
      "Epoch 752/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0742 - learning_rate: 7.0000e-06\n",
      "Epoch 753/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0745 - learning_rate: 7.0000e-06\n",
      "Epoch 754/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0738 - learning_rate: 7.0000e-06\n",
      "Epoch 755/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0742 - learning_rate: 7.0000e-06\n",
      "Epoch 756/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0735 - learning_rate: 7.0000e-06\n",
      "Epoch 757/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.0011 - val_loss: 0.0748 - learning_rate: 7.0000e-06\n",
      "Epoch 758/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0742 - learning_rate: 7.0000e-06\n",
      "Epoch 759/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0733 - learning_rate: 7.0000e-06\n",
      "Epoch 760/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0744 - learning_rate: 7.0000e-06\n",
      "Epoch 761/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0733 - learning_rate: 7.0000e-06\n",
      "Epoch 762/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0739 - learning_rate: 7.0000e-06\n",
      "Epoch 763/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0728 - learning_rate: 7.0000e-06\n",
      "Epoch 764/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0734 - learning_rate: 7.0000e-06\n",
      "Epoch 765/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0740 - learning_rate: 7.0000e-06\n",
      "Epoch 766/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0757 - learning_rate: 7.0000e-06\n",
      "Epoch 767/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0744 - learning_rate: 7.0000e-06\n",
      "Epoch 768/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0753 - learning_rate: 7.0000e-06\n",
      "Epoch 769/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0751 - learning_rate: 7.0000e-06\n",
      "Epoch 770/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0745 - learning_rate: 7.0000e-06\n",
      "Epoch 771/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0729 - learning_rate: 7.0000e-06\n",
      "Epoch 772/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0747 - learning_rate: 7.0000e-06\n",
      "Epoch 773/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0740 - learning_rate: 7.0000e-06\n",
      "Epoch 774/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0731 - learning_rate: 7.0000e-06\n",
      "Epoch 775/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0742 - learning_rate: 7.0000e-06\n",
      "Epoch 776/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0724 - learning_rate: 7.0000e-06\n",
      "Epoch 777/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0740 - learning_rate: 7.0000e-06\n",
      "Epoch 778/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0737 - learning_rate: 7.0000e-06\n",
      "Epoch 779/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0736 - learning_rate: 7.0000e-06\n",
      "Epoch 780/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0733 - learning_rate: 7.0000e-06\n",
      "Epoch 781/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0742 - learning_rate: 7.0000e-06\n",
      "Epoch 782/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0743 - learning_rate: 7.0000e-06\n",
      "Epoch 783/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0728 - learning_rate: 7.0000e-06\n",
      "Epoch 784/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0740 - learning_rate: 7.0000e-06\n",
      "Epoch 785/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0742 - learning_rate: 7.0000e-06\n",
      "Epoch 786/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0757 - learning_rate: 7.0000e-06\n",
      "Epoch 787/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0734 - learning_rate: 7.0000e-06\n",
      "Epoch 788/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0736 - learning_rate: 7.0000e-06\n",
      "Epoch 789/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0735 - learning_rate: 7.0000e-06\n",
      "Epoch 790/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0740 - learning_rate: 7.0000e-06\n",
      "Epoch 791/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0732 - learning_rate: 7.0000e-06\n",
      "Epoch 792/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0750 - learning_rate: 7.0000e-06\n",
      "Epoch 793/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0730 - learning_rate: 7.0000e-06\n",
      "Epoch 794/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0751 - learning_rate: 7.0000e-06\n",
      "Epoch 795/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0736 - learning_rate: 7.0000e-06\n",
      "Epoch 796/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0744 - learning_rate: 7.0000e-06\n",
      "Epoch 797/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0748 - learning_rate: 7.0000e-06\n",
      "Epoch 798/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0763 - learning_rate: 7.0000e-06\n",
      "Epoch 799/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0756 - learning_rate: 7.0000e-06\n",
      "Epoch 800/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.0011 - val_loss: 0.0757 - learning_rate: 7.0000e-06\n",
      "Epoch 801/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0739 - learning_rate: 7.0000e-06\n",
      "Epoch 802/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0759 - learning_rate: 7.0000e-06\n",
      "Epoch 803/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0729 - learning_rate: 7.0000e-06\n",
      "Epoch 804/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0735 - learning_rate: 7.0000e-06\n",
      "Epoch 805/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0744 - learning_rate: 7.0000e-06\n",
      "Epoch 806/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0754 - learning_rate: 7.0000e-06\n",
      "Epoch 807/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0724 - learning_rate: 7.0000e-06\n",
      "Epoch 808/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0715 - learning_rate: 7.0000e-06\n",
      "Epoch 809/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0010 - val_loss: 0.0722 - learning_rate: 7.0000e-06\n",
      "Epoch 810/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0747 - learning_rate: 7.0000e-06\n",
      "Epoch 811/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0739 - learning_rate: 7.0000e-06\n",
      "Epoch 812/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0742 - learning_rate: 7.0000e-06\n",
      "Epoch 813/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0739 - learning_rate: 7.0000e-06\n",
      "Epoch 814/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0738 - learning_rate: 7.0000e-06\n",
      "Epoch 815/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0735 - learning_rate: 7.0000e-06\n",
      "Epoch 816/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0733 - learning_rate: 7.0000e-06\n",
      "Epoch 817/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0746 - learning_rate: 7.0000e-06\n",
      "Epoch 818/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0741 - learning_rate: 7.0000e-06\n",
      "Epoch 819/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0744 - learning_rate: 7.0000e-06\n",
      "Epoch 820/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0748 - learning_rate: 7.0000e-06\n",
      "Epoch 821/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0741 - learning_rate: 7.0000e-06\n",
      "Epoch 822/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0752 - learning_rate: 7.0000e-06\n",
      "Epoch 823/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0742 - learning_rate: 7.0000e-06\n",
      "Epoch 824/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0734 - learning_rate: 7.0000e-06\n",
      "Epoch 825/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0739 - learning_rate: 7.0000e-06\n",
      "Epoch 826/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0729 - learning_rate: 7.0000e-06\n",
      "Epoch 827/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0751 - learning_rate: 7.0000e-06\n",
      "Epoch 828/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0733 - learning_rate: 7.0000e-06\n",
      "Epoch 829/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0735 - learning_rate: 7.0000e-06\n",
      "Epoch 830/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0737 - learning_rate: 7.0000e-06\n",
      "Epoch 831/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0760 - learning_rate: 7.0000e-06\n",
      "Epoch 832/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0732 - learning_rate: 7.0000e-06\n",
      "Epoch 833/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0729 - learning_rate: 7.0000e-06\n",
      "Epoch 834/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0754 - learning_rate: 7.0000e-06\n",
      "Epoch 835/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0742 - learning_rate: 7.0000e-06\n",
      "Epoch 836/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0740 - learning_rate: 7.0000e-06\n",
      "Epoch 837/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.0011 - val_loss: 0.0739 - learning_rate: 7.0000e-06\n",
      "Epoch 838/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0731 - learning_rate: 7.0000e-06\n",
      "Epoch 839/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0732 - learning_rate: 7.0000e-06\n",
      "Epoch 840/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0732 - learning_rate: 7.0000e-06\n",
      "Epoch 841/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0736 - learning_rate: 7.0000e-06\n",
      "Epoch 842/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0756 - learning_rate: 7.0000e-06\n",
      "Epoch 843/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0719 - learning_rate: 7.0000e-06\n",
      "Epoch 844/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0721 - learning_rate: 7.0000e-06\n",
      "Epoch 845/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0763 - learning_rate: 7.0000e-06\n",
      "Epoch 846/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0756 - learning_rate: 7.0000e-06\n",
      "Epoch 847/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0736 - learning_rate: 7.0000e-06\n",
      "Epoch 848/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0747 - learning_rate: 7.0000e-06\n",
      "Epoch 849/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0736 - learning_rate: 7.0000e-06\n",
      "Epoch 850/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0735 - learning_rate: 7.0000e-06\n",
      "Epoch 851/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0759 - learning_rate: 7.0000e-06\n",
      "Epoch 852/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0731 - learning_rate: 7.0000e-06\n",
      "Epoch 853/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0737 - learning_rate: 7.0000e-06\n",
      "Epoch 854/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0756 - learning_rate: 7.0000e-06\n",
      "Epoch 855/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0747 - learning_rate: 7.0000e-06\n",
      "Epoch 856/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0731 - learning_rate: 7.0000e-06\n",
      "Epoch 857/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0743 - learning_rate: 7.0000e-06\n",
      "Epoch 858/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0729 - learning_rate: 7.0000e-06\n",
      "Epoch 859/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0749 - learning_rate: 7.0000e-06\n",
      "Epoch 860/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0731 - learning_rate: 7.0000e-06\n",
      "Epoch 861/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0732 - learning_rate: 7.0000e-06\n",
      "Epoch 862/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0010 - val_loss: 0.0745 - learning_rate: 7.0000e-06\n",
      "Epoch 863/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0744 - learning_rate: 7.0000e-06\n",
      "Epoch 864/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0749 - learning_rate: 7.0000e-06\n",
      "Epoch 865/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0754 - learning_rate: 7.0000e-06\n",
      "Epoch 866/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0770 - learning_rate: 7.0000e-06\n",
      "Epoch 867/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0745 - learning_rate: 7.0000e-06\n",
      "Epoch 868/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0760 - learning_rate: 7.0000e-06\n",
      "Epoch 869/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0729 - learning_rate: 7.0000e-06\n",
      "Epoch 870/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0741 - learning_rate: 7.0000e-06\n",
      "Epoch 871/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0728 - learning_rate: 7.0000e-06\n",
      "Epoch 872/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0740 - learning_rate: 7.0000e-06\n",
      "Epoch 873/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.0010 - val_loss: 0.0744 - learning_rate: 7.0000e-06\n",
      "Epoch 874/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0752 - learning_rate: 7.0000e-06\n",
      "Epoch 875/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0754 - learning_rate: 7.0000e-06\n",
      "Epoch 876/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0746 - learning_rate: 7.0000e-06\n",
      "Epoch 877/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0765 - learning_rate: 7.0000e-06\n",
      "Epoch 878/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0745 - learning_rate: 7.0000e-06\n",
      "Epoch 879/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0748 - learning_rate: 7.0000e-06\n",
      "Epoch 880/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0722 - learning_rate: 7.0000e-06\n",
      "Epoch 881/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0741 - learning_rate: 7.0000e-06\n",
      "Epoch 882/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0745 - learning_rate: 7.0000e-06\n",
      "Epoch 883/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0748 - learning_rate: 7.0000e-06\n",
      "Epoch 884/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0748 - learning_rate: 7.0000e-06\n",
      "Epoch 885/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0742 - learning_rate: 7.0000e-06\n",
      "Epoch 886/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0735 - learning_rate: 7.0000e-06\n",
      "Epoch 887/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0010 - val_loss: 0.0730 - learning_rate: 7.0000e-06\n",
      "Epoch 888/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0735 - learning_rate: 7.0000e-06\n",
      "Epoch 889/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0010 - val_loss: 0.0740 - learning_rate: 7.0000e-06\n",
      "Epoch 890/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0755 - learning_rate: 7.0000e-06\n",
      "Epoch 891/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0010 - val_loss: 0.0738 - learning_rate: 7.0000e-06\n",
      "Epoch 892/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0735 - learning_rate: 7.0000e-06\n",
      "Epoch 893/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0742 - learning_rate: 7.0000e-06\n",
      "Epoch 894/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0734 - learning_rate: 7.0000e-06\n",
      "Epoch 895/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0743 - learning_rate: 7.0000e-06\n",
      "Epoch 896/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0739 - learning_rate: 7.0000e-06\n",
      "Epoch 897/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0749 - learning_rate: 7.0000e-06\n",
      "Epoch 898/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0729 - learning_rate: 7.0000e-06\n",
      "Epoch 899/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0732 - learning_rate: 7.0000e-06\n",
      "Epoch 900/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0733 - learning_rate: 7.0000e-06\n",
      "Epoch 901/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0738 - learning_rate: 7.0000e-06\n",
      "Epoch 902/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0741 - learning_rate: 7.0000e-06\n",
      "Epoch 903/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0728 - learning_rate: 7.0000e-06\n",
      "Epoch 904/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0740 - learning_rate: 7.0000e-06\n",
      "Epoch 905/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0740 - learning_rate: 7.0000e-06\n",
      "Epoch 906/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0733 - learning_rate: 7.0000e-06\n",
      "Epoch 907/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0742 - learning_rate: 7.0000e-06\n",
      "Epoch 908/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0740 - learning_rate: 7.0000e-06\n",
      "Epoch 909/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0010 - val_loss: 0.0739 - learning_rate: 7.0000e-06\n",
      "Epoch 910/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0753 - learning_rate: 7.0000e-06\n",
      "Epoch 911/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0741 - learning_rate: 7.0000e-06\n",
      "Epoch 912/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0724 - learning_rate: 7.0000e-06\n",
      "Epoch 913/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0741 - learning_rate: 7.0000e-06\n",
      "Epoch 914/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0735 - learning_rate: 7.0000e-06\n",
      "Epoch 915/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0745 - learning_rate: 7.0000e-06\n",
      "Epoch 916/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0749 - learning_rate: 7.0000e-06\n",
      "Epoch 917/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0725 - learning_rate: 7.0000e-06\n",
      "Epoch 918/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0737 - learning_rate: 7.0000e-06\n",
      "Epoch 919/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0748 - learning_rate: 7.0000e-06\n",
      "Epoch 920/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0758 - learning_rate: 7.0000e-06\n",
      "Epoch 921/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0735 - learning_rate: 7.0000e-06\n",
      "Epoch 922/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0743 - learning_rate: 7.0000e-06\n",
      "Epoch 923/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0722 - learning_rate: 7.0000e-06\n",
      "Epoch 924/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0739 - learning_rate: 7.0000e-06\n",
      "Epoch 925/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0733 - learning_rate: 7.0000e-06\n",
      "Epoch 926/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0746 - learning_rate: 7.0000e-06\n",
      "Epoch 927/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0739 - learning_rate: 7.0000e-06\n",
      "Epoch 928/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0736 - learning_rate: 7.0000e-06\n",
      "Epoch 929/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0743 - learning_rate: 7.0000e-06\n",
      "Epoch 930/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0758 - learning_rate: 7.0000e-06\n",
      "Epoch 931/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0746 - learning_rate: 7.0000e-06\n",
      "Epoch 932/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0010 - val_loss: 0.0752 - learning_rate: 7.0000e-06\n",
      "Epoch 933/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0752 - learning_rate: 7.0000e-06\n",
      "Epoch 934/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0723 - learning_rate: 7.0000e-06\n",
      "Epoch 935/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0719 - learning_rate: 7.0000e-06\n",
      "Epoch 936/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0717 - learning_rate: 7.0000e-06\n",
      "Epoch 937/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0737 - learning_rate: 7.0000e-06\n",
      "Epoch 938/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0747 - learning_rate: 7.0000e-06\n",
      "Epoch 939/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0733 - learning_rate: 7.0000e-06\n",
      "Epoch 940/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0745 - learning_rate: 7.0000e-06\n",
      "Epoch 941/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0745 - learning_rate: 7.0000e-06\n",
      "Epoch 942/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0720 - learning_rate: 7.0000e-06\n",
      "Epoch 943/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0752 - learning_rate: 7.0000e-06\n",
      "Epoch 944/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0728 - learning_rate: 7.0000e-06\n",
      "Epoch 945/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0750 - learning_rate: 7.0000e-06\n",
      "Epoch 946/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0731 - learning_rate: 7.0000e-06\n",
      "Epoch 947/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0730 - learning_rate: 7.0000e-06\n",
      "Epoch 948/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0739 - learning_rate: 7.0000e-06\n",
      "Epoch 949/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0747 - learning_rate: 7.0000e-06\n",
      "Epoch 950/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0738 - learning_rate: 7.0000e-06\n",
      "Epoch 951/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0743 - learning_rate: 7.0000e-06\n",
      "Epoch 952/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0731 - learning_rate: 7.0000e-06\n",
      "Epoch 953/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0727 - learning_rate: 7.0000e-06\n",
      "Epoch 954/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0740 - learning_rate: 7.0000e-06\n",
      "Epoch 955/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0735 - learning_rate: 7.0000e-06\n",
      "Epoch 956/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0740 - learning_rate: 7.0000e-06\n",
      "Epoch 957/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0728 - learning_rate: 7.0000e-06\n",
      "Epoch 958/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0738 - learning_rate: 7.0000e-06\n",
      "Epoch 959/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0744 - learning_rate: 7.0000e-06\n",
      "Epoch 960/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0734 - learning_rate: 7.0000e-06\n",
      "Epoch 961/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0747 - learning_rate: 7.0000e-06\n",
      "Epoch 962/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0728 - learning_rate: 7.0000e-06\n",
      "Epoch 963/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0752 - learning_rate: 7.0000e-06\n",
      "Epoch 964/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0738 - learning_rate: 7.0000e-06\n",
      "Epoch 965/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0761 - learning_rate: 7.0000e-06\n",
      "Epoch 966/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0745 - learning_rate: 7.0000e-06\n",
      "Epoch 967/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0753 - learning_rate: 7.0000e-06\n",
      "Epoch 968/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0735 - learning_rate: 7.0000e-06\n",
      "Epoch 969/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0010 - val_loss: 0.0750 - learning_rate: 7.0000e-06\n",
      "Epoch 970/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0746 - learning_rate: 7.0000e-06\n",
      "Epoch 971/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0754 - learning_rate: 7.0000e-06\n",
      "Epoch 972/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0734 - learning_rate: 7.0000e-06\n",
      "Epoch 973/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0756 - learning_rate: 7.0000e-06\n",
      "Epoch 974/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0726 - learning_rate: 7.0000e-06\n",
      "Epoch 975/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0745 - learning_rate: 7.0000e-06\n",
      "Epoch 976/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0740 - learning_rate: 7.0000e-06\n",
      "Epoch 977/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0748 - learning_rate: 7.0000e-06\n",
      "Epoch 978/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0735 - learning_rate: 7.0000e-06\n",
      "Epoch 979/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0747 - learning_rate: 7.0000e-06\n",
      "Epoch 980/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0723 - learning_rate: 7.0000e-06\n",
      "Epoch 981/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0737 - learning_rate: 7.0000e-06\n",
      "Epoch 982/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0727 - learning_rate: 7.0000e-06\n",
      "Epoch 983/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0745 - learning_rate: 7.0000e-06\n",
      "Epoch 984/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0721 - learning_rate: 7.0000e-06\n",
      "Epoch 985/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0724 - learning_rate: 7.0000e-06\n",
      "Epoch 986/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0734 - learning_rate: 7.0000e-06\n",
      "Epoch 987/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0747 - learning_rate: 7.0000e-06\n",
      "Epoch 988/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0747 - learning_rate: 7.0000e-06\n",
      "Epoch 989/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0740 - learning_rate: 7.0000e-06\n",
      "Epoch 990/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0728 - learning_rate: 7.0000e-06\n",
      "Epoch 991/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0733 - learning_rate: 7.0000e-06\n",
      "Epoch 992/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0738 - learning_rate: 7.0000e-06\n",
      "Epoch 993/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0747 - learning_rate: 7.0000e-06\n",
      "Epoch 994/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0759 - learning_rate: 7.0000e-06\n",
      "Epoch 995/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0741 - learning_rate: 7.0000e-06\n",
      "Epoch 996/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0746 - learning_rate: 7.0000e-06\n",
      "Epoch 997/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0758 - learning_rate: 7.0000e-06\n",
      "Epoch 998/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0751 - learning_rate: 7.0000e-06\n",
      "Epoch 999/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0746 - learning_rate: 7.0000e-06\n",
      "Epoch 1000/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0712 - learning_rate: 7.0000e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model with the custom callback\n",
    "history = model_builder.train_model(\n",
    "    train_dataset, \n",
    "    val_dataset, \n",
    "    epochs=1000,\n",
    "    callbacks_list=[lr_scheduler]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Extract the losses from the history object\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "train_loss_x_midpoints = history.history.get('x_midpoints_reshape_loss', train_loss)\n",
    "val_loss_x_midpoints = history.history.get('val_x_midpoints_reshape_loss', val_loss)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2,1)\n",
    "plt.plot(train_loss_x_midpoints, label='Train Loss x_midpoints_reshape')\n",
    "plt.plot(val_loss_x_midpoints, label='Validation Loss x_midpoints_reshape')\n",
    "plt.xlabel('Epochs')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss ')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder.model.save(\"/home/da886/Analysis/12KFixed_Mixed_4_32by32_SparsespotsRandomIndex.keras\")\n",
    "# loaded_model = tf.keras.models.load_model(\n",
    "# \"/home/da886/Analysis/30KFixed_13_SparsespotsrandomSPOTS.keras\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1, batch shape: (800, 32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1729539030.656114  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.656294  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.656908  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.657321  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.657342  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.657548  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.657912  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.657973  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.658101  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.658433  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.658575  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.658587  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.658932  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.659094  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.659113  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.659398  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.659559  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.659678  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.659976  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.660072  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.660225  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.660526  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.660627  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.660737  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.661122  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.661161  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.661249  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.661623  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.661725  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.661840  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.662236  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.662244  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.662379  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.662732  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.662734  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.662870  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.663211  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.663254  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.663387  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.663865  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.663948  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.664120  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.664429  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.664488  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.664658  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.665049  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.665156  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.665182  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.665442  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.665761  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.665783  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.665888  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.666283  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.666416  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.666607  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.666771  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.666930  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.667109  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.667352  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.667559  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.667631  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.668308  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.668351  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.668479  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.685657  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.685943  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.685980  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.686099  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.686583  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.686587  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.686727  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.687055  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.687216  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.687224  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.687573  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.687795  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.687900  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.688117  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.688343  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.688409  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.688657  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.688895  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.688939  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.689207  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.689407  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.689458  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.689623  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.689949  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.690008  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.690177  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.690495  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.690566  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.690695  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.691017  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.691082  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.691310  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.691512  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.691571  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.691724  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.692010  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.692132  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.692248  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.692593  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.692637  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.692801  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.693103  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.693231  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.693550  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.693562  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.693668  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.694068  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.694275  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.694334  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.694548  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.694787  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.694964  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.695246  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.695299  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.695547  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.695761  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.695811  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.696058  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.696253  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.696290  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.696586  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.696769  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.696797  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.697086  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.697284  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.697351  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.697492  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.697775  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.697953  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.698028  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.698224  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.698717  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.698739  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.698895  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.699259  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.699386  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.699390  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.699878  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.699971  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.700057  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.700395  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.709952  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.710228  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.710467  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.710703  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.710942  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.711172  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.711408  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.711649  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.711892  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.712139  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.712386  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.712620  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.712927  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.713212  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.713527  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.713586  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.713993  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.714069  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.714321  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.714528  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.714563  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.714853  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.715071  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.715105  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.715282  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.715612  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.715665  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.715738  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.716060  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.716138  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.716499  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.716571  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.716829  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.716940  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.717160  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.717438  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.717607  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.717608  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.717813  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.717946  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.718179  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.718303  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.718303  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.718672  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.718711  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.718848  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.719040  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.719258  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.719460  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.719470  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.719679  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.719770  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.720145  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.720226  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.720231  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.720558  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.720561  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.720758  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.720864  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.721100  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.721262  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.721478  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.721620  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.721622  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.721985  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.722013  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.722385  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.722388  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.722636  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.722775  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.722965  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.723054  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.723350  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.723539  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.723627  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.723866  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.724219  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.724225  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.724602  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.724607  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.724909  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.725010  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.725276  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.725377  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.725665  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.725757  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.726121  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.726138  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.726510  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.726523  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.726890  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.726974  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.727201  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.727318  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.727525  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.727717  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.727904  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.728100  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.728278  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.728471  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.728665  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.728853  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.729040  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.729227  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.729412  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.729568  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.729783  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.729860  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.730163  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.730169  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.730455  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.730597  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.730755  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.730967  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.731119  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.731237  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.731328  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.731630  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.731642  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.731833  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.732101  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.732131  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.732341  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.732542  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.732553  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.732785  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.733076  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.733325  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.733414  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.733776  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.733871  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.734026  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.734379  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.734388  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.734715  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.734835  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.735043  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.735352  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.735724  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.736090  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.736500  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.736909  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.737412  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.737840  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.738264  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.738485  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.738748  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.738988  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.739238  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.739490  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.739733  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.740007  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.740257  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.740528  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.740804  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.741083  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.741343  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.741785  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.741793  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.742040  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.742202  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.742355  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.742631  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.742681  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.742866  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.742992  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.742996  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.743354  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.743357  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.743542  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.743656  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.743660  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.743984  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.744100  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.744167  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.744281  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.744442  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.744680  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.744796  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.744870  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.744974  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.745211  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.745340  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.745426  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.745655  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.745734  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.746023  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.746107  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.746388  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.746465  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.746663  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.746755  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.747091  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.747174  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.747358  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.747565  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.747711  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.748092  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.748216  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.748220  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.748636  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.748640  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.748749  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.748900  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.749200  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.749207  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.749305  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.749470  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.749711  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.749840  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.749843  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.750258  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.750372  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.750518  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.750763  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.751017  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.751263  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.751516  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.751770  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.752028  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.752286  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.752545  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.752802  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.753067  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.753339  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.753788  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.753929  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.754132  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.754227  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.754530  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.754607  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.754926  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.755014  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.755191  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.755491  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.755575  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.755754  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.755943  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.756094  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.756272  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.756511  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.756620  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.756781  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.756952  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.757126  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.757291  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.757459  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.757617  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.757785  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.757950  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.758118  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.758283  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.758445  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.758614  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.758779  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.758941  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.759110  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.759270  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.759427  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.759710  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.759859  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.760145  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.760384  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.760536  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.760783  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.760977  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.760986  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.761158  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.761435  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.761541  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.761614  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.761904  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.762217  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.762295  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.762572  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.762753  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.762904  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.763242  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.763322  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.763518  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.763801  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.764079  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.764345  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.764800  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.765251  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.765735  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.766217  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.766729  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.767153  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.767247  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.767566  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.767650  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.767834  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.768093  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.768348  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.768606  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.768883  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.769158  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.769323  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.769484  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.769650  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.769817  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.769986  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.770150  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.770315  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.770481  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.770640  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.770920  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.771076  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.771240  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.771507  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.771669  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.771823  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.772213  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.772291  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.772493  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.772896  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.772902  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.772978  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.773340  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.773357  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.773542  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.773673  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.773680  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.774028  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.774226  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.774241  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.774345  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.774624  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.774668  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.774844  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.774969  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.774972  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.775329  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.775407  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.775608  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.775788  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.775949  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.776159  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.776252  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.776594  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.776668  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.776864  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.777164  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.777237  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.777505  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.777833  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.777918  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.778201  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.778618  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.778916  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.779257  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.779619  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.780031  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.780617  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.780805  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.781052  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.781403  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.781647  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.781893  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.782150  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.782411  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.782667  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.782928  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.783210  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.783484  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.783629  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.783769  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.784008  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.784098  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.784311  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.784401  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.784619  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.784785  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.784971  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.785149  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.785328  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.785484  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.785697  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.785880  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.786057  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.786239  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.786427  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.786510  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.786596  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.786872  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.786933  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.787047  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.787401  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.787486  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.787598  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.787706  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.787887  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.788067  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.788259  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.788427  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.788838  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.788859  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.789152  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.789546  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.789620  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.789835  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.790141  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.790518  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.790595  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.790911  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.791264  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.791339  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.791655  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.791974  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.792121  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.792299  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.792620  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.792801  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.792987  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.793347  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.793487  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.793711  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.793982  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.794337  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.794420  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.794715  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.795022  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.795213  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.795377  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.795682  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.796136  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.796213  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.796435  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.796782  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.797159  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.797519  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.797853  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.798607  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.799242  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.800048  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.800697  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.801501  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.802171  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.802831  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.805085  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.805353  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.805625  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.805903  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.806238  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.806422  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.806594  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.806895  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.807205  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.807560  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.807873  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.808196  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.808523  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.808836  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.809164  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.809503  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.809831  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.810201  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.810549  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.810907  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.811485  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.812317  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.812322  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.812659  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.812978  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.813242  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.813333  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.813647  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.813967  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.814393  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.814557  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.814758  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.814861  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.815222  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.815304  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.815690  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.815767  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.815994  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.816185  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.816374  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.816556  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.816731  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.817027  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.817422  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.817491  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.817736  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.818047  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.818310  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.818408  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.818723  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.819043  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.819340  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.819411  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.819696  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.819802  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.819877  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.820145  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.820319  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.820677  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.820677  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.820793  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.821020  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.821198  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.821388  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.821902  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.821915  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.822011  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.822242  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.822620  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.822804  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.823087  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.823169  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.823547  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.823731  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.823913  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.824070  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.824843  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.825744  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.826711  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.828118  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.828981  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.829879  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.829929  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.830221  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.830544  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.830860  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.831169  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.831526  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.831858  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.832089  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.832270  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.832630  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.833010  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.833371  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.833705  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.834481  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.835380  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.836353  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.837760  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.838630  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.839593  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.841769  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.843978  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.844298  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.844619  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.844935  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.845258  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.845577  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.845898  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.846209  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.846535  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.846865  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.847199  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.847528  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.847884  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.848262  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.848657  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.849049  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.849465  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.849901  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.850328  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.851306  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.852247  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.855054  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.855371  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.855696  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.856018  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.856339  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.856663  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1729539030.856989  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.857317  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.857661  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.858015  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.858369  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.858722  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.859074  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.859274  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.859502  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.859691  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.859925  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.860101  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.860441  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.860520  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.861047  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.861202  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.861417  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.861742  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.862416  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.862597  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.862993  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.863502  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.863578  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.864248  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.864451  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.864876  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.865046  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.865230  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.865583  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.865766  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.865967  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.866316  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.866494  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.866666  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.866990  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.867317  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.867724  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.867810  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.868160  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.868508  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.868859  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.869298  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.869376  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.869776  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.870176  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.870593  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.871029  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.871453  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.871467  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.871877  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.871970  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.872210  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.872550  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.873052  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.873144  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.873517  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.874055  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.874151  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.874459  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.874929  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.875627  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.876311  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.877162  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.877997  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.878567  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.878876  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.879225  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.879304  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.879616  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.879930  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.880235  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.880562  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.880755  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.880925  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.881222  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.881230  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.881666  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.881733  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.882012  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.882195  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.882370  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.882691  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.882891  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.883057  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.883290  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.883508  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.883752  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.883918  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.884197  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.884292  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.884782  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.884855  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.885258  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.885469  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.885741  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.886271  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.886349  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.886992  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.887158  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.888019  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.888197  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.889160  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.890984  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.893234  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.893723  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.894115  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.894495  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.894876  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.895217  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.895538  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.895836  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.896140  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.896501  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.896844  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.896880  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.897469  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.897491  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.897927  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.897938  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.898434  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.898447  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.898936  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.898952  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.899379  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.899393  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.899960  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.899972  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.900480  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.900491  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.900990  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.901099  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.901599  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.902222  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.902334  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.903613  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.903612  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.903700  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.903984  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.904288  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.904608  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.905123  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.905225  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.905545  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.905862  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.906164  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.906466  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.906830  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.907206  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.907731  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.907818  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.908170  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.908546  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.908876  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.909206  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.909635  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.910047  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.910530  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.911071  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.911241  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.911715  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.911916  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.912276  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.912629  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.912976  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.913208  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.913223  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.913551  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.913897  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.914348  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.914709  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.915088  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.916340  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.916355  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.917455  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.918632  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.919654  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.920011  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.920369  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.920752  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.921237  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.921252  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.921312  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.921734  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.921819  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.922228  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.922315  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.922743  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.922830  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.923242  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.923328  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.923670  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.923934  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.924117  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.924369  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.924566  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.924998  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.925127  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.925203  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.925572  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.926174  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.926347  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.926592  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.926782  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.927406  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.927582  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.928145  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.928837  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.928953  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.929825  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.929843  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.930770  408298 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.931360  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.933127  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.933479  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.933838  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.934226  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.934535  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.935137  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.935146  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.935488  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.935837  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.936197  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.936802  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.936907  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.937288  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.937714  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.938147  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.938702  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.939269  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.939974  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.940067  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.940713  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.941409  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.942117  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.943028  408304 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.943349  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.943700  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.944312  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.944700  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.945015  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.945357  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.945696  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.946050  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.946410  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.947043  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.947426  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.947845  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.948274  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.948828  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.949397  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.949984  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.950714  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.951395  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.952108  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729539030.953018  408249 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Processing batch 3, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Processing batch 4, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Processing batch 5, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Processing batch 6, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Processing batch 7, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Processing batch 8, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Processing batch 9, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Processing batch 10, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Processing batch 11, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Processing batch 12, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the function for visualizing midpoints\n",
    "def visualize_midpoints(image, midpoints, title=\"Predicted Midpoint Visualization\"):\n",
    "    \"\"\"\n",
    "    Visualizes midpoints on an image without using a probability vector.\n",
    "\n",
    "    Parameters:\n",
    "    - image: A 3D tensor representing the image.\n",
    "    - midpoints: A 2D tensor representing the midpoint coordinates (x, y).\n",
    "    - title: The title of the plot.\n",
    "\n",
    "    Returns:\n",
    "    None (displays the image with midpoints).\n",
    "    \"\"\"\n",
    "    # Convert to NumPy arrays for easier handling\n",
    "    image_np = image\n",
    "    midpoints_np = midpoints\n",
    "\n",
    "    # Denormalize image if necessary (adjust based on your normalization method)\n",
    "    denormalized_image = image_np  # Modify if normalization was applied during training\n",
    "\n",
    "    # Visualize the image\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(denormalized_image, cmap='gray')\n",
    "    plt.title(title)\n",
    "\n",
    "    # Plot midpoints directly, only if they are not (0, 0)\n",
    "    for i, (x, y) in enumerate(midpoints_np):\n",
    "        if x >= 0 and y >= 0:  # Only plot if the point is not (0, 0)\n",
    "            plt.scatter(x, y, color='red', s=5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Create the validation dataset\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n",
    "# val_dataset = val_dataset.batch(800)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)\n",
    "# # Initialize lists to collect the data\n",
    "all_images = []\n",
    "all_true_midpoints = []\n",
    "all_pred_midpoints = []\n",
    "\n",
    "# # Loop through each batch in the validation dataset, predict, and collect results\n",
    "# for i, (data_batch, midpoints_batch) in enumerate(val_dataset):\n",
    "\n",
    "for i, (data_batch, midpoints_batch) in enumerate(train_dataset):\n",
    "    print(f\"Processing batch {i + 1}, batch shape: {data_batch.shape}\")\n",
    "    \n",
    "    # Get the model predictions\n",
    "    predictions =model_builder.model.predict(data_batch)\n",
    "\n",
    "    # Extend the lists to store data from each batch\n",
    "    all_images.extend(data_batch.numpy())  # Store all images\n",
    "    all_true_midpoints.extend(midpoints_batch.numpy())  # Store all true midpoints\n",
    "    all_pred_midpoints.extend(predictions)  # Store all predicted midpoints\n",
    "\n",
    "# Convert lists to arrays for easier indexing\n",
    "all_images = np.array(all_images)\n",
    "all_true_midpoints = np.array(all_true_midpoints)\n",
    "all_pred_midpoints = np.array(all_pred_midpoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "# train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9600, 32, 32), (9600, 1, 4, 2), (9600, 1, 4, 2))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images.shape,all_pred_midpoints.shape,all_true_midpoints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWMAAAF2CAYAAAC72fnJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvn0lEQVR4nO3deVRUV54H8G9RQIEshSiyRCW4xyjkNB0JozEmoqC2rYl9OmkzDjpm0UETNUtH0wa3kYzpk5hOXM5MZvRMj0vGTNCTdNQoETLaaI9GjtFERmmMZBQ0dlOlJBRL3flDqFiy1C281LtQ388592BV3XrvV/cVP5633q+uSQghQEREhgowOgAiImIyJiLSApMxEZEGmIyJiDTAZExEpAEmYyIiDTAZExFpgMmYiEgDTMZERBpgMqYOu/vuuzF79mzX7cLCQphMJhQWFhoW0+1uj1G12bNn4+677/bY78KFCzCZTNi6dWunxQJ0/uulzsNk3EVt3boVJpPJ1UJCQjBkyBAsWLAAVVVVRofnlU8++QQrVqwwNIbmcXzqqadaffzVV1919fnuu+98HJ1vbNy4sdP/WFDbAo0OgO7MqlWrkJSUhNraWhw+fBibNm3CJ598gtOnT6NHjx4+jWXs2LH44YcfEBwc7NXzPvnkE2zYsMHwhBwSEoL/+q//wsaNG1u8hh07diAkJAS1tbVu9//Lv/wLnE6nL8NsV2lpKQICOnaOtXHjRvTu3Ztn1gbhmXEXN2nSJPzt3/4tnnrqKWzduhWLFi1CeXk59uzZ0+ZzampqOiWWgIAAhISEdDgZGC0rKwt2ux179+51u/+Pf/wjysvLMWXKlBbPCQoKgsVi8VWIHlksFgQFBRkdBnVA1/ytoTY98sgjAIDy8nIAN+c0w8PDUVZWhsmTJyMiIgJPPvkkAMDpdGL9+vW49957ERISgtjYWDz77LP461//6rZNIQTWrFmDvn37okePHnj44Ydx5syZFvtua8742LFjmDx5Mnr27ImwsDAkJyfj7bffdsW3YcMGAHCbdmmmOsb23HXXXRg7diy2b9/udv+2bdswcuRIjBgxosVzWpszrq6uxuzZs2G1WhEVFYXs7GxUV1e3+tzw8HD8+c9/RmZmJsLCwpCQkIBVq1bh9i9TrKmpwQsvvIB+/frBYrFg6NCh+O1vf9ui3+1zxs3TWUeOHMGSJUsQExODsLAwPProo7h69arb886cOYOioiLXMRg3bhwAoL6+HitXrsTgwYMREhKCXr16YcyYMThw4IDEqJIsTlN0M2VlZQCAXr16ue5raGhAZmYmxowZg9/+9reu6Ytnn30WW7duxZw5c/Dcc8+hvLwc7777Lk6ePIkjR464zrBee+01rFmzBpMnT8bkyZPxxRdfYOLEiairq/MYz4EDB/Czn/0M8fHxeP755xEXF4evv/4aH3/8MZ5//nk8++yzuHTpEg4cOIDf//73LZ7vixhvNXPmTDz//PO4ceMGwsPD0dDQgF27dmHJkiUtpihaI4TAtGnTcPjwYcybNw/33HMP8vPzkZ2d3Wr/xsZGZGVl4YEHHsC6deuwb98+5ObmoqGhAatWrXJt8+c//zkOHTqEuXPn4r777sP+/fvx0ksv4f/+7//w1ltveYxr4cKF6NmzJ3Jzc3HhwgWsX78eCxYswPvvvw8AWL9+PRYuXIjw8HC8+uqrAIDY2FgAwIoVK5CXl4ennnoKo0aNgt1ux/Hjx/HFF19gwoQJUuNKEgR1SVu2bBEAxMGDB8XVq1dFRUWF2Llzp+jVq5cIDQ0V3377rRBCiOzsbAFAvPLKK27P/+///m8BQGzbts3t/n379rndf+XKFREcHCymTJkinE6nq9+yZcsEAJGdne2679ChQwKAOHTokBBCiIaGBpGUlCQSExPFX//6V7f93LqtnJwc0dpbsTNibAsAkZOTI/7yl7+I4OBg8fvf/14IIcQf/vAHYTKZxIULF0Rubq4AIK5evep6XnZ2tkhMTHTd3r17twAg1q1b57qvoaFBPPjggwKA2LJli9tzAYiFCxe6jcuUKVNEcHCwaz/N21yzZo1bzL/4xS+EyWQS58+fd92XmJjo9nqb3ycZGRluY7N48WJhNptFdXW16757771XPPTQQy3GJiUlRUyZMsXDCNKd4jRFF5eRkYGYmBj069cPTzzxBMLDw5Gfn4+77rrLrd/8+fPdbu/atQtWqxUTJkzAd99952qpqakIDw/HoUOHAAAHDx5EXV0dFi5c6DZ9sGjRIo+xnTx5EuXl5Vi0aBGioqLcHrt1W23xRYy369mzJ7KysrBjxw4AwPbt2/E3f/M3SExMlHr+J598gsDAQLfxNpvNWLhwYZvPWbBggevfJpMJCxYsQF1dHQ4ePOjaptlsxnPPPef2vBdeeAFCiBZz3K155pln3MbmwQcfRGNjI7755huPz42KisKZM2dw7tw5j32p4zhN0cVt2LABQ4YMQWBgIGJjYzF06NAWH6AFBgaib9++bvedO3cONpsNffr0aXW7V65cAQDXL+vgwYPdHo+JiUHPnj3bja15yqS1uVYZvoixNTNnzsSsWbNw8eJF7N69G+vWrZN+7jfffIP4+HiEh4e73T906NBW+wcEBGDAgAFu9w0ZMgTAzWuTm7eZkJCAiIgIt3733HOP63FP+vfv73a7eVxun3tvzapVqzBt2jQMGTIEI0aMQFZWFmbNmoXk5GSPzyV5TMZd3KhRo/DTn/603T4Wi6VFgnY6nejTpw+2bdvW6nNiYmKUxdhRRsX485//HBaLBdnZ2XA4HPjlL3/ZKfvxJbPZ3Or9QmLVtbFjx6KsrAx79uzBp59+ivfeew9vvfUWNm/e3OZ12eQ9JmM/NXDgQBw8eBCjR49GaGhom/2a/3t+7tw5tzO4q1evejyrGjhwIADg9OnTyMjIaLNfW1MWvoixNaGhoZg+fTr+4z/+A5MmTULv3r2ln5uYmIiCggLXB4DNSktLW+3vdDrx5z//2XU2DAD/+7//CwCuqzQSExNx8OBBXL9+3e3s+OzZs67HVWhv6ig6Ohpz5szBnDlzcOPGDYwdOxYrVqxgMlaIc8Z+6pe//CUaGxuxevXqFo81NDS4LsXKyMhAUFAQ3nnnHbezqPXr13vcx09+8hMkJSVh/fr1LS7tunVbYWFhANCijy9ibMuLL76I3NxcLF++3KvnTZ48GQ0NDdi0aZPrvsbGRrzzzjttPufdd991/VsIgXfffRdBQUEYP368a5uNjY1u/QDgrbfegslkwqRJk7yKsS1hYWGtXoJ37do1t9vh4eEYNGgQHA6Hkv3STTwz9lMPPfQQnn32WeTl5aGkpAQTJ05EUFAQzp07h127duHtt9/GL37xC8TExODFF19EXl4efvazn2Hy5Mk4efIk9u7d6/GMMSAgAJs2bcLUqVNx3333Yc6cOYiPj8fZs2dx5swZ7N+/HwCQmpoKAHjuueeQmZkJs9mMJ554wicxtiUlJQUpKSleP2/q1KkYPXo0XnnlFVy4cAHDhw/Hhx9+CJvN1mr/kJAQ7Nu3D9nZ2UhLS8PevXvxhz/8AcuWLXNNw0ydOhUPP/wwXn31VVy4cAEpKSn49NNPsWfPHixatMj1P5A7lZqaik2bNmHNmjUYNGgQ+vTpg0ceeQTDhw/HuHHjkJqaiujoaBw/fhwffPCB2wePpICRl3JQxzVfsvQ///M/7fbLzs4WYWFhbT7+z//8zyI1NVWEhoaKiIgIMXLkSPHyyy+LS5cuufo0NjaKlStXivj4eBEaGirGjRsnTp8+3eIyqtsvbWt2+PBhMWHCBBERESHCwsJEcnKyeOedd1yPNzQ0iIULF4qYmBhhMplaXOamMsa2oOnStvbIXNomhBDXrl0Ts2bNEpGRkcJqtYpZs2aJkydPtnppW1hYmCgrKxMTJ04UPXr0ELGxsSI3N1c0Nja6bfP69eti8eLFIiEhQQQFBYnBgweLN954w+1yNSHavrTt9vdJa8eqsrJSTJkyRURERAgArsvc1qxZI0aNGiWioqJEaGioGDZsmPjHf/xHUVdX1+54kXdMQkjM4BORcrNnz8YHH3yAGzduGB0KaYBzxkREGmAyJiLSAJMxEZEGOGdMRKQBnhkTEWmAyZiISAPaFX04nU5cunQJERERUt/sRUSkKyEErl+/joSEBI8r4GiXjC9duoR+/foZHQYRkTIVFRUtvjnxdp02TbFhwwbcfffdCAkJQVpaGv70pz9JPe/2rwnUya3LArXXVAoICJBqRsTm6/0BcuOhM9njpHJsdd2nSka8/70hk9c65cz4/fffx5IlS7B582akpaVh/fr1yMzMRGlpaZvfTdtM56kJ1bHJXMhixD5lycQmuz/Z16nz+0OGyvhVj62v9+nr96I3VF9kJhNfp5xGvPnmm3j66acxZ84cDB8+HJs3b0aPHj3wb//2b52xOyKiLk95Mq6rq8OJEyfcvr82ICAAGRkZKC4ubtHf4XDAbre7NSIif6M8GX/33XdobGx0rSzbLDY2FpWVlS365+XlwWq1uho/vCMif2T4px1Lly6FzWZztYqKCqNDIiLyOeUf4PXu3RtmsxlVVVVu91dVVSEuLq5Ff4vFAovFojoMIqIuRfmZcXBwMFJTU1FQUOC6z+l0oqCgAOnp6ap3R0TULXTKpW1LlixBdnY2fvrTn2LUqFFYv349ampqMGfOnM7YHRFRl9cpyfjxxx/H1atX8dprr6GyshL33Xcf9u3b1+JDva7G6XRK9WtrWfTbNTY2KukDGHP9rex4yJC9rlN2PGQEBsq9/RsaGjz2kS02UTlmsmT2qfr9I7NPlWNmxLiqpt1XaNrtdlitVqPDuCMqk7Es2V8mzQ63ofwlGcsw4v3T1cfMGzabDZGRke32MfxqCiIiYjImItICkzERkQaYjImINMBkTESkASZjIiINMBkTEWlAu2WXvKFyVQddr2XU+VpM2eupZcjGL3Od65dffim1Ldl+s2bN8thH5/FXeT27SkYUKul8PT7PjImINMBkTESkASZjIiINMBkTEWmAyZiISANMxkREGmAyJiLSAJMxEZEGmIyJiDTQpSvwVC7tIkN2W7JVPjLbU73UkwzZii2ZfdbV1SnbFiAX28iRI6W2pZIR1XC6Vtb5C5nfXyGEdDUfz4yJiDTAZExEpAEmYyIiDTAZEwEwA1gOYH/TT3Uz8ERyuvQHeESqLAOwAjfPTjKa7lttWDTkj3hmTARgDH78ZQhouk3kS0zGRAAOA2i+iNDZdJvIlzhNQQRgbdPPMbiZiNe205eoM3TpZCxTXKFyORzZbcn2k7loXOeldWQLOmQYXcDQiDubIw4MlPtVMuJ1yvyeyBYmqFwqSdexAOTGQ/VSW5ymICLSAJMxEZEGmIyJiDTAZExEpAEmYyIiDTAZExFpgMmYiEgDTMZERBpgMiYi0oC2FXhms9ljtYxs1ZAqstVwspVpRlT5qGSxWDz2cTgcSvepcqkqlVQuLyUbv+z7X+XvicptyS5jJjMeKivrjKL8zHjFihUwmUxubdiwYap3Q0TUrXTKmfG9996LgwcP/rgTybp9IiJ/1SlZMjAwEHFxcZ2xaSKibqlTPsA7d+4cEhISMGDAADz55JO4ePFim30dDgfsdrtbIyLyN8qTcVpaGrZu3Yp9+/Zh06ZNKC8vx4MPPojr16+32j8vLw9Wq9XV+vXrpzokIiLtmUQnf7xYXV2NxMREvPnmm5g7d26Lxx0Oh9sn7na7Hf369fOLqylUfs+sEXg1xY9kP81XGb/O7w0ZRlxNIUv12NpsNkRGRrbbp9M/WYuKisKQIUNw/vz5Vh+3WCxSv9RERN1Zpxd93LhxA2VlZYiPj+/sXRERdVnKk/GLL76IoqIiXLhwAX/84x/x6KOPwmw241e/+pXqXRERdRvKpym+/fZb/OpXv8K1a9cQExODMWPG4OjRo4iJifFqOzLrY+m6tpfsddUNDQ0e++hcWaR6PliGrhWJsuMvE7/qY6my6k8llfs0Yq1I1Z/5KE/GO3fuVL1JIqJuj18URESkASZjIiINMBkTEWmAyZiISANMxkREGmAyJiLSAJMxEZEGtP7Wd92+KEh2f7IXlqssNNF1CRudi1aMoPJ1yhY6yOxT5/GXKaKSKaBSTfWY8cyYiEgDTMZERBpgMiYi0gCTMRGRBpiMiYg0wGRMRKQBJmMiIg0wGRMRaYDJmIhIA1pX4PmSrhVIshVsXX05IpVUViMCvl+2SHWlpwydKyU7a3kyM4BlAMYAOAxgLYDmEZU55irHH2AyJiI/tQzACtycHshoum+1YdFwmoKI/NQY/JgAA5puG4nJmIj80mEAzZNLzqbbRuI0BRH5pbVNP2+dMzYSkzER+aVGGDtHfDtOUxARaYDJmIhIA0zGREQaYDImItKA1h/gear2UbmGnExlkco1xwC5Ch7l62xJVKeprCaTHTOV1UyqqxFVriEnM/6yY6Zy3TeV8QO+fw/Nnz9falvvvvuuVD9V6zt68/vLM2Mi8ntmAMsB7G/6aTag7FvrM2MiIl+4vTTaBGCNj2PgmTER+b0WpdFGfMGVz/dIRKSZFqXRCj+PksVpCiLye7eXRr9uQAxMxkTk924vjQ4w4MyY0xRERBpgMiYi0oBJaLbekN1uh9Vqleqr+qJrVYwodFDJiPh9XcDjDV+/z1SPv8r4VS7PZMRST0YtL2Wz2RAZGdluH6/PjD///HNMnToVCQkJMJlM2L17t9vjQgi89tpriI+PR2hoKDIyMnDu3Dlvd0NE1GEtijiMDUeK18m4pqYGKSkp2LBhQ6uPr1u3Dr/73e+wefNmHDt2DGFhYcjMzERtbe0dB0tEJKO5iGNi089lRgYjS9wBACI/P9912+l0iri4OPHGG2+47quurhYWi0Xs2LFDaps2m00AkGomk8ljk92WymY2m6WaEbHpGr/MsZRtqsfD1/tUPf4q41d5DDrzeO4HhLil7ffBPttrNpvNY+5T+gFeeXk5KisrkZGR4brParUiLS0NxcXFrT7H4XDAbre7NSKiO6Hb+nYylF5nXFlZCQCIjY11uz82Ntb12O3y8vKwcuVKlWEQkZ/TbX07GYZf2rZ06VLYbDZXq6ioMDokIurimos4Mpt+6nndkjulyTguLg4AUFVV5XZ/VVWV67HbWSwWREZGujUiIn+jNBknJSUhLi4OBQUFrvvsdjuOHTuG9PR0lbsiIupWvJ4zvnHjBs6fP++6XV5ejpKSEkRHR6N///5YtGgR1qxZg8GDByMpKQnLly9HQkICpk+frjJuIqJuxetkfPz4cTz88MOu20uWLAEAZGdnY+vWrXj55ZdRU1ODZ555BtXV1RgzZgz27duHkJAQdVE3ET6urlNdGSW7hI0M2WVuzp4967HP7NmzpbZ19OhRj31UVtYBvj/mgNxxlx1/mX6y75/AQLlfX5nlmVRXpqms+lO5VJgR7x9ZXboc2teYjN35SzKWSXoqk7EsJuMfqV73ULVOKYcmIiL1mIyJiDTAZExEpAEmYyIiDTAZExFpgMmYiEgDTMZERBrg6tBNZK6LVL1MkhHXzA4bNsyn+5O9flXn60RlrtOVvQZd5fW3MnHJUv1e1Kx8oUvgmTERkQaYjImINMBkTESkASZjIiINMBkTEWmAyZiISANMxkREGmAyJiLSAJMxEZEGtK7A81StpLLKR2ZbwcHBUtuqr69Xtk9ZEyZMkOp34MABj31Urvogu5qJygo81atWqFyRRaWgoCCpfjKvU2U1n2pGVPOprJSUpee7jIjIzzAZExFpgMmYiEgDTMZERBpgMiYi0gCTMRGRBpiMiYg0wGRMRKQBJmMiIg1oXYGnosJFZTWWbGWdbDWZTGyy8Y8bN06q31/+8hePfUpKSqS2JbMmoGxll8rjZMR6bkas4Sf7fjSigjAw0HNqUfnekH2NsutYyhxzmXUPhRDS7w2eGUsyA1guBPYJgeVCwMwFF4lIIa3PjHWyDEAubv71ymi6b7Vx4RBRN8MzY0lj8ONgBQAYbWAsRNT9MBlLOgygeebHCeCIgbEQUffDaQpJawGYcPOM+EjTbSIiVZiMJTUCWC35iT8Rkbc4TUFEpAEmYyIiDWg9TaFi2SWVBQCyhQn33HOPVD+Z2LKzs6W29Zvf/Eaq30MPPeSxj+yF8SoZsbSOTGECIFecIFMAABgztkYUpKhcxsmI+GWoPpZenxl//vnnmDp1KhISEmAymbB79263x2fPng2TyeTWsrKyVMVLRNQteZ2Ma2pqkJKSgg0bNrTZJysrC5cvX3a1HTt23FGQRETdndfTFJMmTcKkSZPa7WOxWBAXF9fhoIiI/E2nfIBXWFiIPn36YOjQoZg/fz6uXbvWZl+HwwG73e7WiIj8jfJknJWVhX//939HQUEB/umf/glFRUWYNGlSm5PdeXl5sFqtrtavXz/VIRERaU/51RRPPPGE698jR45EcnIyBg4ciMLCQowfP75F/6VLl2LJkiWu23a7nQmZiPxOp19nPGDAAPTu3Rvnz59v9XGLxYLIyEi3RkTkbzo9GX/77be4du0a4uPjO3tXRERdltfTFDdu3HA7yy0vL0dJSQmio6MRHR2NlStXYsaMGYiLi0NZWRlefvllDBo0CJmZmUoDJyLqTkzCy9KnwsJCPPzwwy3uz87OxqZNmzB9+nScPHkS1dXVSEhIwMSJE7F69WrExsZKbd9ut8NqtcoFL1ERJ1sZpXJpHZXVZL169ZLq194VK12B7LI5MsfAiGo4lctG6bxPI8i+Thkqx8KbZZdsNpvHKVivk3FnYzJ2x2TsjsnY2H0awV+SMb8oiIhIA0zGREQaYDImItIAkzERkQaYjImINMBkTESkASZjIiINMBkTEWlA6zXwPJG5GFzlWlwqLz6XVV1d7fN9BgUFSfWTKZqQLZRRuc6Zv6zhZ8Q+ZYtzZBhRRKWS4WvgERGRekzGREQaYDImItIAkzERkQaYjImINMBkTESkASZjIiINMBkTEWmgSxd9qCwUMIJMEYkRBQz19fVS/VQWwahc6YPcyYytbGGF7PgbUSDVmcwAlgEYA+AwgLUAVP9mdulkTETkC8sArMDNqYSMpvtWK94HpymIiDwYgx+TZUDTbdWYjImIPDgMoHmCxtl0WzVOUxARebC26eetc8aqMRkTEXnQCPVzxLfjNAURkQaYjImINMBkTESkASZjIiINdPsP8GQrgWT6qa4+kql6Ul2ZJrM9I7alcmkdleOv2u2xmYXAMgCjARzBzU/pZRcKM5vNUv2MqOKcPn26xz75+flS25I5nrLHUuf3RrdPxkQ6WwYgF+6VXauMC4cMxGkKP2IG8BshsM/pxG+EgFnThR79yWi4V3aNNjAWMhbPjP3IMgC5QiAAwHghAJMJa4wOys8dwc0z4gDcrOw6Ymw4ZCAmYz/Sor6+KSGTcZoruW6dMyb/xGTsRw7D/SzsMBOx4RpNppaVXZw+8ktMxn5kLW5+mjxGCBw2mZBndEBE5MJk7EcaAawxmTg1QaQhXk1BRKQBkzDi6uZ22O12WK1Wo8PQhuqiD5XL4agslFH5Oo1YwikwUO4/mQ0Nnks6jDjmsvuULSBRWdzSHdhsNkRGRrbbx6sz47y8PNx///2IiIhAnz59MH36dJSWlrr1qa2tRU5ODnr16oXw8HDMmDEDVVVV3kdPRN1Gc3HLxKafy4wNR0teJeOioiLk5OTg6NGjOHDgAOrr6zFx4kTU1NS4+ixevBgfffQRdu3ahaKiIly6dAmPPfaY8sCJqOtgcYsEcQeuXLkiAIiioiIhhBDV1dUiKChI7Nq1y9Xn66+/FgBEcXGx1DZtNpsAwNbUAgICpJrs9kwmk7KmMi6Vr1P1mMm0wMBAqabrMTebzVKto/t8DRCNgBBNP1/T4HfLl81ms3nMfXd0NYXNZgMAREdHAwBOnDiB+vp6ZGRkuPoMGzYM/fv3R3FxMR544IE72R0RdVEsbvGsw8nY6XRi0aJFGD16NEaMGAEAqKysRHBwMKKiotz6xsbGorKystXtOBwOOBwO12273d7RkIhIUyxu8azDl7bl5OTg9OnT2Llz5x0FkJeXB6vV6mr9+vW7o+0REXVFHUrGCxYswMcff4xDhw6hb9++rvvj4uJQV1eH6upqt/5VVVWIi4trdVtLly6FzWZztYqKio6ERETUpXmVjIUQWLBgAfLz8/HZZ58hKSnJ7fHU1FQEBQWhoKDAdV9paSkuXryI9PT0VrdpsVgQGRnp1oiI/I1Xc8Y5OTnYvn079uzZg4iICNc8sNVqRWhoKKxWK+bOnYslS5YgOjoakZGRWLhwIdLT0/nhHRFRO7yqwGurkmfLli2YPXs2gJtFHy+88AJ27NgBh8OBzMxMbNy4sc1pitvdWoHnqXLIi9C7LCOWiZGtxlJZzWfE0kCyVC77oyvZY66SEct7GUWmAk/rcmgmYyZjHTAZdw4mY3f8oiAiIg0wGRMRaYDJmIhIA0zGREQaYDImItIAkzERkQaYjImINMBkTESkAa1Xh9btQnqVRQ6A3OszYgyMuIDeYrFI9auvr/fYR3bMVPaTfW+oLGCQ3afKohUj3o8yY2ZE/DLrHgohpAuaeGZMRKQBJmMiIg0wGRMRaYDJmIhIA0zGREQaYDImItIAkzERkQaYjImINKBt0YfJZPJ4sbqvixNUF33I0PUie0Bu/GXHzOFwSPUzm80e+6h+X6gsmlC5ooluRVG3khmzoKAgqW01NDR47CM7FipXNJGJyxs8MyYi0gCTMRGRBpiMiYg0wGRMRKQBJmMiIg0wGRMRaYDJmIhIA0zGREQaYDImItKAthV4OlYXGbEckRFkX6fKJYR0pvK9qLKaT2cyr0FmCS3VdH4/8syYiEgDTMZERBpgMiYi0gCTMRGRBpiMiYg0wGRMRKQBJmMiIg0wGRMRaYDJmIhIA14l47y8PNx///2IiIhAnz59MH36dJSWlrr1GTdunGv9uuY2b948pUE3u30/rbWAgABlzYj4VTeVr9PpdHpssnHJamxs9NhkBQYGSjUj3hsqqRx/6jxevYuKioqQk5ODo0eP4sCBA6ivr8fEiRNRU1Pj1u/pp5/G5cuXXW3dunVKgyYi6m68+m6Kffv2ud3eunUr+vTpgxMnTmDs2LGu+3v06IG4uDg1ERIR+YE7+v+VzWYDAERHR7vdv23bNvTu3RsjRozA0qVL8f3339/JbugWZiGwXAjsa/pp7gZfKkNEd/CtbU6nE4sWLcLo0aMxYsQI1/0zZ85EYmIiEhIScOrUKfz6179GaWkpPvzww1a343A44HA4XLftdntHQ/ILywDk4uZf0Yym+1YbFw4RqSI6aN68eSIxMVFUVFS026+goEAAEOfPn2/18dzcXAGg1WYyme64BQQEKGttxdnR1pHXsx8Q4pa238vt+Pp1ysalemxlWmBgoFRTOWZGjIWu4+9PzWazecypHZqmWLBgAT7++GMcOnQIffv2bbdvWloaAOD8+fOtPr506VLYbDZXq6io6EhIfuMIgOZvZHU23Sairs+raQohBBYuXIj8/HwUFhYiKSnJ43NKSkoAAPHx8a0+brFYYLFYvAnDr61t+jkaNxPx2nb6ElHX4VUyzsnJwfbt27Fnzx5ERESgsrISAGC1WhEaGoqysjJs374dkydPRq9evXDq1CksXrwYY8eORXJycqe8AH/TaDJxjpioO/JmnhhtzIds2bJFCCHExYsXxdixY0V0dLSwWCxi0KBB4qWXXpKaL2lms9kMn9+506ZyDlrnOVeZ16hz/Gyd18xms8em8n1mxGv05n0tkwNNTUlWG3a7HVar1egw7ohsRZbMelyy1VFGHEaZ1ykbl2ZvQ7pDZrPZYx/Zakld11qU+d1sfl/bbDZERka221fvOk4iIj/BZExEpAEmYyIiDTAZExFpgMmYiEgDTMZERBpgMiYi0gCTMRGRBjr8FZpdhcolZWQLE2QvQO/KF7PL9jMiftW8ubjfl3QuCFJ53FUWR8mSGTPV488zYyIiDTAZExFpgMmYiEgDTMZERBpgMiYi0gCTMRGRBpiMiYg0wGRMRKSBLl300dVXmlB5MbtsP5l9yo6FzEoNMis+yG5LlhEFALKru8hsS3b8ZcdW18Iblb9zsmPR0NCgbJ+qx5VnxkREGmAyJiLSAJMxEZEGmIyJiDTAZExEpAEmYyIiDTAZExFpgMmYiFowC4HfCIF9Tid+IwTMBlyH72+6dNEHEXWOpQByhUAAgPFCACYT1hgdVDfX7ZOxbJWPrkvrqN6nr5ehkt2fbAWbygpClYyoclNZTXa70fjxv80BAEYLAadB70WZfp05Fr7CaQoiauEwgOY/L86m29S5uv2ZMRF5b23TzzG4mYjXttOX1GAyJqIWGgGsNjoIP8NpCiIiDTAZExFpgMmYiEgDTMZERBpgMiYi0gCTMRGRBrxKxps2bUJycjIiIyMRGRmJ9PR07N271/V4bW0tcnJy0KtXL4SHh2PGjBmoqqrqWGABATCbze02p9PpsckSQnhsRggICJBqMvGrbiaTyWNraGiQajLHUvmaY5JjKyMwMFCqqSQz/qrXA1RJ9n2m8n2h85h5lYz79u2L119/HSdOnMDx48fxyCOPYNq0aThz5gwAYPHixfjoo4+wa9cuFBUV4dKlS3jsscc6JXAiom5F3KGePXuK9957T1RXV4ugoCCxa9cu12Nff/21ACCKi4ult2ez2QQAERAQIMxmc7sNQLdvAQEBUs2I2Ewmk8dm9Pj5amwDAwOlmq/HX/dj4Otm1JjZbDaPua/Dc8aNjY3YuXMnampqkJ6ejhMnTqC+vh4ZGRmuPsOGDUP//v1RXFzc0d0QEfkFryexvvzyS6Snp6O2thbh4eHIz8/H8OHDUVJSguDgYERFRbn1j42NRWVlZZvbczgccDgcrtt2u93bkIiIujyvz4yHDh2KkpISHDt2DPPnz0d2dja++uqrDgeQl5cHq9Xqav369evwtoiIuiqvk3FwcDAGDRqE1NRU5OXlISUlBW+//Tbi4uJQV1eH6upqt/5VVVWIi4trc3tLly6FzWZztYqKCq9fBBFRV3fH1xk7nU44HA6kpqYiKCgIBQUFrsdKS0tx8eJFpKent/l8i8XiulSuuRER+Ruv5oyXLl2KSZMmoX///rh+/Tq2b9+OwsJC7N+/H1arFXPnzsWSJUsQHR2NyMhILFy4EOnp6XjggQc6K34iom7Bq2R85coV/N3f/R0uX74Mq9WK5ORk7N+/HxMmTAAAvPXWWwgICMCMGTPgcDiQmZmJjRs3digwXy9jY8SySyr3qXIJG9mxl4ktKChIalv19fVS/VRekK/yPdbY2KhsW7Jk3xsyhSuqf98GDhzosc/q1e7fmGxqbMTwPXsQc/Ysrg4bhq+mTYMwmzFz5kxlcan8HTabzVL7kx1br5Lxv/7rv7b7eEhICDZs2IANGzZ4s1kiIgzfswcjP/gAJgBxp08DAM74UdEYv5uCiLQQc/Ysmv/fY2q67U+YjIlIC1eHDUPzJIJout3ZzACWA9jf9NPzxEPn4Rp4RKSFr6ZNAwC3OePOtgzACtw8K22uHTZq7T8mYyLSgjCbfT5HPAY/Tg8ENN02CqcpiMhvHQbQfK2Ds+m2UXhmTER+a23TzzG4mYjXttO3szEZE5HfaoRxc8S30y4Zqy6s0Hm/Rr1WX1L9GnUdM13jAoyJTabQ4fvvv/dBJJ1HZlyb+8j0NQnN3kXffvstv7mNiLqViooK9O3bt90+2iVjp9OJS5cuISIiwlX6arfb0a9fP1RUVHTJLxJi/Mbr6q+B8Ruro/ELIXD9+nUkJCR4LEvXbpoiICCgzb8gXf1b3Ri/8br6a2D8xupI/FarVaofL20jItIAkzERkQa6RDK2WCzIzc2FxWIxOpQOYfzG6+qvgfEbyxfxa/cBHhGRP+oSZ8ZERN0dkzERkQaYjImINMBkTESkgS6RjDds2IC7774bISEhSEtLw5/+9CejQ5KyYsUKmEwmtzbMB6sXdNTnn3+OqVOnIiEhASaTCbt373Z7XAiB1157DfHx8QgNDUVGRgbOnTtnTLCt8BT/7NmzWxyPrKwsY4JtRV5eHu6//35ERESgT58+mD59OkpLS9361NbWIicnB7169UJ4eDhmzJiBqqoqgyJ2JxP/uHHjWhyDefPmGRSxu02bNiE5OdlV2JGeno69e/e6Hu/ssdc+Gb///vtYsmQJcnNz8cUXXyAlJQWZmZm4cuWK0aFJuffee3H58mVXO3zYyG9MbV9NTQ1SUlLaXFB23bp1+N3vfofNmzfj2LFjCAsLQ2ZmJmpra30caes8xQ8AWVlZbsdjx44dPoywfUVFRcjJycHRo0dx4MAB1NfXY+LEiaipqXH1Wbx4MT766CPs2rULRUVFuHTpEh7TZNFOmfgB4Omnn3Y7BuvWrTMoYnd9+/bF66+/jhMnTuD48eN45JFHMG3aNJw5cwaAD8ZeaG7UqFEiJyfHdbuxsVEkJCSIvLw8A6OSk5ubK1JSUowOo0MAiPz8fNdtp9Mp4uLixBtvvOG6r7q6WlgsFrFjxw4DImzf7fELIUR2draYNm2aIfF0xJUrVwQAUVRUJIS4Od5BQUFi165drj5ff/21ACCKi4uNCrNNt8cvhBAPPfSQeP75540Lyks9e/YU7733nk/GXusz47q6Opw4cQIZGRmu+wICApCRkYHi4mIDI5N37tw5JCQkYMCAAXjyySdx8eJFo0PqkPLyclRWVrodC6vVirS0tC5zLACgsLAQffr0wdChQzF//nxcu3bN6JDaZLPZAADR0dEAgBMnTqC+vt7tGAwbNgz9+/fX8hjcHn+zbdu2oXfv3hgxYgSWLl2q5VdpNjY2YufOnaipqUF6erpPxl67Lwq61XfffYfGxkbExsa63R8bG4uzXWAZ77S0NGzduhVDhw7F5cuXsXLlSjz44IM4ffo0IiIijA7PK5WVlQDQ6rFofkx3WVlZeOyxx5CUlISysjIsW7YMkyZNQnFxMcxmI9cFbsnpdGLRokUYPXo0RowYAeDmMQgODkZUVJRbXx2PQWvxA8DMmTORmJiIhIQEnDp1Cr/+9a9RWlqKDz/80MBof/Tll18iPT0dtbW1CA8PR35+PoYPH46SkpJOH3utk3FXN2nSJNe/k5OTkZaWhsTERPznf/4n5s6da2Bk/umJJ55w/XvkyJFITk7GwIEDUVhYiPHjxxsYWUs5OTk4ffq01p8xtKet+J955hnXv0eOHIn4+HiMHz8eZWVlGDhwoK/DbGHo0KEoKSmBzWbDBx98gOzsbBQVFflk31pPU/Tu3Rtms7nFJ5ZVVVWIi4szKKqOi4qKwpAhQ3D+/HmjQ/Fa83h3l2MBAAMGDEDv3r21Ox4LFizAxx9/jEOHDrl9nWxcXBzq6upQXV3t1l+3Y9BW/K1JS0sDAG2OQXBwMAYNGoTU1FTk5eUhJSUFb7/9tk/GXutkHBwcjNTUVBQUFLjuczqdKCgoQHp6uoGRdcyNGzdQVlaG+Ph4o0PxWlJSEuLi4tyOhd1ux7Fjx7rksQBuripz7do1bY6HEAILFixAfn4+PvvsMyQlJbk9npqaiqCgILdjUFpaiosXL2pxDDzF35qSkhIA0OYY3M7pdMLhcPhm7JV8DNiJdu7cKSwWi9i6dav46quvxDPPPCOioqJEZWWl0aF59MILL4jCwkJRXl4ujhw5IjIyMkTv3r3FlStXjA6tVdevXxcnT54UJ0+eFADEm2++KU6ePCm++eYbIYQQr7/+uoiKihJ79uwRp06dEtOmTRNJSUnihx9+MDjym9qL//r16+LFF18UxcXFory8XBw8eFD85Cc/EYMHDxa1tbVGhy6EEGL+/PnCarWKwsJCcfnyZVf7/vvvXX3mzZsn+vfvLz777DNx/PhxkZ6eLtLT0w2M+kee4j9//rxYtWqVOH78uCgvLxd79uwRAwYMEGPHjjU48pteeeUVUVRUJMrLy8WpU6fEK6+8Ikwmk/j000+FEJ0/9tonYyGEeOedd0T//v1FcHCwGDVqlDh69KjRIUl5/PHHRXx8vAgODhZ33XWXePzxx8X58+eNDqtNhw4dEgBatOzsbCHEzcvbli9fLmJjY4XFYhHjx48XpaWlxgZ9i/bi//7778XEiRNFTEyMCAoKEomJieLpp5/W6o96a7EDEFu2bHH1+eGHH8Q//MM/iJ49e4oePXqIRx99VFy+fNm4oG/hKf6LFy+KsWPHiujoaGGxWMSgQYPESy+9JGw2m7GBN/n7v/97kZiYKIKDg0VMTIwYP368KxEL0fljz6/QJCLSgNZzxkRE/oLJmIhIA0zGREQaYDImItIAkzERkQaYjImINMBkTESkASZjIiINMBkTEWmAyZiISANMxkREGmAyJiLSwP8DhYSe3r8Jcd8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Select an index to visualize from the entire dataset\n",
    "index_to_visualize = np.random.randint(0, len(all_images))\n",
    "\n",
    "# index_to_visualize = 11548\n",
    "# Visualize the selected image with predicted and true midpoints\n",
    "visualize_midpoints(all_images[index_to_visualize], all_pred_midpoints[index_to_visualize, 0, :, :] * np.max(centers), title=\"Predicted Midpoints\")\n",
    "visualize_midpoints(all_images[index_to_visualize], all_true_midpoints[index_to_visualize, 0, :, :] * np.max(centers), title=\"Ground Truth Midpoints\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-160.59007, 303.0473)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(all_pred_midpoints)*np.max(centers),np.max(all_pred_midpoints)*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 63.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(all_true_midpoints)*np.max(centers),np.max(all_true_midpoints)*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0, 0.0, 63.0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(train_images), np.max(train_images), np.min(train_midpoints)*np.max(centers), np.max(train_midpoints)*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[37.49769  ,  0.893701 ],\n",
       "         [ 5.268126 ,  2.3811095],\n",
       "         [ 6.2055097,  9.41111  ],\n",
       "         [38.5479   , 14.923272 ],\n",
       "         [ 1.6805356, 27.386879 ],\n",
       "         [45.822754 , 30.42933  ],\n",
       "         [27.461199 , 36.76014  ],\n",
       "         [39.048737 , 38.981136 ],\n",
       "         [13.185979 , 48.234604 ],\n",
       "         [38.724014 , 50.478184 ],\n",
       "         [ 5.041256 , 56.032772 ],\n",
       "         [27.951286 , 54.13892  ],\n",
       "         [28.76817  , 58.81217  ]]], dtype=float32),\n",
       " array([[[37.,  1.],\n",
       "         [ 6.,  3.],\n",
       "         [ 5., 11.],\n",
       "         [38., 13.],\n",
       "         [ 1., 30.],\n",
       "         [46., 33.],\n",
       "         [28., 34.],\n",
       "         [38., 38.],\n",
       "         [14., 48.],\n",
       "         [38., 50.],\n",
       "         [ 5., 57.],\n",
       "         [28., 57.],\n",
       "         [29., 59.]]], dtype=float32))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pred_midpoints[2]*np.max(centers),all_true_midpoints[2]*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1., 35., 12.],\n",
       "        [ 1., 63., 52.],\n",
       "        [ 1., 11., 43.],\n",
       "        ...,\n",
       "        [ 1., 10., 33.],\n",
       "        [ 1., 11., 48.],\n",
       "        [ 1., 59., 49.]],\n",
       "\n",
       "       [[ 1.,  5., 24.],\n",
       "        [ 1., 34., 55.],\n",
       "        [ 1., 42., 29.],\n",
       "        ...,\n",
       "        [ 1.,  2., 55.],\n",
       "        [ 1., 13., 17.],\n",
       "        [ 1., 45.,  8.]],\n",
       "\n",
       "       [[ 1., 38., 36.],\n",
       "        [ 1., 11., 33.],\n",
       "        [ 1., 40., 40.],\n",
       "        ...,\n",
       "        [ 1., 45.,  5.],\n",
       "        [ 1.,  8.,  7.],\n",
       "        [ 1., 55., 37.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1., 50., 18.],\n",
       "        [ 1., 20., 19.],\n",
       "        [ 1., 63.,  8.],\n",
       "        ...,\n",
       "        [ 1., 32., 44.],\n",
       "        [ 1., 63., 24.],\n",
       "        [ 1., 51., 52.]],\n",
       "\n",
       "       [[ 1.,  6., 33.],\n",
       "        [ 1., 23., 59.],\n",
       "        [ 1., 13., 48.],\n",
       "        ...,\n",
       "        [ 1., 26., 62.],\n",
       "        [ 1., 20., 42.],\n",
       "        [ 1., 53.,  2.]],\n",
       "\n",
       "       [[ 1., 24., 40.],\n",
       "        [ 1., 30., 43.],\n",
       "        [ 1., 38., 55.],\n",
       "        ...,\n",
       "        [ 1., 31., 56.],\n",
       "        [ 1., 21., 50.],\n",
       "        [ 1., 15.,  6.]]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[2],)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize variables to track the min and max MSE\n",
    "min_mse = float('inf')\n",
    "max_mse = float('-inf')\n",
    "min_mse_index = -1\n",
    "max_mse_index = -1\n",
    "\n",
    "# Loop through each prediction to calculate the MSE\n",
    "for i in range(len(all_pred_midpoints)):\n",
    "    mse = np.mean((all_pred_midpoints[i] - all_true_midpoints[i]) **2)\n",
    "    \n",
    "    if mse < min_mse:\n",
    "        min_mse = mse\n",
    "        min_mse_index = i\n",
    "    \n",
    "    if mse > max_mse:\n",
    "        max_mse = mse\n",
    "        max_mse_index = i\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot an image with its centers\n",
    "def plot_image_with_centers(image, true_center, predicted_center, title):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image.squeeze(), cmap='gray')  # Display the image\n",
    "\n",
    "    # Plot the actual center (Groundtruth)\n",
    "    plt.scatter(true_center[:, 0], true_center[:, 1], color='green', label='Groundtruth', s=10)\n",
    "\n",
    "    # Plot the predicted center\n",
    "    plt.scatter(predicted_center[:, 0], predicted_center[:, 1], color='red', label='Predictions', s=10)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the image with the least MSE\n",
    "plot_image_with_centers(all_images[min_mse_index],\n",
    "                        all_true_midpoints[min_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[min_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        f'Image with Least MSE. MSE: {min_mse:.4f}')\n",
    "\n",
    "# Plotting the image with the largest MSE\n",
    "plot_image_with_centers(all_images[max_mse_index],\n",
    "                        all_true_midpoints[max_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[max_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        f'Image with Largest MSE. MSE: {max_mse:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5266"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_mse_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "objectdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
