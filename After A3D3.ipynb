{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Set CUDA device order and visible devices\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7,8,9\"\n",
    "\n",
    "# # Set the device\n",
    "# device = '/cpu:0'\n",
    "# if tf.config.experimental.list_physical_devices('GPU'):\n",
    "#     try:\n",
    "#         # Restrict TensorFlow to only use the second GPU\n",
    "#         gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#         if gpus:\n",
    "#             tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "#             device = '/gpu:0'\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)\n",
    "\n",
    "# print(\"device\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 16:12:47.335463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79196 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:45:00.0, compute capability: 8.0\n",
      "2024-10-21 16:12:47.336913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 79196 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:46:00.0, compute capability: 8.0\n",
      "2024-10-21 16:12:47.338362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 79196 MB memory:  -> device: 2, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:49:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"  # Only GPUs 0 and 1 will be visible to TensorFlow\n",
    "\n",
    "import tensorflow as tf\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\",\"/gpu:2\"])\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 16:12:32.015128: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-21 16:12:32.103736: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-21 16:12:32.140493: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-21 16:12:32.152957: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-21 16:12:32.223546: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-21 16:12:32.994272: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# DataLoader Class Definition\n",
    "# -----------------------------\n",
    "class DataLoader:\n",
    "    def __init__(self, h5_filename):\n",
    "        self.h5_filename = h5_filename\n",
    "        self.images, self.centers = self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        with h5py.File(self.h5_filename, 'r') as f:\n",
    "            images = np.array(f['images'])\n",
    "            centers = np.array(f['centers_training'])\n",
    "        return images, centers\n",
    "\n",
    "    def plot_image_with_centers(self, image_index=None):\n",
    "        if image_index is None:\n",
    "            image_index = np.random.randint(0, len(self.images))\n",
    "\n",
    "        image = self.images[image_index]\n",
    "        centers = self.centers[image_index]\n",
    "\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        valid_centers = centers[centers[:, 0] == 1]\n",
    "        for center in valid_centers:\n",
    "            plt.scatter(center[1], center[2], c='red', marker='o',s=5)  # center[1] is x and center[2] is y\n",
    "        plt.title('Image with Valid Centers Marked')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_centers(centers):\n",
    "        return centers[np.lexsort((centers[:, 0], centers[:, 1]))]\n",
    "\n",
    "    def normalize_data(self):\n",
    "        normalized_images = self.images / np.max(self.images)\n",
    "        sorted_centers = np.array([self.sort_centers(image_centers[:, 1:]) for image_centers in self.centers])\n",
    "        normalized_centers = sorted_centers / np.max(centers)\n",
    "\n",
    "        normalized_midpoints = tf.expand_dims(normalized_centers, axis=1)\n",
    "        return normalized_images, normalized_midpoints.numpy()\n",
    "\n",
    "    def split_data(self, train_size=0.8, random_state=42):\n",
    "        normalized_images, normalized_midpoints_np = self.normalize_data()\n",
    "        return train_test_split(normalized_images, normalized_midpoints_np, train_size=train_size, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Utility Function Definition\n",
    "# -----------------------------\n",
    "def plot_transposed_images_with_midpoints(dataset, image_indices=[0, 1, 2, 3]):\n",
    "    \"\"\"\n",
    "    Extracts multiple images and their midpoints from the given dataset, transposes the images, \n",
    "    corrects the midpoints, and plots the transposed images with the corrected midpoints.\n",
    "\n",
    "    Args:\n",
    "    - dataset (tf.data.Dataset): The dataset from which to extract the images and midpoints.\n",
    "    - image_indices (list): The indices of the images in the batch to visualize. Default is [0, 1, 2, 3].\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract a sample image batch and its corresponding midpoints from the dataset\n",
    "    sample_image_batch, sample_midpoints_batch = next(iter(dataset))\n",
    "\n",
    "    # Create a figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(6, 6))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(image_indices):\n",
    "            # Select the specified image and corresponding midpoints from the batch\n",
    "            sample_image = np.array(sample_image_batch[image_indices[i]])\n",
    "            sample_midpoints = np.array(sample_midpoints_batch[image_indices[i]])\n",
    "\n",
    "            # Transpose the image\n",
    "            transposed_image = sample_image.T\n",
    "\n",
    "            # Correct the midpoints by swapping the x and y coordinates\n",
    "            transposed_midpoints_corrected = sample_midpoints[:, :, [1, 0]]\n",
    "\n",
    "            # Plot the transposed image with corrected midpoints\n",
    "            ax.imshow(transposed_image, cmap='gray')\n",
    "            ax.scatter(\n",
    "                transposed_midpoints_corrected[:, :, 0] * 31, \n",
    "                transposed_midpoints_corrected[:, :, 1] * 31, \n",
    "                c='red', marker='o', s=5\n",
    "            )\n",
    "            ax.set_title(f'Image {image_indices[i]} for this batch')\n",
    "        else:\n",
    "            ax.axis('off')  # If fewer than 4 images are requested, hide the unused subplots\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Custom Loss and Callback Definitions\n",
    "# -----------------------------\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def custom_loss(exponent):\n",
    "    def loss(y_true, y_pred):\n",
    "        diff = tf.abs(y_true - y_pred)\n",
    "        powered_diff = tf.pow(diff, exponent)\n",
    "        return tf.reduce_mean(powered_diff)\n",
    "    return loss\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class DynamicExponentCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, initial_exponent, increment, update_frequency):\n",
    "        super().__init__()\n",
    "        self.exponent = initial_exponent\n",
    "        self.increment = increment\n",
    "        self.update_frequency = update_frequency\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.update_frequency == 0:\n",
    "            self.exponent += self.increment\n",
    "            print(f\"\\nEpoch {epoch + 1}: Increasing exponent to {self.exponent}\")\n",
    "            self.model.loss = self.custom_loss(self.exponent)\n",
    "\n",
    "    def custom_loss(self, exponent):\n",
    "        def loss(y_true, y_pred):\n",
    "            diff = tf.abs(y_true - y_pred)\n",
    "            powered_diff = tf.pow(diff, exponent)\n",
    "            return tf.reduce_mean(powered_diff)\n",
    "        return loss\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'initial_exponent': self.exponent,\n",
    "            'increment': self.increment,\n",
    "            'update_frequency': self.update_frequency,\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my NEW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "\n",
    "class ModelBuilder:\n",
    "    def __init__(self, input_shape=(32, 32, 1), num_classes=4, num_coordinates=2, learning_rate=1e-2, weights_path=None,l1_reg=0.001,l2_reg =0.01):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.num_coordinates = num_coordinates\n",
    "        self.learning_rate = learning_rate\n",
    "        self.l1_reg = l1_reg\n",
    "        self.l2_reg = l2_reg\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        # Load weights if a path is provided\n",
    "        if weights_path is not None:\n",
    "            self.model.load_weights(weights_path)\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "        # self.optimizer =tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "    def build_model(self):\n",
    "        \n",
    "        l1 = regularizers.l1(self.l1_reg)\n",
    "        l2 = regularizers.l2(self.l2_reg)\n",
    "\n",
    "    \n",
    "        x_input = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "        \n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x_input)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        \n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        \n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.3)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        # x = layers.MaxPool2D()(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.3)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=5, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        # x = layers.Conv2D(128, kernel_size=5, padding='same', activation='relu')(x)\n",
    "        # # x = layers.MaxPool2D()(x)\n",
    "        # # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Flatten()(x)\n",
    "        \n",
    "        x_midpoints = layers.Dense(self.num_classes * self.num_coordinates, activation='sigmoid', name='x_midpoints')(x)\n",
    "        x_midpoints_reshape = layers.Reshape((-1, self.num_classes, self.num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "        \n",
    "        return tf.keras.models.Model(x_input, x_midpoints_reshape)\n",
    "\n",
    "    def compile_model(self, loss_function):\n",
    "        self.model.compile(optimizer=self.optimizer, loss=loss_function)\n",
    "\n",
    "    def train_model(self, train_dataset, val_dataset, epochs, callbacks_list):\n",
    "        history = self.model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks_list)\n",
    "        return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Main Script Execution\n",
    "# -----------------------------\n",
    "\n",
    "# Load data\n",
    "# h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KFixed_Mixed_13.h5'             \n",
    "h5_filename = '/home/da886/Final Electron counting project/Images and Labels/12KFixed_Mixed_13_32by32_SparsespotsRandomIndex.h5'\n",
    "# h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KFixed_13_SparsespotsRandomIndex.h5'\n",
    "# h5_filename ='/home/da886/Final Electron counting project/Images and Labels/30KFixed-index6_13.h5'\n",
    "data_loader = DataLoader(h5_filename)\n",
    "images, centers = data_loader.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x7f40c45e5610>, 5819)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAk0klEQVR4nO3dfXBU5f338c8JJAtKshiBhJRAgw+gInRKJeZW+aGkQHqPg4Jz+zRTsAyONDhValU6PradicUZRR2EPzqV+hsRS0dgdH5qFU0Y20BLKoMPNQPcacGBRGWGLASzhOx1/+Ht1gjIfpM9XGfD+zWzM5C9OLnOuXbz4WTPfjZwzjkBAHCa5fmeAADgzEQAAQC8IIAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPBioO8JfFMqldK+fftUWFioIAh8TwcAYOSc06FDh1RWVqa8vJOf50QugPbt26fy8nLf0wAA9NHevXs1atSok94fWgCtWLFCjz/+uFpbWzVp0iQ988wzmjJlyin/XWFhoSTpSv1vDQzyM/tmudomlDcg87EuZdt2mMfEMm9JSnWHtu28gswfwqnOpGnbQSyW+Vjjybp1eVwy87nnDcp83pLxuIS5o8a1D/IzX3vL8fty4yEvaFRYjrnheXxMXXpX/5P+eX4yoQTQSy+9pCVLlmjVqlWqrKzU8uXLNXPmTDU3N2vEiBHf+m+/+rXbwCA/8wBSji5+YHnCGQMozGNimrekwPBSo3HbeRk/RqRUYDuGgWHb1l8XO+P6OMPc84IC07ZNx8X8a3HDfhrXPggMAWRc+1D3M0osx9zyPP7/h+NUz4tQLkJ44okntHDhQt122226+OKLtWrVKp111ln6/e9/H8a3AwDkoKwH0NGjR9XU1KTq6ur/fJO8PFVXV6uxsfG48clkUolEoscNAND/ZT2APv/8c3V3d6ukpKTH10tKStTa2nrc+Lq6OsXj8fSNCxAA4Mzg/X1AS5cuVXt7e/q2d+9e31MCAJwGWb8IYdiwYRowYIDa2tp6fL2trU2lpaXHjY/FYooZrjYCAPQPWT8DKigo0OTJk7Vp06b011KplDZt2qSqqqpsfzsAQI4K5TLsJUuWaN68efrBD36gKVOmaPny5ero6NBtt90WxrcDAOSgUALoxhtv1GeffaaHHnpIra2t+t73vqfXX3/9uAsTAABnrsC5aL2FN5FIKB6Pa5pmG96IGqKQ3ilsFqVevCg9ZCzHJVfbIazbj1JrRq7K1SaEiDRVHHNdqk+9rPb2dhUVFZ18k5l/dwAAsocAAgB4QQABALwggAAAXhBAAAAvCCAAgBcEEADACwIIAOAFAQQA8IIAAgB4EUoXXL9irTUxCAwfQ+GOHrVtu6Ag820nk6Zth1kLZJm31Iu5GwT5hmPYZVsf8zEMs+bJwlo5ZBGVfZTs1TqRqeyynlMYfr5ZfhZmOJYzIACAFwQQAMALAggA4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAFwQQAMALAggA4AVdcKcQaqeahbGbyjQXa7+XtcvKsP1Qj6GR6858P/POPtu07VRHh2m8qTcw1MehsRvR2qmWq6LUY5dDOAMCAHhBAAEAvCCAAABeEEAAAC8IIACAFwQQAMALAggA4AUBBADwggACAHhBAAEAvOgfVTxBkPnYMCttjCJTOxN2jYhl+5a1VMhVSYZ5W6t1rCLzWDlTqnWMj0PTcQmz+irEmizTtjM8HpwBAQC8IIAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAAL/pHF1yYwupKkkLtsDOxdlO5lHG8Ye5hdvVZ+71MEzGuj/GYBwMyH++6jY9Dw+M2iMVMm3Zdx2xzsQizwzDM55tx3kG+oe8wxLUPA2dAAAAvsh5AjzzyiIIg6HEbP358tr8NACDHhfIruEsuuURvvfXWf77JQH7TBwDoKZRkGDhwoEpLS8PYNACgnwjlNaCdO3eqrKxMY8eO1a233qo9e/acdGwymVQikehxAwD0f1kPoMrKSq1evVqvv/66Vq5cqZaWFl111VU6dOjQCcfX1dUpHo+nb+Xl5dmeEgAgggLnwv2M3YMHD2rMmDF64okntGDBguPuTyaTSn7tUtpEIqHy8nJN02wNDPIz+yZhXs7MZdjHC/My7DBxGfaJcRl2pOXiZdjHXJfqtVHt7e0qKio66bjQrw4YOnSoLrzwQu3ateuE98diMcWMD2oAQO4L/X1Ahw8f1u7duzVy5MiwvxUAIIdkPYDuueceNTQ06F//+pf++te/6vrrr9eAAQN08803Z/tbAQByWNZ/BffJJ5/o5ptv1oEDBzR8+HBdeeWV2rJli4YPH57tb/UfgSFHXYi/Hzf8rtbKdR0NbdtmUXlNxyrEeVvX3rqeLiKvd5iqj6LE+vqf9bES4uu5kXruZ1nWA2jt2rXZ3iQAoB+iCw4A4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAFwQQAMALAggA4AUBBADwIvSPYzgdTJ+VEmKnVs52NkWkZ6xXIvKZSmGvvekzYaxzMRzDYGCGn9H11VyOdRkGR6d/zcyy/bB76cJi+Qwrl5Iy+NgwzoAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAAL6JbxRMEGVdWhFqDYqkpKci8LkWSXDJpnU3mLLUZEarisVTOSMa1z9UKlAiJVN1UYPj/swv5MR6lWqCwuAy6dYxjOQMCAHhBAAEAvCCAAABeEEAAAC8IIACAFwQQAMALAggA4AUBBADwggACAHhBAAEAvCCAAABeRLgLLi/zridDz1OYXWPuaIR6siLU72YRqa6xCAn1uITYTRbEYplPw9qNGKXHuOUYWjsJw5pHmNvOcCxnQAAALwggAIAXBBAAwAsCCADgBQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwIvodsG5lKRU9jd7rMv2Dyy9TdYeJsO2g4H5pk3naqda3qBBpvGpzs7MB1vXJ2+AYdvGx2qIj5VQ+8CMPWbmfjcLy/qE3RsX5vqYHofG/bTMO9NuTunL50MGTwnOgAAAXpgDaPPmzbr22mtVVlamIAi0YcOGHvc75/TQQw9p5MiRGjx4sKqrq7Vz585szRcA0E+YA6ijo0OTJk3SihUrTnj/smXL9PTTT2vVqlXaunWrzj77bM2cOVOdll+VAAD6PfNrQDU1NaqpqTnhfc45LV++XA888IBmz54tSXr++edVUlKiDRs26KabburbbAEA/UZWXwNqaWlRa2urqqur01+Lx+OqrKxUY2PjCf9NMplUIpHocQMA9H9ZDaDW1lZJUklJSY+vl5SUpO/7prq6OsXj8fStvLw8m1MCAESU96vgli5dqvb29vRt7969vqcEADgNshpApaWlkqS2trYeX29ra0vf902xWExFRUU9bgCA/i+rAVRRUaHS0lJt2rQp/bVEIqGtW7eqqqoqm98KAJDjzFfBHT58WLt27Ur/vaWlRdu3b1dxcbFGjx6tu+66S7/5zW90wQUXqKKiQg8++KDKysp03XXXZXPeAIAcZw6gbdu26eqrr07/fcmSJZKkefPmafXq1br33nvV0dGh22+/XQcPHtSVV16p119/XYOMFStf1lVkWFmRozUllrm47pCrRCLCVK0TNkt9i3XtrePPBNZjEna9jkWYP1fCfBxa5m2p+clwbOBcmEfOLpFIKB6Pa5pma2CQYf/ZGRBApj4oKVpPzjNBlAIlVx/jYW77TBGRY3jMdaleG9Xe3v6tr+t7vwoOAHBmIoAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPCCAAIAeEEAAQC8IIAAAF6Yu+AiKSqVHFHpg8plUaocsszFOg/jfgb5hqdqyvY4dF1HDYONj/Go1GRZ5WrlUJSOYQY4AwIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPCCAAIAeEEAAQC8iG4VTxBkXlmRY/UTadbaGQtLNUyY1SDW7RsrbYL8gozHmipnJMmlbOMtrNU9qcwfK+b9DFOYz03L88e6lsZ5mx6Hx7psczFNJOTncpZxBgQA8IIAAgB4QQABALwggAAAXhBAAAAvCCAAgBcEEADACwIIAOAFAQQA8IIAAgB4QQABALyIbhecc5JytOMtDNYuqzB7sqxC7Juy9GpZ+rqkaHWqmeZi7Bg8eOuUjMees7bJtG3LvM+Y9QlTjvVicgYEAPCCAAIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPCCAAIAeBHdKp6oCILMx1prMFLdtvEWLvNtR6kCJcy5WGp7whalYz70vxszHjvsr0NN2/7syswfh1FaHzND/VEwwFaVZDouYVbxWOu9Mmj44gwIAOAFAQQA8MIcQJs3b9a1116rsrIyBUGgDRs29Lh//vz5CoKgx23WrFnZmi8AoJ8wB1BHR4cmTZqkFStWnHTMrFmztH///vTtxRdf7NMkAQD9j/kihJqaGtXU1HzrmFgsptLS0l5PCgDQ/4XyGlB9fb1GjBihcePGadGiRTpw4MBJxyaTSSUSiR43AED/l/UAmjVrlp5//nlt2rRJv/3tb9XQ0KCamhp1d5/4csy6ujrF4/H0rby8PNtTAgBEUNbfB3TTTTel/3zppZdq4sSJOu+881RfX6/p06cfN37p0qVasmRJ+u+JRIIQAoAzQOiXYY8dO1bDhg3Trl27Tnh/LBZTUVFRjxsAoP8LPYA++eQTHThwQCNHjgz7WwEAcoj5V3CHDx/ucTbT0tKi7du3q7i4WMXFxXr00Uc1d+5clZaWavfu3br33nt1/vnna+bMmVmdOAAgt5kDaNu2bbr66qvTf//q9Zt58+Zp5cqV2rFjh/7whz/o4MGDKisr04wZM/TrX/9asVjM9o3yBkiBrTMpI9b+tSDzk8SgwHY4XTJpm4tB3qBBGY9NhTgPq1D7wKw9WSH2AIbZ7RZmx+Bn/+ug7R+E2aUYJS6D4rM04881w3Exdwxanm+Wx1WGXZTmAJo2bZrctxyQN954w7pJAMAZiC44AIAXBBAAwAsCCADgBQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwIusfx5Q1qS6M+5hM/UfDbD1MFk6u9xRSx9UuFKdnZkPtvR19Wa8pctqYL5t04b1Cax9hJZ5HDV2u+Vq71mIa5/TLPuZF97zLdSOwRBwBgQA8IIAAgB4QQABALwggAAAXhBAAAAvCCAAgBcEEADACwIIAOAFAQQA8IIAAgB4Ed0qHoNQ6ycs1SPW2pEwt20RoboU191t+wd5mVcruWTSOBsDa0VNiEzVVDI+f4yPlbxBgzIem7KuT4Qetxau65jxH0RkPw3PNbmUlEEzGWdAAAAvCCAAgBcEEADACwIIAOAFAQQA8IIAAgB4QQABALwggAAAXhBAAAAvCCAAgBcEEADAi37RBWfqKEoZu8YsPUzWPrCobNvKOJdgYH7GY0Pt9bMKs98tzGN4rMu27Vgs820be8xSnZ2GiYR4vC0/IyT7zwkLl0FJ2uli6qM0zDvDsZwBAQC8IIAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPCCAAIAeEEAAQC8IIAAAF70jyoeS21GqHU5tjwPBmZeD2KtqMkbNCjzbRtre1wyaRsfZr2OqUrEWE8UYp1RkF9gGh/mMbSuZ04Ks1rHyvq4CvExPrBiTMZjj/3ff2V9HpwBAQC8MAVQXV2dLrvsMhUWFmrEiBG67rrr1Nzc3GNMZ2enamtrde6552rIkCGaO3eu2trasjppAEDuMwVQQ0ODamtrtWXLFr355pvq6urSjBkz1NHRkR5z991365VXXtG6devU0NCgffv2ac6cOVmfOAAgtwXO+gLA13z22WcaMWKEGhoaNHXqVLW3t2v48OFas2aNbrjhBknSxx9/rIsuukiNjY26/PLLT7nNRCKheDyuaZqtgUHmFfQZC/M1IGPlezDgzHgNKFRhvgYUoii9BhQZUfrIkSgJ8zWgsd/NeKzlNaBjrkv12qj29nYVFRWddFyfXgNqb2+XJBUXF0uSmpqa1NXVperq6vSY8ePHa/To0WpsbDzhNpLJpBKJRI8bAKD/63UApVIp3XXXXbriiis0YcIESVJra6sKCgo0dOjQHmNLSkrU2tp6wu3U1dUpHo+nb+Xl5b2dEgAgh/Q6gGpra/XBBx9o7dq1fZrA0qVL1d7enr7t3bu3T9sDAOSGXr0PaPHixXr11Ve1efNmjRo1Kv310tJSHT16VAcPHuxxFtTW1qbS0tITbisWiylm+EhgAED/YDoDcs5p8eLFWr9+vd5++21VVFT0uH/y5MnKz8/Xpk2b0l9rbm7Wnj17VFVVlZ0ZAwD6BdMZUG1trdasWaONGzeqsLAw/bpOPB7X4MGDFY/HtWDBAi1ZskTFxcUqKirSnXfeqaqqqoyugAMAnDlMAbRy5UpJ0rRp03p8/bnnntP8+fMlSU8++aTy8vI0d+5cJZNJzZw5U88++2xWJgsA6D/69D6gMHz1PqCrY/8n4/cBmd6XYnyvTmR65tBneWefbRqf+tobrE/ljHlfj/UxbsHz4bQbty3z91o2/6Ar47Gn5X1AAAD0FgEEAPCCAAIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPCiVx/HcDq4ZFIuSGV9u5aPwZYkZ6nisbLUAlnnYdm2Mx5na2WKob4lGGj7GHZLpY2lWscqZ6t1rHK1LidCNVnm2qZjmVfgWOdtqdexHcNAymAqnAEBALwggAAAXhBAAAAvCCAAgBcEEADACwIIAOAFAQQA8IIAAgB4QQABALwggAAAXhBAAAAvItsFFxZzZ5el/8jckWYbbmLpjrP0xkmSC7EfzyrU9Qlx22cKyzEMjP8fDrOnMUSh/gwKk2l98uiCAwBEFwEEAPCCAAIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPAiulU8QZB5BYWlIsJa3xFmxUpUqkRCnkcwMD/jseaaEkuNUJQqhMz1R6nMx0ap0sby/LGuT5SqkizrGaWfQRaWeWe4lpwBAQC8IIAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAAL6LbBeecpAw7kCLS8RXEYqbxLpkMaSbRYu53szD0UwX5BbZt52XeNeaOhriPkrEPzNAbl8ssnXch/4wIBhi64CxjFfLzxzPOgAAAXpgCqK6uTpdddpkKCws1YsQIXXfddWpubu4xZtq0aQqCoMftjjvuyOqkAQC5zxRADQ0Nqq2t1ZYtW/Tmm2+qq6tLM2bMUEdHR49xCxcu1P79+9O3ZcuWZXXSAIDcZ3oN6PXXX+/x99WrV2vEiBFqamrS1KlT018/66yzVFpamp0ZAgD6pT69BtTe3i5JKi4u7vH1F154QcOGDdOECRO0dOlSHTly5KTbSCaTSiQSPW4AgP6v11fBpVIp3XXXXbriiis0YcKE9NdvueUWjRkzRmVlZdqxY4fuu+8+NTc36+WXXz7hdurq6vToo4/2dhoAgBwVONe7z3tdtGiRXnvtNb377rsaNWrUSce9/fbbmj59unbt2qXzzjvvuPuTyaSSX7scOZFIqLy8XNM0WwODzD/KOQq4DDvaInUZdpgfm235qGopOh/5bBXmx2AbmR9bBrl4GfYx16V6bVR7e7uKiopOOq5XZ0CLFy/Wq6++qs2bN39r+EhSZWWlJJ00gGKxmGLGH9wAgNxnCiDnnO68806tX79e9fX1qqioOOW/2b59uyRp5MiRvZogAKB/MgVQbW2t1qxZo40bN6qwsFCtra2SpHg8rsGDB2v37t1as2aNfvSjH+ncc8/Vjh07dPfdd2vq1KmaOHFiKDsAAMhNpgBauXKlpC/fbPp1zz33nObPn6+CggK99dZbWr58uTo6OlReXq65c+fqgQceyNqEAQD9g/lXcN+mvLxcDQ0NfZpQLovSRQWmCyJSthehI/WiqOGFaHesy7btMF+cD7ObLFcvKrAK+cICC8tzIswLFkwXZkjejyFdcAAALwggAIAXBBAAwAsCCADgBQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAALwggAIAXvf5AutAFQeafa2KpHjFWVbzxSVPGY2eWfc+0bQtzfYehXidS1TpWYVaJROnzZgzVSlGqhDJ9NlEuVwhZKqG6bY8Vy3Pf+lwOc9uZ4AwIAOAFAQQA8IIAAgB4QQABALwggAAAXhBAAAAvCCAAgBcEEADACwIIAOAFAQQA8IIAAgB4Ed0uOOckhdAN5VKm4WH2u1l6ssw9TJYOLpyYpd/NeryNvWdh9ruF2gcWlX43YwdkqN1+xm27EOfiuweSMyAAgBcEEADACwIIAOAFAQQA8IIAAgB4QQABALwggAAAXhBAAAAvCCAAgBcEEADAi+hW8QRB5vUmlroPazWIpcLDWplhmYu1SsRYOWQScu2MRRCLZT6NEOtsFFj/L2dbn2BgfsZjrfUqodaxWB4r1mNoeb6FWa1zOrYfFsvPFdPPlCCjJjXOgAAAXhBAAAAvCCAAgBcEEADACwIIAOAFAQQA8IIAAgB4QQABALwggAAAXhBAAAAvCCAAgBcR7oLLy7wbyoXYw5SjHU+m7rBjXbaNh9jtZhVqv1uYPYBG5jWysPS1Wdfe1NOYm8+1KAnyC0zjTY+rEDo3OQMCAHhhCqCVK1dq4sSJKioqUlFRkaqqqvTaa6+l7+/s7FRtba3OPfdcDRkyRHPnzlVbW1vWJw0AyH2mABo1apQee+wxNTU1adu2bbrmmms0e/Zsffjhh5Kku+++W6+88orWrVunhoYG7du3T3PmzAll4gCA3BY417df6BcXF+vxxx/XDTfcoOHDh2vNmjW64YYbJEkff/yxLrroIjU2Nuryyy/PaHuJRELxeFzT8uZoYJDh6xg5+jqNifHzgIIBmY/P5deAQhWh14BCfZ0mzG3jtIrKa0DHXJfqtVHt7e0qKio66bhevwbU3d2ttWvXqqOjQ1VVVWpqalJXV5eqq6vTY8aPH6/Ro0ersbHxpNtJJpNKJBI9bgCA/s8cQO+//76GDBmiWCymO+64Q+vXr9fFF1+s1tZWFRQUaOjQoT3Gl5SUqLW19aTbq6urUzweT9/Ky8vNOwEAyD3mABo3bpy2b9+urVu3atGiRZo3b54++uijXk9g6dKlam9vT9/27t3b620BAHKH+X1ABQUFOv/88yVJkydP1t///nc99dRTuvHGG3X06FEdPHiwx1lQW1ubSktLT7q9WCymWCxmnzkAIKf1+X1AqVRKyWRSkydPVn5+vjZt2pS+r7m5WXv27FFVVVVfvw0AoJ8xnQEtXbpUNTU1Gj16tA4dOqQ1a9aovr5eb7zxhuLxuBYsWKAlS5aouLhYRUVFuvPOO1VVVZXxFXAAgDOHKYA+/fRT/fjHP9b+/fsVj8c1ceJEvfHGG/rhD38oSXryySeVl5enuXPnKplMaubMmXr22Wd7N7NUd+ZVPFFhvFRaLhXOWEmuy3BZsOUy3N7I0UuI8wYPynhs6sgR07ZDvZzZup5hzsXynDA+xrkk/Hiu66jvKZj0+X1A2ZZ+H5BmZ/4+oKgIM4CsLMsa9g+sXA2gs8/OeGzoARTmfxIIIGRZ6O8DAgCgLwggAIAXBBAAwAsCCADgBQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAAL8xt2GH7qpjhmLqkXHujs/md3BFpQlDY1S1hfuJmiE0ILvNak5QL+1Nlc7QJIcS6KZoQouuYvnw+nKpoJ3IBdOjQIUnSu/ofzzPphRDzJFRhP4/D3H6Y2+4IcdtWufqzNlefE8iKQ4cOKR6Pn/T+yHXBpVIp7du3T4WFhQq+1n+VSCRUXl6uvXv3fmu3UK5jP/uPM2EfJfazv8nGfjrndOjQIZWVlSkv7+Sv9ETuDCgvL0+jRo066f1FRUX9evG/wn72H2fCPkrsZ3/T1/38tjOfr3ARAgDACwIIAOBFzgRQLBbTww8/rFgs5nsqoWI/+48zYR8l9rO/OZ37GbmLEAAAZ4acOQMCAPQvBBAAwAsCCADgBQEEAPAiZwJoxYoV+u53v6tBgwapsrJSf/vb33xPKaseeeQRBUHQ4zZ+/Hjf0+qTzZs369prr1VZWZmCINCGDRt63O+c00MPPaSRI0dq8ODBqq6u1s6dO/1Mtg9OtZ/z588/bm1nzZrlZ7K9VFdXp8suu0yFhYUaMWKErrvuOjU3N/cY09nZqdraWp177rkaMmSI5s6dq7a2Nk8z7p1M9nPatGnHrecdd9zhaca9s3LlSk2cODH9ZtOqqiq99tpr6ftP11rmRAC99NJLWrJkiR5++GH94x//0KRJkzRz5kx9+umnvqeWVZdccon279+fvr377ru+p9QnHR0dmjRpklasWHHC+5ctW6ann35aq1at0tatW3X22Wdr5syZ6uzsPM0z7ZtT7ackzZo1q8favvjii6dxhn3X0NCg2tpabdmyRW+++aa6uro0Y8YMdXT8pzDv7rvv1iuvvKJ169apoaFB+/bt05w5czzO2i6T/ZSkhQsX9ljPZcuWeZpx74waNUqPPfaYmpqatG3bNl1zzTWaPXu2PvzwQ0mncS1dDpgyZYqrra1N/727u9uVlZW5uro6j7PKrocffthNmjTJ9zRCI8mtX78+/fdUKuVKS0vd448/nv7awYMHXSwWcy+++KKHGWbHN/fTOefmzZvnZs+e7WU+Yfn000+dJNfQ0OCc+3Lt8vPz3bp169Jj/vnPfzpJrrGx0dc0++yb++mcc//1X//lfvazn/mbVEjOOecc97vf/e60rmXkz4COHj2qpqYmVVdXp7+Wl5en6upqNTY2epxZ9u3cuVNlZWUaO3asbr31Vu3Zs8f3lELT0tKi1tbWHusaj8dVWVnZ79ZVkurr6zVixAiNGzdOixYt0oEDB3xPqU/a29slScXFxZKkpqYmdXV19VjP8ePHa/To0Tm9nt/cz6+88MILGjZsmCZMmKClS5fqyJEjPqaXFd3d3Vq7dq06OjpUVVV1WtcycmWk3/T555+ru7tbJSUlPb5eUlKijz/+2NOssq+yslKrV6/WuHHjtH//fj366KO66qqr9MEHH6iwsND39LKutbVVkk64rl/d11/MmjVLc+bMUUVFhXbv3q1f/vKXqqmpUWNjowYMGOB7emapVEp33XWXrrjiCk2YMEHSl+tZUFCgoUOH9hiby+t5ov2UpFtuuUVjxoxRWVmZduzYofvuu0/Nzc16+eWXPc7W7v3331dVVZU6Ozs1ZMgQrV+/XhdffLG2b99+2tYy8gF0pqipqUn/eeLEiaqsrNSYMWP0xz/+UQsWLPA4M/TVTTfdlP7zpZdeqokTJ+q8885TfX29pk+f7nFmvVNbW6sPPvgg51+jPJWT7eftt9+e/vOll16qkSNHavr06dq9e7fOO++80z3NXhs3bpy2b9+u9vZ2/elPf9K8efPU0NBwWucQ+V/BDRs2TAMGDDjuCoy2tjaVlpZ6mlX4hg4dqgsvvFC7du3yPZVQfLV2Z9q6StLYsWM1bNiwnFzbxYsX69VXX9U777zT42NTSktLdfToUR08eLDH+Fxdz5Pt54lUVlZKUs6tZ0FBgc4//3xNnjxZdXV1mjRpkp566qnTupaRD6CCggJNnjxZmzZtSn8tlUpp06ZNqqqq8jizcB0+fFi7d+/WyJEjfU8lFBUVFSotLe2xrolEQlu3bu3X6ypJn3zyiQ4cOJBTa+uc0+LFi7V+/Xq9/fbbqqio6HH/5MmTlZ+f32M9m5ubtWfPnpxaz1Pt54ls375dknJqPU8klUopmUye3rXM6iUNIVm7dq2LxWJu9erV7qOPPnK33367Gzp0qGttbfU9taz5+c9/7urr611LS4v7y1/+4qqrq92wYcPcp59+6ntqvXbo0CH33nvvuffee89Jck888YR777333L///W/nnHOPPfaYGzp0qNu4caPbsWOHmz17tquoqHBffPGF55nbfNt+Hjp0yN1zzz2usbHRtbS0uLfeest9//vfdxdccIHr7Oz0PfWMLVq0yMXjcVdfX+/279+fvh05ciQ95o477nCjR492b7/9ttu2bZurqqpyVVVVHmdtd6r93LVrl/vVr37ltm3b5lpaWtzGjRvd2LFj3dSpUz3P3Ob+++93DQ0NrqWlxe3YscPdf//9LggC9+c//9k5d/rWMicCyDnnnnnmGTd69GhXUFDgpkyZ4rZs2eJ7Sll14403upEjR7qCggL3ne98x914441u165dvqfVJ++8846TdNxt3rx5zrkvL8V+8MEHXUlJiYvFYm769OmuubnZ76R74dv288iRI27GjBlu+PDhLj8/340ZM8YtXLgw5/7zdKL9k+See+659JgvvvjC/fSnP3XnnHOOO+uss9z111/v9u/f72/SvXCq/dyzZ4+bOnWqKy4udrFYzJ1//vnuF7/4hWtvb/c7caOf/OQnbsyYMa6goMANHz7cTZ8+PR0+zp2+teTjGAAAXkT+NSAAQP9EAAEAvCCAAABeEEAAAC8IIACAFwQQAMALAggA4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC/+HzhBNXZDSMjNAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l=np.random.randint(0,len(centers))\n",
    "data_loader.plot_image_with_centers(l)\n",
    "plt.imshow(images[l]),l\n",
    "# plt.grid(True),l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sorted_centers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mmax(\u001b[43msorted_centers\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sorted_centers' is not defined"
     ]
    }
   ],
   "source": [
    "np.max(sorted_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x7f40c44766d0>, 5819)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[l]),l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., 26., 11.],\n",
       "       [ 1., 20., 26.],\n",
       "       [ 1.,  7.,  8.],\n",
       "       [ 1.,  9., 28.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.random.randint(0,len(centers))\n",
    "centers[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the data and split it into training and validation sets\n",
    "train_images, val_images, train_midpoints, val_midpoints = data_loader.split_data()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0, 0.0, 1.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(train_images), np.max(train_images), np.min(train_midpoints), np.max(train_midpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images: (9600, 32, 32), Train Midpoints: (9600, 1, 4, 2)\n",
      "Validation Images: (2400, 32, 32), Validation Midpoints: (2400, 1, 4, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 400\n",
    "train_dataset = train_dataset.shuffle(buffer_size=8000, reshuffle_each_iteration=True).batch(batch_size)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=8000).batch(batch_size)\n",
    "\n",
    "# Check the shape of the datasets\n",
    "print(f'Train Images: {train_images.shape}, Train Midpoints: {train_midpoints.shape}')\n",
    "print(f'Validation Images: {val_images.shape}, Validation Midpoints: {val_midpoints.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_transposed_images_with_midpoints(train_dataset, image_indices=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set up learning rate scheduler\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.9, patience=10, verbose=1, mode='min', min_lr=3e-6\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,277,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_11 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m3,277,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m8,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m2\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,330,312</span> (39.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,330,312\u001b[0m (39.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,329,800</span> (39.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,329,800\u001b[0m (39.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# dynamic_exponent_callback = DynamicExponentCallback(2, 1, 400)\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    # Instantiate the model builder\n",
    "    # model_builder = ModelBuilder(weights_path= \"/home/da886/Analysis/30KFixed_13_SparsespotsrandomSPOTS.keras\")\n",
    "    model_builder = ModelBuilder()\n",
    "\n",
    "    # Build the model\n",
    "    model_builder.build_model()\n",
    "\n",
    "    # Display the model architecture\n",
    "    model_builder.model.summary()\n",
    "\n",
    "    # Compile the model using the custom loss function\n",
    "    # model_builder.compile_model(loss_function=dynamic_exponent_callback.custom_loss(2))\n",
    "    model_builder.compile_model(loss_function=tf.keras.losses.MeanSquaredError()) \n",
    "    \n",
    "    # model_builder.compile_model(loss_function=custom_loss(3))e\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 16:15:33.467946: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-21 16:15:33.487722: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-21 16:15:33.515430: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1729527333.634398   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.635464   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.636307   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.694458   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.694460   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.694655   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.695047   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.695211   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.695214   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.703187   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.703283   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.703404   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.725598   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.725742   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.725856   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.728691   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.728782   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.729007   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.730203   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.730331   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.730567   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.730712   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.730836   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.731061   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.735046   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.735147   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.735261   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.754098   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.754128   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.754235   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.754773   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.754985   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.754980   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.755306   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.755638   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.755683   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.755772   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.756187   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.756301   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.756332   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.756685   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.756858   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.756888   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.757100   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.757337   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.759309   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.759402   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.759533   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.761914   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.762026   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.762141   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.764260   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.764256   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.764495   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.766852   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.766877   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.767106   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.769228   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.769371   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.769508   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.772079   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.772097   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.772494   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.772636   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.775364   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.775387   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.775480   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.785404   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.785515   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.785613   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.787862   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.787880   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.788055   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.886630   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.886675   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.887233   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.887250   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.887684   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.887781   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.888126   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.888229   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.888503   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.888598   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.889016   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.889029   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.889462   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.889559   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.891032   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.891131   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.891505   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.891600   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.892003   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.892087   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.892549   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.892562   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.893034   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.893048   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.893519   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.893531   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.894956   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.895056   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.895410   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.895491   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.897705   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.897807   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.898120   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.898224   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.900506   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.900613   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.902568   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.902667   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.903144   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.903155   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.903930   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.904033   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.910685   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.910786   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.911201   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.911310   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.911688   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.911851   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.912174   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.912339   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.912639   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.912811   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.913109   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.913285   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.913718   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.913875   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.914463   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.914541   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.915040   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.915139   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.930554   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.930569   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.931111   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.931208   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.931700   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.931714   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.932263   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.932275   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.932770   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.932782   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.933320   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.933333   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.934050   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.934065   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.934755   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.934851   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.935457   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.935540   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.936312   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.936324   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.937049   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.937142   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.937789   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.937886   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.942439   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.942540   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.942832   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.942930   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.943323   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.943406   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.943779   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.943874   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.944351   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.944362   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.944836   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.944932   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.945320   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.945399   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.945907   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.945920   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.946404   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.946485   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.946931   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.947010   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.947459   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.947542   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.948297   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.948386   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.948837   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.948919   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.949345   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.949435   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.949954   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.949966   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.950475   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.950565   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.951034   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.951118   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.951568   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.951668   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.952063   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.952158   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.952604   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.952707   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.953218   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.953399   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.953951   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.954126   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.954639   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.954807   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.955441   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.955535   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.963703   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.963844   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.964158   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.964331   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.964705   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.964806   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.965148   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.965245   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.965616   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.965717   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.966140   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.966314   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.966986   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.967157   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.967911   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.968006   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.968805   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.968899   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.969843   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.969938   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.970891   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.970987   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.971853   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.971949   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.980772   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.980864   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.981380   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.981390   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.981894   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.981996   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.982308   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.982488   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.982744   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.982924   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.983259   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.983367   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.983696   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.983875   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.984117   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.984293   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.984550   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.984725   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.985031   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.985208   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.985492   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.985668   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.986558   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.986735   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.987124   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.987223   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.987639   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.987734   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.988140   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.988240   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.988820   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.988904   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.989371   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.989472   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.989986   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.990093   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.990565   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.990740   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.991210   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.991309   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.992216   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.992397   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.993277   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.993460   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.994351   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.994543   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.995473   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527333.995671   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.005260   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.005331   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.005898   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.005999   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.006498   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.006573   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.007215   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.007229   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.007819   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.007913   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.008512   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.008525   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.009148   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.009243   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.009810   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.009821   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.010481   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.010574   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.011137   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.011219   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.011883   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.011897   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.013374   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.013473   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.014757   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.014936   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.016097   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.016292   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.017454   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.017666   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.018841   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.019113   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.020287   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.020560   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.021744   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.022033   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.038361   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.039003   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.039019   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.039628   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.039721   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.040175   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.040339   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.040712   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.040905   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.041367   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.041475   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.042014   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.042118   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.042759   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.042770   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.043424   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.043506   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.044084   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.044184   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.044733   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.044912   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.045461   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.045567   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.046348   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.046365   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.046965   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.047287   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.048017   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.048126   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.048776   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.048950   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.049601   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.049777   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.050453   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.050557   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.051127   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.052290   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.052869   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.053143   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.053726   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.053947   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.054539   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.055404   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.056005   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.057214   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.057837   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.058921   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.059556   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.060953   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.061602   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.069596   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.070281   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.070358   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.070903   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.071087   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.071578   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.071756   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.072572   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.072583   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.073397   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.073498   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.074048   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.074228   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.074764   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.074940   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.075633   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.075740   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.076453   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.076552   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.077244   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.077340   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.078019   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.079695   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.080496   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.082110   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.082921   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.084502   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.085327   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.086965   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.087807   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.089468   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.090329   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.091988   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.092869   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.094687   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.095577   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.127646   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.128284   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.128738   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.128972   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.129416   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.129653   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.130126   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.130382   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.131838   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.132042   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.132577   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.132827   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.133303   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.133539   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.134072   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.134315   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.134794   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.135108   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.135546   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.135972   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.136394   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.136847   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.137264   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.137741   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.138143   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.139135   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.139218   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.140231   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.140470   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.141085   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.141634   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.141773   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.141849   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.142123   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.142502   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.143079   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.143094   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.143283   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.143479   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.144046   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.144156   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.144605   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.144679   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.145103   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.145666   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.145745   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.146271   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.146866   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.147193   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.148569   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.148812   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.149440   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.149849   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.149964   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.150318   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.150400   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.150639   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.150928   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.151240   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.152017   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.152102   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.152420   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.152746   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.153042   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.153468   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.153584   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.153808   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.154138   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.154599   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.154915   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.155465   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.155673   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.155858   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.156413   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.156943   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.157263   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.158498   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.158951   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.159407   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.159866   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.160304   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.160782   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.163153   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.164172   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.165052   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.165109   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.166169   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.166265   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.167151   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.167387   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.168132   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.168377   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.169095   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.169592   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.169627   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.169719   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.170068   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.170383   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.170824   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.170931   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.171017   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.171408   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.171931   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.172158   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.172239   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.172764   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.173023   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.173390   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.173489   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.174024   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.174205   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.174488   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.174787   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.175134   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.175382   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.176232   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.179094   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.179869   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.180177   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.180486   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.180936   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.181013   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.181279   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.181608   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.181932   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.182266   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.182598   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.182956   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.183319   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.183614   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.184030   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.184403   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.184765   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.185125   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.185645   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.185722   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.186053   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.186452   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.186865   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.187244   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.187656   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.188282   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.188382   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.189070   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.189718   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.190435   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.190512   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.192932   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.195274   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.197625   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.197882   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.198313   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.198725   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.199086   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.199482   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.200084   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.200155   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.200910   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.201709   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.202448   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.202620   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.203507   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.204482   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.204991   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.205389   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.207484   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.210099   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.214046   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.214409   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.214782   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.215147   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.215542   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.215923   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.216317   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.216704   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.217102   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.217542   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.217964   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.219006   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.219431   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.219864   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.220290   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.220795   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.221285   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.221832   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.222351   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.222867   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.223421   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.224392   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.225423   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.226463   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.227575   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.235959   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.236468   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.236941   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.237364   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.237818   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.238342   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.238834   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.239327   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.239853   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.240349   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.240840   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.242202   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.243534   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.244854   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.246218   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.247600   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.249039   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.250502   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.266976   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.267438   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.267933   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.268433   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.268958   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.269479   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.270042   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.270536   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.271064   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.271796   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.271863   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.272469   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.272877   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.273102   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.273827   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.273941   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.274608   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.274788   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.275008   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.275573   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.275747   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.276231   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.276407   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.276729   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.277145   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.277374   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.277924   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.278001   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.278528   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.279121   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.279937   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.279955   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.280246   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.280795   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.281077   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.281393   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.281611   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.282284   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.282544   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.282710   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.283734   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.283997   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.284102   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.285296   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.285395   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.285938   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.286918   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.287011   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.287657   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.288510   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.288681   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.289705   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.290010   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.290606   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.291802   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.292657   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.293713   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.294654   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.295735   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.297078   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.297744   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.298369   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.299063   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.299513   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.299686   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.300229   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.300398   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.301157   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.301840   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.302453   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.302669   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.303154   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.303902   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.304595   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.305054   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.305292   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.307748   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.308243   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.310177   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.312587   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.315077   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.317356   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.317594   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.318051   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.318676   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.319307   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.320320   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.320342   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.320386   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.321118   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.321224   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.321907   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.322007   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.322784   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.322885   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.323124   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.323566   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.323743   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.324500   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.324593   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.325281   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.325391   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.326022   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.326763   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.327598   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.327899   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.328345   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.330383   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.330871   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.332993   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.333376   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.335807   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.336018   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.338880   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.339041   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.341915   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.342089   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.345010   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.345105   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.348101   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.355636   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.356284   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.356968   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.357633   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.358354   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.359069   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.359816   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.360514   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.361266   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.362038   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.362879   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.363733   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.364626   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.365857   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.366939   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.368071   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.369230   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.370222   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.373276   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.374637   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.375966   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.377374   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.377860   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.378490   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.379099   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.379776   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.380482   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.380892   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.381142   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.381503   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.381812   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.382152   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.382478   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.382784   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.383178   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.383475   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.384032   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.384303   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.384871   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.385051   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.385797   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.385897   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.386579   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.386753   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.387278   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.387770   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.387999   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.389024   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.389037   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.389829   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.390302   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.390601   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.390775   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.391333   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.391684   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.391846   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.392800   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.392885   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.392984   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.393785   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.394258   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.395006   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.395409   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.395491   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.396013   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.396842   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.397018   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.398104   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.399336   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.399363   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.399454   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.400454   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.401540   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.403213   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.406201   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.409739   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.410764   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.413681   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.415348   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.419846   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.420058   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.420315   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.420725   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.421157   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.421592   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.423188   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.423293   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.423657   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.424068   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.424507   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.424855   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.425024   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.425697   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.426736   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.428398   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.429153   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.429701   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.431869   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.433693   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.434812   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.434887   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.437481   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.438597   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.440129   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.441265   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.443258   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.444421   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.450581   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.451025   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.451474   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.451887   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.452087   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.452358   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.452600   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.452821   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.453206   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.453310   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.453897   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.453976   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.454366   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.454543   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.454910   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.455106   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.455473   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.455579   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.456067   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.456159   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.456731   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.456831   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.457431   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.457538   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.458144   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.458245   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.458818   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.459391   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.459885   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.460485   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.461145   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.461740   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.462024   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.462750   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.463276   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.463576   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.464010   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.464595   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.464846   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.465853   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.470106   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.471514   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.471616   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.472960   21421 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.498485   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.499559   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.500543   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.501601   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.502785   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.503903   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.505038   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.506270   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.507381   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.508564   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.509963   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.511374   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.512854   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.514507   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.516393   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.518383   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.520360   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.522742   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.525292   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.527691   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.533252   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.545438   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.546140   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.546761   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.547389   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.548200   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.548825   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.549475   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.550207   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.550952   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.551781   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.552522   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.555016   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.557495   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.560086   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.562901   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.566044   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.568915   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.571903   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.605347   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.605983   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.606602   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.607279   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.607992   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.608650   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.609320   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.609982   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.610677   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.611371   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.612165   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.612955   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.613887   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.614895   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.615935   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.617194   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.618240   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.619542   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.620895   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.623297   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.627043   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.637608   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.647070   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.647523   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.647928   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.648363   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.648807   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.650496   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.652914   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.655622   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.658409   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.662171   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.664831   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.667985   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.675327   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.675784   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.676236   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.676682   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.677156   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.677631   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.678153   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.678593   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.679093   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.679533   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.680051   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.680533   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.681101   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.681672   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.683408   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.684003   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.685530   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.686254   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.687045   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.688040   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.693565   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527334.694995   21418 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.035760   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.035801   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.038276   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.038299   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.038866   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.038971   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.041586   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.041762   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.042177   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.042281   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.042757   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.042857   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.043338   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.043443   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.043836   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.044016   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.044399   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.044505   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.047160   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.047271   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.047787   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.047892   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.048296   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.048477   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.048977   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.049075   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.049561   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.049665   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.050135   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.050321   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.050667   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.050870   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.052080   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.052336   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.053756   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.053992   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.066192   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.066312   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.068200   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.068366   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.070164   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.070358   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.077087   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.077363   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.105263   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.105762   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.106197   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.106705   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.107196   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.107901   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.108398   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.108820   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.109618   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.109865   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.110112   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.110616   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.110928   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.111346   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.111453   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.111832   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.112046   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.112448   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.112604   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.113141   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.115548   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.115650   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.118372   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.118473   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.118990   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.119067   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.119678   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.119689   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.120264   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.120359   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.120935   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.120948   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.121647   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.121741   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.123790   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.123884   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.126149   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.126242   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.127001   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.127011   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.127803   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.127813   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.134201   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.134313   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.139724   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.139939   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.184200   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.184220   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.184923   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.184938   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.187247   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.187345   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.187823   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.187902   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.188427   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.188508   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.189032   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.189105   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.189703   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.189734   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.190684   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.190695   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.191662   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.191675   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.192565   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.192668   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.193060   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.193243   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.193615   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.193719   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.194307   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.194319   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.194936   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.195023   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.195544   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.195647   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.196061   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.196234   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.196610   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.196784   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.197201   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.197331   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.197912   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.198105   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.198787   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.198798   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.199521   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.199713   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.200099   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.200272   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.200890   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.200994   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.201638   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.201927   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.202044   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.202324   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.202778   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.203487   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.203945   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.204713   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.205138   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.205848   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.205842   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.205868   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.206320   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.207021   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.207457   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.207918   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.208483   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.209533   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.210060   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.210605   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.210888   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.210993   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.212058   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.212337   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.212441   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.213701   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.217392   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.219008   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.219114   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.219395   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.221314   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.222531   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.222707   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.226131   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.226246   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.228184   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.231307   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.231408   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.243670   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.244147   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.244573   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.245072   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.245515   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.246284   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.246734   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.247279   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.247744   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.248243   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.249045   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.249784   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.250213   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.250642   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.251074   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.251383   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.251711   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.251800   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.252744   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.253253   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.253751   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.253841   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.254355   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.254543   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.254622   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.255217   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.255848   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.256339   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.256445   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.258132   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.258230   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.258964   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.258977   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.261137   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.261341   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.261458   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.261935   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.262042   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.264320   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.264420   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.265108   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.265191   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.265904   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.266004   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.266664   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.268399   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.268500   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.270832   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.270844   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.274379   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.274485   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.286106   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.286516   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.286607   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.286904   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.287311   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.287405   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.287586   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.287811   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.288243   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.289240   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.289836   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.289854   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.289868   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.290469   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.290685   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.290767   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.290959   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.291665   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.291695   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.291771   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.292402   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.292497   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.292581   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.292851   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.293534   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.293550   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.293567   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.294021   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.294503   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.294626   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.294710   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.295403   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.295435   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.295538   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.295932   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.296242   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.296460   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.296549   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.296937   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.297239   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.297316   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.297599   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.297833   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.297989   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.298289   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.298479   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.298670   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.299081   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.299173   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.299365   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.299667   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.299836   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.300093   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.300474   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.301126   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.301138   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.301812   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.302488   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.302593   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.303444   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.303715   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.303808   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.304740   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.306475   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.306639   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.308309   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.308979   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.309191   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.311497   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.311844   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.311930   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.315365   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.316468   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.316881   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.318762   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.325704   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.326224   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.336369   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.337322   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.337930   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.338502   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.339211   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.339788   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.340606   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.341064   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.341824   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.342428   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.343053   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.344341   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.345008   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.348382   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.355771   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.356339   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.356367   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.356666   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.357013   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.357396   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.357498   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.357826   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.358058   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.358333   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.358510   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.358739   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.359057   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.359248   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.359414   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.359787   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.359983   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.360079   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.360432   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.360788   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.360797   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.361093   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.361724   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.361737   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.361862   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.362656   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.362771   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.362846   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.363586   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.363715   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.363788   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.364586   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.364680   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.364762   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.365281   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.365591   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.365692   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.365956   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.366570   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.366731   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.366750   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.367641   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.367757   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.367831   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.368660   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.368829   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.368850   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.369920   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.370040   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.370124   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.371230   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.371311   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.372439   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.373785   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.374049   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.374800   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.376181   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.376585   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.379280   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.381984   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.382743   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.383465   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.383582   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.384390   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.384393   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.384527   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.385237   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.385342   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.386160   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.386243   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.387172   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.387182   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.388097   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.388177   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.389036   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.389117   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.389961   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.390047   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.390932   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.391008   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.391931   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.391945   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.392830   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.392933   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.393578   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.393957   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.393972   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.394737   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.394967   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.395798   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.395907   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.397016   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.397027   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.397985   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.398093   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.399062   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.399162   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.400097   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.400180   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.401128   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.401702   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.402020   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.402695   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.403731   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.403835   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.404821   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.405735   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.406879   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.408914   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.409994   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.412054   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.413633   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.415726   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.417297   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.419421   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.420960   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.423121   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.423817   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.424428   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.424612   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.425198   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.425854   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.426529   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.426829   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.427171   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.427814   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.428469   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.429164   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.429858   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.430570   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.431449   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.432237   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.433075   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.433924   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.434803   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.435828   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.438359   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.440745   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.447776   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.448531   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.449245   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.449993   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.450751   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.451501   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.452255   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.453014   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.453784   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.454542   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.455299   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.456093   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.456857   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.457783   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.458764   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.459640   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.460509   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.461338   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.462283   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.463160   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.464720   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.465687   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.466591   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.469750   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.472515   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.472884   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.473229   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.473899   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.474630   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.475109   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.475364   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.475783   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.476251   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.476606   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.476686   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.477246   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.477422   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.478320   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.478431   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.479214   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.479523   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.480232   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.480393   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.480609   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.481230   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.481838   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.482309   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.482726   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.483399   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.484064   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.484629   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.485506   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.485729   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.487726   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.488547   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.494802   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.495780   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.496724   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.497620   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.497695   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.498668   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.498859   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.499631   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.499878   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.500610   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.500913   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.501632   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.501856   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.502640   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.502921   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.503680   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.503987   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.504618   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.505030   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.505686   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.506200   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.506752   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.507182   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.507799   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.508357   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.508971   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.509459   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.509956   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.510754   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.511139   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.512350   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.512462   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.513661   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.513954   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.515312   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.516793   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.519484   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.522363   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.524413   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.527341   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.529481   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.532465   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.534696   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.535232   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.535893   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.536553   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.537284   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.537735   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.538008   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.538882   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.539336   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.539844   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.540816   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.541868   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.542425   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.542957   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.543965   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.544185   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.545053   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.547285   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.548109   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.556951   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.557930   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.558879   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.559854   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.560863   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.561851   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.562869   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.563790   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.564849   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.565901   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.566934   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.568078   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.569056   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.570223   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.571310   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.572599   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.574241   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.575713   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.581300   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.586220   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.591249   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.596439   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.601120   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.603953   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.604957   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.605801   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.606048   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.607039   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.607809   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.608080   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.608828   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.609152   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.609923   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.610251   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.610942   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.611356   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.611991   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.612478   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.613068   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.613660   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.614172   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.614874   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.615292   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.616161   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.616428   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.617775   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.617782   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.619000   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.619281   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.620299   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.620767   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.621689   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.622253   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.623205   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.624109   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.624692   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.626300   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.626374   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.628242   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.628684   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.630291   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.632672   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.633406   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.637438   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.643255   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.644494   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.645654   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.646811   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.647395   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.647994   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.648638   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.649174   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.649820   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.650414   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.650997   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.651674   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.652199   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.652892   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.653387   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.654228   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.654640   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.655522   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.655905   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.656763   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.657138   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.658037   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.658479   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.659306   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.659778   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.660438   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.661026   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.661882   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.662317   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.662998   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.663597   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.664240   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.664733   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.665318   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.665945   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.666237   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.666415   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.667405   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.667749   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.667769   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.668746   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.668856   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.669386   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.669913   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.670471   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.671063   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.671167   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.672335   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.672412   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.673011   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.673536   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.673967   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.674663   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.674949   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.675521   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.675859   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.676625   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.677081   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.677487   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.678458   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.678563   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.679448   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.679948   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.681132   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.681440   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.682971   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.683057   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.683946   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.684533   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.686376   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.688415   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.688570   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.689586   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.690819   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.694257   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.695229   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.695588   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.699938   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.700859   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.705494   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.705635   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.706490   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.706734   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.707896   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.709055   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.710235   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.711435   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.711521   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.712752   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.712987   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.714002   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.715208   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.716516   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.717795   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.718007   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.719049   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.720314   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.721574   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.722692   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.724111   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.725211   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.726446   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.728136   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.729810   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.731416   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.732933   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.734855   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.736777   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.738425   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.740104   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.745543   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.751132   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.756714   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.762298   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.767882   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.774344   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.808033   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.809101   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.810203   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.811335   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.812490   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.814073   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.814203   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.815286   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.815676   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.816389   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.817240   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.817547   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.818744   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.818918   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.820207   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.820702   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.821808   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.822602   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.823381   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.825067   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.825170   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.826952   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.827706   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.828875   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.831217   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.833889   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.834062   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.840277   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.844786   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.845478   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.846118   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.846776   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.847435   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.848109   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.848783   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.849395   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.850078   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.850766   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.851039   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.851438   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.851720   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.852094   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.852360   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.852857   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.853060   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.853723   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.853832   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.854567   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.854671   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.855548   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.855562   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.856174   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.856474   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.856870   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.857534   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.857634   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.858307   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.858953   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.859675   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.860464   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.860635   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.861179   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.862019   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.862926   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.863397   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.863933   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.865845   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.866933   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.868289   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.868785   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.869758   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.869933   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.871191   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.871210   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.872361   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.872444   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.873601   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.873905   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.874847   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.875049   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.876629   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.877701   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.878198   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.879819   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.880428   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.881590   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.883475   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.885786   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.888399   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.894660   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.903984   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.904662   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.905074   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.905375   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.905763   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.906049   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.906405   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.906746   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.907080   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.907456   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.907747   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.908183   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.908438   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.908911   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.909147   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.909698   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.909864   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.910613   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.910758   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.910968   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.911548   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.911753   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.911831   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.912611   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.912733   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.912805   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.913677   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.913846   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.913866   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.914460   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.914630   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.914885   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.915252   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.915424   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.915833   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.916049   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.916217   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.917008   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.917137   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.917212   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.918066   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.918346   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.918369   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.918845   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.919355   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.919669   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.919862   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.920520   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.921197   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.921429   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.922499   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.922571   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.923488   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.923713   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.924436   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.925254   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.925613   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.926986   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.928072   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.928326   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.930553   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.930841   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.932692   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.933024   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.933483   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.934231   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.935034   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.935829   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.935958   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.936683   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.937733   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.938570   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.938736   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.939376   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.939668   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.940129   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.940591   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.940947   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.941614   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.941828   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.942662   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.942774   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.943796   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.943906   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.944814   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.945145   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.945753   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.946065   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.946687   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.946958   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.947715   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.948087   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.948786   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.949224   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.949828   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.950116   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.951197   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.951307   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.952118   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.952672   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.953017   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.954069   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.954233   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.955323   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.955496   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.956376   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.956771   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.957536   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.958001   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.958914   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.960275   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.960879   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.961477   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.962928   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.963755   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.964162   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.965735   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.966402   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.966702   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.967194   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.967273   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.967941   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.968619   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.969309   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.969648   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.970173   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.970248   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.970911   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.971630   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.972380   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.973144   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.973362   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.973434   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.974181   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.975049   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.976047   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.976518   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.976617   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.976972   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.977897   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.979062   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.979931   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.980415   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.981741   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.983335   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.984258   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.991817   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.992597   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.993329   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.994130   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.994989   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.995714   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.996705   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.997697   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.998607   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527335.999516   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.000527   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.001569   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.002602   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.003825   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.004725   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.005605   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.006721   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.007837   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.008957   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.009833   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.011176   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.012526   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.013717   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.015158   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.016367   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.019221   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.022075   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.024302   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.025123   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.025145   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.025848   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.026572   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.027315   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.028172   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.028294   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.029252   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.030172   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.031203   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.031664   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.031717   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.032406   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.033114   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.033786   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.033892   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.034643   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.035248   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.035269   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.035521   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.036595   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.036691   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.037535   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.038234   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.038588   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.040817   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.041074   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.042426   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.043732   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.044169   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.045286   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.047877   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.051274   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.054032   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.054580   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.055165   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.055659   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.056142   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.056640   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.057171   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.057636   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.058141   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.058670   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.059299   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.059794   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.060328   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.060911   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.061107   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.061424   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.061657   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.062241   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.062343   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.062926   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.063031   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.063430   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.063769   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.063968   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.064504   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.064979   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.065650   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.065727   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.066266   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.066935   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.067113   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.067450   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.067988   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.068578   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.068686   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.069203   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.069854   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.070118   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.070509   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.071192   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.071623   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.072948   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.073130   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.074329   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.075686   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.077220   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.078732   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.080233   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.082650   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.083360   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.084059   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.084780   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.085516   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.086383   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.087342   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.088465   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.088499   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.088988   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.089682   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.089695   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.090224   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.090718   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.091265   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.091757   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.092293   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.092404   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.092923   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.093445   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.093648   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.094065   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.094670   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.094959   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.095268   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.095596   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.095894   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.096105   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.096896   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.096975   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.096990   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.097553   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.097728   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.098056   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.098756   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.098766   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.099281   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.099483   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.099818   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.100146   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.100354   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.100878   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.101483   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.102108   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.102742   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.102906   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.103376   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.104019   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.104753   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.105540   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.105994   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.106602   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.107040   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.107209   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.107725   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.108257   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.109009   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.109569   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.110127   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.110672   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.111336   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.112005   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.112479   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.112716   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.113033   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.113152   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.113589   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.113767   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.113875   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.114359   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.114561   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.114632   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.115252   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.115383   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.115456   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.116173   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.116191   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.116310   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.116791   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.117068   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.117191   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.117367   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.117659   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.118064   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.118181   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.118283   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.118634   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.118924   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.119021   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.119289   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.119916   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.119928   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.120029   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.120815   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.120906   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.121004   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.121340   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.121644   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.122056   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.122161   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.122381   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.122732   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.122962   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.123348   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.123676   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.123834   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.124049   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.124337   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.125086   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.125453   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.125909   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.125977   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.126740   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.127060   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.127539   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.127620   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.128386   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.128665   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.129137   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.129452   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.130279   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.130517   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.131061   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.131890   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.132094   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.132679   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.133395   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.133902   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.134298   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.135904   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.137511   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.139332   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.141148   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.148722   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.149214   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.149763   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.150296   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.150782   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.151326   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.151823   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.152343   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.152860   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.153385   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.153987   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.154602   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.155181   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.155793   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.156432   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.157157   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.158049   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.158134   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.158593   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.159121   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.159536   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.159742   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.160370   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.160928   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.161596   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.162172   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.163126   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.164595   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.165192   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.165602   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.165610   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.165808   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.166159   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.166515   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.166548   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.166742   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.167054   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.167368   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.167613   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.168054   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.168378   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.168395   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.168628   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.168954   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.169289   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.169524   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.170025   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.170222   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.170331   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.171126   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.171136   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.171807   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.172290   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.172669   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.172734   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.173450   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.173601   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.174035   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.174377   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.174843   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.175514   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.176071   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.176289   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.177065   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.177606   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.177847   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.178507   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.179338   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.179695   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.180404   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.180728   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.181167   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.181541   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.182056   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.182177   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.182573   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.182932   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.183338   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.183848   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.183941   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.184267   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.184648   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.185033   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.185609   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.185698   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.186019   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.186439   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.186822   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.187390   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.187488   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.187892   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.188183   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.188364   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.188616   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.189036   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.189191   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.189537   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.189636   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.190021   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.190593   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.190604   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.191123   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.191136   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.191435   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.191613   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.192016   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.192528   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.192613   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.193079   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.193152   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.193572   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.193680   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.194075   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.194653   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.194743   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.195049   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.195516   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.196001   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.196477   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.197504   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.198312   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.199116   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.200053   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.200984   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.201926   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.202476   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.202859   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.203272   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.203677   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.204062   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.204478   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.204870   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.205275   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.205665   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.206056   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.206496   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.206945   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.207381   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.207850   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.208312   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.208845   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.209361   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.209733   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.210365   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.210380   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.210797   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.211204   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.211660   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.212076   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.212466   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.212866   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.213260   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.213654   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.214116   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.214564   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.215007   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.215429   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.215475   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.216134   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.216143   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.216587   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.216857   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.217013   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.217111   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.217544   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.217770   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.217858   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.218332   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.218519   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.218531   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.218779   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.219345   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.219364   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.219791   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.219999   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.220234   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.220689   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.220796   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.221294   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.221472   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.221749   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.222183   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.222299   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.222814   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.223282   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.223393   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.223566   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.223877   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.224049   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.224437   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.224547   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.224902   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.225226   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.225234   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.225879   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.226073   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.226097   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.226322   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.227026   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.227066   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.227137   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.227668   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.227736   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.228101   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.228596   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.228736   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.228904   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.229374   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.229476   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.229930   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.230615   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.230648   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.230726   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.231118   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.231678   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.231779   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.232259   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.232738   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.232931   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.232949   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.233394   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.233681   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.233925   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.234423   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.234710   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.235040   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.235909   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.235918   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.236647   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.237064   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.237296   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.238231   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.239161   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.240091   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.241029   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.241151   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.241579   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.241991   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.242146   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.242393   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.242772   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.243273   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.243341   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.243687   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.244069   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.244593   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.244663   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.244996   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.245373   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.245820   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.246209   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.246632   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.247018   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.247476   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.247957   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.248427   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.249192   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.249488   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.249679   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.250115   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.250323   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.250566   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.251050   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.251215   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.251518   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.252018   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.252188   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.252518   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.253131   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.253437   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.254170   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.254272   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/24\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:15\u001b[0m 11s/step - loss: 0.0979"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1729527336.254888   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.255666   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.256602   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.256906   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.257376   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.257814   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.258006   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.258286   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.258734   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.259193   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.259590   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.259695   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.260178   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.261079   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.261679   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.262247   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.262430   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.262663   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.263116   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.263284   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.263539   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.263911   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.264386   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.264464   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.264851   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.265248   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.265680   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.265838   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.266094   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.266537   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.266980   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.267486   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.267563   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.267569   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.268097   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.268194   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.268469   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.268799   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.268922   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.269388   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.269493   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.269769   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.270479   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.270483   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.270831   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.271228   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.271422   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.271625   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.271989   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.272387   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.272804   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.273168   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.273563   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.273937   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.274316   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.274769   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.275173   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.275570   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.275791   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.276089   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.276435   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.276526   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.276573   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.276812   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.277099   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.277313   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.277440   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.277643   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.277812   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.278238   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.278363   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.278436   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.279088   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.279109   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.279122   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.279614   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.279789   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.280194   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.280305   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.280650   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.280804   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.281036   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.281278   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.281484   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.281754   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.281922   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.282399   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.282474   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.282983   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.283003   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.283505   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.283588   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.283679   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.283940   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.284113   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.284412   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.284740   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.284953   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.285148   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.285620   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.285642   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.285746   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.286409   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.286511   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.286520   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.287253   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.287277   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.287289   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.287819   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.288000   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.288017   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.288237   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.288552   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.288787   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.288885   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.289285   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.289425   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.289706   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.289822   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.290010   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.290334   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.290841   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.290942   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.291243   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.291744   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.291763   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.292173   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.292656   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.292748   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.293120   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.293608   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.293770   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.293873   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.294242   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.294405   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.294996   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.295022   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.295121   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.295629   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.295735   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.295943   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.296248   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.296339   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.296829   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.297048   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.297197   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.297313   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.297884   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.297896   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.298535   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.298562   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.298660   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.298948   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.299479   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.299493   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.299707   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.299900   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.300124   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.300313   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.300856   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.300928   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.301281   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.301762   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.301852   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.302307   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.302579   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.302782   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.303295   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.303761   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.304232   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.304718   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.305320   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.305912   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.306503   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.307098   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.307724   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.308350   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.308831   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.309177   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.309294   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.309740   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.310022   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.310217   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.310636   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.311013   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.311390   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.311949   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.311963   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.312450   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.312641   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.312906   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.313275   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.313437   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.314055   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.314070   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.314527   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.314880   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.315044   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.315685   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.315699   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.316319   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.317000   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.317012   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.317512   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.317673   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.317904   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.318450   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.318527   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.318834   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.319270   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.319396   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.319704   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.320482   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.320563   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.321157   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.321957   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.322027   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.322376   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.322950   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.322963   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.323270   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.323902   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.323965   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.323977   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.324281   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.324578   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.324926   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.325288   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.325603   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.325936   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.326290   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.326681   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.327013   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.327333   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.327671   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.328028   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.328366   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.328715   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.329081   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.329394   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.329767   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.330139   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.330291   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.330692   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.330798   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.331348   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.331361   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.331666   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.331698   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.332052   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.332249   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.332346   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.332752   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.332880   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.332961   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.333323   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.333672   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.333690   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.333808   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.334177   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.334256   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.334687   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.334771   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.335180   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.335258   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.335860   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.335881   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.336355   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.336370   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.336831   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.336916   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.337219   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.337415   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.337658   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.337868   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.338037   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.338349   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.338467   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.338767   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.338895   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.338950   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.339513   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.339542   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.339618   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.340090   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.340218   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.340396   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.340552   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.340881   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.341107   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.341120   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.341439   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.341649   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.341762   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.342182   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.342272   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.342375   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.342802   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.342872   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.342978   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.343655   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.343724   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.343731   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.344177   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.344503   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.344512   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.344815   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.344998   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.345598   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.345700   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.346244   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.346416   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.346855   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.347537   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.348198   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.348966   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.349587   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.349956   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.350307   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.350598   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.350770   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.351226   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.351297   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.351753   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.351772   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.352300   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.352437   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.352750   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.352920   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.353211   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.353372   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.353768   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.353873   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.354363   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.354384   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.354776   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.354939   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.355156   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.355660   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.355739   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.356149   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.356311   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.356557   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.357081   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.357147   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.357626   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.357829   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.358065   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.358267   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.358745   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.358887   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.358984   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.359427   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.359446   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.359960   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.360431   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.360907   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.361387   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.362102   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.362413   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.362876   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.362898   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.363252   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.363592   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.363699   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.364477   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.364500   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.364841   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.364966   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.365215   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.365520   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.365531   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.365963   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.366029   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.366709   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.367499   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.368648   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.369531   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.370124   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.370116   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.370491   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.371189   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.371279   21398 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.371882   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.372318   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.373303   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.373692   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.374044   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.374323   21416 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.374510   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.374936   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.375359   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.375735   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.376114   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.376528   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.377166   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.377756   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.378435   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.379205   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.379882   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.385875   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.386211   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.386509   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.386808   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.387111   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.387404   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.387701   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.388005   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.388322   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.388640   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.388956   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.389273   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.389601   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.389916   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.390243   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.390595   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.390933   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.391270   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.391635   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.391947   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.392317   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.392698   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.393115   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.393547   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.394044   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.394497   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.395004   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.400284   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.400657   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.400991   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.401343   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.401697   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.402033   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.402387   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.402742   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.403077   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.403436   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.403770   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.404128   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.404489   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.404838   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.405164   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.405490   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.405825   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.406158   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.406489   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.406824   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.407160   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.407609   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.408039   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.408469   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.409025   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.409570   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.410122   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.410676   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.413915   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.414245   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.414597   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.414941   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.415283   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.415626   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.415985   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.416362   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.416759   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.417225   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.417699   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.418286   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.418954   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.419619   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.423061   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.423460   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.423762   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.426387   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.426723   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.427069   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.427421   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.427986   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.428416   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.428815   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.429776   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527336.430761   21424 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.1607"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 16:15:37.079641: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-10-21 16:15:37.079791: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "2024-10-21 16:15:37.079911: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "W0000 00:00:1729527337.642983   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.643691   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.647943   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.648272   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.648585   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.648933   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.649242   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.649543   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.649790   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.649853   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.650094   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.650263   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.650501   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.651212   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.651317   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.651826   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.651959   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.652624   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.652634   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.652632   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.653393   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.653433   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.653534   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.654099   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.654286   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.654318   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.654750   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.655124   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.655160   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.655281   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.655829   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.656005   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.656026   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.656454   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.656651   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.656657   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.657074   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.657363   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.657378   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.657781   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.658048   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.658095   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.658493   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.658759   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.658798   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.659086   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.659427   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.659639   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.659943   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.660207   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.660240   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.660746   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.660977   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.661022   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.661687   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.661696   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.661862   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.662415   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.662618   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.662630   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.662880   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.663383   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.663399   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.663489   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.664256   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.664271   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.664269   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.665004   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.665048   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.665101   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.665682   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.665870   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.665900   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.666163   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.666550   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.666580   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.667036   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.667214   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.667366   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.667889   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.668123   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.668155   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.668462   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.668807   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.668833   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.669361   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.669537   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.669562   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.670293   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.670462   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.670461   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.671095   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.671330   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.671612   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.671846   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.672081   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.672345   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.672595   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.672823   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.673124   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.673314   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.673849   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.673939   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.674289   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.674710   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.674866   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.675433   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.675628   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.675975   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.676286   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.676950   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.676976   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.677878   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.677920   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.678696   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.683734   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.684107   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.684396   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.684687   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.684975   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.685265   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.685565   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.685865   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.686170   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.686474   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.686781   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.687093   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.687404   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.687747   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.688067   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.688390   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.688707   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.689041   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.689387   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.689906   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.690437   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.690868   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.691201   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.691732   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.692197   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.692653   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.693373   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.696951   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.697411   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.697746   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.698076   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.698423   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.698760   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.698883   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.699161   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.699471   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.699711   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.699970   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.700200   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.700447   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.700702   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.700944   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.701187   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.701440   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.701790   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.702174   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.702315   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.702593   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.702828   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.703090   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.703344   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.703627   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.703823   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.704117   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.704306   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.704835   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.704934   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.705242   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.706006   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.706030   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.706625   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.706833   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.707130   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.707569   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.707646   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.708123   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.708177   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.708484   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.708652   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.708988   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.709154   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.709277   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.709708   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.709746   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.710090   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.710195   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.710618   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.710699   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.711022   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.711339   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.711640   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.711997   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.712332   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.712675   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.713334   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.713976   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.715149   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.716355   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.717160   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.717987   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.718604   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.719182   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.719201   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.719529   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.719833   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.720136   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.720437   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.720746   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.721059   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.721371   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.721713   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.722037   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.722362   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.722681   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.723013   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.723430   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.723767   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.724113   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.724546   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.725013   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.725198   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.725708   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.726017   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.726344   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.726658   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.726990   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.727309   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.727616   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.727920   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.728282   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.728622   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.728969   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.729630   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.730288   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.731436   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.731492   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.731847   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.732148   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.732516   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.732737   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.732902   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.733240   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.733689   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.733717   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.734039   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.734396   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.734558   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.734787   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.735130   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.735708   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.735785   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.735904   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.736249   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.736538   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.736654   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.736972   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.737431   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.737452   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.737763   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.738094   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.738455   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.738745   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.738858   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.739204   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.739682   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.739780   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.740051   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.740423   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.740841   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.741013   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.741279   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.741744   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.741914   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.742495   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.743045   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.743067   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.743797   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.744217   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.744799   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.745362   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.746026   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.752183   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.752650   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.752746   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.753003   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.753206   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.753366   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.753699   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.753800   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.754308   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.754320   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.754692   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.754823   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.755037   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.755402   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.755505   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.755952   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.756037   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.756469   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.756569   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.757083   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.757161   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.757569   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.757678   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.758069   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.758167   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.758482   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.758885   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.759504   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.759541   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.759732   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.760049   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.760532   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.760553   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.760678   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.761023   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.761105   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.761367   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.761723   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.761936   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.762111   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.762521   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.762602   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.762840   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.763049   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.763230   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.763436   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.763909   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.763932   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.764215   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.764393   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.764652   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.764826   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.765249   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.765669   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.766088   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.766395   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.766835   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.767224   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.767746   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.767967   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.768390   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.768988   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.769343   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.769521   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.770073   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.770756   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.770814   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.771224   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.771681   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.772043   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.772446   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.772794   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.773216   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.773599   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.773975   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.774450   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.774885   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.775326   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.776409   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.776837   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.777249   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.777527   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.777723   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.778095   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.778500   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.778850   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.779282   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.779746   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.779824   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.780199   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.780673   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.781227   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.781307   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.781752   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.782845   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.783435   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.783920   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.784802   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.786003   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.786375   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.787352   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.789541   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.790894   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.791965   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.802110   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.802476   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.802853   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.803216   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.803589   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.803953   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.804343   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.804717   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.805128   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.805545   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.805976   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.806401   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.806842   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.807337   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.807840   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.808355   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.808885   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.809439   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.810379   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.811466   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.812541   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.813616   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.819552   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.819912   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.820294   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.820320   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.820794   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.820909   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.821203   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.821381   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.821594   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.821929   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.822115   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.822384   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.822552   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.822958   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.823061   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.823611   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.823684   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.824267   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.824279   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.825032   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.825068   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.825072   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.825849   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.825862   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.825872   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.826489   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.826603   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.826695   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.826999   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.827160   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.827461   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.827539   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.828050   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.828126   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.828460   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.829046   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.829060   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.829165   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.829716   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.829787   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.830153   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.830627   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.830826   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.831124   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.831235   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.831677   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.831931   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.832203   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.832708   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.833145   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.833333   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.833412   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.833947   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.834553   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.834630   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.835334   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.835438   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.836401   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.837548   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.837650   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.838754   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.841154   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.841284   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.841754   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.842192   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.842683   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.843110   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.843570   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.844052   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.844504   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.844820   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.845029   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.845402   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.845500   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.846006   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.846075   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.846538   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.846641   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.847044   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.847460   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.847954   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.848191   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.848426   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.848876   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.849384   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.849834   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.850120   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.850311   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.850764   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.851989   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.852310   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.854108   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.854278   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.856270   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.856337   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.858332   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.859972   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.860423   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.863677   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.864059   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.867734   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.910090   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.910566   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.911020   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.911489   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.911960   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.912446   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.912925   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.913421   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.913971   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.914526   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.915109   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.915726   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.916277   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.916960   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.918769   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.919495   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.920256   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.921053   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.921919   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.923327   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.925100   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.926974   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.929669   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.930143   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.930603   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.931067   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.931539   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.932026   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.932643   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.932689   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.933272   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.933342   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.933787   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.933956   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.934276   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.934369   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.934550   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.934774   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.935116   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.935293   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.935398   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.935902   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.936079   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.936099   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.936957   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.937023   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.937036   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.937810   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.937829   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.937938   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.938567   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.938586   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.939296   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.939392   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.939812   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.940103   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.940217   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.940609   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.940938   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.940957   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.941394   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.941743   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.941847   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.942249   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.942423   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.943205   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.943306   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.943686   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.944418   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.944733   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.945205   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.946120   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.946230   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.946526   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.947116   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.948065   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.948435   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.949609   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.949722   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.951416   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.953192   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.953368   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.955843   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.956486   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.957257   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.957353   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.957976   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.958567   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.959142   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.959856   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.960613   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.960729   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.961605   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.961621   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.961713   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.962453   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.962514   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.963239   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.963344   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.964037   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.964108   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.964794   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.964816   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.965522   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.966291   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.966935   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.967040   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.967674   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.968325   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.968975   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.970487   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.971885   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.971987   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.973957   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.975546   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.977909   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.979012   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.981925   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.982953   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.985023   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.986962   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.990044   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.992026   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527337.996948   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.102229   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.102882   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.103505   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.104128   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.104800   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.105477   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.106167   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.106845   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.107580   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.108389   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.109223   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.110021   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.110861   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.111973   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.115091   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.116201   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.117338   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.118667   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.120075   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.123487   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.124154   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.124778   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.125409   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.126187   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.126327   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.126943   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.127073   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.127797   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.127878   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.128631   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.128710   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.128935   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.129504   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.129523   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.129873   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.130244   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.130417   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.130847   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.131019   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.131268   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.131911   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.132024   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.132134   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.132671   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.133065   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.133144   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.133498   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.133926   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.134428   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.134515   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.135016   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.135334   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.136282   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.136386   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.137283   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.137660   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.137731   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.138161   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.138852   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.139167   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.140027   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.140211   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.140820   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.141381   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.141943   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.142815   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.143095   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.144424   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.145477   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.145852   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.147379   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.151843   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.152207   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.152772   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.153707   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.154597   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.155480   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.156314   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.156336   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.157294   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.157471   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.158243   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.158645   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.158830   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.159152   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.159661   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.160048   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.160542   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.160917   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.161559   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.162014   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.162598   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.163149   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.164141   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.164505   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.165020   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.166019   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.167043   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.167913   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.171211   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.172362   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.174698   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.178037   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.179146   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.181284   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.184851   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.186998   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.191443   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.191921   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.193763   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.198126   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.200644   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.204919   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.214323   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.218371   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.453041   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.454024   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.454965   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.455919   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.456959   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.458013   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.459112   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.460165   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.461323   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.462648   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.464006   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.465276   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.466677   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.468576   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.474330   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.475693   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.475795   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.476306   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.476789   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.476899   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.477815   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.477930   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.478328   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.478894   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.479003   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.479991   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.480160   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.480663   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.481111   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.481287   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.482237   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.482427   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.483536   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.483636   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.484779   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.484887   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.486153   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.486322   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.487552   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.487726   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.488888   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.489077   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.489075   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.489751   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.490695   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.490764   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.490777   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.491490   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.492192   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.492744   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.492921   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.493024   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.493780   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.497143   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.498618   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.498784   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.500589   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.500756   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.501323   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.502624   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.502796   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.504885   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.505198   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.505278   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.507891   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.508298   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.511766   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.513463   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.514132   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.514732   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.515034   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.515468   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.516120   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.516184   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.516849   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.517024   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.517463   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.517796   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.518200   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.518914   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.519667   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.520411   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.521207   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.521848   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.523815   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.525441   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.528036   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.529009   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.531604   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.532459   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.535038   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.535962   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.538532   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.539261   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.541829   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.546120   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.548570   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.641148   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.641778   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.642413   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.642993   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.643572   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.644248   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.644938   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.645564   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.646179   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.646845   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.647500   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.648177   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.648931   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.649683   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.650582   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.651590   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.652607   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.653816   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 104ms/step - loss: 0.1595 - val_loss: 0.1124 - learning_rate: 0.0100\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1729527338.655071   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.657511   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.660739   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.664831   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.666560   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.667193   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.667947   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.668076   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.668607   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.668785   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.669202   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.669448   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.669935   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.670108   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.670776   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.670845   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.671467   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.671639   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.672113   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.672339   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.672838   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.673007   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.673551   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.673724   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.674300   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.674467   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.675308   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.675523   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.676121   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.676296   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.677173   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.677252   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.678038   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.678215   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.678964   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.679259   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.679976   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.680488   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.680711   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.681152   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.681278   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.681886   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.681905   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.682464   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.682564   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.683341   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.683850   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.684375   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.685161   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.685339   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.687010   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.687694   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.687872   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.689771   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.691144   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.691601   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.691756   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.693700   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.695010   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.697531   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.700157   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.707319   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.707793   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.708212   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.708652   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.709521   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.711085   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.711375   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.711558   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.712009   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.712431   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.712847   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.713385   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.713407   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.713837   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.714318   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.714986   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.715155   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.715452   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.715898   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.716272   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.716374   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.716876   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.717034   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.717533   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.717994   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.718257   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.718523   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.719082   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.719102   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.719543   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.720068   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.720254   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.720593   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.721114   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.721705   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.721888   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.722303   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.722887   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.723867   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.724105   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.724657   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.725371   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.726186   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.726765   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.727204   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.727705   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.731105   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.732716   21427 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.734334   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.741683   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.742163   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.742619   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.743055   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.743522   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.744173   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.744639   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.745157   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.745581   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.746016   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.746528   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.747047   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.747571   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.748135   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.748713   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.749397   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.749460   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.749865   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.750321   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.750765   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.751367   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.751439   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.752071   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.752245   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.752547   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.753184   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.753203   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.753633   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.754129   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.754299   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.754652   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.755163   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.755646   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.756209   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.756787   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.757380   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.759163   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.760005   21373 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.760077   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.760884   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.761902   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729527338.767453   21407 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "2024-10-21 16:15:38.796749: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1346"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 16:15:39.650837: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1327 - val_loss: 0.1199 - learning_rate: 0.0100\n",
      "Epoch 3/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1170 - val_loss: 0.0949 - learning_rate: 0.0100\n",
      "Epoch 4/1000\n",
      "\u001b[1m 1/24\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - loss: 0.1133"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 16:15:40.866558: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1089 - val_loss: 0.0813 - learning_rate: 0.0100\n",
      "Epoch 5/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.1077 - val_loss: 0.0742 - learning_rate: 0.0100\n",
      "Epoch 6/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.1090"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 16:15:43.756233: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1083 - val_loss: 0.1685 - learning_rate: 0.0100\n",
      "Epoch 7/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1085 - val_loss: 0.1027 - learning_rate: 0.0100\n",
      "Epoch 8/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0996 - val_loss: 0.0908 - learning_rate: 0.0100\n",
      "Epoch 9/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0985 - val_loss: 0.0720 - learning_rate: 0.0100\n",
      "Epoch 10/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0963 - val_loss: 0.0564 - learning_rate: 0.0100\n",
      "Epoch 11/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0934 - val_loss: 0.0539 - learning_rate: 0.0100\n",
      "Epoch 12/1000\n",
      "\u001b[1m 1/24\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 159ms/step - loss: 0.0969"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 16:15:49.428466: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0935 - val_loss: 0.0699 - learning_rate: 0.0100\n",
      "Epoch 13/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0912 - val_loss: 0.0656 - learning_rate: 0.0100\n",
      "Epoch 14/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0909 - val_loss: 0.0707 - learning_rate: 0.0100\n",
      "Epoch 15/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0916 - val_loss: 0.0648 - learning_rate: 0.0100\n",
      "Epoch 16/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0899 - val_loss: 0.0713 - learning_rate: 0.0100\n",
      "Epoch 17/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0903 - val_loss: 0.0689 - learning_rate: 0.0100\n",
      "Epoch 18/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0811 - val_loss: 0.0877 - learning_rate: 0.0100\n",
      "Epoch 19/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0774 - val_loss: 0.0830 - learning_rate: 0.0100\n",
      "Epoch 20/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0722 - val_loss: 0.0842 - learning_rate: 0.0100\n",
      "Epoch 21/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0704\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0687 - val_loss: 0.0855 - learning_rate: 0.0100\n",
      "Epoch 22/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0689"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 16:16:00.550116: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0671 - val_loss: 0.0861 - learning_rate: 0.0090\n",
      "Epoch 23/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0623 - val_loss: 0.0820 - learning_rate: 0.0090\n",
      "Epoch 24/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0609 - val_loss: 0.0861 - learning_rate: 0.0090\n",
      "Epoch 25/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0590 - val_loss: 0.0832 - learning_rate: 0.0090\n",
      "Epoch 26/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0596 - val_loss: 0.0814 - learning_rate: 0.0090\n",
      "Epoch 27/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0572 - val_loss: 0.0768 - learning_rate: 0.0090\n",
      "Epoch 28/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0568 - val_loss: 0.0821 - learning_rate: 0.0090\n",
      "Epoch 29/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0562 - val_loss: 0.0731 - learning_rate: 0.0090\n",
      "Epoch 30/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0550 - val_loss: 0.0760 - learning_rate: 0.0090\n",
      "Epoch 31/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0512\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.008099999651312828.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0502 - val_loss: 0.0714 - learning_rate: 0.0090\n",
      "Epoch 32/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0543 - val_loss: 0.0635 - learning_rate: 0.0081\n",
      "Epoch 33/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0512 - val_loss: 0.0740 - learning_rate: 0.0081\n",
      "Epoch 34/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0501 - val_loss: 0.0677 - learning_rate: 0.0081\n",
      "Epoch 35/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0461 - val_loss: 0.0602 - learning_rate: 0.0081\n",
      "Epoch 36/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0381 - val_loss: 0.0613 - learning_rate: 0.0081\n",
      "Epoch 37/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0327 - val_loss: 0.0603 - learning_rate: 0.0081\n",
      "Epoch 38/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0304 - val_loss: 0.0512 - learning_rate: 0.0081\n",
      "Epoch 39/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0292 - val_loss: 0.0539 - learning_rate: 0.0081\n",
      "Epoch 40/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0277 - val_loss: 0.0456 - learning_rate: 0.0081\n",
      "Epoch 41/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0278 - val_loss: 0.0473 - learning_rate: 0.0081\n",
      "Epoch 42/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0269 - val_loss: 0.0523 - learning_rate: 0.0081\n",
      "Epoch 43/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0252 - val_loss: 0.0399 - learning_rate: 0.0081\n",
      "Epoch 44/1000\n",
      "\u001b[1m 1/24\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 159ms/step - loss: 0.0254"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 16:16:22.433062: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0243 - val_loss: 0.0335 - learning_rate: 0.0081\n",
      "Epoch 45/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0237 - val_loss: 0.0386 - learning_rate: 0.0081\n",
      "Epoch 46/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0238 - val_loss: 0.0379 - learning_rate: 0.0081\n",
      "Epoch 47/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0237 - val_loss: 0.0302 - learning_rate: 0.0081\n",
      "Epoch 48/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0229 - val_loss: 0.0310 - learning_rate: 0.0081\n",
      "Epoch 49/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0232 - val_loss: 0.0333 - learning_rate: 0.0081\n",
      "Epoch 50/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0233 - val_loss: 0.0359 - learning_rate: 0.0081\n",
      "Epoch 51/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0230 - val_loss: 0.0341 - learning_rate: 0.0081\n",
      "Epoch 52/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0228 - val_loss: 0.0262 - learning_rate: 0.0081\n",
      "Epoch 53/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0224 - val_loss: 0.0278 - learning_rate: 0.0081\n",
      "Epoch 54/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0223 - val_loss: 0.0277 - learning_rate: 0.0081\n",
      "Epoch 55/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0219 - val_loss: 0.0279 - learning_rate: 0.0081\n",
      "Epoch 56/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0220 - val_loss: 0.0291 - learning_rate: 0.0081\n",
      "Epoch 57/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0219 - val_loss: 0.0275 - learning_rate: 0.0081\n",
      "Epoch 58/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0213 - val_loss: 0.0308 - learning_rate: 0.0081\n",
      "Epoch 59/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0217 - val_loss: 0.0338 - learning_rate: 0.0081\n",
      "Epoch 60/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0214 - val_loss: 0.0282 - learning_rate: 0.0081\n",
      "Epoch 61/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0208 - val_loss: 0.0322 - learning_rate: 0.0081\n",
      "Epoch 62/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0208\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.007289999350905419.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0207 - val_loss: 0.0391 - learning_rate: 0.0081\n",
      "Epoch 63/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0208 - val_loss: 0.0331 - learning_rate: 0.0073\n",
      "Epoch 64/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0204 - val_loss: 0.0589 - learning_rate: 0.0073\n",
      "Epoch 65/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0201 - val_loss: 0.0278 - learning_rate: 0.0073\n",
      "Epoch 66/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0195 - val_loss: 0.0339 - learning_rate: 0.0073\n",
      "Epoch 67/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0196 - val_loss: 0.0306 - learning_rate: 0.0073\n",
      "Epoch 68/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0195 - val_loss: 0.0280 - learning_rate: 0.0073\n",
      "Epoch 69/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0190 - val_loss: 0.0341 - learning_rate: 0.0073\n",
      "Epoch 70/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0193 - val_loss: 0.0306 - learning_rate: 0.0073\n",
      "Epoch 71/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0183 - val_loss: 0.0293 - learning_rate: 0.0073\n",
      "Epoch 72/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0187\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.006560999248176813.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0185 - val_loss: 0.0312 - learning_rate: 0.0073\n",
      "Epoch 73/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0180 - val_loss: 0.0312 - learning_rate: 0.0066\n",
      "Epoch 74/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0181 - val_loss: 0.0305 - learning_rate: 0.0066\n",
      "Epoch 75/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0175 - val_loss: 0.0325 - learning_rate: 0.0066\n",
      "Epoch 76/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0169 - val_loss: 0.0307 - learning_rate: 0.0066\n",
      "Epoch 77/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0172 - val_loss: 0.0316 - learning_rate: 0.0066\n",
      "Epoch 78/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0172 - val_loss: 0.0288 - learning_rate: 0.0066\n",
      "Epoch 79/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0172 - val_loss: 0.0320 - learning_rate: 0.0066\n",
      "Epoch 80/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0165 - val_loss: 0.0314 - learning_rate: 0.0066\n",
      "Epoch 81/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0161 - val_loss: 0.0303 - learning_rate: 0.0066\n",
      "Epoch 82/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0167\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.005904899490997195.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0165 - val_loss: 0.0321 - learning_rate: 0.0066\n",
      "Epoch 83/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0158 - val_loss: 0.0317 - learning_rate: 0.0059\n",
      "Epoch 84/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0157 - val_loss: 0.0317 - learning_rate: 0.0059\n",
      "Epoch 85/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0153 - val_loss: 0.0317 - learning_rate: 0.0059\n",
      "Epoch 86/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0156"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 16:17:07.741074: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0153 - val_loss: 0.0324 - learning_rate: 0.0059\n",
      "Epoch 87/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0150 - val_loss: 0.0327 - learning_rate: 0.0059\n",
      "Epoch 88/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0154 - val_loss: 0.0325 - learning_rate: 0.0059\n",
      "Epoch 89/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0151 - val_loss: 0.0350 - learning_rate: 0.0059\n",
      "Epoch 90/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0152 - val_loss: 0.0334 - learning_rate: 0.0059\n",
      "Epoch 91/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0147 - val_loss: 0.0327 - learning_rate: 0.0059\n",
      "Epoch 92/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0150\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.00531440949998796.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0146 - val_loss: 0.0330 - learning_rate: 0.0059\n",
      "Epoch 93/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0143 - val_loss: 0.0321 - learning_rate: 0.0053\n",
      "Epoch 94/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0139 - val_loss: 0.0336 - learning_rate: 0.0053\n",
      "Epoch 95/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0139 - val_loss: 0.0336 - learning_rate: 0.0053\n",
      "Epoch 96/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0135 - val_loss: 0.0349 - learning_rate: 0.0053\n",
      "Epoch 97/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0136 - val_loss: 0.0357 - learning_rate: 0.0053\n",
      "Epoch 98/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0137 - val_loss: 0.0348 - learning_rate: 0.0053\n",
      "Epoch 99/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0130 - val_loss: 0.0336 - learning_rate: 0.0053\n",
      "Epoch 100/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0128 - val_loss: 0.0346 - learning_rate: 0.0053\n",
      "Epoch 101/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0129 - val_loss: 0.0336 - learning_rate: 0.0053\n",
      "Epoch 102/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0128\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 0.004782968759536744.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0126 - val_loss: 0.0329 - learning_rate: 0.0053\n",
      "Epoch 103/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0127 - val_loss: 0.0325 - learning_rate: 0.0048\n",
      "Epoch 104/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0124 - val_loss: 0.0350 - learning_rate: 0.0048\n",
      "Epoch 105/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0120 - val_loss: 0.0332 - learning_rate: 0.0048\n",
      "Epoch 106/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0116 - val_loss: 0.0330 - learning_rate: 0.0048\n",
      "Epoch 107/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0117 - val_loss: 0.0349 - learning_rate: 0.0048\n",
      "Epoch 108/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0117 - val_loss: 0.0351 - learning_rate: 0.0048\n",
      "Epoch 109/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0113 - val_loss: 0.0345 - learning_rate: 0.0048\n",
      "Epoch 110/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0116 - val_loss: 0.0343 - learning_rate: 0.0048\n",
      "Epoch 111/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0111 - val_loss: 0.0325 - learning_rate: 0.0048\n",
      "Epoch 112/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0113\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 0.0043046717997640375.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0110 - val_loss: 0.0347 - learning_rate: 0.0048\n",
      "Epoch 113/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0105 - val_loss: 0.0345 - learning_rate: 0.0043\n",
      "Epoch 114/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0106 - val_loss: 0.0332 - learning_rate: 0.0043\n",
      "Epoch 115/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0110 - val_loss: 0.0331 - learning_rate: 0.0043\n",
      "Epoch 116/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0133 - val_loss: 0.0332 - learning_rate: 0.0043\n",
      "Epoch 117/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0108 - val_loss: 0.0354 - learning_rate: 0.0043\n",
      "Epoch 118/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0107 - val_loss: 0.0381 - learning_rate: 0.0043\n",
      "Epoch 119/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0104 - val_loss: 0.0339 - learning_rate: 0.0043\n",
      "Epoch 120/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0098 - val_loss: 0.0329 - learning_rate: 0.0043\n",
      "Epoch 121/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0098 - val_loss: 0.0344 - learning_rate: 0.0043\n",
      "Epoch 122/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0097\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 0.0038742044940590858.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0094 - val_loss: 0.0365 - learning_rate: 0.0043\n",
      "Epoch 123/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0090 - val_loss: 0.0347 - learning_rate: 0.0039\n",
      "Epoch 124/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0089 - val_loss: 0.0340 - learning_rate: 0.0039\n",
      "Epoch 125/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0089 - val_loss: 0.0348 - learning_rate: 0.0039\n",
      "Epoch 126/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0085 - val_loss: 0.0364 - learning_rate: 0.0039\n",
      "Epoch 127/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0083 - val_loss: 0.0341 - learning_rate: 0.0039\n",
      "Epoch 128/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0085 - val_loss: 0.0349 - learning_rate: 0.0039\n",
      "Epoch 129/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0081 - val_loss: 0.0333 - learning_rate: 0.0039\n",
      "Epoch 130/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0084 - val_loss: 0.0351 - learning_rate: 0.0039\n",
      "Epoch 131/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0080 - val_loss: 0.0351 - learning_rate: 0.0039\n",
      "Epoch 132/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0082\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 0.003486784128472209.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0080 - val_loss: 0.0347 - learning_rate: 0.0039\n",
      "Epoch 133/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0078 - val_loss: 0.0341 - learning_rate: 0.0035\n",
      "Epoch 134/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0075 - val_loss: 0.0343 - learning_rate: 0.0035\n",
      "Epoch 135/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0076 - val_loss: 0.0363 - learning_rate: 0.0035\n",
      "Epoch 136/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0074 - val_loss: 0.0353 - learning_rate: 0.0035\n",
      "Epoch 137/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0070 - val_loss: 0.0347 - learning_rate: 0.0035\n",
      "Epoch 138/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0070 - val_loss: 0.0356 - learning_rate: 0.0035\n",
      "Epoch 139/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0068 - val_loss: 0.0372 - learning_rate: 0.0035\n",
      "Epoch 140/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0068 - val_loss: 0.0341 - learning_rate: 0.0035\n",
      "Epoch 141/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0070 - val_loss: 0.0348 - learning_rate: 0.0035\n",
      "Epoch 142/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0070\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 0.003138105757534504.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0068 - val_loss: 0.0346 - learning_rate: 0.0035\n",
      "Epoch 143/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0069 - val_loss: 0.0358 - learning_rate: 0.0031\n",
      "Epoch 144/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0065 - val_loss: 0.0362 - learning_rate: 0.0031\n",
      "Epoch 145/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0062 - val_loss: 0.0343 - learning_rate: 0.0031\n",
      "Epoch 146/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0061 - val_loss: 0.0325 - learning_rate: 0.0031\n",
      "Epoch 147/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0061 - val_loss: 0.0352 - learning_rate: 0.0031\n",
      "Epoch 148/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0061 - val_loss: 0.0348 - learning_rate: 0.0031\n",
      "Epoch 149/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0059 - val_loss: 0.0360 - learning_rate: 0.0031\n",
      "Epoch 150/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0058 - val_loss: 0.0355 - learning_rate: 0.0031\n",
      "Epoch 151/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0059 - val_loss: 0.0370 - learning_rate: 0.0031\n",
      "Epoch 152/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0061\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 0.0028242952656000854.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0059 - val_loss: 0.0336 - learning_rate: 0.0031\n",
      "Epoch 153/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0054 - val_loss: 0.0366 - learning_rate: 0.0028\n",
      "Epoch 154/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0053 - val_loss: 0.0340 - learning_rate: 0.0028\n",
      "Epoch 155/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0052 - val_loss: 0.0360 - learning_rate: 0.0028\n",
      "Epoch 156/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0053 - val_loss: 0.0373 - learning_rate: 0.0028\n",
      "Epoch 157/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0051 - val_loss: 0.0343 - learning_rate: 0.0028\n",
      "Epoch 158/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0051 - val_loss: 0.0355 - learning_rate: 0.0028\n",
      "Epoch 159/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0051 - val_loss: 0.0345 - learning_rate: 0.0028\n",
      "Epoch 160/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0049 - val_loss: 0.0375 - learning_rate: 0.0028\n",
      "Epoch 161/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0048 - val_loss: 0.0370 - learning_rate: 0.0028\n",
      "Epoch 162/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0047\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 0.0025418657809495927.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0046 - val_loss: 0.0369 - learning_rate: 0.0028\n",
      "Epoch 163/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0049 - val_loss: 0.0347 - learning_rate: 0.0025\n",
      "Epoch 164/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0046 - val_loss: 0.0358 - learning_rate: 0.0025\n",
      "Epoch 165/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0045 - val_loss: 0.0377 - learning_rate: 0.0025\n",
      "Epoch 166/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0045 - val_loss: 0.0358 - learning_rate: 0.0025\n",
      "Epoch 167/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0045 - val_loss: 0.0354 - learning_rate: 0.0025\n",
      "Epoch 168/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0043 - val_loss: 0.0361 - learning_rate: 0.0025\n",
      "Epoch 169/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0044 - val_loss: 0.0353 - learning_rate: 0.0025\n",
      "Epoch 170/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0043 - val_loss: 0.0360 - learning_rate: 0.0025\n",
      "Epoch 171/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0040 - val_loss: 0.0379 - learning_rate: 0.0025\n",
      "Epoch 172/1000\n",
      "\u001b[1m 1/24\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 164ms/step - loss: 0.0038"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 16:18:39.906523: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0043\n",
      "Epoch 172: ReduceLROnPlateau reducing learning rate to 0.0022876791190356016.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0042 - val_loss: 0.0339 - learning_rate: 0.0025\n",
      "Epoch 173/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0039 - val_loss: 0.0351 - learning_rate: 0.0023\n",
      "Epoch 174/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0038 - val_loss: 0.0359 - learning_rate: 0.0023\n",
      "Epoch 175/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0039 - val_loss: 0.0356 - learning_rate: 0.0023\n",
      "Epoch 176/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0039 - val_loss: 0.0364 - learning_rate: 0.0023\n",
      "Epoch 177/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0038 - val_loss: 0.0347 - learning_rate: 0.0023\n",
      "Epoch 178/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0037 - val_loss: 0.0357 - learning_rate: 0.0023\n",
      "Epoch 179/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0037 - val_loss: 0.0367 - learning_rate: 0.0023\n",
      "Epoch 180/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0035 - val_loss: 0.0339 - learning_rate: 0.0023\n",
      "Epoch 181/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0035 - val_loss: 0.0363 - learning_rate: 0.0023\n",
      "Epoch 182/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0036\n",
      "Epoch 182: ReduceLROnPlateau reducing learning rate to 0.0020589112071320416.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0035 - val_loss: 0.0356 - learning_rate: 0.0023\n",
      "Epoch 183/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0035 - val_loss: 0.0350 - learning_rate: 0.0021\n",
      "Epoch 184/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0034 - val_loss: 0.0376 - learning_rate: 0.0021\n",
      "Epoch 185/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0032 - val_loss: 0.0347 - learning_rate: 0.0021\n",
      "Epoch 186/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0033 - val_loss: 0.0360 - learning_rate: 0.0021\n",
      "Epoch 187/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0030 - val_loss: 0.0360 - learning_rate: 0.0021\n",
      "Epoch 188/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0032 - val_loss: 0.0349 - learning_rate: 0.0021\n",
      "Epoch 189/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0030 - val_loss: 0.0341 - learning_rate: 0.0021\n",
      "Epoch 190/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0029 - val_loss: 0.0364 - learning_rate: 0.0021\n",
      "Epoch 191/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0031 - val_loss: 0.0348 - learning_rate: 0.0021\n",
      "Epoch 192/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0030\n",
      "Epoch 192: ReduceLROnPlateau reducing learning rate to 0.0018530200235545636.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0030 - val_loss: 0.0350 - learning_rate: 0.0021\n",
      "Epoch 193/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0029 - val_loss: 0.0369 - learning_rate: 0.0019\n",
      "Epoch 194/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0027 - val_loss: 0.0360 - learning_rate: 0.0019\n",
      "Epoch 195/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0027 - val_loss: 0.0348 - learning_rate: 0.0019\n",
      "Epoch 196/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0030 - val_loss: 0.0356 - learning_rate: 0.0019\n",
      "Epoch 197/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0027 - val_loss: 0.0348 - learning_rate: 0.0019\n",
      "Epoch 198/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0027 - val_loss: 0.0376 - learning_rate: 0.0019\n",
      "Epoch 199/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0028 - val_loss: 0.0352 - learning_rate: 0.0019\n",
      "Epoch 200/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0027 - val_loss: 0.0368 - learning_rate: 0.0019\n",
      "Epoch 201/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0026 - val_loss: 0.0370 - learning_rate: 0.0019\n",
      "Epoch 202/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0026\n",
      "Epoch 202: ReduceLROnPlateau reducing learning rate to 0.0016677180421538651.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0026 - val_loss: 0.0359 - learning_rate: 0.0019\n",
      "Epoch 203/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0026 - val_loss: 0.0360 - learning_rate: 0.0017\n",
      "Epoch 204/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0025 - val_loss: 0.0370 - learning_rate: 0.0017\n",
      "Epoch 205/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0025 - val_loss: 0.0354 - learning_rate: 0.0017\n",
      "Epoch 206/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0023 - val_loss: 0.0358 - learning_rate: 0.0017\n",
      "Epoch 207/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0024 - val_loss: 0.0373 - learning_rate: 0.0017\n",
      "Epoch 208/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0024 - val_loss: 0.0363 - learning_rate: 0.0017\n",
      "Epoch 209/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0025 - val_loss: 0.0364 - learning_rate: 0.0017\n",
      "Epoch 210/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0023 - val_loss: 0.0364 - learning_rate: 0.0017\n",
      "Epoch 211/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0023 - val_loss: 0.0352 - learning_rate: 0.0017\n",
      "Epoch 212/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0023\n",
      "Epoch 212: ReduceLROnPlateau reducing learning rate to 0.0015009462484158575.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0022 - val_loss: 0.0345 - learning_rate: 0.0017\n",
      "Epoch 213/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0022 - val_loss: 0.0362 - learning_rate: 0.0015\n",
      "Epoch 214/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0021 - val_loss: 0.0377 - learning_rate: 0.0015\n",
      "Epoch 215/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0023 - val_loss: 0.0342 - learning_rate: 0.0015\n",
      "Epoch 216/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0021 - val_loss: 0.0370 - learning_rate: 0.0015\n",
      "Epoch 217/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0020 - val_loss: 0.0382 - learning_rate: 0.0015\n",
      "Epoch 218/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0021 - val_loss: 0.0355 - learning_rate: 0.0015\n",
      "Epoch 219/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0023 - val_loss: 0.0349 - learning_rate: 0.0015\n",
      "Epoch 220/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0021 - val_loss: 0.0340 - learning_rate: 0.0015\n",
      "Epoch 221/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0022 - val_loss: 0.0361 - learning_rate: 0.0015\n",
      "Epoch 222/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0021\n",
      "Epoch 222: ReduceLROnPlateau reducing learning rate to 0.0013508516130968928.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0021 - val_loss: 0.0360 - learning_rate: 0.0015\n",
      "Epoch 223/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0021 - val_loss: 0.0351 - learning_rate: 0.0014\n",
      "Epoch 224/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0020 - val_loss: 0.0350 - learning_rate: 0.0014\n",
      "Epoch 225/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0019 - val_loss: 0.0363 - learning_rate: 0.0014\n",
      "Epoch 226/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0020 - val_loss: 0.0379 - learning_rate: 0.0014\n",
      "Epoch 227/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0019 - val_loss: 0.0351 - learning_rate: 0.0014\n",
      "Epoch 228/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0018 - val_loss: 0.0353 - learning_rate: 0.0014\n",
      "Epoch 229/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0021 - val_loss: 0.0339 - learning_rate: 0.0014\n",
      "Epoch 230/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0018 - val_loss: 0.0371 - learning_rate: 0.0014\n",
      "Epoch 231/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0018 - val_loss: 0.0366 - learning_rate: 0.0014\n",
      "Epoch 232/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0019\n",
      "Epoch 232: ReduceLROnPlateau reducing learning rate to 0.0012157664517872036.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0018 - val_loss: 0.0376 - learning_rate: 0.0014\n",
      "Epoch 233/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0019 - val_loss: 0.0351 - learning_rate: 0.0012\n",
      "Epoch 234/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0019 - val_loss: 0.0365 - learning_rate: 0.0012\n",
      "Epoch 235/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0018 - val_loss: 0.0346 - learning_rate: 0.0012\n",
      "Epoch 236/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0017 - val_loss: 0.0359 - learning_rate: 0.0012\n",
      "Epoch 237/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0017 - val_loss: 0.0368 - learning_rate: 0.0012\n",
      "Epoch 238/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0018 - val_loss: 0.0366 - learning_rate: 0.0012\n",
      "Epoch 239/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0016 - val_loss: 0.0367 - learning_rate: 0.0012\n",
      "Epoch 240/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0016 - val_loss: 0.0370 - learning_rate: 0.0012\n",
      "Epoch 241/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0017 - val_loss: 0.0357 - learning_rate: 0.0012\n",
      "Epoch 242/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0018\n",
      "Epoch 242: ReduceLROnPlateau reducing learning rate to 0.0010941897751763463.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0017 - val_loss: 0.0356 - learning_rate: 0.0012\n",
      "Epoch 243/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0016 - val_loss: 0.0363 - learning_rate: 0.0011\n",
      "Epoch 244/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0015 - val_loss: 0.0343 - learning_rate: 0.0011\n",
      "Epoch 245/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0016 - val_loss: 0.0370 - learning_rate: 0.0011\n",
      "Epoch 246/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0015 - val_loss: 0.0352 - learning_rate: 0.0011\n",
      "Epoch 247/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0016 - val_loss: 0.0350 - learning_rate: 0.0011\n",
      "Epoch 248/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0016 - val_loss: 0.0370 - learning_rate: 0.0011\n",
      "Epoch 249/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0018 - val_loss: 0.0351 - learning_rate: 0.0011\n",
      "Epoch 250/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0017 - val_loss: 0.0353 - learning_rate: 0.0011\n",
      "Epoch 251/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0015 - val_loss: 0.0361 - learning_rate: 0.0011\n",
      "Epoch 252/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0016\n",
      "Epoch 252: ReduceLROnPlateau reducing learning rate to 0.0009847708395682275.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0016 - val_loss: 0.0369 - learning_rate: 0.0011\n",
      "Epoch 253/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0015 - val_loss: 0.0368 - learning_rate: 9.8477e-04\n",
      "Epoch 254/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0014 - val_loss: 0.0350 - learning_rate: 9.8477e-04\n",
      "Epoch 255/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0015 - val_loss: 0.0378 - learning_rate: 9.8477e-04\n",
      "Epoch 256/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0015 - val_loss: 0.0369 - learning_rate: 9.8477e-04\n",
      "Epoch 257/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0013 - val_loss: 0.0357 - learning_rate: 9.8477e-04\n",
      "Epoch 258/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0016 - val_loss: 0.0359 - learning_rate: 9.8477e-04\n",
      "Epoch 259/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0014 - val_loss: 0.0378 - learning_rate: 9.8477e-04\n",
      "Epoch 260/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0014 - val_loss: 0.0382 - learning_rate: 9.8477e-04\n",
      "Epoch 261/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0016 - val_loss: 0.0386 - learning_rate: 9.8477e-04\n",
      "Epoch 262/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0014\n",
      "Epoch 262: ReduceLROnPlateau reducing learning rate to 0.0008862937451340258.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0014 - val_loss: 0.0361 - learning_rate: 9.8477e-04\n",
      "Epoch 263/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0014 - val_loss: 0.0381 - learning_rate: 8.8629e-04\n",
      "Epoch 264/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0013 - val_loss: 0.0360 - learning_rate: 8.8629e-04\n",
      "Epoch 265/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0013 - val_loss: 0.0369 - learning_rate: 8.8629e-04\n",
      "Epoch 266/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0013 - val_loss: 0.0359 - learning_rate: 8.8629e-04\n",
      "Epoch 267/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0013 - val_loss: 0.0354 - learning_rate: 8.8629e-04\n",
      "Epoch 268/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0012 - val_loss: 0.0358 - learning_rate: 8.8629e-04\n",
      "Epoch 269/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0013 - val_loss: 0.0357 - learning_rate: 8.8629e-04\n",
      "Epoch 270/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0013 - val_loss: 0.0361 - learning_rate: 8.8629e-04\n",
      "Epoch 271/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0012 - val_loss: 0.0363 - learning_rate: 8.8629e-04\n",
      "Epoch 272/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0015\n",
      "Epoch 272: ReduceLROnPlateau reducing learning rate to 0.0007976643915753812.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0015 - val_loss: 0.0369 - learning_rate: 8.8629e-04\n",
      "Epoch 273/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0015 - val_loss: 0.0375 - learning_rate: 7.9766e-04\n",
      "Epoch 274/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0014 - val_loss: 0.0354 - learning_rate: 7.9766e-04\n",
      "Epoch 275/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0012 - val_loss: 0.0366 - learning_rate: 7.9766e-04\n",
      "Epoch 276/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0013 - val_loss: 0.0364 - learning_rate: 7.9766e-04\n",
      "Epoch 277/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0013 - val_loss: 0.0370 - learning_rate: 7.9766e-04\n",
      "Epoch 278/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0367 - learning_rate: 7.9766e-04\n",
      "Epoch 279/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0013 - val_loss: 0.0360 - learning_rate: 7.9766e-04\n",
      "Epoch 280/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0362 - learning_rate: 7.9766e-04\n",
      "Epoch 281/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0352 - learning_rate: 7.9766e-04\n",
      "Epoch 282/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0012\n",
      "Epoch 282: ReduceLROnPlateau reducing learning rate to 0.0007178979576565325.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0368 - learning_rate: 7.9766e-04\n",
      "Epoch 283/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0014 - val_loss: 0.0369 - learning_rate: 7.1790e-04\n",
      "Epoch 284/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0362 - learning_rate: 7.1790e-04\n",
      "Epoch 285/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0354 - learning_rate: 7.1790e-04\n",
      "Epoch 286/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0375 - learning_rate: 7.1790e-04\n",
      "Epoch 287/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0012 - val_loss: 0.0372 - learning_rate: 7.1790e-04\n",
      "Epoch 288/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0014 - val_loss: 0.0357 - learning_rate: 7.1790e-04\n",
      "Epoch 289/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0377 - learning_rate: 7.1790e-04\n",
      "Epoch 290/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0012 - val_loss: 0.0364 - learning_rate: 7.1790e-04\n",
      "Epoch 291/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0350 - learning_rate: 7.1790e-04\n",
      "Epoch 292/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0011\n",
      "Epoch 292: ReduceLROnPlateau reducing learning rate to 0.0006461081618908793.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0356 - learning_rate: 7.1790e-04\n",
      "Epoch 293/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0014 - val_loss: 0.0362 - learning_rate: 6.4611e-04\n",
      "Epoch 294/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0012 - val_loss: 0.0371 - learning_rate: 6.4611e-04\n",
      "Epoch 295/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0012 - val_loss: 0.0344 - learning_rate: 6.4611e-04\n",
      "Epoch 296/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0360 - learning_rate: 6.4611e-04\n",
      "Epoch 297/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0013 - val_loss: 0.0364 - learning_rate: 6.4611e-04\n",
      "Epoch 298/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0012 - val_loss: 0.0372 - learning_rate: 6.4611e-04\n",
      "Epoch 299/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0010 - val_loss: 0.0369 - learning_rate: 6.4611e-04\n",
      "Epoch 300/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0010 - val_loss: 0.0360 - learning_rate: 6.4611e-04\n",
      "Epoch 301/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0368 - learning_rate: 6.4611e-04\n",
      "Epoch 302/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0011\n",
      "Epoch 302: ReduceLROnPlateau reducing learning rate to 0.0005814973614178598.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0011 - val_loss: 0.0377 - learning_rate: 6.4611e-04\n",
      "Epoch 303/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0010 - val_loss: 0.0351 - learning_rate: 5.8150e-04\n",
      "Epoch 304/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0363 - learning_rate: 5.8150e-04\n",
      "Epoch 305/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 9.9306e-04 - val_loss: 0.0352 - learning_rate: 5.8150e-04\n",
      "Epoch 306/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0366 - learning_rate: 5.8150e-04\n",
      "Epoch 307/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0010 - val_loss: 0.0369 - learning_rate: 5.8150e-04\n",
      "Epoch 308/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 9.2640e-04 - val_loss: 0.0372 - learning_rate: 5.8150e-04\n",
      "Epoch 309/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0013 - val_loss: 0.0361 - learning_rate: 5.8150e-04\n",
      "Epoch 310/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0012 - val_loss: 0.0353 - learning_rate: 5.8150e-04\n",
      "Epoch 311/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0010 - val_loss: 0.0377 - learning_rate: 5.8150e-04\n",
      "Epoch 312/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0010\n",
      "Epoch 312: ReduceLROnPlateau reducing learning rate to 0.0005233476462308317.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0010 - val_loss: 0.0371 - learning_rate: 5.8150e-04\n",
      "Epoch 313/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0010 - val_loss: 0.0380 - learning_rate: 5.2335e-04\n",
      "Epoch 314/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0010 - val_loss: 0.0362 - learning_rate: 5.2335e-04\n",
      "Epoch 315/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0369 - learning_rate: 5.2335e-04\n",
      "Epoch 316/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0010 - val_loss: 0.0382 - learning_rate: 5.2335e-04\n",
      "Epoch 317/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0012 - val_loss: 0.0354 - learning_rate: 5.2335e-04\n",
      "Epoch 318/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0385 - learning_rate: 5.2335e-04\n",
      "Epoch 319/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0010 - val_loss: 0.0378 - learning_rate: 5.2335e-04\n",
      "Epoch 320/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 9.4678e-04 - val_loss: 0.0367 - learning_rate: 5.2335e-04\n",
      "Epoch 321/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 9.1013e-04 - val_loss: 0.0378 - learning_rate: 5.2335e-04\n",
      "Epoch 322/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 9.8770e-04\n",
      "Epoch 322: ReduceLROnPlateau reducing learning rate to 0.0004710128763690591.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 9.6623e-04 - val_loss: 0.0367 - learning_rate: 5.2335e-04\n",
      "Epoch 323/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 9.5709e-04 - val_loss: 0.0371 - learning_rate: 4.7101e-04\n",
      "Epoch 324/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 8.9559e-04 - val_loss: 0.0372 - learning_rate: 4.7101e-04\n",
      "Epoch 325/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 8.8815e-04 - val_loss: 0.0359 - learning_rate: 4.7101e-04\n",
      "Epoch 326/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 9.9431e-04 - val_loss: 0.0371 - learning_rate: 4.7101e-04\n",
      "Epoch 327/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0367 - learning_rate: 4.7101e-04\n",
      "Epoch 328/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0366 - learning_rate: 4.7101e-04\n",
      "Epoch 329/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.9138e-04 - val_loss: 0.0356 - learning_rate: 4.7101e-04\n",
      "Epoch 330/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 9.7669e-04 - val_loss: 0.0362 - learning_rate: 4.7101e-04\n",
      "Epoch 331/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 9.4432e-04 - val_loss: 0.0360 - learning_rate: 4.7101e-04\n",
      "Epoch 332/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 9.2013e-04\n",
      "Epoch 332: ReduceLROnPlateau reducing learning rate to 0.0004239115834934637.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 9.0978e-04 - val_loss: 0.0356 - learning_rate: 4.7101e-04\n",
      "Epoch 333/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 9.7858e-04 - val_loss: 0.0354 - learning_rate: 4.2391e-04\n",
      "Epoch 334/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0359 - learning_rate: 4.2391e-04\n",
      "Epoch 335/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.8078e-04 - val_loss: 0.0373 - learning_rate: 4.2391e-04\n",
      "Epoch 336/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0010 - val_loss: 0.0347 - learning_rate: 4.2391e-04\n",
      "Epoch 337/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0010 - val_loss: 0.0351 - learning_rate: 4.2391e-04\n",
      "Epoch 338/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 9.5245e-04 - val_loss: 0.0348 - learning_rate: 4.2391e-04\n",
      "Epoch 339/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 8.5723e-04 - val_loss: 0.0347 - learning_rate: 4.2391e-04\n",
      "Epoch 340/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 9.4718e-04 - val_loss: 0.0378 - learning_rate: 4.2391e-04\n",
      "Epoch 341/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 9.8569e-04 - val_loss: 0.0364 - learning_rate: 4.2391e-04\n",
      "Epoch 342/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 16:21:46.197605: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 342: ReduceLROnPlateau reducing learning rate to 0.0003815204225247726.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0010 - val_loss: 0.0355 - learning_rate: 4.2391e-04\n",
      "Epoch 343/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0010 - val_loss: 0.0362 - learning_rate: 3.8152e-04\n",
      "Epoch 344/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.9387e-04 - val_loss: 0.0364 - learning_rate: 3.8152e-04\n",
      "Epoch 345/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 8.6615e-04 - val_loss: 0.0359 - learning_rate: 3.8152e-04\n",
      "Epoch 346/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.8190e-04 - val_loss: 0.0361 - learning_rate: 3.8152e-04\n",
      "Epoch 347/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 9.8606e-04 - val_loss: 0.0372 - learning_rate: 3.8152e-04\n",
      "Epoch 348/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0010 - val_loss: 0.0369 - learning_rate: 3.8152e-04\n",
      "Epoch 349/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 9.1630e-04 - val_loss: 0.0372 - learning_rate: 3.8152e-04\n",
      "Epoch 350/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.8325e-04 - val_loss: 0.0362 - learning_rate: 3.8152e-04\n",
      "Epoch 351/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.2874e-04 - val_loss: 0.0370 - learning_rate: 3.8152e-04\n",
      "Epoch 352/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0010\n",
      "Epoch 352: ReduceLROnPlateau reducing learning rate to 0.0003433683828916401.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 9.9979e-04 - val_loss: 0.0358 - learning_rate: 3.8152e-04\n",
      "Epoch 353/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.3111e-04 - val_loss: 0.0382 - learning_rate: 3.4337e-04\n",
      "Epoch 354/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 9.8610e-04 - val_loss: 0.0370 - learning_rate: 3.4337e-04\n",
      "Epoch 355/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.2033e-04 - val_loss: 0.0371 - learning_rate: 3.4337e-04\n",
      "Epoch 356/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.3318e-04 - val_loss: 0.0367 - learning_rate: 3.4337e-04\n",
      "Epoch 357/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.2081e-04 - val_loss: 0.0360 - learning_rate: 3.4337e-04\n",
      "Epoch 358/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 9.4595e-04 - val_loss: 0.0367 - learning_rate: 3.4337e-04\n",
      "Epoch 359/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.5144e-04 - val_loss: 0.0368 - learning_rate: 3.4337e-04\n",
      "Epoch 360/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.9473e-04 - val_loss: 0.0383 - learning_rate: 3.4337e-04\n",
      "Epoch 361/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.5041e-04 - val_loss: 0.0374 - learning_rate: 3.4337e-04\n",
      "Epoch 362/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 8.3873e-04\n",
      "Epoch 362: ReduceLROnPlateau reducing learning rate to 0.0003090315498411656.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.3787e-04 - val_loss: 0.0355 - learning_rate: 3.4337e-04\n",
      "Epoch 363/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.3500e-04 - val_loss: 0.0356 - learning_rate: 3.0903e-04\n",
      "Epoch 364/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.7360e-04 - val_loss: 0.0375 - learning_rate: 3.0903e-04\n",
      "Epoch 365/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.1677e-04 - val_loss: 0.0368 - learning_rate: 3.0903e-04\n",
      "Epoch 366/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.3616e-04 - val_loss: 0.0373 - learning_rate: 3.0903e-04\n",
      "Epoch 367/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.8015e-04 - val_loss: 0.0378 - learning_rate: 3.0903e-04\n",
      "Epoch 368/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.2583e-04 - val_loss: 0.0355 - learning_rate: 3.0903e-04\n",
      "Epoch 369/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 8.8445e-04 - val_loss: 0.0357 - learning_rate: 3.0903e-04\n",
      "Epoch 370/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.8651e-04 - val_loss: 0.0377 - learning_rate: 3.0903e-04\n",
      "Epoch 371/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.9558e-04 - val_loss: 0.0371 - learning_rate: 3.0903e-04\n",
      "Epoch 372/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 8.0106e-04\n",
      "Epoch 372: ReduceLROnPlateau reducing learning rate to 0.00027812838961835954.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.8593e-04 - val_loss: 0.0359 - learning_rate: 3.0903e-04\n",
      "Epoch 373/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.0172e-04 - val_loss: 0.0364 - learning_rate: 2.7813e-04\n",
      "Epoch 374/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.6723e-04 - val_loss: 0.0353 - learning_rate: 2.7813e-04\n",
      "Epoch 375/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.3627e-04 - val_loss: 0.0372 - learning_rate: 2.7813e-04\n",
      "Epoch 376/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.6585e-04 - val_loss: 0.0344 - learning_rate: 2.7813e-04\n",
      "Epoch 377/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.6418e-04 - val_loss: 0.0362 - learning_rate: 2.7813e-04\n",
      "Epoch 378/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.8652e-04 - val_loss: 0.0365 - learning_rate: 2.7813e-04\n",
      "Epoch 379/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.8395e-04 - val_loss: 0.0369 - learning_rate: 2.7813e-04\n",
      "Epoch 380/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.6955e-04 - val_loss: 0.0376 - learning_rate: 2.7813e-04\n",
      "Epoch 381/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.2608e-04 - val_loss: 0.0374 - learning_rate: 2.7813e-04\n",
      "Epoch 382/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.6617e-04\n",
      "Epoch 382: ReduceLROnPlateau reducing learning rate to 0.00025031555851455777.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.6083e-04 - val_loss: 0.0370 - learning_rate: 2.7813e-04\n",
      "Epoch 383/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 8.1088e-04 - val_loss: 0.0369 - learning_rate: 2.5032e-04\n",
      "Epoch 384/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 7.5440e-04 - val_loss: 0.0373 - learning_rate: 2.5032e-04\n",
      "Epoch 385/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 9.1154e-04 - val_loss: 0.0371 - learning_rate: 2.5032e-04\n",
      "Epoch 386/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0010 - val_loss: 0.0366 - learning_rate: 2.5032e-04\n",
      "Epoch 387/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 7.5566e-04 - val_loss: 0.0354 - learning_rate: 2.5032e-04\n",
      "Epoch 388/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.3028e-04 - val_loss: 0.0365 - learning_rate: 2.5032e-04\n",
      "Epoch 389/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.1693e-04 - val_loss: 0.0370 - learning_rate: 2.5032e-04\n",
      "Epoch 390/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.8998e-04 - val_loss: 0.0366 - learning_rate: 2.5032e-04\n",
      "Epoch 391/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.1229e-04 - val_loss: 0.0373 - learning_rate: 2.5032e-04\n",
      "Epoch 392/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.1362e-04\n",
      "Epoch 392: ReduceLROnPlateau reducing learning rate to 0.00022528400004375725.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.1222e-04 - val_loss: 0.0356 - learning_rate: 2.5032e-04\n",
      "Epoch 393/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 8.2548e-04 - val_loss: 0.0366 - learning_rate: 2.2528e-04\n",
      "Epoch 394/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 7.0392e-04 - val_loss: 0.0371 - learning_rate: 2.2528e-04\n",
      "Epoch 395/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 9.4492e-04 - val_loss: 0.0345 - learning_rate: 2.2528e-04\n",
      "Epoch 396/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.3908e-04 - val_loss: 0.0364 - learning_rate: 2.2528e-04\n",
      "Epoch 397/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.7968e-04 - val_loss: 0.0365 - learning_rate: 2.2528e-04\n",
      "Epoch 398/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.2483e-04 - val_loss: 0.0369 - learning_rate: 2.2528e-04\n",
      "Epoch 399/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.9843e-04 - val_loss: 0.0373 - learning_rate: 2.2528e-04\n",
      "Epoch 400/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.8537e-04 - val_loss: 0.0367 - learning_rate: 2.2528e-04\n",
      "Epoch 401/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.0548e-04 - val_loss: 0.0352 - learning_rate: 2.2528e-04\n",
      "Epoch 402/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 9.4313e-04\n",
      "Epoch 402: ReduceLROnPlateau reducing learning rate to 0.000202755605278071.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 9.1239e-04 - val_loss: 0.0347 - learning_rate: 2.2528e-04\n",
      "Epoch 403/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.3538e-04 - val_loss: 0.0366 - learning_rate: 2.0276e-04\n",
      "Epoch 404/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.4163e-04 - val_loss: 0.0346 - learning_rate: 2.0276e-04\n",
      "Epoch 405/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.6742e-04 - val_loss: 0.0369 - learning_rate: 2.0276e-04\n",
      "Epoch 406/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 8.4418e-04 - val_loss: 0.0377 - learning_rate: 2.0276e-04\n",
      "Epoch 407/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 8.2690e-04 - val_loss: 0.0378 - learning_rate: 2.0276e-04\n",
      "Epoch 408/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.0503e-04 - val_loss: 0.0363 - learning_rate: 2.0276e-04\n",
      "Epoch 409/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.8063e-04 - val_loss: 0.0370 - learning_rate: 2.0276e-04\n",
      "Epoch 410/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.6118e-04 - val_loss: 0.0376 - learning_rate: 2.0276e-04\n",
      "Epoch 411/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.4652e-04 - val_loss: 0.0361 - learning_rate: 2.0276e-04\n",
      "Epoch 412/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.7384e-04\n",
      "Epoch 412: ReduceLROnPlateau reducing learning rate to 0.00018248004344059154.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.6505e-04 - val_loss: 0.0357 - learning_rate: 2.0276e-04\n",
      "Epoch 413/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.0977e-04 - val_loss: 0.0380 - learning_rate: 1.8248e-04\n",
      "Epoch 414/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.2782e-04 - val_loss: 0.0357 - learning_rate: 1.8248e-04\n",
      "Epoch 415/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.1420e-04 - val_loss: 0.0357 - learning_rate: 1.8248e-04\n",
      "Epoch 416/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.6145e-04 - val_loss: 0.0377 - learning_rate: 1.8248e-04\n",
      "Epoch 417/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 8.6820e-04 - val_loss: 0.0369 - learning_rate: 1.8248e-04\n",
      "Epoch 418/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 7.7552e-04 - val_loss: 0.0374 - learning_rate: 1.8248e-04\n",
      "Epoch 419/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.9975e-04 - val_loss: 0.0363 - learning_rate: 1.8248e-04\n",
      "Epoch 420/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.3734e-04 - val_loss: 0.0360 - learning_rate: 1.8248e-04\n",
      "Epoch 421/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.8750e-04 - val_loss: 0.0374 - learning_rate: 1.8248e-04\n",
      "Epoch 422/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 8.9365e-04\n",
      "Epoch 422: ReduceLROnPlateau reducing learning rate to 0.00016423203778686004.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 8.7503e-04 - val_loss: 0.0365 - learning_rate: 1.8248e-04\n",
      "Epoch 423/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.4503e-04 - val_loss: 0.0361 - learning_rate: 1.6423e-04\n",
      "Epoch 424/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.8710e-04 - val_loss: 0.0367 - learning_rate: 1.6423e-04\n",
      "Epoch 425/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.6475e-04 - val_loss: 0.0376 - learning_rate: 1.6423e-04\n",
      "Epoch 426/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.2788e-04 - val_loss: 0.0363 - learning_rate: 1.6423e-04\n",
      "Epoch 427/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.6112e-04 - val_loss: 0.0376 - learning_rate: 1.6423e-04\n",
      "Epoch 428/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.6805e-04 - val_loss: 0.0366 - learning_rate: 1.6423e-04\n",
      "Epoch 429/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.6876e-04 - val_loss: 0.0370 - learning_rate: 1.6423e-04\n",
      "Epoch 430/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.6975e-04 - val_loss: 0.0376 - learning_rate: 1.6423e-04\n",
      "Epoch 431/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.2697e-04 - val_loss: 0.0361 - learning_rate: 1.6423e-04\n",
      "Epoch 432/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 8.0282e-04\n",
      "Epoch 432: ReduceLROnPlateau reducing learning rate to 0.00014780883793719113.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.8054e-04 - val_loss: 0.0367 - learning_rate: 1.6423e-04\n",
      "Epoch 433/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.5965e-04 - val_loss: 0.0379 - learning_rate: 1.4781e-04\n",
      "Epoch 434/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.9745e-04 - val_loss: 0.0382 - learning_rate: 1.4781e-04\n",
      "Epoch 435/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 9.2200e-04 - val_loss: 0.0378 - learning_rate: 1.4781e-04\n",
      "Epoch 436/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 9.0943e-04 - val_loss: 0.0371 - learning_rate: 1.4781e-04\n",
      "Epoch 437/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 9.6509e-04 - val_loss: 0.0358 - learning_rate: 1.4781e-04\n",
      "Epoch 438/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.3818e-04 - val_loss: 0.0371 - learning_rate: 1.4781e-04\n",
      "Epoch 439/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.7692e-04 - val_loss: 0.0369 - learning_rate: 1.4781e-04\n",
      "Epoch 440/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.2104e-04 - val_loss: 0.0357 - learning_rate: 1.4781e-04\n",
      "Epoch 441/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.2554e-04 - val_loss: 0.0376 - learning_rate: 1.4781e-04\n",
      "Epoch 442/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.7922e-04\n",
      "Epoch 442: ReduceLROnPlateau reducing learning rate to 0.00013302795414347202.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.6873e-04 - val_loss: 0.0354 - learning_rate: 1.4781e-04\n",
      "Epoch 443/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.4859e-04 - val_loss: 0.0374 - learning_rate: 1.3303e-04\n",
      "Epoch 444/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 6.7475e-04 - val_loss: 0.0369 - learning_rate: 1.3303e-04\n",
      "Epoch 445/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.2957e-04 - val_loss: 0.0365 - learning_rate: 1.3303e-04\n",
      "Epoch 446/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 9.0747e-04 - val_loss: 0.0369 - learning_rate: 1.3303e-04\n",
      "Epoch 447/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.8727e-04 - val_loss: 0.0375 - learning_rate: 1.3303e-04\n",
      "Epoch 448/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.8176e-04 - val_loss: 0.0364 - learning_rate: 1.3303e-04\n",
      "Epoch 449/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.3987e-04 - val_loss: 0.0369 - learning_rate: 1.3303e-04\n",
      "Epoch 450/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.6339e-04 - val_loss: 0.0373 - learning_rate: 1.3303e-04\n",
      "Epoch 451/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.9941e-04 - val_loss: 0.0375 - learning_rate: 1.3303e-04\n",
      "Epoch 452/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.2882e-04\n",
      "Epoch 452: ReduceLROnPlateau reducing learning rate to 0.00011972515349043534.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.2083e-04 - val_loss: 0.0378 - learning_rate: 1.3303e-04\n",
      "Epoch 453/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.2829e-04 - val_loss: 0.0377 - learning_rate: 1.1973e-04\n",
      "Epoch 454/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3608e-04 - val_loss: 0.0372 - learning_rate: 1.1973e-04\n",
      "Epoch 455/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.1993e-04 - val_loss: 0.0356 - learning_rate: 1.1973e-04\n",
      "Epoch 456/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.3165e-04 - val_loss: 0.0374 - learning_rate: 1.1973e-04\n",
      "Epoch 457/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.7461e-04 - val_loss: 0.0362 - learning_rate: 1.1973e-04\n",
      "Epoch 458/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.9880e-04 - val_loss: 0.0368 - learning_rate: 1.1973e-04\n",
      "Epoch 459/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.8034e-04 - val_loss: 0.0358 - learning_rate: 1.1973e-04\n",
      "Epoch 460/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.1271e-04 - val_loss: 0.0368 - learning_rate: 1.1973e-04\n",
      "Epoch 461/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 9.0488e-04 - val_loss: 0.0356 - learning_rate: 1.1973e-04\n",
      "Epoch 462/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.8409e-04\n",
      "Epoch 462: ReduceLROnPlateau reducing learning rate to 0.00010775263945106417.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.7902e-04 - val_loss: 0.0361 - learning_rate: 1.1973e-04\n",
      "Epoch 463/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.7735e-04 - val_loss: 0.0359 - learning_rate: 1.0775e-04\n",
      "Epoch 464/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.0212e-04 - val_loss: 0.0353 - learning_rate: 1.0775e-04\n",
      "Epoch 465/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.1173e-04 - val_loss: 0.0373 - learning_rate: 1.0775e-04\n",
      "Epoch 466/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.6540e-04 - val_loss: 0.0379 - learning_rate: 1.0775e-04\n",
      "Epoch 467/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 9.4923e-04 - val_loss: 0.0357 - learning_rate: 1.0775e-04\n",
      "Epoch 468/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.3044e-04 - val_loss: 0.0362 - learning_rate: 1.0775e-04\n",
      "Epoch 469/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.0871e-04 - val_loss: 0.0369 - learning_rate: 1.0775e-04\n",
      "Epoch 470/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.7079e-04 - val_loss: 0.0363 - learning_rate: 1.0775e-04\n",
      "Epoch 471/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.5782e-04 - val_loss: 0.0377 - learning_rate: 1.0775e-04\n",
      "Epoch 472/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.8072e-04\n",
      "Epoch 472: ReduceLROnPlateau reducing learning rate to 9.697737550595775e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.6693e-04 - val_loss: 0.0373 - learning_rate: 1.0775e-04\n",
      "Epoch 473/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.2254e-04 - val_loss: 0.0370 - learning_rate: 9.6977e-05\n",
      "Epoch 474/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.2781e-04 - val_loss: 0.0375 - learning_rate: 9.6977e-05\n",
      "Epoch 475/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.6125e-04 - val_loss: 0.0358 - learning_rate: 9.6977e-05\n",
      "Epoch 476/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.9449e-04 - val_loss: 0.0357 - learning_rate: 9.6977e-05\n",
      "Epoch 477/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.9374e-04 - val_loss: 0.0365 - learning_rate: 9.6977e-05\n",
      "Epoch 478/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.6664e-04 - val_loss: 0.0368 - learning_rate: 9.6977e-05\n",
      "Epoch 479/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.0799e-04 - val_loss: 0.0365 - learning_rate: 9.6977e-05\n",
      "Epoch 480/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.8513e-04 - val_loss: 0.0372 - learning_rate: 9.6977e-05\n",
      "Epoch 481/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.5907e-04 - val_loss: 0.0368 - learning_rate: 9.6977e-05\n",
      "Epoch 482/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.0589e-04\n",
      "Epoch 482: ReduceLROnPlateau reducing learning rate to 8.727963795536197e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.8884e-04 - val_loss: 0.0354 - learning_rate: 9.6977e-05\n",
      "Epoch 483/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.1749e-04 - val_loss: 0.0375 - learning_rate: 8.7280e-05\n",
      "Epoch 484/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.8968e-04 - val_loss: 0.0367 - learning_rate: 8.7280e-05\n",
      "Epoch 485/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.7683e-04 - val_loss: 0.0361 - learning_rate: 8.7280e-05\n",
      "Epoch 486/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.5862e-04 - val_loss: 0.0345 - learning_rate: 8.7280e-05\n",
      "Epoch 487/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.5794e-04 - val_loss: 0.0368 - learning_rate: 8.7280e-05\n",
      "Epoch 488/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.6662e-04 - val_loss: 0.0370 - learning_rate: 8.7280e-05\n",
      "Epoch 489/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.0430e-04 - val_loss: 0.0366 - learning_rate: 8.7280e-05\n",
      "Epoch 490/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.6469e-04 - val_loss: 0.0371 - learning_rate: 8.7280e-05\n",
      "Epoch 491/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.8837e-04 - val_loss: 0.0392 - learning_rate: 8.7280e-05\n",
      "Epoch 492/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.6367e-04\n",
      "Epoch 492: ReduceLROnPlateau reducing learning rate to 7.85516735049896e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.5826e-04 - val_loss: 0.0360 - learning_rate: 8.7280e-05\n",
      "Epoch 493/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.2814e-04 - val_loss: 0.0363 - learning_rate: 7.8552e-05\n",
      "Epoch 494/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 7.4691e-04 - val_loss: 0.0362 - learning_rate: 7.8552e-05\n",
      "Epoch 495/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.8555e-04 - val_loss: 0.0381 - learning_rate: 7.8552e-05\n",
      "Epoch 496/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8854e-04 - val_loss: 0.0354 - learning_rate: 7.8552e-05\n",
      "Epoch 497/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.6912e-04 - val_loss: 0.0373 - learning_rate: 7.8552e-05\n",
      "Epoch 498/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.9358e-04 - val_loss: 0.0353 - learning_rate: 7.8552e-05\n",
      "Epoch 499/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3284e-04 - val_loss: 0.0359 - learning_rate: 7.8552e-05\n",
      "Epoch 500/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 9.2226e-04 - val_loss: 0.0362 - learning_rate: 7.8552e-05\n",
      "Epoch 501/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.2457e-04 - val_loss: 0.0377 - learning_rate: 7.8552e-05\n",
      "Epoch 502/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.7590e-04\n",
      "Epoch 502: ReduceLROnPlateau reducing learning rate to 7.0696507464163e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.6775e-04 - val_loss: 0.0351 - learning_rate: 7.8552e-05\n",
      "Epoch 503/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.4967e-04 - val_loss: 0.0372 - learning_rate: 7.0697e-05\n",
      "Epoch 504/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.1748e-04 - val_loss: 0.0366 - learning_rate: 7.0697e-05\n",
      "Epoch 505/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.9371e-04 - val_loss: 0.0370 - learning_rate: 7.0697e-05\n",
      "Epoch 506/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.9865e-04 - val_loss: 0.0370 - learning_rate: 7.0697e-05\n",
      "Epoch 507/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.9751e-04 - val_loss: 0.0372 - learning_rate: 7.0697e-05\n",
      "Epoch 508/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.3791e-04 - val_loss: 0.0369 - learning_rate: 7.0697e-05\n",
      "Epoch 509/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.0154e-04 - val_loss: 0.0369 - learning_rate: 7.0697e-05\n",
      "Epoch 510/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 6.7565e-04 - val_loss: 0.0373 - learning_rate: 7.0697e-05\n",
      "Epoch 511/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.5814e-04 - val_loss: 0.0367 - learning_rate: 7.0697e-05\n",
      "Epoch 512/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.7039e-04\n",
      "Epoch 512: ReduceLROnPlateau reducing learning rate to 6.36268567177467e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.6359e-04 - val_loss: 0.0356 - learning_rate: 7.0697e-05\n",
      "Epoch 513/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.7725e-04 - val_loss: 0.0370 - learning_rate: 6.3627e-05\n",
      "Epoch 514/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.6048e-04 - val_loss: 0.0374 - learning_rate: 6.3627e-05\n",
      "Epoch 515/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.1071e-04 - val_loss: 0.0359 - learning_rate: 6.3627e-05\n",
      "Epoch 516/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.7482e-04 - val_loss: 0.0351 - learning_rate: 6.3627e-05\n",
      "Epoch 517/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.8005e-04 - val_loss: 0.0360 - learning_rate: 6.3627e-05\n",
      "Epoch 518/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 6.2381e-04 - val_loss: 0.0377 - learning_rate: 6.3627e-05\n",
      "Epoch 519/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0712e-04 - val_loss: 0.0378 - learning_rate: 6.3627e-05\n",
      "Epoch 520/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.7240e-04 - val_loss: 0.0362 - learning_rate: 6.3627e-05\n",
      "Epoch 521/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0755e-04 - val_loss: 0.0377 - learning_rate: 6.3627e-05\n",
      "Epoch 522/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.1437e-04\n",
      "Epoch 522: ReduceLROnPlateau reducing learning rate to 5.726417366531678e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.1155e-04 - val_loss: 0.0352 - learning_rate: 6.3627e-05\n",
      "Epoch 523/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3243e-04 - val_loss: 0.0366 - learning_rate: 5.7264e-05\n",
      "Epoch 524/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.1066e-04 - val_loss: 0.0359 - learning_rate: 5.7264e-05\n",
      "Epoch 525/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8683e-04 - val_loss: 0.0378 - learning_rate: 5.7264e-05\n",
      "Epoch 526/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3482e-04 - val_loss: 0.0379 - learning_rate: 5.7264e-05\n",
      "Epoch 527/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.6604e-04 - val_loss: 0.0358 - learning_rate: 5.7264e-05\n",
      "Epoch 528/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.8224e-04 - val_loss: 0.0360 - learning_rate: 5.7264e-05\n",
      "Epoch 529/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.7430e-04 - val_loss: 0.0356 - learning_rate: 5.7264e-05\n",
      "Epoch 530/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.4757e-04 - val_loss: 0.0361 - learning_rate: 5.7264e-05\n",
      "Epoch 531/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.1699e-04 - val_loss: 0.0365 - learning_rate: 5.7264e-05\n",
      "Epoch 532/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.5845e-04\n",
      "Epoch 532: ReduceLROnPlateau reducing learning rate to 5.1537755643948914e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.5189e-04 - val_loss: 0.0375 - learning_rate: 5.7264e-05\n",
      "Epoch 533/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.8530e-04 - val_loss: 0.0365 - learning_rate: 5.1538e-05\n",
      "Epoch 534/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.1579e-04 - val_loss: 0.0371 - learning_rate: 5.1538e-05\n",
      "Epoch 535/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.9121e-04 - val_loss: 0.0372 - learning_rate: 5.1538e-05\n",
      "Epoch 536/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.5691e-04 - val_loss: 0.0381 - learning_rate: 5.1538e-05\n",
      "Epoch 537/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0378e-04 - val_loss: 0.0359 - learning_rate: 5.1538e-05\n",
      "Epoch 538/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.8432e-04 - val_loss: 0.0354 - learning_rate: 5.1538e-05\n",
      "Epoch 539/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.2340e-04 - val_loss: 0.0358 - learning_rate: 5.1538e-05\n",
      "Epoch 540/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.8097e-04 - val_loss: 0.0371 - learning_rate: 5.1538e-05\n",
      "Epoch 541/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 7.1941e-04 - val_loss: 0.0361 - learning_rate: 5.1538e-05\n",
      "Epoch 542/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.4527e-04\n",
      "Epoch 542: ReduceLROnPlateau reducing learning rate to 4.638397876988165e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.4050e-04 - val_loss: 0.0371 - learning_rate: 5.1538e-05\n",
      "Epoch 543/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.2488e-04 - val_loss: 0.0369 - learning_rate: 4.6384e-05\n",
      "Epoch 544/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.7000e-04 - val_loss: 0.0370 - learning_rate: 4.6384e-05\n",
      "Epoch 545/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.1702e-04 - val_loss: 0.0348 - learning_rate: 4.6384e-05\n",
      "Epoch 546/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.9025e-04 - val_loss: 0.0365 - learning_rate: 4.6384e-05\n",
      "Epoch 547/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.5107e-04 - val_loss: 0.0367 - learning_rate: 4.6384e-05\n",
      "Epoch 548/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.1543e-04 - val_loss: 0.0371 - learning_rate: 4.6384e-05\n",
      "Epoch 549/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.9474e-04 - val_loss: 0.0375 - learning_rate: 4.6384e-05\n",
      "Epoch 550/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.3846e-04 - val_loss: 0.0371 - learning_rate: 4.6384e-05\n",
      "Epoch 551/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.3726e-04 - val_loss: 0.0371 - learning_rate: 4.6384e-05\n",
      "Epoch 552/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.3145e-04\n",
      "Epoch 552: ReduceLROnPlateau reducing learning rate to 4.174558089289349e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 6.1836e-04 - val_loss: 0.0367 - learning_rate: 4.6384e-05\n",
      "Epoch 553/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.6398e-04 - val_loss: 0.0379 - learning_rate: 4.1746e-05\n",
      "Epoch 554/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.4496e-04 - val_loss: 0.0364 - learning_rate: 4.1746e-05\n",
      "Epoch 555/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.1020e-04 - val_loss: 0.0366 - learning_rate: 4.1746e-05\n",
      "Epoch 556/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.2660e-04 - val_loss: 0.0366 - learning_rate: 4.1746e-05\n",
      "Epoch 557/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.8496e-04 - val_loss: 0.0376 - learning_rate: 4.1746e-05\n",
      "Epoch 558/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.1554e-04 - val_loss: 0.0371 - learning_rate: 4.1746e-05\n",
      "Epoch 559/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.9593e-04 - val_loss: 0.0358 - learning_rate: 4.1746e-05\n",
      "Epoch 560/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.6155e-04 - val_loss: 0.0359 - learning_rate: 4.1746e-05\n",
      "Epoch 561/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 5.4007e-04 - val_loss: 0.0381 - learning_rate: 4.1746e-05\n",
      "Epoch 562/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.1065e-04\n",
      "Epoch 562: ReduceLROnPlateau reducing learning rate to 3.7571023131022234e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.1636e-04 - val_loss: 0.0361 - learning_rate: 4.1746e-05\n",
      "Epoch 563/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.2511e-04 - val_loss: 0.0366 - learning_rate: 3.7571e-05\n",
      "Epoch 564/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.5669e-04 - val_loss: 0.0377 - learning_rate: 3.7571e-05\n",
      "Epoch 565/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.7302e-04 - val_loss: 0.0361 - learning_rate: 3.7571e-05\n",
      "Epoch 566/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.5430e-04 - val_loss: 0.0371 - learning_rate: 3.7571e-05\n",
      "Epoch 567/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.6723e-04 - val_loss: 0.0365 - learning_rate: 3.7571e-05\n",
      "Epoch 568/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.9931e-04 - val_loss: 0.0376 - learning_rate: 3.7571e-05\n",
      "Epoch 569/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 7.0499e-04 - val_loss: 0.0362 - learning_rate: 3.7571e-05\n",
      "Epoch 570/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.7214e-04 - val_loss: 0.0361 - learning_rate: 3.7571e-05\n",
      "Epoch 571/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.5918e-04 - val_loss: 0.0369 - learning_rate: 3.7571e-05\n",
      "Epoch 572/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.0745e-04\n",
      "Epoch 572: ReduceLROnPlateau reducing learning rate to 3.381392016308382e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.1200e-04 - val_loss: 0.0341 - learning_rate: 3.7571e-05\n",
      "Epoch 573/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.6844e-04 - val_loss: 0.0367 - learning_rate: 3.3814e-05\n",
      "Epoch 574/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.1359e-04 - val_loss: 0.0367 - learning_rate: 3.3814e-05\n",
      "Epoch 575/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.6255e-04 - val_loss: 0.0371 - learning_rate: 3.3814e-05\n",
      "Epoch 576/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.1579e-04 - val_loss: 0.0364 - learning_rate: 3.3814e-05\n",
      "Epoch 577/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.4806e-04 - val_loss: 0.0383 - learning_rate: 3.3814e-05\n",
      "Epoch 578/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3741e-04 - val_loss: 0.0352 - learning_rate: 3.3814e-05\n",
      "Epoch 579/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.9396e-04 - val_loss: 0.0373 - learning_rate: 3.3814e-05\n",
      "Epoch 580/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.1328e-04 - val_loss: 0.0362 - learning_rate: 3.3814e-05\n",
      "Epoch 581/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.8550e-04 - val_loss: 0.0371 - learning_rate: 3.3814e-05\n",
      "Epoch 582/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.1095e-04\n",
      "Epoch 582: ReduceLROnPlateau reducing learning rate to 3.043252945644781e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 5.9883e-04 - val_loss: 0.0361 - learning_rate: 3.3814e-05\n",
      "Epoch 583/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.5769e-04 - val_loss: 0.0358 - learning_rate: 3.0433e-05\n",
      "Epoch 584/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.6728e-04 - val_loss: 0.0356 - learning_rate: 3.0433e-05\n",
      "Epoch 585/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.8111e-04 - val_loss: 0.0375 - learning_rate: 3.0433e-05\n",
      "Epoch 586/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.3139e-04 - val_loss: 0.0373 - learning_rate: 3.0433e-05\n",
      "Epoch 587/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3713e-04 - val_loss: 0.0359 - learning_rate: 3.0433e-05\n",
      "Epoch 588/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3739e-04 - val_loss: 0.0383 - learning_rate: 3.0433e-05\n",
      "Epoch 589/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.5700e-04 - val_loss: 0.0365 - learning_rate: 3.0433e-05\n",
      "Epoch 590/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.6038e-04 - val_loss: 0.0358 - learning_rate: 3.0433e-05\n",
      "Epoch 591/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3306e-04 - val_loss: 0.0376 - learning_rate: 3.0433e-05\n",
      "Epoch 592/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.8328e-04\n",
      "Epoch 592: ReduceLROnPlateau reducing learning rate to 2.738927651080303e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.5786e-04 - val_loss: 0.0370 - learning_rate: 3.0433e-05\n",
      "Epoch 593/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.4469e-04 - val_loss: 0.0355 - learning_rate: 2.7389e-05\n",
      "Epoch 594/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.5453e-04 - val_loss: 0.0390 - learning_rate: 2.7389e-05\n",
      "Epoch 595/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.8242e-04 - val_loss: 0.0381 - learning_rate: 2.7389e-05\n",
      "Epoch 596/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.0084e-04 - val_loss: 0.0384 - learning_rate: 2.7389e-05\n",
      "Epoch 597/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.3267e-04 - val_loss: 0.0366 - learning_rate: 2.7389e-05\n",
      "Epoch 598/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.7247e-04 - val_loss: 0.0371 - learning_rate: 2.7389e-05\n",
      "Epoch 599/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.7886e-04 - val_loss: 0.0371 - learning_rate: 2.7389e-05\n",
      "Epoch 600/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.8409e-04 - val_loss: 0.0383 - learning_rate: 2.7389e-05\n",
      "Epoch 601/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.9276e-04 - val_loss: 0.0367 - learning_rate: 2.7389e-05\n",
      "Epoch 602/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.6624e-04\n",
      "Epoch 602: ReduceLROnPlateau reducing learning rate to 2.4650348859722725e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.6712e-04 - val_loss: 0.0364 - learning_rate: 2.7389e-05\n",
      "Epoch 603/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.5807e-04 - val_loss: 0.0374 - learning_rate: 2.4650e-05\n",
      "Epoch 604/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.6570e-04 - val_loss: 0.0362 - learning_rate: 2.4650e-05\n",
      "Epoch 605/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.2562e-04 - val_loss: 0.0369 - learning_rate: 2.4650e-05\n",
      "Epoch 606/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.6624e-04 - val_loss: 0.0369 - learning_rate: 2.4650e-05\n",
      "Epoch 607/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.8132e-04 - val_loss: 0.0370 - learning_rate: 2.4650e-05\n",
      "Epoch 608/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8840e-04 - val_loss: 0.0358 - learning_rate: 2.4650e-05\n",
      "Epoch 609/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0409e-04 - val_loss: 0.0374 - learning_rate: 2.4650e-05\n",
      "Epoch 610/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.6671e-04 - val_loss: 0.0377 - learning_rate: 2.4650e-05\n",
      "Epoch 611/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.9509e-04 - val_loss: 0.0352 - learning_rate: 2.4650e-05\n",
      "Epoch 612/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.3407e-04\n",
      "Epoch 612: ReduceLROnPlateau reducing learning rate to 2.218531462858664e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3041e-04 - val_loss: 0.0376 - learning_rate: 2.4650e-05\n",
      "Epoch 613/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.9720e-04 - val_loss: 0.0378 - learning_rate: 2.2185e-05\n",
      "Epoch 614/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.9959e-04 - val_loss: 0.0349 - learning_rate: 2.2185e-05\n",
      "Epoch 615/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.2433e-04 - val_loss: 0.0356 - learning_rate: 2.2185e-05\n",
      "Epoch 616/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.7907e-04 - val_loss: 0.0383 - learning_rate: 2.2185e-05\n",
      "Epoch 617/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.1979e-04 - val_loss: 0.0362 - learning_rate: 2.2185e-05\n",
      "Epoch 618/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.3681e-04 - val_loss: 0.0382 - learning_rate: 2.2185e-05\n",
      "Epoch 619/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.3101e-04 - val_loss: 0.0363 - learning_rate: 2.2185e-05\n",
      "Epoch 620/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 5.7280e-04 - val_loss: 0.0353 - learning_rate: 2.2185e-05\n",
      "Epoch 621/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8231e-04 - val_loss: 0.0375 - learning_rate: 2.2185e-05\n",
      "Epoch 622/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.0798e-04\n",
      "Epoch 622: ReduceLROnPlateau reducing learning rate to 1.9966783656855114e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 6.0529e-04 - val_loss: 0.0384 - learning_rate: 2.2185e-05\n",
      "Epoch 623/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.8662e-04 - val_loss: 0.0369 - learning_rate: 1.9967e-05\n",
      "Epoch 624/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.3504e-04 - val_loss: 0.0366 - learning_rate: 1.9967e-05\n",
      "Epoch 625/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.6748e-04 - val_loss: 0.0368 - learning_rate: 1.9967e-05\n",
      "Epoch 626/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.4058e-04 - val_loss: 0.0369 - learning_rate: 1.9967e-05\n",
      "Epoch 627/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0230e-04 - val_loss: 0.0364 - learning_rate: 1.9967e-05\n",
      "Epoch 628/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3016e-04 - val_loss: 0.0360 - learning_rate: 1.9967e-05\n",
      "Epoch 629/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.0245e-04 - val_loss: 0.0363 - learning_rate: 1.9967e-05\n",
      "Epoch 630/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.9596e-04 - val_loss: 0.0369 - learning_rate: 1.9967e-05\n",
      "Epoch 631/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.6880e-04 - val_loss: 0.0373 - learning_rate: 1.9967e-05\n",
      "Epoch 632/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.0261e-04\n",
      "Epoch 632: ReduceLROnPlateau reducing learning rate to 1.7970104636333417e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.9916e-04 - val_loss: 0.0385 - learning_rate: 1.9967e-05\n",
      "Epoch 633/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3094e-04 - val_loss: 0.0382 - learning_rate: 1.7970e-05\n",
      "Epoch 634/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8117e-04 - val_loss: 0.0382 - learning_rate: 1.7970e-05\n",
      "Epoch 635/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.8969e-04 - val_loss: 0.0377 - learning_rate: 1.7970e-05\n",
      "Epoch 636/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3038e-04 - val_loss: 0.0377 - learning_rate: 1.7970e-05\n",
      "Epoch 637/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.5806e-04 - val_loss: 0.0364 - learning_rate: 1.7970e-05\n",
      "Epoch 638/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.5779e-04 - val_loss: 0.0377 - learning_rate: 1.7970e-05\n",
      "Epoch 639/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.7766e-04 - val_loss: 0.0358 - learning_rate: 1.7970e-05\n",
      "Epoch 640/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.4387e-04 - val_loss: 0.0359 - learning_rate: 1.7970e-05\n",
      "Epoch 641/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8215e-04 - val_loss: 0.0369 - learning_rate: 1.7970e-05\n",
      "Epoch 642/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.6764e-04\n",
      "Epoch 642: ReduceLROnPlateau reducing learning rate to 1.6173094991245307e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.5222e-04 - val_loss: 0.0362 - learning_rate: 1.7970e-05\n",
      "Epoch 643/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3157e-04 - val_loss: 0.0365 - learning_rate: 1.6173e-05\n",
      "Epoch 644/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8471e-04 - val_loss: 0.0358 - learning_rate: 1.6173e-05\n",
      "Epoch 645/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0042e-04 - val_loss: 0.0375 - learning_rate: 1.6173e-05\n",
      "Epoch 646/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.9965e-04 - val_loss: 0.0393 - learning_rate: 1.6173e-05\n",
      "Epoch 647/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.3977e-04 - val_loss: 0.0377 - learning_rate: 1.6173e-05\n",
      "Epoch 648/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.8304e-04 - val_loss: 0.0374 - learning_rate: 1.6173e-05\n",
      "Epoch 649/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.7165e-04 - val_loss: 0.0364 - learning_rate: 1.6173e-05\n",
      "Epoch 650/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.3536e-04 - val_loss: 0.0352 - learning_rate: 1.6173e-05\n",
      "Epoch 651/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8885e-04 - val_loss: 0.0375 - learning_rate: 1.6173e-05\n",
      "Epoch 652/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.9005e-04\n",
      "Epoch 652: ReduceLROnPlateau reducing learning rate to 1.4555785492120777e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.7887e-04 - val_loss: 0.0363 - learning_rate: 1.6173e-05\n",
      "Epoch 653/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.5649e-04 - val_loss: 0.0374 - learning_rate: 1.4556e-05\n",
      "Epoch 654/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0711e-04 - val_loss: 0.0358 - learning_rate: 1.4556e-05\n",
      "Epoch 655/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.4739e-04 - val_loss: 0.0372 - learning_rate: 1.4556e-05\n",
      "Epoch 656/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0591e-04 - val_loss: 0.0373 - learning_rate: 1.4556e-05\n",
      "Epoch 657/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8665e-04 - val_loss: 0.0378 - learning_rate: 1.4556e-05\n",
      "Epoch 658/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 8.7010e-04 - val_loss: 0.0354 - learning_rate: 1.4556e-05\n",
      "Epoch 659/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.0027e-04 - val_loss: 0.0365 - learning_rate: 1.4556e-05\n",
      "Epoch 660/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8197e-04 - val_loss: 0.0362 - learning_rate: 1.4556e-05\n",
      "Epoch 661/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.2955e-04 - val_loss: 0.0363 - learning_rate: 1.4556e-05\n",
      "Epoch 662/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.5414e-04\n",
      "Epoch 662: ReduceLROnPlateau reducing learning rate to 1.3100206615490606e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.6149e-04 - val_loss: 0.0366 - learning_rate: 1.4556e-05\n",
      "Epoch 663/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.1265e-04 - val_loss: 0.0365 - learning_rate: 1.3100e-05\n",
      "Epoch 664/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.4341e-04 - val_loss: 0.0375 - learning_rate: 1.3100e-05\n",
      "Epoch 665/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.9078e-04 - val_loss: 0.0370 - learning_rate: 1.3100e-05\n",
      "Epoch 666/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.7461e-04 - val_loss: 0.0365 - learning_rate: 1.3100e-05\n",
      "Epoch 667/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3924e-04 - val_loss: 0.0364 - learning_rate: 1.3100e-05\n",
      "Epoch 668/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.1269e-04 - val_loss: 0.0347 - learning_rate: 1.3100e-05\n",
      "Epoch 669/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.0761e-04 - val_loss: 0.0384 - learning_rate: 1.3100e-05\n",
      "Epoch 670/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.5665e-04 - val_loss: 0.0367 - learning_rate: 1.3100e-05\n",
      "Epoch 671/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.6104e-04 - val_loss: 0.0370 - learning_rate: 1.3100e-05\n",
      "Epoch 672/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.6966e-04\n",
      "Epoch 672: ReduceLROnPlateau reducing learning rate to 1.1790186363214161e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.6087e-04 - val_loss: 0.0349 - learning_rate: 1.3100e-05\n",
      "Epoch 673/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.6866e-04 - val_loss: 0.0379 - learning_rate: 1.1790e-05\n",
      "Epoch 674/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.4185e-04 - val_loss: 0.0372 - learning_rate: 1.1790e-05\n",
      "Epoch 675/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.7677e-04 - val_loss: 0.0355 - learning_rate: 1.1790e-05\n",
      "Epoch 676/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.1804e-04 - val_loss: 0.0372 - learning_rate: 1.1790e-05\n",
      "Epoch 677/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.6686e-04 - val_loss: 0.0356 - learning_rate: 1.1790e-05\n",
      "Epoch 678/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.6476e-04 - val_loss: 0.0371 - learning_rate: 1.1790e-05\n",
      "Epoch 679/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.2314e-04 - val_loss: 0.0379 - learning_rate: 1.1790e-05\n",
      "Epoch 680/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.8520e-04 - val_loss: 0.0368 - learning_rate: 1.1790e-05\n",
      "Epoch 681/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.9254e-04 - val_loss: 0.0368 - learning_rate: 1.1790e-05\n",
      "Epoch 682/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 8.0951e-04\n",
      "Epoch 682: ReduceLROnPlateau reducing learning rate to 1.0611167726892746e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 7.9614e-04 - val_loss: 0.0383 - learning_rate: 1.1790e-05\n",
      "Epoch 683/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 5.9509e-04 - val_loss: 0.0354 - learning_rate: 1.0611e-05\n",
      "Epoch 684/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 16:27:58.781506: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.6076e-04 - val_loss: 0.0370 - learning_rate: 1.0611e-05\n",
      "Epoch 685/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.5334e-04 - val_loss: 0.0373 - learning_rate: 1.0611e-05\n",
      "Epoch 686/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.3807e-04 - val_loss: 0.0375 - learning_rate: 1.0611e-05\n",
      "Epoch 687/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8772e-04 - val_loss: 0.0387 - learning_rate: 1.0611e-05\n",
      "Epoch 688/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.5364e-04 - val_loss: 0.0364 - learning_rate: 1.0611e-05\n",
      "Epoch 689/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0545e-04 - val_loss: 0.0379 - learning_rate: 1.0611e-05\n",
      "Epoch 690/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0612e-04 - val_loss: 0.0359 - learning_rate: 1.0611e-05\n",
      "Epoch 691/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.1093e-04 - val_loss: 0.0372 - learning_rate: 1.0611e-05\n",
      "Epoch 692/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.6276e-04\n",
      "Epoch 692: ReduceLROnPlateau reducing learning rate to 9.550050708639902e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.3786e-04 - val_loss: 0.0390 - learning_rate: 1.0611e-05\n",
      "Epoch 693/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.5589e-04 - val_loss: 0.0364 - learning_rate: 9.5501e-06\n",
      "Epoch 694/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.9899e-04 - val_loss: 0.0362 - learning_rate: 9.5501e-06\n",
      "Epoch 695/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.3593e-04 - val_loss: 0.0367 - learning_rate: 9.5501e-06\n",
      "Epoch 696/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.7497e-04 - val_loss: 0.0369 - learning_rate: 9.5501e-06\n",
      "Epoch 697/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.3047e-04 - val_loss: 0.0367 - learning_rate: 9.5501e-06\n",
      "Epoch 698/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.8224e-04 - val_loss: 0.0372 - learning_rate: 9.5501e-06\n",
      "Epoch 699/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.5755e-04 - val_loss: 0.0364 - learning_rate: 9.5501e-06\n",
      "Epoch 700/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.5606e-04 - val_loss: 0.0367 - learning_rate: 9.5501e-06\n",
      "Epoch 701/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.9790e-04 - val_loss: 0.0362 - learning_rate: 9.5501e-06\n",
      "Epoch 702/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.8149e-04\n",
      "Epoch 702: ReduceLROnPlateau reducing learning rate to 8.595045801484958e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.7802e-04 - val_loss: 0.0373 - learning_rate: 9.5501e-06\n",
      "Epoch 703/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.1596e-04 - val_loss: 0.0373 - learning_rate: 8.5950e-06\n",
      "Epoch 704/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 5.8850e-04 - val_loss: 0.0357 - learning_rate: 8.5950e-06\n",
      "Epoch 705/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.5933e-04 - val_loss: 0.0378 - learning_rate: 8.5950e-06\n",
      "Epoch 706/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3405e-04 - val_loss: 0.0376 - learning_rate: 8.5950e-06\n",
      "Epoch 707/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.6828e-04 - val_loss: 0.0369 - learning_rate: 8.5950e-06\n",
      "Epoch 708/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.9527e-04 - val_loss: 0.0368 - learning_rate: 8.5950e-06\n",
      "Epoch 709/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.7154e-04 - val_loss: 0.0379 - learning_rate: 8.5950e-06\n",
      "Epoch 710/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.7249e-04 - val_loss: 0.0388 - learning_rate: 8.5950e-06\n",
      "Epoch 711/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.2340e-04 - val_loss: 0.0375 - learning_rate: 8.5950e-06\n",
      "Epoch 712/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.9346e-04\n",
      "Epoch 712: ReduceLROnPlateau reducing learning rate to 7.735541385045509e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8191e-04 - val_loss: 0.0380 - learning_rate: 8.5950e-06\n",
      "Epoch 713/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.4853e-04 - val_loss: 0.0383 - learning_rate: 7.7355e-06\n",
      "Epoch 714/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.4309e-04 - val_loss: 0.0366 - learning_rate: 7.7355e-06\n",
      "Epoch 715/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.8435e-04 - val_loss: 0.0361 - learning_rate: 7.7355e-06\n",
      "Epoch 716/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.1158e-04 - val_loss: 0.0371 - learning_rate: 7.7355e-06\n",
      "Epoch 717/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.3706e-04 - val_loss: 0.0387 - learning_rate: 7.7355e-06\n",
      "Epoch 718/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.7564e-04 - val_loss: 0.0370 - learning_rate: 7.7355e-06\n",
      "Epoch 719/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.5166e-04 - val_loss: 0.0389 - learning_rate: 7.7355e-06\n",
      "Epoch 720/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.4013e-04 - val_loss: 0.0364 - learning_rate: 7.7355e-06\n",
      "Epoch 721/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.9347e-04 - val_loss: 0.0378 - learning_rate: 7.7355e-06\n",
      "Epoch 722/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.0209e-04\n",
      "Epoch 722: ReduceLROnPlateau reducing learning rate to 6.961987492104527e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8909e-04 - val_loss: 0.0368 - learning_rate: 7.7355e-06\n",
      "Epoch 723/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 6.4232e-04 - val_loss: 0.0365 - learning_rate: 6.9620e-06\n",
      "Epoch 724/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 6.6756e-04 - val_loss: 0.0356 - learning_rate: 6.9620e-06\n",
      "Epoch 725/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.0975e-04 - val_loss: 0.0366 - learning_rate: 6.9620e-06\n",
      "Epoch 726/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.3668e-04 - val_loss: 0.0374 - learning_rate: 6.9620e-06\n",
      "Epoch 727/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.7910e-04 - val_loss: 0.0372 - learning_rate: 6.9620e-06\n",
      "Epoch 728/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.4991e-04 - val_loss: 0.0370 - learning_rate: 6.9620e-06\n",
      "Epoch 729/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.4457e-04 - val_loss: 0.0368 - learning_rate: 6.9620e-06\n",
      "Epoch 730/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.0239e-04 - val_loss: 0.0356 - learning_rate: 6.9620e-06\n",
      "Epoch 731/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8430e-04 - val_loss: 0.0363 - learning_rate: 6.9620e-06\n",
      "Epoch 732/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.3676e-04\n",
      "Epoch 732: ReduceLROnPlateau reducing learning rate to 6.265788579185028e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.2966e-04 - val_loss: 0.0381 - learning_rate: 6.9620e-06\n",
      "Epoch 733/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.6654e-04 - val_loss: 0.0361 - learning_rate: 6.2658e-06\n",
      "Epoch 734/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.7977e-04 - val_loss: 0.0365 - learning_rate: 6.2658e-06\n",
      "Epoch 735/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.4894e-04 - val_loss: 0.0377 - learning_rate: 6.2658e-06\n",
      "Epoch 736/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.6728e-04 - val_loss: 0.0356 - learning_rate: 6.2658e-06\n",
      "Epoch 737/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.6850e-04 - val_loss: 0.0361 - learning_rate: 6.2658e-06\n",
      "Epoch 738/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 5.5763e-04 - val_loss: 0.0384 - learning_rate: 6.2658e-06\n",
      "Epoch 739/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.4000e-04 - val_loss: 0.0364 - learning_rate: 6.2658e-06\n",
      "Epoch 740/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 7.7373e-04 - val_loss: 0.0358 - learning_rate: 6.2658e-06\n",
      "Epoch 741/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0751e-04 - val_loss: 0.0380 - learning_rate: 6.2658e-06\n",
      "Epoch 742/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.1833e-04\n",
      "Epoch 742: ReduceLROnPlateau reducing learning rate to 5.639209803121048e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.9649e-04 - val_loss: 0.0375 - learning_rate: 6.2658e-06\n",
      "Epoch 743/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.9155e-04 - val_loss: 0.0368 - learning_rate: 5.6392e-06\n",
      "Epoch 744/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.1786e-04 - val_loss: 0.0382 - learning_rate: 5.6392e-06\n",
      "Epoch 745/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.5541e-04 - val_loss: 0.0359 - learning_rate: 5.6392e-06\n",
      "Epoch 746/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 5.8483e-04 - val_loss: 0.0357 - learning_rate: 5.6392e-06\n",
      "Epoch 747/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.0866e-04 - val_loss: 0.0366 - learning_rate: 5.6392e-06\n",
      "Epoch 748/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.8473e-04 - val_loss: 0.0378 - learning_rate: 5.6392e-06\n",
      "Epoch 749/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.6107e-04 - val_loss: 0.0382 - learning_rate: 5.6392e-06\n",
      "Epoch 750/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.1832e-04 - val_loss: 0.0350 - learning_rate: 5.6392e-06\n",
      "Epoch 751/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.3915e-04 - val_loss: 0.0377 - learning_rate: 5.6392e-06\n",
      "Epoch 752/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.4324e-04\n",
      "Epoch 752: ReduceLROnPlateau reducing learning rate to 5.075289027445251e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.1990e-04 - val_loss: 0.0381 - learning_rate: 5.6392e-06\n",
      "Epoch 753/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.4506e-04 - val_loss: 0.0359 - learning_rate: 5.0753e-06\n",
      "Epoch 754/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3541e-04 - val_loss: 0.0346 - learning_rate: 5.0753e-06\n",
      "Epoch 755/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 5.6749e-04 - val_loss: 0.0368 - learning_rate: 5.0753e-06\n",
      "Epoch 756/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.2273e-04 - val_loss: 0.0365 - learning_rate: 5.0753e-06\n",
      "Epoch 757/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.5223e-04 - val_loss: 0.0357 - learning_rate: 5.0753e-06\n",
      "Epoch 758/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.6630e-04 - val_loss: 0.0346 - learning_rate: 5.0753e-06\n",
      "Epoch 759/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.7394e-04 - val_loss: 0.0365 - learning_rate: 5.0753e-06\n",
      "Epoch 760/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.2528e-04 - val_loss: 0.0374 - learning_rate: 5.0753e-06\n",
      "Epoch 761/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.6812e-04 - val_loss: 0.0365 - learning_rate: 5.0753e-06\n",
      "Epoch 762/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.3379e-04\n",
      "Epoch 762: ReduceLROnPlateau reducing learning rate to 4.567760288409772e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 5.2674e-04 - val_loss: 0.0358 - learning_rate: 5.0753e-06\n",
      "Epoch 763/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.1139e-04 - val_loss: 0.0361 - learning_rate: 4.5678e-06\n",
      "Epoch 764/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.4705e-04 - val_loss: 0.0376 - learning_rate: 4.5678e-06\n",
      "Epoch 765/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 9.2556e-04 - val_loss: 0.0381 - learning_rate: 4.5678e-06\n",
      "Epoch 766/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0683e-04 - val_loss: 0.0379 - learning_rate: 4.5678e-06\n",
      "Epoch 767/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8004e-04 - val_loss: 0.0383 - learning_rate: 4.5678e-06\n",
      "Epoch 768/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.1565e-04 - val_loss: 0.0383 - learning_rate: 4.5678e-06\n",
      "Epoch 769/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.2979e-04 - val_loss: 0.0374 - learning_rate: 4.5678e-06\n",
      "Epoch 770/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0894e-04 - val_loss: 0.0359 - learning_rate: 4.5678e-06\n",
      "Epoch 771/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.4937e-04 - val_loss: 0.0371 - learning_rate: 4.5678e-06\n",
      "Epoch 772/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.7169e-04\n",
      "Epoch 772: ReduceLROnPlateau reducing learning rate to 4.110984218641534e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.6259e-04 - val_loss: 0.0382 - learning_rate: 4.5678e-06\n",
      "Epoch 773/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 7.2690e-04 - val_loss: 0.0387 - learning_rate: 4.1110e-06\n",
      "Epoch 774/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.3326e-04 - val_loss: 0.0391 - learning_rate: 4.1110e-06\n",
      "Epoch 775/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.7390e-04 - val_loss: 0.0382 - learning_rate: 4.1110e-06\n",
      "Epoch 776/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.3833e-04 - val_loss: 0.0351 - learning_rate: 4.1110e-06\n",
      "Epoch 777/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.6230e-04 - val_loss: 0.0392 - learning_rate: 4.1110e-06\n",
      "Epoch 778/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0479e-04 - val_loss: 0.0375 - learning_rate: 4.1110e-06\n",
      "Epoch 779/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.2644e-04 - val_loss: 0.0371 - learning_rate: 4.1110e-06\n",
      "Epoch 780/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 8.0336e-04 - val_loss: 0.0371 - learning_rate: 4.1110e-06\n",
      "Epoch 781/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 6.9914e-04 - val_loss: 0.0379 - learning_rate: 4.1110e-06\n",
      "Epoch 782/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.2734e-04\n",
      "Epoch 782: ReduceLROnPlateau reducing learning rate to 3.6998858377046417e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.2149e-04 - val_loss: 0.0380 - learning_rate: 4.1110e-06\n",
      "Epoch 783/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.6843e-04 - val_loss: 0.0372 - learning_rate: 3.6999e-06\n",
      "Epoch 784/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 7.4864e-04 - val_loss: 0.0359 - learning_rate: 3.6999e-06\n",
      "Epoch 785/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.4353e-04 - val_loss: 0.0369 - learning_rate: 3.6999e-06\n",
      "Epoch 786/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.7899e-04 - val_loss: 0.0385 - learning_rate: 3.6999e-06\n",
      "Epoch 787/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.7646e-04 - val_loss: 0.0395 - learning_rate: 3.6999e-06\n",
      "Epoch 788/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.2050e-04 - val_loss: 0.0366 - learning_rate: 3.6999e-06\n",
      "Epoch 789/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.8183e-04 - val_loss: 0.0358 - learning_rate: 3.6999e-06\n",
      "Epoch 790/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3218e-04 - val_loss: 0.0375 - learning_rate: 3.6999e-06\n",
      "Epoch 791/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.5600e-04 - val_loss: 0.0369 - learning_rate: 3.6999e-06\n",
      "Epoch 792/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.5938e-04\n",
      "Epoch 792: ReduceLROnPlateau reducing learning rate to 3.3298972539341776e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.4888e-04 - val_loss: 0.0372 - learning_rate: 3.6999e-06\n",
      "Epoch 793/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3118e-04 - val_loss: 0.0366 - learning_rate: 3.3299e-06\n",
      "Epoch 794/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.5143e-04 - val_loss: 0.0386 - learning_rate: 3.3299e-06\n",
      "Epoch 795/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.1415e-04 - val_loss: 0.0356 - learning_rate: 3.3299e-06\n",
      "Epoch 796/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.8183e-04 - val_loss: 0.0375 - learning_rate: 3.3299e-06\n",
      "Epoch 797/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.3663e-04 - val_loss: 0.0349 - learning_rate: 3.3299e-06\n",
      "Epoch 798/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.4343e-04 - val_loss: 0.0382 - learning_rate: 3.3299e-06\n",
      "Epoch 799/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.6493e-04 - val_loss: 0.0376 - learning_rate: 3.3299e-06\n",
      "Epoch 800/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.5856e-04 - val_loss: 0.0362 - learning_rate: 3.3299e-06\n",
      "Epoch 801/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.3758e-04 - val_loss: 0.0368 - learning_rate: 3.3299e-06\n",
      "Epoch 802/1000\n",
      "\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.4478e-04\n",
      "Epoch 802: ReduceLROnPlateau reducing learning rate to 3e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.2090e-04 - val_loss: 0.0380 - learning_rate: 3.3299e-06\n",
      "Epoch 803/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0837e-04 - val_loss: 0.0363 - learning_rate: 3.0000e-06\n",
      "Epoch 804/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0956e-04 - val_loss: 0.0365 - learning_rate: 3.0000e-06\n",
      "Epoch 805/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.6913e-04 - val_loss: 0.0386 - learning_rate: 3.0000e-06\n",
      "Epoch 806/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.4303e-04 - val_loss: 0.0369 - learning_rate: 3.0000e-06\n",
      "Epoch 807/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.6319e-04 - val_loss: 0.0370 - learning_rate: 3.0000e-06\n",
      "Epoch 808/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.1513e-04 - val_loss: 0.0369 - learning_rate: 3.0000e-06\n",
      "Epoch 809/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.8526e-04 - val_loss: 0.0361 - learning_rate: 3.0000e-06\n",
      "Epoch 810/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8116e-04 - val_loss: 0.0359 - learning_rate: 3.0000e-06\n",
      "Epoch 811/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.4049e-04 - val_loss: 0.0378 - learning_rate: 3.0000e-06\n",
      "Epoch 812/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0495e-04 - val_loss: 0.0372 - learning_rate: 3.0000e-06\n",
      "Epoch 813/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.3872e-04 - val_loss: 0.0370 - learning_rate: 3.0000e-06\n",
      "Epoch 814/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.9177e-04 - val_loss: 0.0360 - learning_rate: 3.0000e-06\n",
      "Epoch 815/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.3639e-04 - val_loss: 0.0377 - learning_rate: 3.0000e-06\n",
      "Epoch 816/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.3844e-04 - val_loss: 0.0375 - learning_rate: 3.0000e-06\n",
      "Epoch 817/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.1277e-04 - val_loss: 0.0347 - learning_rate: 3.0000e-06\n",
      "Epoch 818/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0363e-04 - val_loss: 0.0358 - learning_rate: 3.0000e-06\n",
      "Epoch 819/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.1897e-04 - val_loss: 0.0388 - learning_rate: 3.0000e-06\n",
      "Epoch 820/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.4392e-04 - val_loss: 0.0363 - learning_rate: 3.0000e-06\n",
      "Epoch 821/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8056e-04 - val_loss: 0.0353 - learning_rate: 3.0000e-06\n",
      "Epoch 822/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.5556e-04 - val_loss: 0.0371 - learning_rate: 3.0000e-06\n",
      "Epoch 823/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.2209e-04 - val_loss: 0.0361 - learning_rate: 3.0000e-06\n",
      "Epoch 824/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.7475e-04 - val_loss: 0.0366 - learning_rate: 3.0000e-06\n",
      "Epoch 825/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0033e-04 - val_loss: 0.0375 - learning_rate: 3.0000e-06\n",
      "Epoch 826/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.6562e-04 - val_loss: 0.0381 - learning_rate: 3.0000e-06\n",
      "Epoch 827/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.7689e-04 - val_loss: 0.0374 - learning_rate: 3.0000e-06\n",
      "Epoch 828/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 5.4987e-04 - val_loss: 0.0381 - learning_rate: 3.0000e-06\n",
      "Epoch 829/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3655e-04 - val_loss: 0.0361 - learning_rate: 3.0000e-06\n",
      "Epoch 830/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.9221e-04 - val_loss: 0.0370 - learning_rate: 3.0000e-06\n",
      "Epoch 831/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.8086e-04 - val_loss: 0.0377 - learning_rate: 3.0000e-06\n",
      "Epoch 832/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.8969e-04 - val_loss: 0.0350 - learning_rate: 3.0000e-06\n",
      "Epoch 833/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.4428e-04 - val_loss: 0.0370 - learning_rate: 3.0000e-06\n",
      "Epoch 834/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0780e-04 - val_loss: 0.0373 - learning_rate: 3.0000e-06\n",
      "Epoch 835/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.7041e-04 - val_loss: 0.0358 - learning_rate: 3.0000e-06\n",
      "Epoch 836/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.4466e-04 - val_loss: 0.0367 - learning_rate: 3.0000e-06\n",
      "Epoch 837/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.5059e-04 - val_loss: 0.0360 - learning_rate: 3.0000e-06\n",
      "Epoch 838/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0947e-04 - val_loss: 0.0364 - learning_rate: 3.0000e-06\n",
      "Epoch 839/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.1550e-04 - val_loss: 0.0371 - learning_rate: 3.0000e-06\n",
      "Epoch 840/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.2492e-04 - val_loss: 0.0368 - learning_rate: 3.0000e-06\n",
      "Epoch 841/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.4346e-04 - val_loss: 0.0370 - learning_rate: 3.0000e-06\n",
      "Epoch 842/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.0998e-04 - val_loss: 0.0358 - learning_rate: 3.0000e-06\n",
      "Epoch 843/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.9569e-04 - val_loss: 0.0361 - learning_rate: 3.0000e-06\n",
      "Epoch 844/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.9634e-04 - val_loss: 0.0381 - learning_rate: 3.0000e-06\n",
      "Epoch 845/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.7025e-04 - val_loss: 0.0375 - learning_rate: 3.0000e-06\n",
      "Epoch 846/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.5081e-04 - val_loss: 0.0377 - learning_rate: 3.0000e-06\n",
      "Epoch 847/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.3282e-04 - val_loss: 0.0376 - learning_rate: 3.0000e-06\n",
      "Epoch 848/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.6646e-04 - val_loss: 0.0373 - learning_rate: 3.0000e-06\n",
      "Epoch 849/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 6.6296e-04 - val_loss: 0.0373 - learning_rate: 3.0000e-06\n",
      "Epoch 850/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8948e-04 - val_loss: 0.0351 - learning_rate: 3.0000e-06\n",
      "Epoch 851/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.3981e-04 - val_loss: 0.0357 - learning_rate: 3.0000e-06\n",
      "Epoch 852/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.1365e-04 - val_loss: 0.0371 - learning_rate: 3.0000e-06\n",
      "Epoch 853/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.4814e-04 - val_loss: 0.0369 - learning_rate: 3.0000e-06\n",
      "Epoch 854/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.5806e-04 - val_loss: 0.0387 - learning_rate: 3.0000e-06\n",
      "Epoch 855/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.8499e-04 - val_loss: 0.0339 - learning_rate: 3.0000e-06\n",
      "Epoch 856/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3357e-04 - val_loss: 0.0361 - learning_rate: 3.0000e-06\n",
      "Epoch 857/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.9907e-04 - val_loss: 0.0380 - learning_rate: 3.0000e-06\n",
      "Epoch 858/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.2921e-04 - val_loss: 0.0369 - learning_rate: 3.0000e-06\n",
      "Epoch 859/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.4662e-04 - val_loss: 0.0367 - learning_rate: 3.0000e-06\n",
      "Epoch 860/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.4237e-04 - val_loss: 0.0363 - learning_rate: 3.0000e-06\n",
      "Epoch 861/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.2599e-04 - val_loss: 0.0369 - learning_rate: 3.0000e-06\n",
      "Epoch 862/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.1693e-04 - val_loss: 0.0374 - learning_rate: 3.0000e-06\n",
      "Epoch 863/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.6344e-04 - val_loss: 0.0382 - learning_rate: 3.0000e-06\n",
      "Epoch 864/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.3252e-04 - val_loss: 0.0384 - learning_rate: 3.0000e-06\n",
      "Epoch 865/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.5411e-04 - val_loss: 0.0372 - learning_rate: 3.0000e-06\n",
      "Epoch 866/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.2156e-04 - val_loss: 0.0377 - learning_rate: 3.0000e-06\n",
      "Epoch 867/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 7.0656e-04 - val_loss: 0.0377 - learning_rate: 3.0000e-06\n",
      "Epoch 868/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3615e-04 - val_loss: 0.0372 - learning_rate: 3.0000e-06\n",
      "Epoch 869/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.0098e-04 - val_loss: 0.0356 - learning_rate: 3.0000e-06\n",
      "Epoch 870/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 9.2777e-04 - val_loss: 0.0362 - learning_rate: 3.0000e-06\n",
      "Epoch 871/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8634e-04 - val_loss: 0.0370 - learning_rate: 3.0000e-06\n",
      "Epoch 872/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0132e-04 - val_loss: 0.0374 - learning_rate: 3.0000e-06\n",
      "Epoch 873/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0775e-04 - val_loss: 0.0353 - learning_rate: 3.0000e-06\n",
      "Epoch 874/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.4920e-04 - val_loss: 0.0356 - learning_rate: 3.0000e-06\n",
      "Epoch 875/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.3519e-04 - val_loss: 0.0384 - learning_rate: 3.0000e-06\n",
      "Epoch 876/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3458e-04 - val_loss: 0.0361 - learning_rate: 3.0000e-06\n",
      "Epoch 877/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3810e-04 - val_loss: 0.0338 - learning_rate: 3.0000e-06\n",
      "Epoch 878/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.9371e-04 - val_loss: 0.0373 - learning_rate: 3.0000e-06\n",
      "Epoch 879/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.0026e-04 - val_loss: 0.0356 - learning_rate: 3.0000e-06\n",
      "Epoch 880/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.9477e-04 - val_loss: 0.0372 - learning_rate: 3.0000e-06\n",
      "Epoch 881/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.5091e-04 - val_loss: 0.0356 - learning_rate: 3.0000e-06\n",
      "Epoch 882/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 7.4187e-04 - val_loss: 0.0374 - learning_rate: 3.0000e-06\n",
      "Epoch 883/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.1616e-04 - val_loss: 0.0389 - learning_rate: 3.0000e-06\n",
      "Epoch 884/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.1306e-04 - val_loss: 0.0366 - learning_rate: 3.0000e-06\n",
      "Epoch 885/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.7414e-04 - val_loss: 0.0353 - learning_rate: 3.0000e-06\n",
      "Epoch 886/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.3483e-04 - val_loss: 0.0362 - learning_rate: 3.0000e-06\n",
      "Epoch 887/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.4169e-04 - val_loss: 0.0352 - learning_rate: 3.0000e-06\n",
      "Epoch 888/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3230e-04 - val_loss: 0.0365 - learning_rate: 3.0000e-06\n",
      "Epoch 889/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.7426e-04 - val_loss: 0.0358 - learning_rate: 3.0000e-06\n",
      "Epoch 890/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.4424e-04 - val_loss: 0.0357 - learning_rate: 3.0000e-06\n",
      "Epoch 891/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.7423e-04 - val_loss: 0.0357 - learning_rate: 3.0000e-06\n",
      "Epoch 892/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.6064e-04 - val_loss: 0.0354 - learning_rate: 3.0000e-06\n",
      "Epoch 893/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 7.3378e-04 - val_loss: 0.0360 - learning_rate: 3.0000e-06\n",
      "Epoch 894/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8783e-04 - val_loss: 0.0360 - learning_rate: 3.0000e-06\n",
      "Epoch 895/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.7394e-04 - val_loss: 0.0386 - learning_rate: 3.0000e-06\n",
      "Epoch 896/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 6.2114e-04 - val_loss: 0.0370 - learning_rate: 3.0000e-06\n",
      "Epoch 897/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 6.2721e-04 - val_loss: 0.0370 - learning_rate: 3.0000e-06\n",
      "Epoch 898/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.4405e-04 - val_loss: 0.0357 - learning_rate: 3.0000e-06\n",
      "Epoch 899/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.0611e-04 - val_loss: 0.0376 - learning_rate: 3.0000e-06\n",
      "Epoch 900/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 7.3792e-04 - val_loss: 0.0359 - learning_rate: 3.0000e-06\n",
      "Epoch 901/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.0121e-04 - val_loss: 0.0371 - learning_rate: 3.0000e-06\n",
      "Epoch 902/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.1745e-04 - val_loss: 0.0376 - learning_rate: 3.0000e-06\n",
      "Epoch 903/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.5903e-04 - val_loss: 0.0357 - learning_rate: 3.0000e-06\n",
      "Epoch 904/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.1623e-04 - val_loss: 0.0367 - learning_rate: 3.0000e-06\n",
      "Epoch 905/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.6664e-04 - val_loss: 0.0356 - learning_rate: 3.0000e-06\n",
      "Epoch 906/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.2247e-04 - val_loss: 0.0358 - learning_rate: 3.0000e-06\n",
      "Epoch 907/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.7963e-04 - val_loss: 0.0356 - learning_rate: 3.0000e-06\n",
      "Epoch 908/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.5501e-04 - val_loss: 0.0354 - learning_rate: 3.0000e-06\n",
      "Epoch 909/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.4178e-04 - val_loss: 0.0355 - learning_rate: 3.0000e-06\n",
      "Epoch 910/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 6.4137e-04 - val_loss: 0.0359 - learning_rate: 3.0000e-06\n",
      "Epoch 911/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.3327e-04 - val_loss: 0.0357 - learning_rate: 3.0000e-06\n",
      "Epoch 912/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.3113e-04 - val_loss: 0.0370 - learning_rate: 3.0000e-06\n",
      "Epoch 913/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8939e-04 - val_loss: 0.0365 - learning_rate: 3.0000e-06\n",
      "Epoch 914/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.2977e-04 - val_loss: 0.0351 - learning_rate: 3.0000e-06\n",
      "Epoch 915/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.7614e-04 - val_loss: 0.0377 - learning_rate: 3.0000e-06\n",
      "Epoch 916/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.1431e-04 - val_loss: 0.0372 - learning_rate: 3.0000e-06\n",
      "Epoch 917/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.3635e-04 - val_loss: 0.0376 - learning_rate: 3.0000e-06\n",
      "Epoch 918/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.9664e-04 - val_loss: 0.0364 - learning_rate: 3.0000e-06\n",
      "Epoch 919/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 7.4525e-04 - val_loss: 0.0375 - learning_rate: 3.0000e-06\n",
      "Epoch 920/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.6704e-04 - val_loss: 0.0369 - learning_rate: 3.0000e-06\n",
      "Epoch 921/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.7382e-04 - val_loss: 0.0361 - learning_rate: 3.0000e-06\n",
      "Epoch 922/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.6337e-04 - val_loss: 0.0371 - learning_rate: 3.0000e-06\n",
      "Epoch 923/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.9113e-04 - val_loss: 0.0368 - learning_rate: 3.0000e-06\n",
      "Epoch 924/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.0950e-04 - val_loss: 0.0373 - learning_rate: 3.0000e-06\n",
      "Epoch 925/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8181e-04 - val_loss: 0.0378 - learning_rate: 3.0000e-06\n",
      "Epoch 926/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.0665e-04 - val_loss: 0.0362 - learning_rate: 3.0000e-06\n",
      "Epoch 927/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.8254e-04 - val_loss: 0.0361 - learning_rate: 3.0000e-06\n",
      "Epoch 928/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.0372e-04 - val_loss: 0.0364 - learning_rate: 3.0000e-06\n",
      "Epoch 929/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 6.4442e-04 - val_loss: 0.0366 - learning_rate: 3.0000e-06\n",
      "Epoch 930/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3623e-04 - val_loss: 0.0368 - learning_rate: 3.0000e-06\n",
      "Epoch 931/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.3924e-04 - val_loss: 0.0369 - learning_rate: 3.0000e-06\n",
      "Epoch 932/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.5176e-04 - val_loss: 0.0352 - learning_rate: 3.0000e-06\n",
      "Epoch 933/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.9327e-04 - val_loss: 0.0379 - learning_rate: 3.0000e-06\n",
      "Epoch 934/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.6126e-04 - val_loss: 0.0371 - learning_rate: 3.0000e-06\n",
      "Epoch 935/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.5411e-04 - val_loss: 0.0383 - learning_rate: 3.0000e-06\n",
      "Epoch 936/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.8844e-04 - val_loss: 0.0367 - learning_rate: 3.0000e-06\n",
      "Epoch 937/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.1310e-04 - val_loss: 0.0371 - learning_rate: 3.0000e-06\n",
      "Epoch 938/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3389e-04 - val_loss: 0.0376 - learning_rate: 3.0000e-06\n",
      "Epoch 939/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.4127e-04 - val_loss: 0.0372 - learning_rate: 3.0000e-06\n",
      "Epoch 940/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.5902e-04 - val_loss: 0.0367 - learning_rate: 3.0000e-06\n",
      "Epoch 941/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.7406e-04 - val_loss: 0.0366 - learning_rate: 3.0000e-06\n",
      "Epoch 942/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8525e-04 - val_loss: 0.0367 - learning_rate: 3.0000e-06\n",
      "Epoch 943/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.5598e-04 - val_loss: 0.0361 - learning_rate: 3.0000e-06\n",
      "Epoch 944/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8679e-04 - val_loss: 0.0372 - learning_rate: 3.0000e-06\n",
      "Epoch 945/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.9962e-04 - val_loss: 0.0369 - learning_rate: 3.0000e-06\n",
      "Epoch 946/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.9406e-04 - val_loss: 0.0355 - learning_rate: 3.0000e-06\n",
      "Epoch 947/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.3037e-04 - val_loss: 0.0355 - learning_rate: 3.0000e-06\n",
      "Epoch 948/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.2032e-04 - val_loss: 0.0378 - learning_rate: 3.0000e-06\n",
      "Epoch 949/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.7047e-04 - val_loss: 0.0379 - learning_rate: 3.0000e-06\n",
      "Epoch 950/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.5193e-04 - val_loss: 0.0364 - learning_rate: 3.0000e-06\n",
      "Epoch 951/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.2528e-04 - val_loss: 0.0369 - learning_rate: 3.0000e-06\n",
      "Epoch 952/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.4017e-04 - val_loss: 0.0387 - learning_rate: 3.0000e-06\n",
      "Epoch 953/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.3614e-04 - val_loss: 0.0370 - learning_rate: 3.0000e-06\n",
      "Epoch 954/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.5189e-04 - val_loss: 0.0387 - learning_rate: 3.0000e-06\n",
      "Epoch 955/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.2114e-04 - val_loss: 0.0382 - learning_rate: 3.0000e-06\n",
      "Epoch 956/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0404e-04 - val_loss: 0.0379 - learning_rate: 3.0000e-06\n",
      "Epoch 957/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.3220e-04 - val_loss: 0.0379 - learning_rate: 3.0000e-06\n",
      "Epoch 958/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.7714e-04 - val_loss: 0.0360 - learning_rate: 3.0000e-06\n",
      "Epoch 959/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.5609e-04 - val_loss: 0.0368 - learning_rate: 3.0000e-06\n",
      "Epoch 960/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.0255e-04 - val_loss: 0.0381 - learning_rate: 3.0000e-06\n",
      "Epoch 961/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.9158e-04 - val_loss: 0.0358 - learning_rate: 3.0000e-06\n",
      "Epoch 962/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.4624e-04 - val_loss: 0.0377 - learning_rate: 3.0000e-06\n",
      "Epoch 963/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.8667e-04 - val_loss: 0.0370 - learning_rate: 3.0000e-06\n",
      "Epoch 964/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.9373e-04 - val_loss: 0.0374 - learning_rate: 3.0000e-06\n",
      "Epoch 965/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.8841e-04 - val_loss: 0.0348 - learning_rate: 3.0000e-06\n",
      "Epoch 966/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.7254e-04 - val_loss: 0.0370 - learning_rate: 3.0000e-06\n",
      "Epoch 967/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.7552e-04 - val_loss: 0.0374 - learning_rate: 3.0000e-06\n",
      "Epoch 968/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.8139e-04 - val_loss: 0.0372 - learning_rate: 3.0000e-06\n",
      "Epoch 969/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.2911e-04 - val_loss: 0.0372 - learning_rate: 3.0000e-06\n",
      "Epoch 970/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.3592e-04 - val_loss: 0.0375 - learning_rate: 3.0000e-06\n",
      "Epoch 971/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.7749e-04 - val_loss: 0.0363 - learning_rate: 3.0000e-06\n",
      "Epoch 972/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.3181e-04 - val_loss: 0.0378 - learning_rate: 3.0000e-06\n",
      "Epoch 973/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.1030e-04 - val_loss: 0.0382 - learning_rate: 3.0000e-06\n",
      "Epoch 974/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 5.1950e-04 - val_loss: 0.0373 - learning_rate: 3.0000e-06\n",
      "Epoch 975/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.5634e-04 - val_loss: 0.0369 - learning_rate: 3.0000e-06\n",
      "Epoch 976/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.1368e-04 - val_loss: 0.0373 - learning_rate: 3.0000e-06\n",
      "Epoch 977/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.7989e-04 - val_loss: 0.0363 - learning_rate: 3.0000e-06\n",
      "Epoch 978/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.4562e-04 - val_loss: 0.0380 - learning_rate: 3.0000e-06\n",
      "Epoch 979/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.7633e-04 - val_loss: 0.0391 - learning_rate: 3.0000e-06\n",
      "Epoch 980/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.6010e-04 - val_loss: 0.0366 - learning_rate: 3.0000e-06\n",
      "Epoch 981/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.1247e-04 - val_loss: 0.0384 - learning_rate: 3.0000e-06\n",
      "Epoch 982/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.9346e-04 - val_loss: 0.0355 - learning_rate: 3.0000e-06\n",
      "Epoch 983/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.1752e-04 - val_loss: 0.0367 - learning_rate: 3.0000e-06\n",
      "Epoch 984/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.4466e-04 - val_loss: 0.0377 - learning_rate: 3.0000e-06\n",
      "Epoch 985/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.0810e-04 - val_loss: 0.0370 - learning_rate: 3.0000e-06\n",
      "Epoch 986/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.7472e-04 - val_loss: 0.0377 - learning_rate: 3.0000e-06\n",
      "Epoch 987/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.2166e-04 - val_loss: 0.0386 - learning_rate: 3.0000e-06\n",
      "Epoch 988/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.2543e-04 - val_loss: 0.0376 - learning_rate: 3.0000e-06\n",
      "Epoch 989/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0647e-04 - val_loss: 0.0365 - learning_rate: 3.0000e-06\n",
      "Epoch 990/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3131e-04 - val_loss: 0.0394 - learning_rate: 3.0000e-06\n",
      "Epoch 991/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.2566e-04 - val_loss: 0.0372 - learning_rate: 3.0000e-06\n",
      "Epoch 992/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.7832e-04 - val_loss: 0.0363 - learning_rate: 3.0000e-06\n",
      "Epoch 993/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.5495e-04 - val_loss: 0.0364 - learning_rate: 3.0000e-06\n",
      "Epoch 994/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 8.2009e-04 - val_loss: 0.0365 - learning_rate: 3.0000e-06\n",
      "Epoch 995/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.0371e-04 - val_loss: 0.0355 - learning_rate: 3.0000e-06\n",
      "Epoch 996/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 5.7648e-04 - val_loss: 0.0364 - learning_rate: 3.0000e-06\n",
      "Epoch 997/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 7.0228e-04 - val_loss: 0.0362 - learning_rate: 3.0000e-06\n",
      "Epoch 998/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.3653e-04 - val_loss: 0.0356 - learning_rate: 3.0000e-06\n",
      "Epoch 999/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.4192e-04 - val_loss: 0.0387 - learning_rate: 3.0000e-06\n",
      "Epoch 1000/1000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.2030e-04 - val_loss: 0.0373 - learning_rate: 3.0000e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model with the custom callback\n",
    "history = model_builder.train_model(\n",
    "    train_dataset, \n",
    "    val_dataset, \n",
    "    epochs=1000,\n",
    "    callbacks_list=[lr_scheduler]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Extract the losses from the history object\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "train_loss_x_midpoints = history.history.get('x_midpoints_reshape_loss', train_loss)\n",
    "val_loss_x_midpoints = history.history.get('val_x_midpoints_reshape_loss', val_loss)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2,1)\n",
    "plt.plot(train_loss_x_midpoints, label='Train Loss x_midpoints_reshape')\n",
    "plt.plot(val_loss_x_midpoints, label='Validation Loss x_midpoints_reshape')\n",
    "plt.xlabel('Epochs')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss ')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder.model.save(\"/home/da886/Analysis/12KFixed_Mixed_4_32by32_SparsespotsRandomIndex.keras\")\n",
    "# loaded_model = tf.keras.models.load_model(\n",
    "# \"/home/da886/Analysis/30KFixed_13_SparsespotsrandomSPOTS.keras\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1, batch shape: (800, 32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1729532936.127457   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.128275   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.128374   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.128404   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.129497   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.129551   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.129594   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.130408   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.130466   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.130501   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.131268   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.131334   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.131368   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.132049   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.132103   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.132141   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.132746   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.132907   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.133013   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.133311   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.133794   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.133899   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.134182   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.134643   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.134690   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.134975   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.135461   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.135563   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.135627   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.136150   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.136378   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.136466   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.136754   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.137134   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.137181   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.137355   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.137783   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.138175   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.138222   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.138409   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.138900   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.139003   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.139438   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.139712   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.139856   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.140091   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.140625   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.140640   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.140775   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.141253   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.141467   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.141604   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.141876   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.142226   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.142558   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.142739   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.142980   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.143501   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.143518   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.143710   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.144009   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.144433   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.144688   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.145028   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.162795   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.162877   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.163358   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.163491   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.163512   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.163796   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.164247   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.164619   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.164635   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.164983   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.165340   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.165388   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.165679   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.166024   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.166127   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.166382   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.166870   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.166976   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.167021   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.167540   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.167773   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.167856   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.168199   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.168715   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.168795   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.168906   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.169319   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.169404   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.169889   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.169953   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.170200   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.170518   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.170710   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.171073   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.171112   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.171457   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.171743   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.171818   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.172108   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.172277   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.172441   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.172874   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.172885   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.173162   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.173489   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.173541   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.173793   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.174121   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.174355   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.174437   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.174621   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.175200   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.175198   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.175232   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.175876   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.175923   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.175960   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.176240   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.176580   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.176604   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.176746   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.177331   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.177344   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.177356   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.178033   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.178075   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.178176   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.178762   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.178806   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.178907   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.179647   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.179675   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.179697   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.180295   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.180321   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.180439   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.181175   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.181206   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.181356   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.181696   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.182328   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.191301   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.191603   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.191832   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.192068   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.192303   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.192530   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.192636   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.192816   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.193010   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.193193   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.193369   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.193551   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.193722   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.193898   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.194079   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.194321   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.194456   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.194629   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.194800   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.194998   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.195163   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.195283   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.195435   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.195694   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.195853   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.196257   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.196265   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.196496   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.196809   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.197053   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.197085   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.197261   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.197618   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.197891   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.197939   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.198125   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.198666   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.198672   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.198799   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.199373   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.199460   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.199476   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.199855   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.200035   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.200182   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.200607   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.200636   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.200985   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.201216   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.201448   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.201616   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.201941   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.201973   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.202161   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.202317   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.202721   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.202801   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.203180   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.203264   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.203430   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.203864   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.204056   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.204156   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.204393   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.204711   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.204790   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.204992   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.205261   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.205563   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.205593   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.205726   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.205914   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.206088   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.206274   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.206443   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.206626   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.206797   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.207133   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.207290   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.207391   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.207718   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.207918   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.207953   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.208222   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.208482   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.208520   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.208791   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.209047   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.209087   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.209353   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.209617   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.209657   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.209920   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.210180   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.210207   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.210477   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.210730   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.210774   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.211048   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.211271   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.211295   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.211856   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.211890   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.211913   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.212545   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.212574   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.212590   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.213181   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.213189   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.213650   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.213781   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.214095   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.214199   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.214576   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.214686   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.215110   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.215224   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.215462   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.215613   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.216105   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.216352   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.216596   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.216861   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.217171   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.217546   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.217802   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.219092   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.219401   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.219651   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.219902   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.220148   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.220402   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.220672   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.220923   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.221194   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.221409   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.221476   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.221748   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.221934   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.222121   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.222290   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.222439   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.222820   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.222901   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.223283   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.223368   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.223565   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.223947   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.224024   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.224069   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.224606   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.224787   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.224822   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.225141   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.225322   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.225781   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.225788   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.225943   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.226289   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.226536   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.226550   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.226759   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.226989   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.227357   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.227419   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.227531   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.228011   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.228036   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.228458   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.228586   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.228779   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.229299   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.229323   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.229587   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.229781   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.229981   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.230284   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.230427   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.230975   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.231048   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.231358   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.231593   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.231726   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.232028   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.232274   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.232405   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.232795   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.232946   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.233101   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.233474   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.233545   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.233879   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.233990   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.234387   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.234394   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.234735   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.234859   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.235032   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.235225   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.235395   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.235586   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.235766   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.236015   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.236171   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.236465   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.236739   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.236811   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.237124   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.237416   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.237483   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.237795   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.238092   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.238160   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.238479   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.238769   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.238843   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.239148   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.239449   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.239510   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.239659   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.240196   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.240247   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.240333   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.240818   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.240865   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.240954   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.241335   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.241488   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.241660   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.241908   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.242204   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.242242   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.242415   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.242740   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.243016   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.243148   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.243376   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.243527   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.244018   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.244048   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.244505   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.244530   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.244999   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.245023   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.245339   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.245508   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.245658   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.246134   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.246604   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.246905   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.247227   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.247573   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.248534   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.248847   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.249116   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.249366   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.249622   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.249873   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.250152   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.250404   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.250686   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.250978   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.251256   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.251520   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.251537   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.251837   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.252196   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.252209   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.252471   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.252946   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.252957   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.253218   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.253676   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.253687   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.253696   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.254230   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.254403   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.254476   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.254761   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.254965   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.255223   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.255445   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.255586   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.256174   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.256188   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.256309   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.256651   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.256885   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.256909   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.257344   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.257445   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.257825   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.257945   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.258141   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.258621   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.258722   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.259157   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.259339   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.259493   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.259794   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.259988   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.260366   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.260520   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.260823   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.261038   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.261526   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.262043   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.262474   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.263031   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.263108   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.263301   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.263546   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.263795   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.264043   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.264300   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.264557   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.264814   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.265081   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.265356   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.265628   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.265896   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.266176   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.266447   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.266840   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.266936   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.267289   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.267302   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.267650   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.267777   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.267956   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.268281   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.268655   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.268676   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.268938   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.269288   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.269314   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.269567   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.269834   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.269940   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.270430   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.270454   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.270595   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.271008   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.271189   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.271298   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.271470   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.271793   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.272089   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.272124   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.272379   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.272550   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.272882   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.273224   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.273364   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.273596   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.273891   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.274049   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.274378   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.274538   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.274844   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.275005   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.275325   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.275499   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.275673   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.275944   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.276100   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.276437   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.276546   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.277007   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.277032   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.277475   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.277600   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.277823   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.278385   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.278419   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.278454   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.278890   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.279070   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.279454   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.279673   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.279843   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.280214   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.280455   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.280621   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.281031   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.281409   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.281756   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.282125   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.282500   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.282828   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.283576   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.284216   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.284557   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.284996   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.285090   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.285305   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.285704   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.285810   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.286009   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.286309   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.286763   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.286856   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.287047   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.287194   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.287601   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.287849   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.287899   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.288081   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.288565   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.288720   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.288795   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.289152   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.289262   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.289675   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.289781   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.290090   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.290616   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.290641   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.290941   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.291460   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.291484   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.291806   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.292117   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.292369   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.292543   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.293015   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.293136   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.293368   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.293679   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.294129   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.294233   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.294566   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.294870   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.295037   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.295397   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.295619   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.295823   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.296338   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.297175   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.298067   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.300539   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.300816   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.301085   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.301360   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.301645   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.301936   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.302245   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.302541   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.302842   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.303156   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.303464   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.303792   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.304110   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.304432   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.304772   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.305102   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.305456   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.305800   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.306168   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.306749   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.307229   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.307640   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.307762   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.307949   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.308417   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.308433   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.308840   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.308929   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.309278   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.309718   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.310110   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.310409   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.310716   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.311032   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.311360   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.311672   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.311993   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.312332   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.312659   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.313008   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.313353   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.313718   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.314297   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.314875   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.315334   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.315357   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.315447   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.315885   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.315963   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.316618   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.316705   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.316722   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.317134   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.317209   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.317780   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.317956   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.318259   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.318492   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.318719   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.318959   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.319122   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.319410   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.319583   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.319887   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.320057   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.320338   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.320563   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.320761   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.320970   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.321574   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.321775   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.322402   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.322704   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.323200   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.323725   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.324075   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.324086   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.324213   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.324531   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.325016   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.325122   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.325432   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.325625   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.325794   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.326131   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.326626   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.326771   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.326854   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.327169   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.327691   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.327904   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.328216   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.328230   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.329046   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/25\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1729532936.329167   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.330057   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.330408   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.331036   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.332436   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.333299   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.334247   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.336376   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.349057   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.349397   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.349722   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.350050   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.350381   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.350703   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.351032   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.351349   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.351682   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.352028   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.352365   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.352697   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.353064   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.353636   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.353716   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.354226   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.354312   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.354834   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.354903   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.355385   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.355460   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.355800   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.356049   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.356213   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.356669   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.356752   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.357087   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.357439   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.357751   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.357916   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.358283   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.358800   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.358887   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.359225   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.359399   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.359796   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.359881   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.360407   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.360730   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.360884   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.361331   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.361407   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.361856   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.361964   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.362211   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.362552   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.362654   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.363160   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.363243   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.363524   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.363880   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.364400   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.364478   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.364835   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.365346   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.365451   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.365764   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.366173   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.366608   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.366911   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.367515   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.367639   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.368194   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.368223   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.368514   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.368867   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.369406   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.369514   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.370370   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.371318   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.371726   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.372227   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.372896   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.373374   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.373795   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.373874   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.374215   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.374669   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.374743   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.375172   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.375468   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.375642   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.376139   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.376705   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.376776   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.377205   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.377551   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.378161   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.378199   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.378516   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.378645   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.379041   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.379139   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.379571   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.380158   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.380175   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.380668   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.381140   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.381236   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.381709   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.382335   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.382506   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.383187   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.383827   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.384034   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.384864   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.385986   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.387458   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.387836   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.388154   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.388454   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.388768   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.389081   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.389392   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.389706   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.389999   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.390299   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.390668   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.391050   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.391452   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.391782   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.392159   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.392489   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.392830   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.393250   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.393657   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.394145   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.394641   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.395270   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.396067   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.396554   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.396630   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.396888   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.397200   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.397517   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.398033   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.398356   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.398655   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.398967   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.399337   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.399717   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.399812   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.400169   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.400299   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.400514   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.400723   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.400888   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.401336   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.401353   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.401800   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.401902   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.402156   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.402443   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.402552   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.402983   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.403086   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.403387   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.403556   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.403705   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.403777   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.404365   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.404575   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.404595   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.405266   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.405302   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.405330   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.406014   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.406046   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.406146   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.406540   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.406562   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.407060   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.407085   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.407654   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.407820   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.407840   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.408419   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.408444   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.409225   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.409273   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.409769   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.410609   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.410637   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.411985   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.412021   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.413414   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.414946   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.415326   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.415638   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.416071   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.416148   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.416477   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.416823   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.417161   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.417503   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.417885   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.418769   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.419027   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.419215   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.419745   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.419851   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.420343   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.420352   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.420678   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.421012   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.421517   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.421904   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.421941   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.422050   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.422437   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.423527   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.424497   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.424664   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.425115   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.425857   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.428025   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.428556   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.428664   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.429031   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.429464   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.429625   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.429890   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.430206   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.430545   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.430896   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.431254   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.431612   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.432120   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.432324   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.432866   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.432974   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.433321   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.433853   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.433958   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.434530   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.435098   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.435687   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.436279   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.436540   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.436707   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.437257   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.437318   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.437442   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.437741   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.438134   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.438292   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.438518   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.438862   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.439418   21423 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.439446   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.439812   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.440865   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.440888   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.441367   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.441463   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.441854   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.441961   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.442393   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.442491   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.442715   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.443199   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.443302   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.443550   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.444132   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.444142   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.444503   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.444735   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.445149   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.445623   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.445702   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.446131   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.446351   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.446584   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.447326   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.447340   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.447908   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.448268   21419 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.448511   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.449391   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.450093   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.450840   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1729532936.451738   21413 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Processing batch 2, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Processing batch 3, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Processing batch 4, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Processing batch 5, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Processing batch 6, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Processing batch 7, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Processing batch 8, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Processing batch 9, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Processing batch 10, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Processing batch 11, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Processing batch 12, batch shape: (800, 32, 32)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the function for visualizing midpoints\n",
    "def visualize_midpoints(image, midpoints, title=\"Predicted Midpoint Visualization\"):\n",
    "    \"\"\"\n",
    "    Visualizes midpoints on an image without using a probability vector.\n",
    "\n",
    "    Parameters:\n",
    "    - image: A 3D tensor representing the image.\n",
    "    - midpoints: A 2D tensor representing the midpoint coordinates (x, y).\n",
    "    - title: The title of the plot.\n",
    "\n",
    "    Returns:\n",
    "    None (displays the image with midpoints).\n",
    "    \"\"\"\n",
    "    # Convert to NumPy arrays for easier handling\n",
    "    image_np = image\n",
    "    midpoints_np = midpoints\n",
    "\n",
    "    # Denormalize image if necessary (adjust based on your normalization method)\n",
    "    denormalized_image = image_np  # Modify if normalization was applied during training\n",
    "\n",
    "    # Visualize the image\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(denormalized_image, cmap='gray')\n",
    "    plt.title(title)\n",
    "\n",
    "    # Plot midpoints directly, only if they are not (0, 0)\n",
    "    for i, (x, y) in enumerate(midpoints_np):\n",
    "        if x >= 0 and y >= 0:  # Only plot if the point is not (0, 0)\n",
    "            plt.scatter(x, y, color='red', s=5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Create the validation dataset\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n",
    "# val_dataset = val_dataset.batch(800)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)\n",
    "# # Initialize lists to collect the data\n",
    "all_images = []\n",
    "all_true_midpoints = []\n",
    "all_pred_midpoints = []\n",
    "\n",
    "# # Loop through each batch in the validation dataset, predict, and collect results\n",
    "# for i, (data_batch, midpoints_batch) in enumerate(val_dataset):\n",
    "\n",
    "for i, (data_batch, midpoints_batch) in enumerate(train_dataset):\n",
    "    print(f\"Processing batch {i + 1}, batch shape: {data_batch.shape}\")\n",
    "    \n",
    "    # Get the model predictions\n",
    "    predictions =model_builder.model.predict(data_batch)\n",
    "\n",
    "    # Extend the lists to store data from each batch\n",
    "    all_images.extend(data_batch.numpy())  # Store all images\n",
    "    all_true_midpoints.extend(midpoints_batch.numpy())  # Store all true midpoints\n",
    "    all_pred_midpoints.extend(predictions)  # Store all predicted midpoints\n",
    "\n",
    "# Convert lists to arrays for easier indexing\n",
    "all_images = np.array(all_images)\n",
    "all_true_midpoints = np.array(all_true_midpoints)\n",
    "all_pred_midpoints = np.array(all_pred_midpoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "# train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9600, 32, 32), (9600, 1, 4, 2), (9600, 1, 4, 2))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images.shape,all_pred_midpoints.shape,all_true_midpoints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Select an index to visualize from the entire dataset\n",
    "index_to_visualize = np.random.randint(0, len(all_images))\n",
    "\n",
    "# index_to_visualize = 11548\n",
    "# Visualize the selected image with predicted and true midpoints\n",
    "visualize_midpoints(all_images[index_to_visualize], all_pred_midpoints[index_to_visualize, 0, :, :] * np.max(centers), title=\"Predicted Midpoints\")\n",
    "visualize_midpoints(all_images[index_to_visualize], all_true_midpoints[index_to_visualize, 0, :, :] * np.max(centers), title=\"Ground Truth Midpoints\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-160.59007, 303.0473)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(all_pred_midpoints)*np.max(centers),np.max(all_pred_midpoints)*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 63.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(all_true_midpoints)*np.max(centers),np.max(all_true_midpoints)*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0, 0.0, 63.0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(train_images), np.max(train_images), np.min(train_midpoints)*np.max(centers), np.max(train_midpoints)*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[37.49769  ,  0.893701 ],\n",
       "         [ 5.268126 ,  2.3811095],\n",
       "         [ 6.2055097,  9.41111  ],\n",
       "         [38.5479   , 14.923272 ],\n",
       "         [ 1.6805356, 27.386879 ],\n",
       "         [45.822754 , 30.42933  ],\n",
       "         [27.461199 , 36.76014  ],\n",
       "         [39.048737 , 38.981136 ],\n",
       "         [13.185979 , 48.234604 ],\n",
       "         [38.724014 , 50.478184 ],\n",
       "         [ 5.041256 , 56.032772 ],\n",
       "         [27.951286 , 54.13892  ],\n",
       "         [28.76817  , 58.81217  ]]], dtype=float32),\n",
       " array([[[37.,  1.],\n",
       "         [ 6.,  3.],\n",
       "         [ 5., 11.],\n",
       "         [38., 13.],\n",
       "         [ 1., 30.],\n",
       "         [46., 33.],\n",
       "         [28., 34.],\n",
       "         [38., 38.],\n",
       "         [14., 48.],\n",
       "         [38., 50.],\n",
       "         [ 5., 57.],\n",
       "         [28., 57.],\n",
       "         [29., 59.]]], dtype=float32))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pred_midpoints[2]*np.max(centers),all_true_midpoints[2]*np.max(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1., 35., 12.],\n",
       "        [ 1., 63., 52.],\n",
       "        [ 1., 11., 43.],\n",
       "        ...,\n",
       "        [ 1., 10., 33.],\n",
       "        [ 1., 11., 48.],\n",
       "        [ 1., 59., 49.]],\n",
       "\n",
       "       [[ 1.,  5., 24.],\n",
       "        [ 1., 34., 55.],\n",
       "        [ 1., 42., 29.],\n",
       "        ...,\n",
       "        [ 1.,  2., 55.],\n",
       "        [ 1., 13., 17.],\n",
       "        [ 1., 45.,  8.]],\n",
       "\n",
       "       [[ 1., 38., 36.],\n",
       "        [ 1., 11., 33.],\n",
       "        [ 1., 40., 40.],\n",
       "        ...,\n",
       "        [ 1., 45.,  5.],\n",
       "        [ 1.,  8.,  7.],\n",
       "        [ 1., 55., 37.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1., 50., 18.],\n",
       "        [ 1., 20., 19.],\n",
       "        [ 1., 63.,  8.],\n",
       "        ...,\n",
       "        [ 1., 32., 44.],\n",
       "        [ 1., 63., 24.],\n",
       "        [ 1., 51., 52.]],\n",
       "\n",
       "       [[ 1.,  6., 33.],\n",
       "        [ 1., 23., 59.],\n",
       "        [ 1., 13., 48.],\n",
       "        ...,\n",
       "        [ 1., 26., 62.],\n",
       "        [ 1., 20., 42.],\n",
       "        [ 1., 53.,  2.]],\n",
       "\n",
       "       [[ 1., 24., 40.],\n",
       "        [ 1., 30., 43.],\n",
       "        [ 1., 38., 55.],\n",
       "        ...,\n",
       "        [ 1., 31., 56.],\n",
       "        [ 1., 21., 50.],\n",
       "        [ 1., 15.,  6.]]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[2],)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize variables to track the min and max MSE\n",
    "min_mse = float('inf')\n",
    "max_mse = float('-inf')\n",
    "min_mse_index = -1\n",
    "max_mse_index = -1\n",
    "\n",
    "# Loop through each prediction to calculate the MSE\n",
    "for i in range(len(all_pred_midpoints)):\n",
    "    mse = np.mean((all_pred_midpoints[i] - all_true_midpoints[i]) **2)\n",
    "    \n",
    "    if mse < min_mse:\n",
    "        min_mse = mse\n",
    "        min_mse_index = i\n",
    "    \n",
    "    if mse > max_mse:\n",
    "        max_mse = mse\n",
    "        max_mse_index = i\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot an image with its centers\n",
    "def plot_image_with_centers(image, true_center, predicted_center, title):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image.squeeze(), cmap='gray')  # Display the image\n",
    "\n",
    "    # Plot the actual center (Groundtruth)\n",
    "    plt.scatter(true_center[:, 0], true_center[:, 1], color='green', label='Groundtruth', s=10)\n",
    "\n",
    "    # Plot the predicted center\n",
    "    plt.scatter(predicted_center[:, 0], predicted_center[:, 1], color='red', label='Predictions', s=10)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the image with the least MSE\n",
    "plot_image_with_centers(all_images[min_mse_index],\n",
    "                        all_true_midpoints[min_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[min_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        f'Image with Least MSE. MSE: {min_mse:.4f}')\n",
    "\n",
    "# Plotting the image with the largest MSE\n",
    "plot_image_with_centers(all_images[max_mse_index],\n",
    "                        all_true_midpoints[max_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[max_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        f'Image with Largest MSE. MSE: {max_mse:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5266"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_mse_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "objectdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
