{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 20:38:49.346787: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-25 20:38:49.423554: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-25 20:38:49.497508: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-25 20:38:49.532610: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-25 20:38:49.602165: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-25 20:38:53.137435: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device /gpu:9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set CUDA device order and visible devices\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7,8,9\"\n",
    "\n",
    "# Set the device\n",
    "device = '/cpu:0'\n",
    "if tf.config.experimental.list_physical_devices('GPU'):\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the second GPU\n",
    "        gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "        if gpus:\n",
    "            tf.config.experimental.set_visible_devices(gpus[9], 'GPU')\n",
    "            device = '/gpu:9'\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "print(\"device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (60000, 64, 64)\n",
      "Centers shape: (60000, 12, 3)\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def load_data(file_path, num_images):\n",
    "    images = []\n",
    "    # bounding_boxes = []\n",
    "    centers = []\n",
    "\n",
    "    with h5py.File(file_path, 'r') as h5file:\n",
    "        for i in range(num_images):\n",
    "            # Load image data\n",
    "            image_dataset = f'image_{i}_image'\n",
    "            image_data = np.array(h5file[image_dataset])\n",
    "            images.append(image_data)\n",
    "\n",
    "            # # Load bounding boxes\n",
    "            # bbox_dataset = f'image_{i}_bounding_boxes_training'\n",
    "            # bbox_data = np.array(h5file[bbox_dataset])\n",
    "            # bounding_boxes.append(bbox_data)\n",
    "\n",
    "            # Load center positions\n",
    "            center_dataset = f'image_{i}_center_positions_training'\n",
    "            center_data = np.array(h5file[center_dataset])\n",
    "            centers.append(center_data)\n",
    "\n",
    "    # Convert lists to NumPy arrays for easier handling in deep learning pipelines\n",
    "    images = np.array(images)\n",
    "    # bounding_boxes = np.array(bounding_boxes)\n",
    "    centers = np.array(centers)\n",
    "\n",
    "    return images, centers\n",
    "\n",
    "# # Example usage\n",
    "file_path = '/home/da886/ElectronCountingProject/60KImages_64x64Training10electronhits.h5'  ####for training\n",
    "num_images = 60000\n",
    "\n",
    "# file_path = '/home/da886/ElectronCountingProject/500Images_64x64Testing10electronhits.h5'  ####for testing\n",
    "# num_images = 500\n",
    "\n",
    "images, centers = load_data(file_path, num_images)\n",
    "\n",
    "# Verify shapes\n",
    "print(f'Images shape: {images.shape}')\n",
    "# print(f'Bounding boxes shape: {bounding_boxes.shape}')\n",
    "print(f'Centers shape: {centers.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 20:41:14.168111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79078 MB memory:  -> device: 9, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:cf:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "# # Assuming images and centers are already defined\n",
    "# image_normalized = (images + 1e-9) / 9.26\n",
    "# center_coordinates = centers / [1, 64, 64]  # Normalizing the center coordinates\n",
    "# images_np = image_normalized\n",
    "\n",
    "# probabilities = np.array(center_coordinates[:, :, :-2])\n",
    "# probabilities =  tf.expand_dims(probabilities, axis=1)\n",
    "# center_coordinates_np = np.array(center_coordinates[:, :, 1:])\n",
    "# center_coordinates_np = tf.expand_dims(center_coordinates_np, axis=1)\n",
    "# batch_size = 256\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((images_np, {'x_prob_reshape': probabilities, 'x_midpoints_reshape': center_coordinates_np}))\n",
    "# dataset = dataset.shuffle(buffer_size=512,reshuffle_each_iteration= True).batch(batch_size)\n",
    "\n",
    "\n",
    "# Assuming images and centers are already defined\n",
    "image_normalized = (images + 1e-9) / 9.26\n",
    "center_coordinates = centers / [1, 64, 64]  # Normalizing the center coordinates\n",
    "images_np = image_normalized\n",
    "probabilities = np.array(center_coordinates[:, :, :-2])\n",
    "probabilities =  tf.expand_dims(probabilities, axis=1)\n",
    "center_coordinates_np = np.array(center_coordinates[:, :, 1:])\n",
    "center_coordinates_np = tf.expand_dims(center_coordinates_np, axis=1)\n",
    "batch_size = 128\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images_np, {'x_prob_reshape': probabilities, 'x_midpoints_reshape': center_coordinates_np}))\n",
    "# dataset = dataset.shuffle(buffer_size=10000,reshuffle_each_iteration= True).batch(batch_size)\n",
    "# # Determine the size of the dataset\n",
    "dataset_size = len(images_np)\n",
    "\n",
    "# Calculate the number of samples for training (e.g., 80% for training, 20% for validation)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "\n",
    "# Shuffle each dataset separately\n",
    "train_dataset = train_dataset.shuffle(buffer_size=512,reshuffle_each_iteration= True).batch(batch_size)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=512,reshuffle_each_iteration= True).batch(batch_size)\n",
    "\n",
    "# Prefetch to improve performance\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "val_dataset = val_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 12, 2), dtype=float64, numpy=\n",
       "array([[[0.4609375, 0.6953125],\n",
       "        [0.1796875, 0.6640625],\n",
       "        [0.3828125, 0.4765625],\n",
       "        [0.9765625, 0.4453125],\n",
       "        [0.0234375, 0.6640625],\n",
       "        [0.9609375, 0.6171875],\n",
       "        [0.7265625, 0.1015625],\n",
       "        [0.3046875, 0.6015625],\n",
       "        [0.       , 0.       ],\n",
       "        [0.       , 0.       ],\n",
       "        [0.       , 0.       ],\n",
       "        [0.       , 0.       ]]])>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center_coordinates_np[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe8209da1e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images_np[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # File path to the HDF5 file\n",
    "# file_path = '/home/da886/ElectronCountingProject/60KImages_64x64Training10electronhits.h5'\n",
    "\n",
    "# # Function to visualize the first image with midpoint coordinates\n",
    "# def visualize_first_image_with_midpoints(file_path):\n",
    "#     # Open the HDF5 file\n",
    "#     h5_file = h5py.File(file_path, 'r')\n",
    "\n",
    "#     # Get the list of image keys and midpoint keys\n",
    "#     image_keys = [key for key in h5_file.keys() if 'image' in key and '_image' in key]\n",
    "#     midpoint_keys = [key for key in h5_file.keys() if 'center_positions' in key and '_center_positions' in key]\n",
    "\n",
    "#     d = np.random.randint(0, 10000)\n",
    "#     # Select the first key for visualization\n",
    "#     selected_image_key = image_keys[d]\n",
    "#     selected_midpoint_key = selected_image_key.replace('_image', '_center_positions')\n",
    "\n",
    "#     # Extract the image and midpoint coordinates\n",
    "#     image_data = h5_file[selected_image_key][:]\n",
    "#     midpoints = h5_file[selected_midpoint_key][:]\n",
    "    \n",
    "#     # Close the file\n",
    "#     h5_file.close()\n",
    "\n",
    "#     # Plot the first image with midpoint coordinates\n",
    "#     plt.figure(figsize=(4, 5))\n",
    "#     plt.imshow(image_data, cmap='gray')\n",
    "#     plt.scatter(midpoints[:, 0], midpoints[:, 1], c='red', s=5)\n",
    "#     plt.title(f'{selected_image_key} with Midpoint Coordinates')\n",
    "#     plt.xlabel('X-axis')\n",
    "#     plt.ylabel('Y-axis')\n",
    "#     plt.show()\n",
    "\n",
    "# # Call the function with the file path\n",
    "# visualize_first_image_with_midpoints(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3., 1., 1., 0., 0., 0., 1., 3., 0., 3.],\n",
       "        [3., 2., 0., 0., 1., 1., 2., 1., 2., 0.]]),\n",
       " array([0.        , 0.09921875, 0.1984375 , 0.29765625, 0.396875  ,\n",
       "        0.49609375, 0.5953125 , 0.69453125, 0.79375   , 0.89296875,\n",
       "        0.9921875 ]),\n",
       " <a list of 2 BarContainer objects>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# p = np.random.randint(0,len(center_coordinates_np))\n",
    "# center_coordinates_np[p]\n",
    "plt.hist(center_coordinates_np[9].numpy().squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Josh's suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_shape = (64, 64, 1)\n",
    "# num_classes = 12\n",
    "# num_coordinates = 2\n",
    "\n",
    "\n",
    "# x_input = layers.Input(shape=input_shape)\n",
    "# #Layer 1\n",
    "# x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x_input)\n",
    "# x = layers.MaxPool2D()(x)\n",
    "# x = layers.BatchNormalization()(x) \n",
    "# x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "\n",
    "# # #Layer 2\n",
    "# # x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "# # x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "\n",
    "# # #Layer 3\n",
    "# # x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "# # x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "\n",
    "# # #Layer 4\n",
    "# # x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "# # x = layers.MaxPool2D()(x)\n",
    "# # x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "# # x = layers.MaxPool2D()(x)\n",
    "# # x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "# # x = layers.MaxPool2D()(x)\n",
    "\n",
    "# #Layer 5\n",
    "# x = layers.Conv2D(256, kernel_size=5, padding='same', activation='relu')(x)\n",
    "# x = layers.MaxPool2D()(x)\n",
    "# x = layers.BatchNormalization()(x) \n",
    "\n",
    "\n",
    "# x = layers.Flatten()(x)\n",
    "# # Probability output\n",
    "# x_prob = layers.Dense(num_classes, activation='sigmoid', name='x_prob')(x)\n",
    "# x_prob_reshape = layers.Reshape((-1,num_classes,1), name='x_prob_reshape')(x_prob)\n",
    "\n",
    "# # Bounding box output\n",
    "# x_midpoints = layers.Dense(num_classes * num_coordinates, activation='sigmoid', name='x_midpoints')(x)\n",
    "# x_midpoints_reshape = layers.Reshape((-1, num_classes, num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model = tf.keras.models.Model(x_input, [x_prob_reshape,x_midpoints_reshape])\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "input_shape = (64, 64, 1)\n",
    "num_classes = 12\n",
    "num_coordinates = 2\n",
    "\n",
    "\n",
    "x_input = layers.Input(shape=input_shape)\n",
    "#Layer 1\n",
    "x = layers.Conv2D(1025, kernel_size=3, padding='same', activation='relu')(x_input)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Conv2D(512, kernel_size=5, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.BatchNormalization()(x) \n",
    "# x = layers.Dropout(0.3)(x) \n",
    "\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "# Probability output\n",
    "x_prob = layers.Dense(num_classes, activation='sigmoid', name='x_prob')(x)\n",
    "x_prob_reshape = layers.Reshape((-1,num_classes,1), name='x_prob_reshape')(x_prob)\n",
    "\n",
    "# Bounding box output\n",
    "x_midpoints = layers.Dense(num_classes * num_coordinates, activation='sigmoid', name='x_midpoints')(x)\n",
    "x_midpoints_reshape = layers.Reshape((-1, num_classes, num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.models.Model(x_input, [x_prob_reshape,x_midpoints_reshape])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class MaskedMeanSquaredError(tf.keras.losses.Loss):\n",
    "    def __init__(self, name=\"masked_mse_loss\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # Create mask\n",
    "        mask = tf.reduce_sum(y_true, axis=-1) > 0\n",
    "        mask = tf.cast(mask, tf.float32)\n",
    "        mask = tf.expand_dims(mask, axis=-1)\n",
    "\n",
    "        # Apply mask to the true and predicted values\n",
    "        y_true_masked = y_true * mask\n",
    "        y_pred_masked = y_pred * mask\n",
    "\n",
    "        # Calculate mean squared error\n",
    "        mse = tf.reduce_mean(tf.square(y_true_masked - y_pred_masked), axis=-1)\n",
    "        # mse = tf.keras.losses.MeanSquaredError(y_true_masked,y_pred_masked)\n",
    "        # Normalize the loss by the number of non-zero elements in the mask\n",
    "        mask_sum = tf.reduce_sum(mask)\n",
    "        masked_loss = tf.reduce_sum(mse) / mask_sum\n",
    "        return masked_loss\n",
    "\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class MaskedBinaryCrossentropy(tf.keras.losses.Loss):\n",
    "    def __init__(self, name=\"masked_binary_crossentropy\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # Create mask\n",
    "        mask = tf.reduce_sum(y_true, axis=-1) > 0\n",
    "        mask = tf.cast(mask, tf.float32)\n",
    "        mask = tf.expand_dims(mask, axis=-1)\n",
    "\n",
    "        # Apply mask to the true and predicted values\n",
    "        y_true_masked = y_true * mask\n",
    "        y_pred_masked = y_pred * mask\n",
    "\n",
    "        # Calculate binary cross-entropy\n",
    "        bce = tf.keras.losses.binary_crossentropy(y_true_masked, y_pred_masked)\n",
    "\n",
    "        # Normalize the loss by the number of non-zero elements in the mask\n",
    "        mask_sum = tf.reduce_sum(mask)\n",
    "        masked_loss = tf.reduce_sum(bce) / mask_sum\n",
    "        return masked_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer= optimizer, loss= {'x_prob_reshape': MaskedBinaryCrossentropy(), 'x_midpoints_reshape':MaskedMeanSquaredError()})   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model(\"/home/da886/ElectronCountingProject/Weights from my data/weights for Josh's relu/10000images.keras\") ####the weights are for 60000images. it was a typo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, callbacks\n",
    "# Custom callback to save the model every 10 epochs\n",
    "class CustomModelCheckpoint(callbacks.Callback):\n",
    "    def __init__(self, save_freq, save_path):\n",
    "        super(CustomModelCheckpoint, self).__init__()\n",
    "        self.save_freq = save_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.save_freq == 0:\n",
    "            self.model.save(self.save_path.format(epoch=epoch + 1))\n",
    "            print(f\"Model saved at epoch {epoch + 1}\")\n",
    "\n",
    "save_freq = 20  # Save every 10 epochs\n",
    "save_path = \"/home/da886/ElectronCountingProject/Weights from my data/weights for Josh's relu/myversionnew_epoch_{epoch:02d}.h5\"\n",
    "checkpoint_callback = CustomModelCheckpoint(save_freq=save_freq, save_path=save_path)\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='loss', factor=0.2, patience=8, min_lr=3e-5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721842273.164868 1145526 service.cc:146] XLA service 0x7fb8280047a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1721842273.165188 1145526 service.cc:154]   StreamExecutor device (0): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2024-07-24 17:31:13.210435: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-24 17:31:13.576527: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-07-24 17:31:24.997954: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[128,1025,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,512,32,32]{3,2,1,0}, f32[512,1025,5,5]{3,2,1,0}), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-07-24 17:31:32.886669: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 8.88882929s\n",
      "Trying algorithm eng0{} for conv (f32[128,1025,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,512,32,32]{3,2,1,0}, f32[512,1025,5,5]{3,2,1,0}), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1721842297.256631 1145526 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1721842297.448027 1145526 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2024-07-24 17:31:45.677493: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[512,1025,5,5]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,1025,32,32]{3,2,1,0}, f32[128,512,32,32]{3,2,1,0}), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-07-24 17:31:56.714711: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 12.037290743s\n",
      "Trying algorithm eng0{} for conv (f32[512,1025,5,5]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,1025,32,32]{3,2,1,0}, f32[128,512,32,32]{3,2,1,0}), window={size=5x5 pad=2_2x2_2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-07-24 17:31:58.689042: W external/local_xla/xla/service/gpu/nvptx_compiler.cc:762] The NVIDIA driver's CUDA version is 12.4 which is older than the ptxas CUDA version (12.5.82). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/375\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:21:48\u001b[0m 52s/step - loss: 1.0075"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1721842319.487169 1145526 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 167ms/step - loss: 0.1697 - val_loss: 0.1107\n",
      "Epoch 2/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 149ms/step - loss: 0.0898 - val_loss: 0.0901\n",
      "Epoch 3/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0845 - val_loss: 0.0893\n",
      "Epoch 4/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 147ms/step - loss: 0.0801 - val_loss: 0.0887\n",
      "Epoch 5/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 154ms/step - loss: 0.0766 - val_loss: 0.0885\n",
      "Epoch 6/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 146ms/step - loss: 0.0735 - val_loss: 0.0886\n",
      "Epoch 7/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 151ms/step - loss: 0.0707 - val_loss: 0.0886\n",
      "Epoch 8/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0680 - val_loss: 0.0900\n",
      "Epoch 9/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 152ms/step - loss: 0.0652 - val_loss: 0.0908\n",
      "Epoch 10/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0627 - val_loss: 0.0923\n",
      "Epoch 11/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0604 - val_loss: 0.0936\n",
      "Epoch 12/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 144ms/step - loss: 0.0578 - val_loss: 0.0944\n",
      "Epoch 13/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0555 - val_loss: 0.0960\n",
      "Epoch 14/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 155ms/step - loss: 0.0532 - val_loss: 0.0976\n",
      "Epoch 15/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 156ms/step - loss: 0.0511 - val_loss: 0.0986\n",
      "Epoch 16/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 144ms/step - loss: 0.0490 - val_loss: 0.1007\n",
      "Epoch 17/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0472 - val_loss: 0.1023\n",
      "Epoch 18/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 145ms/step - loss: 0.0452 - val_loss: 0.1044\n",
      "Epoch 19/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 147ms/step - loss: 0.0436 - val_loss: 0.1059\n",
      "Epoch 20/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0417"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 148ms/step - loss: 0.0417 - val_loss: 0.1077\n",
      "Epoch 21/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0401 - val_loss: 0.1095\n",
      "Epoch 22/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0386 - val_loss: 0.1115\n",
      "Epoch 23/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 152ms/step - loss: 0.0371 - val_loss: 0.1137\n",
      "Epoch 24/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 154ms/step - loss: 0.0356 - val_loss: 0.1145\n",
      "Epoch 25/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 153ms/step - loss: 0.0343 - val_loss: 0.1157\n",
      "Epoch 26/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 149ms/step - loss: 0.0329 - val_loss: 0.1172\n",
      "Epoch 27/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0316 - val_loss: 0.1190\n",
      "Epoch 28/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 145ms/step - loss: 0.0304 - val_loss: 0.1204\n",
      "Epoch 29/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0293 - val_loss: 0.1223\n",
      "Epoch 30/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 146ms/step - loss: 0.0283 - val_loss: 0.1228\n",
      "Epoch 31/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 150ms/step - loss: 0.0273 - val_loss: 0.1242\n",
      "Epoch 32/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 144ms/step - loss: 0.0262 - val_loss: 0.1251\n",
      "Epoch 33/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 145ms/step - loss: 0.0252 - val_loss: 0.1265\n",
      "Epoch 34/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 154ms/step - loss: 0.0243 - val_loss: 0.1271\n",
      "Epoch 35/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0234 - val_loss: 0.1280\n",
      "Epoch 36/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 152ms/step - loss: 0.0227 - val_loss: 0.1294\n",
      "Epoch 37/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 150ms/step - loss: 0.0218 - val_loss: 0.1300\n",
      "Epoch 38/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0211 - val_loss: 0.1313\n",
      "Epoch 39/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 147ms/step - loss: 0.0205 - val_loss: 0.1315\n",
      "Epoch 40/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0198"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 40\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 147ms/step - loss: 0.0198 - val_loss: 0.1318\n",
      "Epoch 41/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 152ms/step - loss: 0.0192 - val_loss: 0.1329\n",
      "Epoch 42/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0186 - val_loss: 0.1333\n",
      "Epoch 43/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 147ms/step - loss: 0.0181 - val_loss: 0.1340\n",
      "Epoch 44/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 153ms/step - loss: 0.0175 - val_loss: 0.1348\n",
      "Epoch 45/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 148ms/step - loss: 0.0170 - val_loss: 0.1355\n",
      "Epoch 46/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 152ms/step - loss: 0.0166 - val_loss: 0.1358\n",
      "Epoch 47/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 150ms/step - loss: 0.0161 - val_loss: 0.1364\n",
      "Epoch 48/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0156 - val_loss: 0.1372\n",
      "Epoch 49/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0153 - val_loss: 0.1383\n",
      "Epoch 50/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0149 - val_loss: 0.1387\n",
      "Epoch 51/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 152ms/step - loss: 0.0144 - val_loss: 0.1396\n",
      "Epoch 52/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0141 - val_loss: 0.1398\n",
      "Epoch 53/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 156ms/step - loss: 0.0138 - val_loss: 0.1408\n",
      "Epoch 54/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 145ms/step - loss: 0.0134 - val_loss: 0.1412\n",
      "Epoch 55/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0131 - val_loss: 0.1419\n",
      "Epoch 56/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0129 - val_loss: 0.1420\n",
      "Epoch 57/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0126 - val_loss: 0.1422\n",
      "Epoch 58/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 147ms/step - loss: 0.0123 - val_loss: 0.1435\n",
      "Epoch 59/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 148ms/step - loss: 0.0120 - val_loss: 0.1432\n",
      "Epoch 60/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0117"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 60\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 153ms/step - loss: 0.0117 - val_loss: 0.1444\n",
      "Epoch 61/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 149ms/step - loss: 0.0115 - val_loss: 0.1444\n",
      "Epoch 62/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 154ms/step - loss: 0.0112 - val_loss: 0.1447\n",
      "Epoch 63/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 153ms/step - loss: 0.0110 - val_loss: 0.1454\n",
      "Epoch 64/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0108 - val_loss: 0.1453\n",
      "Epoch 65/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 148ms/step - loss: 0.0106 - val_loss: 0.1455\n",
      "Epoch 66/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0104 - val_loss: 0.1458\n",
      "Epoch 67/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 152ms/step - loss: 0.0102 - val_loss: 0.1455\n",
      "Epoch 68/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0100 - val_loss: 0.1461\n",
      "Epoch 69/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0098 - val_loss: 0.1460\n",
      "Epoch 70/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 153ms/step - loss: 0.0096 - val_loss: 0.1461\n",
      "Epoch 71/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 152ms/step - loss: 0.0095 - val_loss: 0.1462\n",
      "Epoch 72/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 155ms/step - loss: 0.0093 - val_loss: 0.1460\n",
      "Epoch 73/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 153ms/step - loss: 0.0091 - val_loss: 0.1465\n",
      "Epoch 74/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 145ms/step - loss: 0.0090 - val_loss: 0.1462\n",
      "Epoch 75/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 144ms/step - loss: 0.0087 - val_loss: 0.1461\n",
      "Epoch 76/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 152ms/step - loss: 0.0086 - val_loss: 0.1457\n",
      "Epoch 77/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 144ms/step - loss: 0.0085 - val_loss: 0.1462\n",
      "Epoch 78/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 152ms/step - loss: 0.0083 - val_loss: 0.1457\n",
      "Epoch 79/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 153ms/step - loss: 0.0082 - val_loss: 0.1456\n",
      "Epoch 80/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0080"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 80\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 153ms/step - loss: 0.0080 - val_loss: 0.1457\n",
      "Epoch 81/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 156ms/step - loss: 0.0079 - val_loss: 0.1461\n",
      "Epoch 82/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 153ms/step - loss: 0.0077 - val_loss: 0.1459\n",
      "Epoch 83/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 150ms/step - loss: 0.0076 - val_loss: 0.1460\n",
      "Epoch 84/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0075 - val_loss: 0.1454\n",
      "Epoch 85/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0074 - val_loss: 0.1455\n",
      "Epoch 86/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0072 - val_loss: 0.1452\n",
      "Epoch 87/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0072 - val_loss: 0.1455\n",
      "Epoch 88/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 145ms/step - loss: 0.0070 - val_loss: 0.1449\n",
      "Epoch 89/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 147ms/step - loss: 0.0069 - val_loss: 0.1453\n",
      "Epoch 90/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 153ms/step - loss: 0.0068 - val_loss: 0.1445\n",
      "Epoch 91/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0067 - val_loss: 0.1446\n",
      "Epoch 92/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0066 - val_loss: 0.1444\n",
      "Epoch 93/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 144ms/step - loss: 0.0065 - val_loss: 0.1449\n",
      "Epoch 94/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 145ms/step - loss: 0.0064 - val_loss: 0.1444\n",
      "Epoch 95/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 148ms/step - loss: 0.0063 - val_loss: 0.1440\n",
      "Epoch 96/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 149ms/step - loss: 0.0062 - val_loss: 0.1445\n",
      "Epoch 97/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 153ms/step - loss: 0.0061 - val_loss: 0.1436\n",
      "Epoch 98/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 149ms/step - loss: 0.0060 - val_loss: 0.1435\n",
      "Epoch 99/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 144ms/step - loss: 0.0060 - val_loss: 0.1438\n",
      "Epoch 100/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 100\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0059 - val_loss: 0.1435\n",
      "Epoch 101/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0058 - val_loss: 0.1437\n",
      "Epoch 102/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 152ms/step - loss: 0.0057 - val_loss: 0.1438\n",
      "Epoch 103/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 152ms/step - loss: 0.0056 - val_loss: 0.1434\n",
      "Epoch 104/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 145ms/step - loss: 0.0056 - val_loss: 0.1434\n",
      "Epoch 105/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 154ms/step - loss: 0.0055 - val_loss: 0.1432\n",
      "Epoch 106/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 146ms/step - loss: 0.0054 - val_loss: 0.1434\n",
      "Epoch 107/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0053 - val_loss: 0.1431\n",
      "Epoch 108/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0052 - val_loss: 0.1427\n",
      "Epoch 109/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0052 - val_loss: 0.1429\n",
      "Epoch 110/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0051 - val_loss: 0.1427\n",
      "Epoch 111/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0050 - val_loss: 0.1430\n",
      "Epoch 112/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 144ms/step - loss: 0.0050 - val_loss: 0.1422\n",
      "Epoch 113/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0049 - val_loss: 0.1422\n",
      "Epoch 114/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 152ms/step - loss: 0.0049 - val_loss: 0.1420\n",
      "Epoch 115/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0048 - val_loss: 0.1419\n",
      "Epoch 116/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0047 - val_loss: 0.1419\n",
      "Epoch 117/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0046 - val_loss: 0.1422\n",
      "Epoch 118/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 148ms/step - loss: 0.0046 - val_loss: 0.1412\n",
      "Epoch 119/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 147ms/step - loss: 0.0045 - val_loss: 0.1410\n",
      "Epoch 120/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 120\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 147ms/step - loss: 0.0045 - val_loss: 0.1407\n",
      "Epoch 121/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 145ms/step - loss: 0.0045 - val_loss: 0.1414\n",
      "Epoch 122/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0044 - val_loss: 0.1414\n",
      "Epoch 123/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 153ms/step - loss: 0.0043 - val_loss: 0.1410\n",
      "Epoch 124/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 143ms/step - loss: 0.0043 - val_loss: 0.1404\n",
      "Epoch 125/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0042 - val_loss: 0.1401\n",
      "Epoch 126/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 147ms/step - loss: 0.0042 - val_loss: 0.1406\n",
      "Epoch 127/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 145ms/step - loss: 0.0041 - val_loss: 0.1401\n",
      "Epoch 128/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0040 - val_loss: 0.1403\n",
      "Epoch 129/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 144ms/step - loss: 0.0040 - val_loss: 0.1403\n",
      "Epoch 130/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0040 - val_loss: 0.1405\n",
      "Epoch 131/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 150ms/step - loss: 0.0039 - val_loss: 0.1401\n",
      "Epoch 132/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 149ms/step - loss: 0.0039 - val_loss: 0.1397\n",
      "Epoch 133/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 144ms/step - loss: 0.0038 - val_loss: 0.1395\n",
      "Epoch 134/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 149ms/step - loss: 0.0038 - val_loss: 0.1399\n",
      "Epoch 135/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 143ms/step - loss: 0.0038 - val_loss: 0.1393\n",
      "Epoch 136/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 149ms/step - loss: 0.0037 - val_loss: 0.1397\n",
      "Epoch 137/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0037 - val_loss: 0.1392\n",
      "Epoch 138/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0036 - val_loss: 0.1391\n",
      "Epoch 139/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 153ms/step - loss: 0.0035 - val_loss: 0.1388\n",
      "Epoch 140/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0035"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 140\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 159ms/step - loss: 0.0035 - val_loss: 0.1391\n",
      "Epoch 141/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 158ms/step - loss: 0.0035 - val_loss: 0.1388\n",
      "Epoch 142/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 157ms/step - loss: 0.0035 - val_loss: 0.1391\n",
      "Epoch 143/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 161ms/step - loss: 0.0034 - val_loss: 0.1381\n",
      "Epoch 144/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 163ms/step - loss: 0.0034 - val_loss: 0.1383\n",
      "Epoch 145/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 158ms/step - loss: 0.0033 - val_loss: 0.1381\n",
      "Epoch 146/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 155ms/step - loss: 0.0033 - val_loss: 0.1373\n",
      "Epoch 147/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 155ms/step - loss: 0.0033 - val_loss: 0.1379\n",
      "Epoch 148/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 155ms/step - loss: 0.0033 - val_loss: 0.1375\n",
      "Epoch 149/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 144ms/step - loss: 0.0032 - val_loss: 0.1376\n",
      "Epoch 150/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 144ms/step - loss: 0.0032 - val_loss: 0.1373\n",
      "Epoch 151/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0032 - val_loss: 0.1375\n",
      "Epoch 152/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0031 - val_loss: 0.1370\n",
      "Epoch 153/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 149ms/step - loss: 0.0031 - val_loss: 0.1372\n",
      "Epoch 154/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0031 - val_loss: 0.1376\n",
      "Epoch 155/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0030 - val_loss: 0.1373\n",
      "Epoch 156/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0030 - val_loss: 0.1367\n",
      "Epoch 157/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 149ms/step - loss: 0.0030 - val_loss: 0.1364\n",
      "Epoch 158/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0030 - val_loss: 0.1365\n",
      "Epoch 159/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0030 - val_loss: 0.1361\n",
      "Epoch 160/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0029"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 160\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0029 - val_loss: 0.1362\n",
      "Epoch 161/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 155ms/step - loss: 0.0029 - val_loss: 0.1357\n",
      "Epoch 162/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0028 - val_loss: 0.1362\n",
      "Epoch 163/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0028 - val_loss: 0.1359\n",
      "Epoch 164/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 144ms/step - loss: 0.0028 - val_loss: 0.1357\n",
      "Epoch 165/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0028 - val_loss: 0.1355\n",
      "Epoch 166/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0028 - val_loss: 0.1359\n",
      "Epoch 167/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0027 - val_loss: 0.1356\n",
      "Epoch 168/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0027 - val_loss: 0.1353\n",
      "Epoch 169/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0027 - val_loss: 0.1355\n",
      "Epoch 170/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0027 - val_loss: 0.1353\n",
      "Epoch 171/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 148ms/step - loss: 0.0027 - val_loss: 0.1356\n",
      "Epoch 172/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 149ms/step - loss: 0.0026 - val_loss: 0.1354\n",
      "Epoch 173/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0026 - val_loss: 0.1354\n",
      "Epoch 174/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0026 - val_loss: 0.1349\n",
      "Epoch 175/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0026 - val_loss: 0.1353\n",
      "Epoch 176/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0025 - val_loss: 0.1347\n",
      "Epoch 177/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 145ms/step - loss: 0.0025 - val_loss: 0.1347\n",
      "Epoch 178/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 148ms/step - loss: 0.0025 - val_loss: 0.1347\n",
      "Epoch 179/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 156ms/step - loss: 0.0025 - val_loss: 0.1346\n",
      "Epoch 180/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 180\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0024 - val_loss: 0.1346\n",
      "Epoch 181/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0024 - val_loss: 0.1341\n",
      "Epoch 182/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 152ms/step - loss: 0.0024 - val_loss: 0.1345\n",
      "Epoch 183/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 155ms/step - loss: 0.0024 - val_loss: 0.1343\n",
      "Epoch 184/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 149ms/step - loss: 0.0024 - val_loss: 0.1338\n",
      "Epoch 185/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 156ms/step - loss: 0.0024 - val_loss: 0.1343\n",
      "Epoch 186/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 156ms/step - loss: 0.0024 - val_loss: 0.1338\n",
      "Epoch 187/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 157ms/step - loss: 0.0023 - val_loss: 0.1339\n",
      "Epoch 188/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0023 - val_loss: 0.1338\n",
      "Epoch 189/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 158ms/step - loss: 0.0023 - val_loss: 0.1337\n",
      "Epoch 190/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 163ms/step - loss: 0.0023 - val_loss: 0.1335\n",
      "Epoch 191/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 159ms/step - loss: 0.0023 - val_loss: 0.1334\n",
      "Epoch 192/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 157ms/step - loss: 0.0022 - val_loss: 0.1332\n",
      "Epoch 193/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 157ms/step - loss: 0.0022 - val_loss: 0.1334\n",
      "Epoch 194/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 148ms/step - loss: 0.0022 - val_loss: 0.1333\n",
      "Epoch 195/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 144ms/step - loss: 0.0022 - val_loss: 0.1335\n",
      "Epoch 196/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0022 - val_loss: 0.1333\n",
      "Epoch 197/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 143ms/step - loss: 0.0022 - val_loss: 0.1328\n",
      "Epoch 198/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0022 - val_loss: 0.1329\n",
      "Epoch 199/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 144ms/step - loss: 0.0021 - val_loss: 0.1328\n",
      "Epoch 200/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0021"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 200\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 153ms/step - loss: 0.0021 - val_loss: 0.1327\n",
      "Epoch 201/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 154ms/step - loss: 0.0021 - val_loss: 0.1327\n",
      "Epoch 202/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0021 - val_loss: 0.1324\n",
      "Epoch 203/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0021 - val_loss: 0.1323\n",
      "Epoch 204/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 145ms/step - loss: 0.0021 - val_loss: 0.1325\n",
      "Epoch 205/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0021 - val_loss: 0.1325\n",
      "Epoch 206/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0021 - val_loss: 0.1322\n",
      "Epoch 207/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 152ms/step - loss: 0.0020 - val_loss: 0.1325\n",
      "Epoch 208/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 147ms/step - loss: 0.0020 - val_loss: 0.1322\n",
      "Epoch 209/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 145ms/step - loss: 0.0020 - val_loss: 0.1321\n",
      "Epoch 210/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 154ms/step - loss: 0.0020 - val_loss: 0.1325\n",
      "Epoch 211/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 143ms/step - loss: 0.0020 - val_loss: 0.1323\n",
      "Epoch 212/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 149ms/step - loss: 0.0019 - val_loss: 0.1321\n",
      "Epoch 213/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 149ms/step - loss: 0.0019 - val_loss: 0.1320\n",
      "Epoch 214/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 149ms/step - loss: 0.0019 - val_loss: 0.1315\n",
      "Epoch 215/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 147ms/step - loss: 0.0019 - val_loss: 0.1319\n",
      "Epoch 216/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0019 - val_loss: 0.1318\n",
      "Epoch 217/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 147ms/step - loss: 0.0019 - val_loss: 0.1316\n",
      "Epoch 218/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 149ms/step - loss: 0.0019 - val_loss: 0.1316\n",
      "Epoch 219/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 148ms/step - loss: 0.0018 - val_loss: 0.1316\n",
      "Epoch 220/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0018"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 220\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0018 - val_loss: 0.1315\n",
      "Epoch 221/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0019 - val_loss: 0.1316\n",
      "Epoch 222/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0019 - val_loss: 0.1313\n",
      "Epoch 223/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 151ms/step - loss: 0.0018 - val_loss: 0.1314\n",
      "Epoch 224/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 148ms/step - loss: 0.0018 - val_loss: 0.1309\n",
      "Epoch 225/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0018 - val_loss: 0.1311\n",
      "Epoch 226/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 152ms/step - loss: 0.0018 - val_loss: 0.1310\n",
      "Epoch 227/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 152ms/step - loss: 0.0018 - val_loss: 0.1310\n",
      "Epoch 228/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 145ms/step - loss: 0.0018 - val_loss: 0.1311\n",
      "Epoch 229/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0018 - val_loss: 0.1310\n",
      "Epoch 230/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0018 - val_loss: 0.1308\n",
      "Epoch 231/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0017 - val_loss: 0.1305\n",
      "Epoch 232/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 152ms/step - loss: 0.0017 - val_loss: 0.1311\n",
      "Epoch 233/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 152ms/step - loss: 0.0017 - val_loss: 0.1309\n",
      "Epoch 234/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0017 - val_loss: 0.1309\n",
      "Epoch 235/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 153ms/step - loss: 0.0017 - val_loss: 0.1307\n",
      "Epoch 236/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 148ms/step - loss: 0.0017 - val_loss: 0.1308\n",
      "Epoch 237/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0017 - val_loss: 0.1311\n",
      "Epoch 238/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0017 - val_loss: 0.1309\n",
      "Epoch 239/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0017 - val_loss: 0.1307\n",
      "Epoch 240/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 240\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 147ms/step - loss: 0.0016 - val_loss: 0.1303\n",
      "Epoch 241/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 145ms/step - loss: 0.0017 - val_loss: 0.1305\n",
      "Epoch 242/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 144ms/step - loss: 0.0016 - val_loss: 0.1306\n",
      "Epoch 243/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 149ms/step - loss: 0.0016 - val_loss: 0.1308\n",
      "Epoch 244/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 143ms/step - loss: 0.0016 - val_loss: 0.1307\n",
      "Epoch 245/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 143ms/step - loss: 0.0016 - val_loss: 0.1304\n",
      "Epoch 246/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 144ms/step - loss: 0.0016 - val_loss: 0.1302\n",
      "Epoch 247/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0016 - val_loss: 0.1299\n",
      "Epoch 248/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 147ms/step - loss: 0.0016 - val_loss: 0.1306\n",
      "Epoch 249/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 147ms/step - loss: 0.0016 - val_loss: 0.1302\n",
      "Epoch 250/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0016 - val_loss: 0.1299\n",
      "Epoch 251/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0016 - val_loss: 0.1302\n",
      "Epoch 252/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 154ms/step - loss: 0.0016 - val_loss: 0.1302\n",
      "Epoch 253/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 148ms/step - loss: 0.0015 - val_loss: 0.1300\n",
      "Epoch 254/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 149ms/step - loss: 0.0015 - val_loss: 0.1303\n",
      "Epoch 255/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0015 - val_loss: 0.1300\n",
      "Epoch 256/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0015 - val_loss: 0.1301\n",
      "Epoch 257/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 152ms/step - loss: 0.0015 - val_loss: 0.1297\n",
      "Epoch 258/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0015 - val_loss: 0.1291\n",
      "Epoch 259/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0015 - val_loss: 0.1295\n",
      "Epoch 260/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 260\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 156ms/step - loss: 0.0015 - val_loss: 0.1297\n",
      "Epoch 261/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 154ms/step - loss: 0.0015 - val_loss: 0.1296\n",
      "Epoch 262/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 149ms/step - loss: 0.0015 - val_loss: 0.1292\n",
      "Epoch 263/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0015 - val_loss: 0.1296\n",
      "Epoch 264/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0015 - val_loss: 0.1293\n",
      "Epoch 265/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0015 - val_loss: 0.1293\n",
      "Epoch 266/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0015 - val_loss: 0.1295\n",
      "Epoch 267/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 147ms/step - loss: 0.0014 - val_loss: 0.1296\n",
      "Epoch 268/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 147ms/step - loss: 0.0014 - val_loss: 0.1293\n",
      "Epoch 269/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0014 - val_loss: 0.1294\n",
      "Epoch 270/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 153ms/step - loss: 0.0014 - val_loss: 0.1295\n",
      "Epoch 271/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 149ms/step - loss: 0.0014 - val_loss: 0.1295\n",
      "Epoch 272/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 148ms/step - loss: 0.0014 - val_loss: 0.1290\n",
      "Epoch 273/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 149ms/step - loss: 0.0014 - val_loss: 0.1290\n",
      "Epoch 274/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 148ms/step - loss: 0.0014 - val_loss: 0.1293\n",
      "Epoch 275/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 143ms/step - loss: 0.0014 - val_loss: 0.1289\n",
      "Epoch 276/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 144ms/step - loss: 0.0014 - val_loss: 0.1290\n",
      "Epoch 277/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 149ms/step - loss: 0.0014 - val_loss: 0.1293\n",
      "Epoch 278/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 148ms/step - loss: 0.0014 - val_loss: 0.1288\n",
      "Epoch 279/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 144ms/step - loss: 0.0014 - val_loss: 0.1287\n",
      "Epoch 280/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 280\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 144ms/step - loss: 0.0014 - val_loss: 0.1290\n",
      "Epoch 281/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 148ms/step - loss: 0.0013 - val_loss: 0.1290\n",
      "Epoch 282/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 147ms/step - loss: 0.0013 - val_loss: 0.1288\n",
      "Epoch 283/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 144ms/step - loss: 0.0013 - val_loss: 0.1289\n",
      "Epoch 284/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 144ms/step - loss: 0.0013 - val_loss: 0.1288\n",
      "Epoch 285/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0013 - val_loss: 0.1290\n",
      "Epoch 286/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 152ms/step - loss: 0.0013 - val_loss: 0.1288\n",
      "Epoch 287/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 153ms/step - loss: 0.0013 - val_loss: 0.1285\n",
      "Epoch 288/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 147ms/step - loss: 0.0013 - val_loss: 0.1286\n",
      "Epoch 289/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 148ms/step - loss: 0.0013 - val_loss: 0.1284\n",
      "Epoch 290/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 145ms/step - loss: 0.0013 - val_loss: 0.1284\n",
      "Epoch 291/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 144ms/step - loss: 0.0013 - val_loss: 0.1284\n",
      "Epoch 292/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 144ms/step - loss: 0.0013 - val_loss: 0.1285\n",
      "Epoch 293/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0013 - val_loss: 0.1286\n",
      "Epoch 294/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0013 - val_loss: 0.1283\n",
      "Epoch 295/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 153ms/step - loss: 0.0013 - val_loss: 0.1283\n",
      "Epoch 296/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 144ms/step - loss: 0.0013 - val_loss: 0.1284\n",
      "Epoch 297/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0013 - val_loss: 0.1283\n",
      "Epoch 298/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 152ms/step - loss: 0.0013 - val_loss: 0.1289\n",
      "Epoch 299/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0012 - val_loss: 0.1283\n",
      "Epoch 300/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 300\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 153ms/step - loss: 0.0012 - val_loss: 0.1286\n",
      "Epoch 301/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0012 - val_loss: 0.1281\n",
      "Epoch 302/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0012 - val_loss: 0.1283\n",
      "Epoch 303/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0012 - val_loss: 0.1283\n",
      "Epoch 304/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 155ms/step - loss: 0.0012 - val_loss: 0.1278\n",
      "Epoch 305/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 147ms/step - loss: 0.0012 - val_loss: 0.1282\n",
      "Epoch 306/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 147ms/step - loss: 0.0012 - val_loss: 0.1283\n",
      "Epoch 307/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 148ms/step - loss: 0.0012 - val_loss: 0.1282\n",
      "Epoch 308/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0012 - val_loss: 0.1278\n",
      "Epoch 309/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0012 - val_loss: 0.1283\n",
      "Epoch 310/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0012 - val_loss: 0.1278\n",
      "Epoch 311/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0012 - val_loss: 0.1281\n",
      "Epoch 312/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0012 - val_loss: 0.1282\n",
      "Epoch 313/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 148ms/step - loss: 0.0012 - val_loss: 0.1279\n",
      "Epoch 314/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 155ms/step - loss: 0.0012 - val_loss: 0.1276\n",
      "Epoch 315/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 155ms/step - loss: 0.0012 - val_loss: 0.1276\n",
      "Epoch 316/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 147ms/step - loss: 0.0012 - val_loss: 0.1275\n",
      "Epoch 317/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 151ms/step - loss: 0.0012 - val_loss: 0.1276\n",
      "Epoch 318/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0012 - val_loss: 0.1275\n",
      "Epoch 319/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 149ms/step - loss: 0.0012 - val_loss: 0.1278\n",
      "Epoch 320/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 320\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 147ms/step - loss: 0.0011 - val_loss: 0.1274\n",
      "Epoch 321/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 149ms/step - loss: 0.0011 - val_loss: 0.1276\n",
      "Epoch 322/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 148ms/step - loss: 0.0011 - val_loss: 0.1272\n",
      "Epoch 323/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0011 - val_loss: 0.1273\n",
      "Epoch 324/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 158ms/step - loss: 0.0011 - val_loss: 0.1274\n",
      "Epoch 325/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 144ms/step - loss: 0.0011 - val_loss: 0.1276\n",
      "Epoch 326/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 149ms/step - loss: 0.0011 - val_loss: 0.1279\n",
      "Epoch 327/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 144ms/step - loss: 0.0011 - val_loss: 0.1276\n",
      "Epoch 328/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0011 - val_loss: 0.1277\n",
      "Epoch 329/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0011 - val_loss: 0.1273\n",
      "Epoch 330/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0011 - val_loss: 0.1272\n",
      "Epoch 331/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 153ms/step - loss: 0.0011 - val_loss: 0.1274\n",
      "Epoch 332/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 153ms/step - loss: 0.0011 - val_loss: 0.1272\n",
      "Epoch 333/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - loss: 0.0011 - val_loss: 0.1273\n",
      "Epoch 334/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 149ms/step - loss: 0.0011 - val_loss: 0.1271\n",
      "Epoch 335/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 147ms/step - loss: 0.0011 - val_loss: 0.1273\n",
      "Epoch 336/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0011 - val_loss: 0.1271\n",
      "Epoch 337/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0011 - val_loss: 0.1273\n",
      "Epoch 338/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0011 - val_loss: 0.1272\n",
      "Epoch 339/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 145ms/step - loss: 0.0011 - val_loss: 0.1270\n",
      "Epoch 340/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 340\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 157ms/step - loss: 0.0011 - val_loss: 0.1271\n",
      "Epoch 341/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 158ms/step - loss: 0.0011 - val_loss: 0.1270\n",
      "Epoch 342/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 153ms/step - loss: 0.0011 - val_loss: 0.1272\n",
      "Epoch 343/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - loss: 0.0011 - val_loss: 0.1269\n",
      "Epoch 344/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 150ms/step - loss: 0.0011 - val_loss: 0.1269\n",
      "Epoch 345/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 151ms/step - loss: 0.0010 - val_loss: 0.1271\n",
      "Epoch 346/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 170ms/step - loss: 0.0010 - val_loss: 0.1271\n",
      "Epoch 347/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 188ms/step - loss: 0.0010 - val_loss: 0.1271\n",
      "Epoch 348/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 195ms/step - loss: 0.0011 - val_loss: 0.1272\n",
      "Epoch 349/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 195ms/step - loss: 0.0010 - val_loss: 0.1271\n",
      "Epoch 350/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 185ms/step - loss: 0.0010 - val_loss: 0.1269\n",
      "Epoch 351/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 184ms/step - loss: 0.0010 - val_loss: 0.1267\n",
      "Epoch 352/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 186ms/step - loss: 0.0010 - val_loss: 0.1269\n",
      "Epoch 353/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 184ms/step - loss: 0.0010 - val_loss: 0.1271\n",
      "Epoch 354/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 185ms/step - loss: 0.0010 - val_loss: 0.1270\n",
      "Epoch 355/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 184ms/step - loss: 0.0010 - val_loss: 0.1270\n",
      "Epoch 356/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 183ms/step - loss: 0.0010 - val_loss: 0.1266\n",
      "Epoch 357/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 194ms/step - loss: 9.9546e-04 - val_loss: 0.1266\n",
      "Epoch 358/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 184ms/step - loss: 9.8839e-04 - val_loss: 0.1265\n",
      "Epoch 359/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 184ms/step - loss: 0.0010 - val_loss: 0.1266\n",
      "Epoch 360/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 360\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 201ms/step - loss: 0.0010 - val_loss: 0.1263\n",
      "Epoch 361/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 183ms/step - loss: 0.0010 - val_loss: 0.1264\n",
      "Epoch 362/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 184ms/step - loss: 9.9378e-04 - val_loss: 0.1265\n",
      "Epoch 363/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 183ms/step - loss: 9.8437e-04 - val_loss: 0.1267\n",
      "Epoch 364/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 183ms/step - loss: 9.7854e-04 - val_loss: 0.1264\n",
      "Epoch 365/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 184ms/step - loss: 9.7715e-04 - val_loss: 0.1263\n",
      "Epoch 366/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 193ms/step - loss: 9.8192e-04 - val_loss: 0.1267\n",
      "Epoch 367/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 195ms/step - loss: 9.8135e-04 - val_loss: 0.1267\n",
      "Epoch 368/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 181ms/step - loss: 9.7100e-04 - val_loss: 0.1267\n",
      "Epoch 369/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 184ms/step - loss: 9.6430e-04 - val_loss: 0.1264\n",
      "Epoch 370/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 180ms/step - loss: 9.6263e-04 - val_loss: 0.1265\n",
      "Epoch 371/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 190ms/step - loss: 9.7697e-04 - val_loss: 0.1267\n",
      "Epoch 372/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 205ms/step - loss: 9.7466e-04 - val_loss: 0.1261\n",
      "Epoch 373/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 199ms/step - loss: 9.5306e-04 - val_loss: 0.1261\n",
      "Epoch 374/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 205ms/step - loss: 9.4782e-04 - val_loss: 0.1261\n",
      "Epoch 375/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 196ms/step - loss: 9.4676e-04 - val_loss: 0.1263\n",
      "Epoch 376/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 201ms/step - loss: 9.4251e-04 - val_loss: 0.1263\n",
      "Epoch 377/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 191ms/step - loss: 9.3725e-04 - val_loss: 0.1262\n",
      "Epoch 378/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 200ms/step - loss: 9.4498e-04 - val_loss: 0.1260\n",
      "Epoch 379/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 198ms/step - loss: 9.4872e-04 - val_loss: 0.1262\n",
      "Epoch 380/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 9.4480e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 380\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 203ms/step - loss: 9.4475e-04 - val_loss: 0.1261\n",
      "Epoch 381/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 191ms/step - loss: 9.1170e-04 - val_loss: 0.1261\n",
      "Epoch 382/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 186ms/step - loss: 9.1337e-04 - val_loss: 0.1261\n",
      "Epoch 383/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 186ms/step - loss: 9.1025e-04 - val_loss: 0.1260\n",
      "Epoch 384/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 185ms/step - loss: 9.2643e-04 - val_loss: 0.1260\n",
      "Epoch 385/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 183ms/step - loss: 9.4691e-04 - val_loss: 0.1260\n",
      "Epoch 386/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 187ms/step - loss: 9.2353e-04 - val_loss: 0.1259\n",
      "Epoch 387/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 184ms/step - loss: 9.0544e-04 - val_loss: 0.1263\n",
      "Epoch 388/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 186ms/step - loss: 8.9411e-04 - val_loss: 0.1262\n",
      "Epoch 389/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 187ms/step - loss: 9.0166e-04 - val_loss: 0.1260\n",
      "Epoch 390/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 184ms/step - loss: 9.0937e-04 - val_loss: 0.1262\n",
      "Epoch 391/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 185ms/step - loss: 9.0380e-04 - val_loss: 0.1259\n",
      "Epoch 392/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 185ms/step - loss: 8.9391e-04 - val_loss: 0.1258\n",
      "Epoch 393/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 185ms/step - loss: 8.8657e-04 - val_loss: 0.1260\n",
      "Epoch 394/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 187ms/step - loss: 9.0128e-04 - val_loss: 0.1257\n",
      "Epoch 395/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 185ms/step - loss: 8.9421e-04 - val_loss: 0.1259\n",
      "Epoch 396/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 186ms/step - loss: 8.7999e-04 - val_loss: 0.1255\n",
      "Epoch 397/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 182ms/step - loss: 8.7669e-04 - val_loss: 0.1256\n",
      "Epoch 398/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 194ms/step - loss: 8.7403e-04 - val_loss: 0.1261\n",
      "Epoch 399/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 184ms/step - loss: 8.7178e-04 - val_loss: 0.1259\n",
      "Epoch 400/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 8.8777e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 400\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 201ms/step - loss: 8.8774e-04 - val_loss: 0.1259\n",
      "Epoch 401/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 184ms/step - loss: 8.8234e-04 - val_loss: 0.1259\n",
      "Epoch 402/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 195ms/step - loss: 8.7731e-04 - val_loss: 0.1259\n",
      "Epoch 403/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 184ms/step - loss: 8.6738e-04 - val_loss: 0.1257\n",
      "Epoch 404/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 185ms/step - loss: 8.7288e-04 - val_loss: 0.1260\n",
      "Epoch 405/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 185ms/step - loss: 8.7480e-04 - val_loss: 0.1258\n",
      "Epoch 406/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 186ms/step - loss: 8.6124e-04 - val_loss: 0.1258\n",
      "Epoch 407/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 183ms/step - loss: 8.6121e-04 - val_loss: 0.1257\n",
      "Epoch 408/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 183ms/step - loss: 8.5361e-04 - val_loss: 0.1258\n",
      "Epoch 409/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 183ms/step - loss: 8.5109e-04 - val_loss: 0.1255\n",
      "Epoch 410/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 195ms/step - loss: 8.4180e-04 - val_loss: 0.1255\n",
      "Epoch 411/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 185ms/step - loss: 8.4306e-04 - val_loss: 0.1255\n",
      "Epoch 412/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 182ms/step - loss: 8.5303e-04 - val_loss: 0.1257\n",
      "Epoch 413/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 183ms/step - loss: 8.4769e-04 - val_loss: 0.1255\n",
      "Epoch 414/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 184ms/step - loss: 8.5432e-04 - val_loss: 0.1255\n",
      "Epoch 415/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 183ms/step - loss: 8.4870e-04 - val_loss: 0.1256\n",
      "Epoch 416/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 185ms/step - loss: 8.3625e-04 - val_loss: 0.1256\n",
      "Epoch 417/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 184ms/step - loss: 8.3223e-04 - val_loss: 0.1253\n",
      "Epoch 418/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 195ms/step - loss: 8.3744e-04 - val_loss: 0.1254\n",
      "Epoch 419/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 185ms/step - loss: 8.3115e-04 - val_loss: 0.1254\n",
      "Epoch 420/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 8.1826e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 420\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 200ms/step - loss: 8.1825e-04 - val_loss: 0.1254\n",
      "Epoch 421/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 184ms/step - loss: 8.2568e-04 - val_loss: 0.1253\n",
      "Epoch 422/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 182ms/step - loss: 8.3006e-04 - val_loss: 0.1253\n",
      "Epoch 423/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 185ms/step - loss: 8.2578e-04 - val_loss: 0.1250\n",
      "Epoch 424/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 184ms/step - loss: 8.1296e-04 - val_loss: 0.1254\n",
      "Epoch 425/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 182ms/step - loss: 8.1245e-04 - val_loss: 0.1253\n",
      "Epoch 426/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 182ms/step - loss: 8.1593e-04 - val_loss: 0.1253\n",
      "Epoch 427/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 183ms/step - loss: 8.1410e-04 - val_loss: 0.1253\n",
      "Epoch 428/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 183ms/step - loss: 8.0584e-04 - val_loss: 0.1254\n",
      "Epoch 429/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 185ms/step - loss: 7.9924e-04 - val_loss: 0.1255\n",
      "Epoch 430/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 185ms/step - loss: 8.1296e-04 - val_loss: 0.1249\n",
      "Epoch 431/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 182ms/step - loss: 8.1638e-04 - val_loss: 0.1252\n",
      "Epoch 432/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 193ms/step - loss: 8.0818e-04 - val_loss: 0.1254\n",
      "Epoch 433/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 182ms/step - loss: 8.0334e-04 - val_loss: 0.1251\n",
      "Epoch 434/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 185ms/step - loss: 7.9613e-04 - val_loss: 0.1251\n",
      "Epoch 435/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 182ms/step - loss: 7.8504e-04 - val_loss: 0.1255\n",
      "Epoch 436/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 180ms/step - loss: 7.7703e-04 - val_loss: 0.1255\n",
      "Epoch 437/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 202ms/step - loss: 7.7815e-04 - val_loss: 0.1252\n",
      "Epoch 438/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 203ms/step - loss: 7.8688e-04 - val_loss: 0.1248\n",
      "Epoch 439/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 199ms/step - loss: 7.8358e-04 - val_loss: 0.1250\n",
      "Epoch 440/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 7.8224e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 440\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 210ms/step - loss: 7.8223e-04 - val_loss: 0.1251\n",
      "Epoch 441/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 186ms/step - loss: 7.8242e-04 - val_loss: 0.1251\n",
      "Epoch 442/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 199ms/step - loss: 7.8281e-04 - val_loss: 0.1250\n",
      "Epoch 443/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 201ms/step - loss: 7.8059e-04 - val_loss: 0.1248\n",
      "Epoch 444/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 188ms/step - loss: 7.6331e-04 - val_loss: 0.1248\n",
      "Epoch 445/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 196ms/step - loss: 7.5606e-04 - val_loss: 0.1248\n",
      "Epoch 446/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 186ms/step - loss: 7.5342e-04 - val_loss: 0.1246\n",
      "Epoch 447/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 180ms/step - loss: 7.6100e-04 - val_loss: 0.1248\n",
      "Epoch 448/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 183ms/step - loss: 7.6710e-04 - val_loss: 0.1246\n",
      "Epoch 449/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 178ms/step - loss: 7.8015e-04 - val_loss: 0.1247\n",
      "Epoch 450/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 184ms/step - loss: 7.6585e-04 - val_loss: 0.1250\n",
      "Epoch 451/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 180ms/step - loss: 7.5400e-04 - val_loss: 0.1250\n",
      "Epoch 452/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 185ms/step - loss: 7.5841e-04 - val_loss: 0.1249\n",
      "Epoch 453/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 183ms/step - loss: 7.5320e-04 - val_loss: 0.1249\n",
      "Epoch 454/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 182ms/step - loss: 7.4903e-04 - val_loss: 0.1247\n",
      "Epoch 455/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 182ms/step - loss: 7.5891e-04 - val_loss: 0.1248\n",
      "Epoch 456/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 182ms/step - loss: 7.5506e-04 - val_loss: 0.1246\n",
      "Epoch 457/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 183ms/step - loss: 7.5217e-04 - val_loss: 0.1250\n",
      "Epoch 458/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 185ms/step - loss: 7.4543e-04 - val_loss: 0.1246\n",
      "Epoch 459/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 185ms/step - loss: 7.3667e-04 - val_loss: 0.1249\n",
      "Epoch 460/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 7.3780e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 460\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 200ms/step - loss: 7.3780e-04 - val_loss: 0.1246\n",
      "Epoch 461/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 184ms/step - loss: 7.5106e-04 - val_loss: 0.1248\n",
      "Epoch 462/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 182ms/step - loss: 7.4911e-04 - val_loss: 0.1247\n",
      "Epoch 463/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 180ms/step - loss: 7.3959e-04 - val_loss: 0.1246\n",
      "Epoch 464/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 183ms/step - loss: 7.3270e-04 - val_loss: 0.1247\n",
      "Epoch 465/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 182ms/step - loss: 7.2879e-04 - val_loss: 0.1247\n",
      "Epoch 466/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 180ms/step - loss: 7.2049e-04 - val_loss: 0.1248\n",
      "Epoch 467/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 177ms/step - loss: 7.2283e-04 - val_loss: 0.1248\n",
      "Epoch 468/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 177ms/step - loss: 7.3088e-04 - val_loss: 0.1244\n",
      "Epoch 469/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 178ms/step - loss: 7.3586e-04 - val_loss: 0.1247\n",
      "Epoch 470/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 180ms/step - loss: 7.3472e-04 - val_loss: 0.1245\n",
      "Epoch 471/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 177ms/step - loss: 7.2710e-04 - val_loss: 0.1247\n",
      "Epoch 472/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 177ms/step - loss: 7.1480e-04 - val_loss: 0.1246\n",
      "Epoch 473/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 176ms/step - loss: 7.1694e-04 - val_loss: 0.1245\n",
      "Epoch 474/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 177ms/step - loss: 7.2201e-04 - val_loss: 0.1246\n",
      "Epoch 475/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 177ms/step - loss: 7.1900e-04 - val_loss: 0.1244\n",
      "Epoch 476/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 177ms/step - loss: 7.1464e-04 - val_loss: 0.1244\n",
      "Epoch 477/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 177ms/step - loss: 7.0802e-04 - val_loss: 0.1244\n",
      "Epoch 478/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 7.0650e-04 - val_loss: 0.1244\n",
      "Epoch 479/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 7.0914e-04 - val_loss: 0.1245\n",
      "Epoch 480/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 7.1577e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 480\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 193ms/step - loss: 7.1576e-04 - val_loss: 0.1245\n",
      "Epoch 481/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 178ms/step - loss: 7.2015e-04 - val_loss: 0.1244\n",
      "Epoch 482/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 176ms/step - loss: 7.0611e-04 - val_loss: 0.1242\n",
      "Epoch 483/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 179ms/step - loss: 6.9503e-04 - val_loss: 0.1246\n",
      "Epoch 484/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 177ms/step - loss: 6.9351e-04 - val_loss: 0.1241\n",
      "Epoch 485/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 177ms/step - loss: 6.9975e-04 - val_loss: 0.1243\n",
      "Epoch 486/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 178ms/step - loss: 7.0905e-04 - val_loss: 0.1244\n",
      "Epoch 487/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 176ms/step - loss: 7.0295e-04 - val_loss: 0.1244\n",
      "Epoch 488/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 177ms/step - loss: 6.9253e-04 - val_loss: 0.1242\n",
      "Epoch 489/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 178ms/step - loss: 6.8536e-04 - val_loss: 0.1246\n",
      "Epoch 490/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 178ms/step - loss: 6.8431e-04 - val_loss: 0.1241\n",
      "Epoch 491/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 176ms/step - loss: 6.7563e-04 - val_loss: 0.1242\n",
      "Epoch 492/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 176ms/step - loss: 6.8736e-04 - val_loss: 0.1240\n",
      "Epoch 493/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 176ms/step - loss: 6.9503e-04 - val_loss: 0.1240\n",
      "Epoch 494/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 176ms/step - loss: 6.8850e-04 - val_loss: 0.1244\n",
      "Epoch 495/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 176ms/step - loss: 6.7247e-04 - val_loss: 0.1244\n",
      "Epoch 496/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 176ms/step - loss: 6.6595e-04 - val_loss: 0.1240\n",
      "Epoch 497/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.7322e-04 - val_loss: 0.1241\n",
      "Epoch 498/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.7784e-04 - val_loss: 0.1244\n",
      "Epoch 499/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.7081e-04 - val_loss: 0.1243\n",
      "Epoch 500/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 6.7912e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 500\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 190ms/step - loss: 6.7910e-04 - val_loss: 0.1244\n",
      "Epoch 501/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.7925e-04 - val_loss: 0.1243\n",
      "Epoch 502/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.6844e-04 - val_loss: 0.1244\n",
      "Epoch 503/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 177ms/step - loss: 6.6117e-04 - val_loss: 0.1243\n",
      "Epoch 504/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 176ms/step - loss: 6.6261e-04 - val_loss: 0.1245\n",
      "Epoch 505/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.6651e-04 - val_loss: 0.1242\n",
      "Epoch 506/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 176ms/step - loss: 6.7088e-04 - val_loss: 0.1242\n",
      "Epoch 507/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.7277e-04 - val_loss: 0.1238\n",
      "Epoch 508/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 176ms/step - loss: 6.6089e-04 - val_loss: 0.1239\n",
      "Epoch 509/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.5276e-04 - val_loss: 0.1242\n",
      "Epoch 510/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.5054e-04 - val_loss: 0.1241\n",
      "Epoch 511/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.5457e-04 - val_loss: 0.1241\n",
      "Epoch 512/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.5590e-04 - val_loss: 0.1241\n",
      "Epoch 513/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.6400e-04 - val_loss: 0.1241\n",
      "Epoch 514/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.6727e-04 - val_loss: 0.1241\n",
      "Epoch 515/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.5791e-04 - val_loss: 0.1237\n",
      "Epoch 516/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.5042e-04 - val_loss: 0.1241\n",
      "Epoch 517/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 176ms/step - loss: 6.4767e-04 - val_loss: 0.1239\n",
      "Epoch 518/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.4236e-04 - val_loss: 0.1238\n",
      "Epoch 519/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.4368e-04 - val_loss: 0.1237\n",
      "Epoch 520/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 6.5271e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 520\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 190ms/step - loss: 6.5271e-04 - val_loss: 0.1241\n",
      "Epoch 521/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.5367e-04 - val_loss: 0.1239\n",
      "Epoch 522/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 176ms/step - loss: 6.4526e-04 - val_loss: 0.1239\n",
      "Epoch 523/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.4327e-04 - val_loss: 0.1240\n",
      "Epoch 524/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.3888e-04 - val_loss: 0.1241\n",
      "Epoch 525/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 176ms/step - loss: 6.3856e-04 - val_loss: 0.1238\n",
      "Epoch 526/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 176ms/step - loss: 6.3538e-04 - val_loss: 0.1239\n",
      "Epoch 527/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.3641e-04 - val_loss: 0.1240\n",
      "Epoch 528/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.4634e-04 - val_loss: 0.1238\n",
      "Epoch 529/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.3945e-04 - val_loss: 0.1237\n",
      "Epoch 530/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.3214e-04 - val_loss: 0.1237\n",
      "Epoch 531/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.2559e-04 - val_loss: 0.1237\n",
      "Epoch 532/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.3045e-04 - val_loss: 0.1235\n",
      "Epoch 533/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.3184e-04 - val_loss: 0.1238\n",
      "Epoch 534/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.2561e-04 - val_loss: 0.1238\n",
      "Epoch 535/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.2297e-04 - val_loss: 0.1240\n",
      "Epoch 536/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.2195e-04 - val_loss: 0.1239\n",
      "Epoch 537/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.1933e-04 - val_loss: 0.1238\n",
      "Epoch 538/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.2427e-04 - val_loss: 0.1238\n",
      "Epoch 539/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.2531e-04 - val_loss: 0.1235\n",
      "Epoch 540/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 6.2101e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 540\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 189ms/step - loss: 6.2100e-04 - val_loss: 0.1236\n",
      "Epoch 541/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.2127e-04 - val_loss: 0.1235\n",
      "Epoch 542/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.2003e-04 - val_loss: 0.1238\n",
      "Epoch 543/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 176ms/step - loss: 6.1722e-04 - val_loss: 0.1235\n",
      "Epoch 544/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.1284e-04 - val_loss: 0.1237\n",
      "Epoch 545/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 176ms/step - loss: 6.1050e-04 - val_loss: 0.1238\n",
      "Epoch 546/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.0500e-04 - val_loss: 0.1239\n",
      "Epoch 547/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.1061e-04 - val_loss: 0.1237\n",
      "Epoch 548/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.1750e-04 - val_loss: 0.1236\n",
      "Epoch 549/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.1799e-04 - val_loss: 0.1235\n",
      "Epoch 550/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.1648e-04 - val_loss: 0.1237\n",
      "Epoch 551/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.1095e-04 - val_loss: 0.1235\n",
      "Epoch 552/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 176ms/step - loss: 6.0109e-04 - val_loss: 0.1236\n",
      "Epoch 553/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.9864e-04 - val_loss: 0.1238\n",
      "Epoch 554/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.0425e-04 - val_loss: 0.1234\n",
      "Epoch 555/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.0190e-04 - val_loss: 0.1235\n",
      "Epoch 556/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.0349e-04 - val_loss: 0.1234\n",
      "Epoch 557/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.9758e-04 - val_loss: 0.1236\n",
      "Epoch 558/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 6.0016e-04 - val_loss: 0.1234\n",
      "Epoch 559/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.9980e-04 - val_loss: 0.1232\n",
      "Epoch 560/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 5.9767e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 560\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 189ms/step - loss: 5.9766e-04 - val_loss: 0.1234\n",
      "Epoch 561/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 174ms/step - loss: 5.9191e-04 - val_loss: 0.1234\n",
      "Epoch 562/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.8996e-04 - val_loss: 0.1236\n",
      "Epoch 563/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.9503e-04 - val_loss: 0.1235\n",
      "Epoch 564/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.9622e-04 - val_loss: 0.1238\n",
      "Epoch 565/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 176ms/step - loss: 5.9750e-04 - val_loss: 0.1236\n",
      "Epoch 566/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.9209e-04 - val_loss: 0.1238\n",
      "Epoch 567/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.8067e-04 - val_loss: 0.1233\n",
      "Epoch 568/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.7953e-04 - val_loss: 0.1238\n",
      "Epoch 569/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.7778e-04 - val_loss: 0.1232\n",
      "Epoch 570/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.8540e-04 - val_loss: 0.1232\n",
      "Epoch 571/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.7891e-04 - val_loss: 0.1233\n",
      "Epoch 572/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.7952e-04 - val_loss: 0.1232\n",
      "Epoch 573/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.8400e-04 - val_loss: 0.1236\n",
      "Epoch 574/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.8209e-04 - val_loss: 0.1234\n",
      "Epoch 575/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.7123e-04 - val_loss: 0.1233\n",
      "Epoch 576/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.6835e-04 - val_loss: 0.1231\n",
      "Epoch 577/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.6824e-04 - val_loss: 0.1234\n",
      "Epoch 578/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.6539e-04 - val_loss: 0.1235\n",
      "Epoch 579/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.6921e-04 - val_loss: 0.1235\n",
      "Epoch 580/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 5.6985e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 580\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 189ms/step - loss: 5.6984e-04 - val_loss: 0.1232\n",
      "Epoch 581/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 176ms/step - loss: 5.6938e-04 - val_loss: 0.1233\n",
      "Epoch 582/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 174ms/step - loss: 5.7186e-04 - val_loss: 0.1233\n",
      "Epoch 583/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 174ms/step - loss: 5.6654e-04 - val_loss: 0.1234\n",
      "Epoch 584/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.6607e-04 - val_loss: 0.1230\n",
      "Epoch 585/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.6630e-04 - val_loss: 0.1228\n",
      "Epoch 586/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.7083e-04 - val_loss: 0.1232\n",
      "Epoch 587/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.6135e-04 - val_loss: 0.1233\n",
      "Epoch 588/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.5472e-04 - val_loss: 0.1231\n",
      "Epoch 589/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 174ms/step - loss: 5.5682e-04 - val_loss: 0.1232\n",
      "Epoch 590/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.6310e-04 - val_loss: 0.1230\n",
      "Epoch 591/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.6710e-04 - val_loss: 0.1231\n",
      "Epoch 592/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.6051e-04 - val_loss: 0.1232\n",
      "Epoch 593/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.5594e-04 - val_loss: 0.1233\n",
      "Epoch 594/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.4851e-04 - val_loss: 0.1231\n",
      "Epoch 595/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.4506e-04 - val_loss: 0.1230\n",
      "Epoch 596/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.5137e-04 - val_loss: 0.1232\n",
      "Epoch 597/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 176ms/step - loss: 5.4850e-04 - val_loss: 0.1232\n",
      "Epoch 598/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.5075e-04 - val_loss: 0.1229\n",
      "Epoch 599/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.5556e-04 - val_loss: 0.1231\n",
      "Epoch 600/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 5.5283e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 600\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 189ms/step - loss: 5.5281e-04 - val_loss: 0.1229\n",
      "Epoch 601/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.4816e-04 - val_loss: 0.1229\n",
      "Epoch 602/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.4349e-04 - val_loss: 0.1229\n",
      "Epoch 603/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.4408e-04 - val_loss: 0.1226\n",
      "Epoch 604/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.4061e-04 - val_loss: 0.1228\n",
      "Epoch 605/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.4390e-04 - val_loss: 0.1231\n",
      "Epoch 606/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.4309e-04 - val_loss: 0.1230\n",
      "Epoch 607/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.4530e-04 - val_loss: 0.1229\n",
      "Epoch 608/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.4168e-04 - val_loss: 0.1228\n",
      "Epoch 609/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 176ms/step - loss: 5.3460e-04 - val_loss: 0.1232\n",
      "Epoch 610/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 177ms/step - loss: 5.3535e-04 - val_loss: 0.1228\n",
      "Epoch 611/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 176ms/step - loss: 5.3432e-04 - val_loss: 0.1229\n",
      "Epoch 612/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.3396e-04 - val_loss: 0.1226\n",
      "Epoch 613/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.3956e-04 - val_loss: 0.1230\n",
      "Epoch 614/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.4571e-04 - val_loss: 0.1230\n",
      "Epoch 615/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.3794e-04 - val_loss: 0.1229\n",
      "Epoch 616/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.3060e-04 - val_loss: 0.1228\n",
      "Epoch 617/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.2513e-04 - val_loss: 0.1228\n",
      "Epoch 618/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.2394e-04 - val_loss: 0.1229\n",
      "Epoch 619/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.2466e-04 - val_loss: 0.1230\n",
      "Epoch 620/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 5.2432e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 620\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 189ms/step - loss: 5.2433e-04 - val_loss: 0.1229\n",
      "Epoch 621/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.2522e-04 - val_loss: 0.1230\n",
      "Epoch 622/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 174ms/step - loss: 5.2516e-04 - val_loss: 0.1231\n",
      "Epoch 623/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.2554e-04 - val_loss: 0.1231\n",
      "Epoch 624/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.2452e-04 - val_loss: 0.1229\n",
      "Epoch 625/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.1878e-04 - val_loss: 0.1226\n",
      "Epoch 626/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.2053e-04 - val_loss: 0.1226\n",
      "Epoch 627/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.2331e-04 - val_loss: 0.1228\n",
      "Epoch 628/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.3134e-04 - val_loss: 0.1230\n",
      "Epoch 629/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.3073e-04 - val_loss: 0.1225\n",
      "Epoch 630/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 176ms/step - loss: 5.1723e-04 - val_loss: 0.1229\n",
      "Epoch 631/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.1536e-04 - val_loss: 0.1228\n",
      "Epoch 632/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.0609e-04 - val_loss: 0.1227\n",
      "Epoch 633/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.1143e-04 - val_loss: 0.1228\n",
      "Epoch 634/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.1789e-04 - val_loss: 0.1226\n",
      "Epoch 635/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 176ms/step - loss: 5.1996e-04 - val_loss: 0.1226\n",
      "Epoch 636/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.1996e-04 - val_loss: 0.1227\n",
      "Epoch 637/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.1049e-04 - val_loss: 0.1225\n",
      "Epoch 638/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.0503e-04 - val_loss: 0.1227\n",
      "Epoch 639/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.0107e-04 - val_loss: 0.1225\n",
      "Epoch 640/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 5.0627e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 640\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 190ms/step - loss: 5.0627e-04 - val_loss: 0.1229\n",
      "Epoch 641/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.0806e-04 - val_loss: 0.1224\n",
      "Epoch 642/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 176ms/step - loss: 5.1290e-04 - val_loss: 0.1226\n",
      "Epoch 643/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.1922e-04 - val_loss: 0.1223\n",
      "Epoch 644/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 174ms/step - loss: 5.0850e-04 - val_loss: 0.1225\n",
      "Epoch 645/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.9897e-04 - val_loss: 0.1225\n",
      "Epoch 646/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.9952e-04 - val_loss: 0.1228\n",
      "Epoch 647/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.0273e-04 - val_loss: 0.1222\n",
      "Epoch 648/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.9862e-04 - val_loss: 0.1222\n",
      "Epoch 649/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.0040e-04 - val_loss: 0.1225\n",
      "Epoch 650/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.0336e-04 - val_loss: 0.1227\n",
      "Epoch 651/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.0089e-04 - val_loss: 0.1225\n",
      "Epoch 652/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 176ms/step - loss: 4.9366e-04 - val_loss: 0.1225\n",
      "Epoch 653/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 176ms/step - loss: 4.9479e-04 - val_loss: 0.1226\n",
      "Epoch 654/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.9119e-04 - val_loss: 0.1227\n",
      "Epoch 655/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 174ms/step - loss: 4.9572e-04 - val_loss: 0.1225\n",
      "Epoch 656/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.0029e-04 - val_loss: 0.1226\n",
      "Epoch 657/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.0206e-04 - val_loss: 0.1222\n",
      "Epoch 658/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.9662e-04 - val_loss: 0.1223\n",
      "Epoch 659/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.9998e-04 - val_loss: 0.1224\n",
      "Epoch 660/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 5.0172e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 660\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 191ms/step - loss: 5.0169e-04 - val_loss: 0.1221\n",
      "Epoch 661/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.9517e-04 - val_loss: 0.1223\n",
      "Epoch 662/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.9070e-04 - val_loss: 0.1225\n",
      "Epoch 663/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.9237e-04 - val_loss: 0.1220\n",
      "Epoch 664/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.9808e-04 - val_loss: 0.1225\n",
      "Epoch 665/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 5.0004e-04 - val_loss: 0.1222\n",
      "Epoch 666/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.9012e-04 - val_loss: 0.1225\n",
      "Epoch 667/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 174ms/step - loss: 4.8188e-04 - val_loss: 0.1228\n",
      "Epoch 668/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.8292e-04 - val_loss: 0.1225\n",
      "Epoch 669/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 176ms/step - loss: 4.8515e-04 - val_loss: 0.1221\n",
      "Epoch 670/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.8035e-04 - val_loss: 0.1222\n",
      "Epoch 671/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 174ms/step - loss: 4.8723e-04 - val_loss: 0.1223\n",
      "Epoch 672/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.9121e-04 - val_loss: 0.1221\n",
      "Epoch 673/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.8183e-04 - val_loss: 0.1222\n",
      "Epoch 674/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.7434e-04 - val_loss: 0.1223\n",
      "Epoch 675/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.7214e-04 - val_loss: 0.1224\n",
      "Epoch 676/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.7584e-04 - val_loss: 0.1225\n",
      "Epoch 677/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.7894e-04 - val_loss: 0.1223\n",
      "Epoch 678/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 174ms/step - loss: 4.8626e-04 - val_loss: 0.1223\n",
      "Epoch 679/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.8037e-04 - val_loss: 0.1221\n",
      "Epoch 680/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 4.7666e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 680\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 189ms/step - loss: 4.7663e-04 - val_loss: 0.1222\n",
      "Epoch 681/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 174ms/step - loss: 4.6780e-04 - val_loss: 0.1225\n",
      "Epoch 682/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.6953e-04 - val_loss: 0.1226\n",
      "Epoch 683/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 174ms/step - loss: 4.7703e-04 - val_loss: 0.1225\n",
      "Epoch 684/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.8045e-04 - val_loss: 0.1223\n",
      "Epoch 685/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.7045e-04 - val_loss: 0.1221\n",
      "Epoch 686/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.6783e-04 - val_loss: 0.1220\n",
      "Epoch 687/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.7055e-04 - val_loss: 0.1221\n",
      "Epoch 688/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.7150e-04 - val_loss: 0.1223\n",
      "Epoch 689/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.7266e-04 - val_loss: 0.1225\n",
      "Epoch 690/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 174ms/step - loss: 4.7401e-04 - val_loss: 0.1225\n",
      "Epoch 691/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.7293e-04 - val_loss: 0.1221\n",
      "Epoch 692/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.7207e-04 - val_loss: 0.1223\n",
      "Epoch 693/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 176ms/step - loss: 4.7084e-04 - val_loss: 0.1221\n",
      "Epoch 694/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.6194e-04 - val_loss: 0.1220\n",
      "Epoch 695/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.6616e-04 - val_loss: 0.1225\n",
      "Epoch 696/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 176ms/step - loss: 4.6020e-04 - val_loss: 0.1220\n",
      "Epoch 697/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.5833e-04 - val_loss: 0.1221\n",
      "Epoch 698/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 175ms/step - loss: 4.6587e-04 - val_loss: 0.1221\n",
      "Epoch 699/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 175ms/step - loss: 4.6480e-04 - val_loss: 0.1221\n",
      "Epoch 700/700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 4.7028e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 700\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 189ms/step - loss: 4.7026e-04 - val_loss: 0.1224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fbfc13bfb30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset,epochs=700,validation_data=val_dataset,callbacks =[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.save(\"/home/da886/ElectronCountingProject/Weights from my data/weights for Josh's relu/myversionnew_1st.h5\") \n",
    "# model = tf.keras.models.load_model(\"/home/da886/ElectronCountingProject/Weights from my data/weights for Josh's relu/myversion1sttrain.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 535ms/step\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((images_np, {'x_prob_reshape': probabilities, 'x_midpoints_reshape': center_coordinates_np}))\n",
    "val_dataset = dataset.batch(500)\n",
    "inputs,targets = next(iter(val_dataset))\n",
    "# inputs,targets = next(iter(test_dataset))\n",
    "output =model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss: 0.0005533194\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# r = np.random.randint(0,100)\n",
    "tensor1 = tf.constant(targets['x_midpoints_reshape'], dtype=tf.float64)\n",
    "\n",
    "tensor2 = tf.constant(output[1], dtype=tf.float32)\n",
    "\n",
    "\n",
    "tensor2 = tf.cast(tensor2, tf.float64)\n",
    "\n",
    "\n",
    "mse_loss_fn = MaskedMeanSquaredError()\n",
    "mse_loss = mse_loss_fn(tensor1, tensor2)\n",
    "\n",
    "print(\"MSE Loss:\", mse_loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWMAAAF2CAYAAAC72fnJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAABBKklEQVR4nO3deXhU1f0/8Pdkm4SETAJCFpYYFQ07GiRGxI1AWEQRXIqgwWpVDAhErWIrqEVjwQWRrS5f8CcgFipYoICAEKsFBIRHEY2IQaiQAEomISUJSc7vD5spM3NCztx7J3MG3q/nuQ/kzl0+d5mTm/O55xybEEKAiIgCKiTQARAREQtjIiItsDAmItIAC2MiIg2wMCYi0gALYyIiDbAwJiLSAAtjIiINsDAmItIAC+MAuPDCCzF69GjXz5s3b4bNZsPmzZsDFpMnzxitNnr0aFx44YWNLnfgwAHYbDYsWLDAb7EA/j9eo2w2G5555plAh+EVx4IFC2Cz2XDgwIEmjSNQ+20K511hXH8x66fIyEhceumlGDt2LEpKSgIdnk/+8Y9/BPyLWn8e77//funnf/jDH1zLHD9+vImjaxpz5sxR+mXxwQcfwGaz4a233mpwmfXr18Nms2HmzJkWRhh8XnjhBaxYsSLQYTQtcZ6ZP3++ACCee+458e6774o333xT5OTkiJCQEJGamioqKir8HkNKSorIyclx/VxbWytOnTolamtrfdpObm6u8Ncl9IyxIQBEZGSkiIuLE1VVVV6fp6amisjISAFAHDt2zDW/urpaVFZWNrr9oqIiAUDMnz/fl/B9VllZKaqrqw2t27lzZ3Hdddcp7cPhcIgbbrihwWVGjx4tQkNDRUlJiRBCiFOnTonTp08bistKAMSUKVNcP9fU1IhTp06Juro6v+wvOjpaev/5e7+BdN49GdcbOHAgRo0ahfvvvx8LFizAhAkTUFRUhA8//LDBdSoqKvwSS0hICCIjIxESEpyXY8CAASgrK8OaNWvc5v/rX/9CUVERBg8e7LVOeHg47HZ7U4XYKLvdjvDwcL/v47bbbkNBQQEOHz7s9XllZSWWL1+Ofv36oXXr1gCAyMhIhIWF+TUuI0JDQxEZGQmbzXZe7LcpBOe33w9uvPFGAEBRURGAX+s0Y2JisH//fgwaNAjNmzfHyJEjAQB1dXWYMWMGOnfujMjISCQkJODBBx/EiRMn3LYphMDUqVPRtm1bNGvWDDfccAO+/vprr303VGe8bds2DBo0CPHx8YiOjka3bt3w2muvueKbPXs2ALhVu9SzOsazadOmDa699losXrzYbf6iRYvQtWtXdOnSxWsdWZ1xaWkpRo8eDYfDgbi4OOTk5KC0tFS6bkxMDH744QdkZ2cjOjoaycnJeO655yA8OiGsqKjAo48+inbt2sFut+Oyyy7DSy+95LWcZ51xfXXWZ599hry8PLRq1QrR0dG49dZbcezYMbf1vv76axQUFLiuwfXXX9/guRo1ahTq6uqwZMkSr89Wr14Np9Ppus8A77ra8vJyTJgwARdeeCHsdjtat26Nfv364YsvvmjwWOpdf/31brFVV1dj8uTJSE9Ph8PhQHR0NPr06YNNmzY1GL/n+amvu33mmWfc7sMzpzNjeemll3D11VejZcuWiIqKQnp6OpYtW+a2bZvNhoqKCrzzzjte22ioznjOnDno3Lkz7HY7kpOTkZub63XvXH/99ejSpQv27t2LG264Ac2aNUObNm0wbdq0Ro+3Kej3KzdA9u/fDwBo2bKla15NTQ2ys7NxzTXX4KWXXkKzZs0AAA8++CAWLFiAe++9F4888giKioowa9Ys7Nq1C5999pnrCWvy5MmYOnUqBg0ahEGDBuGLL75A//79UV1d3Wg869evx0033YSkpCSMHz8eiYmJ+Oabb7Bq1SqMHz8eDz74IA4fPoz169fj3Xff9Vq/KWI801133YXx48fj5MmTiImJQU1NDZYuXYq8vDxUVlY2ur4QArfccgs+/fRTPPTQQ+jYsSOWL1+OnJwc6fK1tbUYMGAArrrqKkybNg1r167FlClTUFNTg+eee861zZtvvhmbNm3Cfffdhx49emDdunV4/PHH8dNPP+HVV19tNK5x48YhPj4eU6ZMwYEDBzBjxgyMHTsW77//PgBgxowZGDduHGJiYvCHP/wBAJCQkNDg9q699lq0bdsWixcvRl5enttnixcvRrNmzTB06NAG13/ooYewbNkyjB07Fp06dcLPP/+MTz/9FN988w2uuOKKRo/nTGVlZXjrrbcwYsQI/O53v0N5eTnefvttZGdn4/PPP0ePHj2UtzVs2DBccsklbvN27tyJGTNmuJ7yAeC1117DzTffjJEjR6K6uhpLlizB7bffjlWrVrn+gnr33Xdx//33o1evXnjggQcAABdffHGD+37mmWfw7LPPIisrC2PGjEFhYSHmzp2L7du3u93rAHDixAkMGDAAw4YNwx133IFly5bhiSeeQNeuXTFw4EDl4/WLQNaRBEJ9nfGGDRvEsWPHxKFDh8SSJUtEy5YtRVRUlPj3v/8thBAiJydHABBPPvmk2/r//Oc/BQCxaNEit/lr1651m3/06FEREREhBg8e7Fa/9dRTTwkAbvVhmzZtEgDEpk2bhBC/1oulpqaKlJQUceLECbf9nLmthuqM/RFjQwCI3Nxc8csvv4iIiAjx7rvvCiGEWL16tbDZbOLAgQNiypQpXnXGOTk5IiUlxfXzihUrBAAxbdo017yamhrRp08frzrj+mszbtw4t/MyePBgERER4dpP/TanTp3qFvNtt90mbDab+P77713zPOvI6++TrKwst3MzceJEERoaKkpLS13zVOuM6z3++OMCgCgsLHTNczqdIjIyUowYMcJtWXjU1TocDpGbm3vW7TdU33/ddde5xVlTU+NVz3/ixAmRkJAgfvvb3541jvrzU1RUJI3h2LFjon379qJr167i5MmTrvn/+c9/3Jarrq4WXbp0ETfeeKPb/IbqjD33W38P9+/f3y3nMmvWLAFA/N///Z/b8QMQ/+///T/XvKqqKpGYmCiGDx8uPY6mdN5WU2RlZaFVq1Zo164dfvOb3yAmJgbLly9HmzZt3JYbM2aM289Lly6Fw+FAv379cPz4cdeUnp6OmJgY1594GzZsQHV1NcaNG+dWfTBhwoRGY9u1axeKioowYcIExMXFuX2mUlfWFDF6io+Px4ABA/Dee+8B+PUp7+qrr0ZKSorS+v/4xz8QFhbmdr5DQ0Mxbty4BtcZO3as6/82mw1jx45FdXU1NmzY4NpmaGgoHnnkEbf1Hn30UQghvOq4ZR544AG3c9OnTx/U1tbixx9/VDoumVGjRgGAW7XO3/72N1RWVrpVUcjExcVh27Zt0jpnX4WGhiIiIgLAr9Vav/zyC2pqatCzZ0+3ag9f1dbWYsSIESgvL8fy5csRHR3t+iwqKsr1/xMnTsDpdKJPnz6G91d/D0+YMMEt5/K73/0OsbGxWL16tdvyMTExrvMPABEREejVqxd++OEHQ/u30nlbTTF79mxceumlCAsLQ0JCAi677DKvBFpYWBjatm3rNm/fvn1wOp1uf3qd6ejRowDg+rJ26NDB7fNWrVohPj7+rLHVV5nI6lpVNEWMMnfddRfuvvtuHDx4ECtWrPCpLu7HH39EUlISYmJi3OZfdtll0uVDQkJw0UUXuc279NJLAcBVn/jjjz8iOTkZzZs3d1uuY8eOrs8b0759e7ef68+LZ927L7p164YuXbrgvffec9UHL168GBdccAGys7PPuu60adOQk5ODdu3aIT09HYMGDcI999zjdS5UvfPOO3j55Zfx7bff4vTp0675qamphrYHAH/84x/x8ccfY/Xq1V7VC6tWrcLUqVOxe/duVFVVueYbTcjVX0PP+yQiIgIXXXSR1zVu27at177i4+Px5ZdfGtq/lc7bwrhXr17o2bPnWZex2+1eBXRdXR1at26NRYsWSddp1aqVZTEaFagYb775ZtjtduTk5KCqqgp33HGHX/bTlEJDQ6XzhcnRykaNGoUnn3wSO3bsQNu2bbFp0yY8+OCDjb45cccdd6BPnz5Yvnw5PvroI0yfPh1//vOf8cEHH7jqPBsq2Gpra92OZ+HChRg9ejSGDh2Kxx9/HK1bt0ZoaCjy8/NdDwS+WrFiBf785z/jT3/6EwYMGOD22T//+U/cfPPNuPbaazFnzhwkJSUhPDwc8+fP90r++ou/rqcVztvC2KiLL74YGzZsQO/evd3+5PJU/+f5vn373J5ajh071uhTVf3TxJ49e5CVldXgcg196ZoiRpmoqCgMHToUCxcuxMCBA3HBBRcor5uSkoKNGze6EoD1CgsLpcvX1dXhhx9+cD0NA8B3330HAK63NFJSUrBhwwaUl5e7PR1/++23rs+tYOSpbsSIEZg0aRIWL16MlJQU1NbWNlpFUS8pKQkPP/wwHn74YRw9ehRXXHEFnn/+eVdhHB8fL30L5ccff3S7zsuWLcNFF13kaoxSb8qUKT4fD/Dr+c/JycHQoUPx1FNPeX3+t7/9DZGRkVi3bp3ba43z58/3Wlb1nNZfw8LCQrdjq66uRlFR0Vm/P7o5b+uMjbrjjjtQW1uLP/3pT16f1dTUuL4EWVlZCA8Px+uvv+72W3fGjBmN7uOKK65AamoqZsyY4fWlOnNb9XVxnss0RYwNeeyxxzBlyhQ8/fTTPq03aNAg1NTUYO7cua55tbW1eP311xtcZ9asWa7/CyEwa9YshIeHo2/fvq5t1tbWui0HAK+++ipsNptl2fPo6Ghp4Xc27du3R58+ffD+++9j4cKFSE1NxdVXX33WdWpra+F0Ot3mtW7dGsnJyW5/8l988cXYunWr2xsxq1atwqFDh9zWrX9KPPPab9u2DVu2bPHpWADg5MmTuPXWW9GmTRvXK2meQkNDYbPZUFtb65p34MABaUs71XOalZWFiIgIzJw50+043n77bTidTuk77rrik7GPrrvuOjz44IPIz8/H7t270b9/f4SHh2Pfvn1YunQpXnvtNdx2221o1aoVHnvsMeTn5+Omm27CoEGDsGvXLqxZs6bRJ8aQkBDMnTsXQ4YMQY8ePXDvvfciKSkJ3377Lb7++musW7cOAJCeng4AeOSRR5CdnY3Q0FD85je/aZIYG9K9e3d0797d5/WGDBmC3r1748knn8SBAwfQqVMnfPDBB16FT73IyEisXbsWOTk5yMjIwJo1a7B69Wo89dRTrmqYIUOG4IYbbsAf/vAHHDhwAN27d8dHH32EDz/8EBMmTDjr61K+SE9Px9y5czF16lRccsklaN26teu99bMZNWoUHnjgARw+fNj1WtzZlJeXo23btrjtttvQvXt3xMTEYMOGDdi+fTtefvll13L3338/li1bhgEDBuCOO+7A/v37sXDhQq/jvemmm/DBBx/g1ltvxeDBg1FUVIR58+ahU6dOOHnypE/n4Nlnn8XevXvxxz/+0avh1MUXX4zMzEwMHjwYr7zyCgYMGIC77roLR48exezZs3HJJZd41dmmp6djw4YNeOWVV5CcnIzU1FRkZGR47bdVq1aYNGkSnn32WQwYMAA333wzCgsLMWfOHFx55ZVuyTrtBew9jgCpfzVm+/btZ10uJydHREdHN/j5G2+8IdLT00VUVJRo3ry56Nq1q/j9738vDh8+7FqmtrZWPPvssyIpKUlERUWJ66+/XuzZs8fr1SPPV9vqffrpp6Jfv36iefPmIjo6WnTr1k28/vrrrs9ramrEuHHjRKtWrYTNZvN6zc3KGBuC/77adjYqr7YJIcTPP/8s7r77bhEbGyscDoe4++67xa5du6SvtkVHR4v9+/eL/v37i2bNmomEhAQxZcoUrybl5eXlYuLEiSI5OVmEh4eLDh06iOnTp3s1p23o1TbP+0R2rYqLi8XgwYNF8+bNBQDl19x++eUXYbfbBQCxd+9e6TI445Wyqqoq8fjjj4vu3bu77onu3buLOXPmeK338ssvizZt2gi73S569+4tduzY4fVqW11dnXjhhRdESkqKsNvt4vLLLxerVq2SXhs08mpb/euGsunM8/r222+LDh06CLvdLtLS0sT8+fNd98eZvv32W3HttdeKqKgot2009ErdrFmzRFpamggPDxcJCQlizJgxXq+FXnfddaJz585e50p2vIFgE0KDmmsiH4wePRrLli3z+emNSGesMyYi0gALYyIiDbAwJiLSAOuMiYg0wCdjIiIN+K0wnj17Ni688EJERkYiIyMDn3/+ub92RUQU9PxSTfH+++/jnnvuwbx585CRkYEZM2Zg6dKlKCwsbLDzmnp1dXU4fPgwmjdvfk725k9E5w8hBMrLy5GcnNz4SD7+eHm5V69ebg0BamtrRXJyssjPz2903UOHDjX48jgnTpw4BeN06NChRss+y5tDV1dXY+fOnZg0aZJrXkhICLKyspTavHt2d+gL2RhmZ3YLeDayp3ChQW5T9tu0rq7Oa159v7Rn8nW0jkCS9VZWU1MTgEj8S3afec6TXV9/O1/Ov+r3ySjPa1lfhqiUa5YXxsePH0dtba3X0DMJCQmu3rLOVFVV5dbJSXl5ueF9m6nWCERhrLJP1WMK9iodK6+d7LpZeX3NbEulMDazT6OxmbnPjG7fzDmz8tpZqaFYVfYb8Lcp8vPz4XA4XFO7du0CHRIRUZOzvDC+4IILEBoaipKSErf5JSUlSExM9Fp+0qRJcDqdrsmzmz8iovOB5dUUERERSE9Px8aNG12j3NbV1WHjxo1uY5bVs9vtbh1NuwILC3N7tFep+z2zn9R6qvXIRuuNzPwJJVvOM17VOu8zq3oCSTYyigrZtVOlcr51+ZPY6H1m5p5SIbvPrKwaMVPlZ2V1oew+M1qPbOX1BfzUn3FeXh5ycnLQs2dP9OrVCzNmzEBFRQXuvfdef+yOiCjo+aUwvvPOO3Hs2DFMnjwZxcXF6NGjB9auXeuV1CMiol9p1zdFWVkZHA6HoWoK2WCDsj9BVP/0V2H1WxhGqyl0YbSawt+vHKky+oaLv9/gCITz5TitrKZo6LidTidiY2PPHkejeyQiIr87p8bAk/02k/2mkv0mlC3nOa8pnt48n4RV34u08klE9Te+0fMh+wvG3/HLYlVN5ngu5+9kmkwgnj4D8XSrer+r/AWmmmDzd1JVFZ+MiYg0wMKYiEgDLIyJiDSgbZ2xkU5KZJ2dmOkoyJNq3ZK/6/d0qSs0WtdmpoGHCln8qvs0GpuZPg+M9kcSTMzkIWTXROU6NdplpWaCK1oionMUC2MiIg2wMCYi0gALYyIiDWibwLPZbI0mMjwbD5hpOqyStFJt5GBlgk01oaFKpSN2f7O68YwOTcjNNBNW6njcxH3g7w7hrew1z8pe1cx8T6xq0CSEUO8SQC00IiLyJxbGREQaYGFMRKQBFsZERBrQNoEnhGi00t+zYlxW6S7rIUw1wRMREeH2c3V1tdcyZlrbyWLznCfbp2pywcpRh42SHaPVLfCaekh5M4ktlWsn276ZIcX8PXqzvxmNQ/V7otpSTyX5bSppaHhNIiKyDAtjIiINsDAmItIAC2MiIg1om8DzFBkZ6TWvsrLS7Werh0CSJc88mWl5pdI1YLAPCtkU3Y429XGq7k912B+jLfCsHOxVtftZXQaOVRl2STbPTELZ312b8smYiEgDLIyJiDTAwpiISAMsjImINBA0CTzPZJ0q1RY3RpMQnq30ALXEH6DWgkoWq2ye0VZoqkkJo0kr2XqqLcesFIgEp2qi1fN6yhJKVicNPZk5/4HoolNl+6rJOtn9KFtOpaWkmXuKT8ZERBpgYUxEpAEWxkREGgiaOmMZz7o21boloy/Ly9aT1S3J6qpkcRitpzNTp2jVeoBanZysXk123FbXXausZ2Xvd2YaqKg0OjBTv2o0fjMNJFS+O2bqwVXWVY3V6PfQ6pwDn4yJiDTAwpiISAMsjImINMDCmIhIA0GdwFMZdsnKSvamaKygkpRUTTIFotc2zzhkvYHJGqgYbazQFDzPo2qyUfWaeN5Xqoli1eGCjJ5HM+ff6L0XiPvYaM+IKuv5EjufjImINMDCmIhIAz4Xxp988gmGDBmC5ORk2Gw2rFixwu1zIQQmT56MpKQkREVFISsrC/v27bMqXiKic5LPhXFFRQW6d++O2bNnSz+fNm0aZs6ciXnz5mHbtm2Ijo5Gdna24Y5+iIjOC8IEAGL58uWun+vq6kRiYqKYPn26a15paamw2+3ivffeU9qm0+kUACybbDab1xQaGuo1WblPM7F5LqMaq8q2mmIKCQlxm1TjUr1O/j5O2faNHlMwTZ7HGBIS0uTn1ep9mplU7j1fyhGn09lo2WdpnXFRURGKi4uRlZXlmudwOJCRkYEtW7ZYuSsionOKpa+2FRcXAwASEhLc5ickJLg+81RVVYWqqirXz2VlZVaGREQUFAL+NkV+fj4cDodrateuXaBDIiJqcpYWxomJiQCAkpISt/klJSWuzzxNmjQJTqfTNR06dMjKkIiIgoKl1RSpqalITEzExo0b0aNHDwC/Vjts27YNY8aMka5jt9tht9sb3bZKayNZiyHZtnV5s0PWos9zyCajXRY2tK5K14ZmqGzPTNeMwuBwO7L1ZC2orOye1CjLh/NR6CrU360dm/ocAuaGV1NZTqX7XCGE8j59LoxPnjyJ77//3vVzUVERdu/ejRYtWqB9+/aYMGECpk6dig4dOiA1NRVPP/00kpOTMXToUF93RUR03vC5MN6xYwduuOEG1895eXkAgJycHCxYsAC///3vUVFRgQceeAClpaW45pprsHbtWkRGRloXNRHROcYmAvH3w1mUlZXB4XB4zTdaTSH7JaBLNYWZkaU9qf7p7+9qChWqsRqtzrC6mqKpBaKaIhD83SmQmeO2anSU+moKp9OJ2NjYs24v4G9TEBFREHWhaXRssjPfYT7beiq/kZuiC02jZE90Kt1Smnk6Ue1K0pO/nz7NbF/lLzDV86P6NO65nJnzL1tXNQ6V9axk9XFauX2jXbqauvcMr0lERJZhYUxEpAEWxkREGmBhTESkgaBJ4Ml4JlvMtOJSSRLIxm5TJXvdSvYam8oYcmaShp7nTBaX7DitjkNFIN66VBmzz0xcKuta/cqXv8+jv19RM7ot2XpmXnfz92uhfDImItIAC2MiIg2wMCYi0kBQ1xmr1BFb2YDBTD2YStNkGaONXQC1BgCqjQRk9cP+bmZrdFtm6jCNNkeXNQiS1b2rNCawujGELC9gdJ8yqj0GelKNX2U51W2p3lNGewdkow8ioiDHwpiISAMsjImINMDCmIhIA9om8MLCwtwq5WUJJM9Ke6OV/4C8Yt8zMWF1kkPlpXRZXFb2RmXmmFSSIVb2iNUQz0SKv3uFk11L1QYwVvagpnrOVJLHZq6JvxuyqJwzM999o6y+z/hkTESkARbGREQaYGFMRKQBFsZERBrQNoHn2XrJ6BA/ZirxA9GazDM21d7SVIeEMprAMHr+VVv4yai0UASMt/Yy2nJMRja4rKwFnsp9YCbJpNoqzMrWjf4+JqPbM5osVd0eW+AREZ2DWBgTEWmAhTERkQZYGBMRaUDbBJ4nlRZsZlopGaWaIFTtbtJznkrLQEC9i06j58NoAkY1CadKpUtR1fOjei48ty9bT7WLUaOsTGaaYbT1ZyCG0JLxdws8M8fNJ2MiIg2wMCYi0gALYyIiDbAwJiLSQNAk8Pw9HprRcbZUW/TI4pe1mvNMCqgk+RralqwFmJVUzpnqGH5mEiue66okVnyJw2hrL9VkmmcrS9k583diTsbMd0eFalJS5ZqYuad0SHQDfDImItICC2MiIg2wMCYi0kDQ1BkbrYsxMxyLlUMgyVhZpyvblr9ftJdt37P3surqaqX1rKxHttvtXvOqqqosi8NMrLJ1Pa9dUzSQ8Pe9rcLKBllmzr/ROKysawb4ZExEpAUWxkREGvCpMM7Pz8eVV16J5s2bo3Xr1hg6dCgKCwvdlqmsrERubi5atmyJmJgYDB8+HCUlJZYGTUR0rvGpMC4oKEBubi62bt2K9evX4/Tp0+jfvz8qKipcy0ycOBErV67E0qVLUVBQgMOHD2PYsGGWB05EdC6xCRO19MeOHUPr1q1RUFCAa6+9Fk6nE61atcLixYtx2223AQC+/fZbdOzYEVu2bMFVV13V6DbLysrgcDjUgld42Vz18FSGLbK6sYLVCQBPVjZkkQ0xI+upTIWZ47byGsiuuWz7siSkJyuH4FE9P1b3GBjMzJwLGauSekIICCHgdDoRGxt79nUN7fG/nE4nAKBFixYAgJ07d+L06dPIyspyLZOWlob27dtjy5YtZnZFRHROM/xqW11dHSZMmIDevXujS5cuAIDi4mJEREQgLi7ObdmEhAQUFxdLt1NVVeX22lFZWZnRkIiIgpbhJ+Pc3Fzs2bMHS5YsMRVAfn4+HA6Ha2rXrp2p7RERBSNDhfHYsWOxatUqbNq0CW3btnXNT0xMRHV1NUpLS92WLykpQWJionRbkyZNgtPpdE2HDh0yEhIRUVDzqZpCCIFx48Zh+fLl2Lx5M1JTU90+T09PR3h4ODZu3Ijhw4cDAAoLC3Hw4EFkZmZKt2m326Utpmw2m1ulvJXD/si2pTJsjmoMqskclSSBmeSLSgsz1V7KrGyNpRq/SlLVDCuHSjLTAkylpztVwZSsU+3tzWivearLBeLelvGpMM7NzcXixYvx4Ycfonnz5q56YIfDgaioKDgcDtx3333Iy8tDixYtEBsbi3HjxiEzM1PpTQoiovOW8AEA6TR//nzXMqdOnRIPP/ywiI+PF82aNRO33nqrOHLkiPI+nE6nACBsNpsICQlxTTabzdB05jbOti3ZcRldLzQ01Gtq6Nw1NsniN7qt+vPaWPwq6/myrtEpPDzca/L3Po2eb9X1rDyPqve7v8+ZlfH7+z4LxH0MQDidzkbLPlPvGftD/XvGVlVTmOlAXKWaQjYvEO+cqjI6eq3V71ir8Hc1hYzR8231u8EqVN8RPx+qKczssymKQL+/Z0xERNbQtgtNlSdjz3lWPxV4PuGqPpXJnoJVE4mex2CmZZqM5z5Vn+KNPlGoPjHKlvP3U7DR+0V1PX8/hancP6r8nfiTbV8Wq7+Hl1L5C7ih5TznqQx15sv15pMxEZEGWBgTEWmAhTERkQZYGBMRaUDbBJ6R5IFqQkO1Ut3KBJJqHJ4JNdWuK1VfsfM8r/5OmMiuo5lX/3RoYWZl4kxG5bo1FIfquTDa0tDo90k1LqP3hpnvudH7x+oEM5+MiYg0wMKYiEgDLIyJiDSgbZ0x4F4PFBbWeKiyOhzZi9myYXRU6qpUXvIG1F9mV2nOKtu+LFZZ/ZiVdW1G6yJl65mppzbaKEO1/lClcYJq/a1qYwLP5fxdjw8Yrye1stGKat240eHVdBneSxWfjImINMDCmIhIAyyMiYg0wMKYiEgDWifwzqwwl1X2V1ZWNroNMz2tGd2WrPJfNfnnuQ+jjTlUWd2fsb8TbFZS7Z9apQ9oXfozllGJNxB9HlvZP7jqd+7Mkeh1wydjIiINsDAmItIAC2MiIg2wMCYi0oDWCbwzqbSaa4qWSypkyRArkzmqx2l0+2aSTCrXRLXXM1lSTOXYrU4GWtkrmWqLUE9WtybzXFe1tzTVOFTuA9X4jX6vzSTrVL4DViei+WRMRKQBFsZERBpgYUxEpAEWxkREGgiaBJ7RrvXMVLJ7JlusHmZFJZEli191KCYrkxCqLQhVWkbJukOVxW80UWkqiaLQhabR7lABebJOZQgkMy3kVK6x1UMUqVw7K4fQ0qUFpxl8MiYi0gALYyIiDbAwJiLSAAtjIiINBE0CT0Zl7DCjXfIB1nYrKEuAyZJWKgk21bH+VJJ6qkkI2bZUxnhTHZvPTDLHaKtCGSu7ALU6KabCaMJadVxF1USlSgLP6LiKvqxrVCC6guWTMRGRBlgYExFpgIUxEZEGWBgTEWlA2wReSEiIWwW5aiJIth0j6/mynJXbUk00GV3PylZDRpMo/k6+qCZWjJ5r1W2ptjRUoZp0NjpmomqC1sprp9LaEVBL+AZiDD8zZYt0e2aCISIia7AwJiLSgE+F8dy5c9GtWzfExsYiNjYWmZmZWLNmjevzyspK5ObmomXLloiJicHw4cNRUlJiedBEROcam/ChEnHlypUIDQ1Fhw4dIITAO++8g+nTp2PXrl3o3LkzxowZg9WrV2PBggVwOBwYO3YsQkJC8NlnnykHVFZWBofDobSsSq9qgXhhXLV+z0pWv4BODbP6+npeO9W6SJXe3gBrGzCoNPRpaF5TM/OdsGrIsvp1nE4nYmNjz76yMCk+Pl689dZborS0VISHh4ulS5e6Pvvmm28EALFlyxbl7TmdTgFAaQoPD3ebZMuEhIR4TarbNzqFhoZ6Tf7ep81m85r8vc/zdbL6+npeN9Xty+5to/e76v0j276u956ZuIyu29A6Tqez0bLPcJ1xbW0tlixZgoqKCmRmZmLnzp04ffo0srKyXMukpaWhffv22LJlS4PbqaqqQllZmdtERHS+8bkw/uqrrxATEwO73Y6HHnoIy5cvR6dOnVBcXIyIiAjExcW5LZ+QkIDi4uIGt5efnw+Hw+Ga2rVr5/NBEBEFO58L48suuwy7d+/Gtm3bMGbMGOTk5GDv3r2GA5g0aRKcTqdrOnTokOFtEREFK58bfUREROCSSy4BAKSnp2P79u147bXXcOedd6K6uhqlpaVuT8clJSVITExscHt2ux12u73R/aoONeQpEC+D+ztZ5+8EoZVJT6MNKxqKQ0iSKEZjU+3pzqr9AWrXTnaMZq65SqMPVbLYrGzcokql0YcsVlWydVX2aSZpaPo947q6OlRVVSE9PR3h4eHYuHGj67PCwkIcPHgQmZmZZndDRHRO8+nJeNKkSRg4cCDat2+P8vJyLF68GJs3b8a6devgcDhw3333IS8vDy1atEBsbCzGjRuHzMxMXHXVVf6Kn4jonOBTYXz06FHcc889OHLkCBwOB7p164Z169ahX79+AIBXX30VISEhGD58OKqqqpCdnY05c+b4JXAionOJT40+mkJDjT4C0ZBCV6wzdtfUdcZm6gVVrp2ZDnRU96lyzmTH5O8OkVQFoqMglX16LiOEgBBCqdGHtr22eTJa2KgOE6NyMVULKdmXXLac0d6o/P1LSPVLqHIeVZNRKjc2YO2XvKamxmueyi8PM4Wx0ULQTGEju18iIiLcflY9r7LYrBzeS5XRVoVmelrzPAarW/eyoyAiIg2wMCYi0gALYyIiDbAwJiLSQNAk8FSSJmay0CpZbtXKedVkiNFEouq2ZFQSKapJN6NJGdn5l8Xv74y80fhVz7XR4Z9U4zL6NggAVFdXW7YtleO0MpFuhpnhzzyPyeqkJJ+MiYg0cN4WxqEAngaw7r//hur1ujURnWeCpprCak8BeAa//jbKAhAiBKaaaKBARGTGeftkfA3+d/AhAHrzyZiIAiion4xVxgA7deqU17xu3bqh8PhxZB0/jhAAdQD+Ce/KfStbERlNkKgmJVW7EDTajFS1VZhKcku2LdVza9XYZA2tp9KqSvWcqe5TJdklY2Uyykyy1GhS2MprrpoglDXdlrXEDEQvEUFdGJvxl5YtAQBX/Oc/+KJZM7xw/HiAIyKi89l5WxjX2myYc8EF//uZhTERBdB5W2dMRKSToHkyNlpv5Nk7lS+srDcyWidndLgpq1n5Mr6Z3q6MXhMzvap53lcquYqGljPaO6BqQxmjzDT6sJKVPaHJ1jNT3++JjT6IiM5BLIyJiDTAwpiISAMsjImINBA0CTyVxIqZcchUG014stvtXvNkL5EbHSpJNYmi2qualcNLyfj7ZXmV2KxORnnuU3U4KNVz5nntVO8V1UY3KtdE9fxYPdSQ0W0ZPWdmhswy0rjIl+8Dn4yJiDTAwpiISAMsjImINMDCmIhIA0GTwJNRqRyXJXOs7KWpqqpKaTkrh0VSHUrKKH8PfWO0t7SG5nmeD1kyysxQSSrnVrVVnkpS1UwPc6r7NMrKpKGZ74TKNVEZSg0wnvC1PFFseE0iIrIMC2MiIg2wMCYi0gALYyIiDQR1Ak+FLFknY7Q7QllyQZY4kDGadDOTkLFyKCkrmUka+jtB5clMd5ZWJn3MnDOj94Hq8EZGE3hWJghVGe1W0+pEN5+MiYg0wMKYiEgDLIyJiDTAwpiISAPnVALPTEW/lV0DyhI8su3L5qnE6+8Eniwu1WSLyriEZpJFVo6Bp5p08zwfRrtbBeTJOpXtq8TVEKPxqn4nwsK8ixGVY/B3S08zXZHKeJ4zK1u9AnwyJiLSAgtjIiINmCqMX3zxRdhsNkyYMME1r7KyErm5uWjZsiViYmIwfPhwlJSUmI2TiOicZrjOePv27fjLX/6Cbt26uc2fOHEiVq9ejaVLl8LhcGDs2LEYNmwYPvvsM5/3cWadnkqdpWr9p+pwRJ7rWjk8S0P7VKHaG5XRfQbixXt/U61fldV/Wl036Eml1zYz97GM5z2k2kOejEqjFdX7x8r7TPWcqTZk8TwfVg9BZejJ+OTJkxg5ciTefPNNxMfHu+Y7nU68/fbbeOWVV3DjjTciPT0d8+fPx7/+9S9s3brVcJBEROc6Q4Vxbm4uBg8ejKysLLf5O3fuxOnTp93mp6WloX379tiyZYt0W1VVVSgrK3ObiIjONz5XUyxZsgRffPEFtm/f7vVZcXExIiIiEBcX5zY/ISEBxcXF0u3l5+fj2Wef9TUMIqJzik9PxocOHcL48eOxaNEiREZGWhLApEmT4HQ6XdOhQ4cs2S4RUTDx6cl4586dOHr0KK644grXvNraWnzyySeYNWsW1q1bh+rqapSWlro9HZeUlCAxMVG6TbvdDrvdLv3szMp21QSMJzMV6kaHwzHTG5XK9s0klFQaGBjtwU62rpkkXyB65lJZLiIiwmueLIlltMGRajLNzPkxeg8ZTVqZSX4bTeqpJOUb2pbR7ZvhU2Hct29ffPXVV27z7r33XqSlpeGJJ55Au3btEB4ejo0bN2L48OEAgMLCQhw8eBCZmZnWRU1EdI7xqTBu3rw5unTp4jYvOjoaLVu2dM2/7777kJeXhxYtWiA2Nhbjxo1DZmYmrrrqKuuiJiI6x1jeN8Wrr76KkJAQDB8+HFVVVcjOzsacOXOs3g0R0TnFJjR7c7+srAwOh8NrvpmGDlax+sV1o3XGZlhZZ6xyTJrdXpYIRJ2xLo1urG7ooCIQDUGsPrdOpxOxsbFnXSZoem1TKXjN3CgqF1z1pjCTrPA8Btk+Za3EqqurG92Wamy6JN2M8neBITvXZgRTYWZlIlqVyrqqD2uq8au8MMBhl4iIzkEsjImINMDCmIhIAyyMiYg0EDQJPJUkhNVvBngyU2FvNImimqyTJTCaIktsFSuTbmaGdQpE14kqzLy1o3I+zCT5dLinZMk6M+dH5XzL3qoxk9zlkzERkQZYGBMRaYCFMRGRBlgYExFpIGgSeFY2f/R3c9Pw8HCveTU1NYZis3JsO6v5u2WX0X2aSTzp0sTYk+WtvRSaYMvo0ixbhex7KEuwybrwVWnerjL2ny/4ZExEpAEWxkREGmBhTESkARbGREQa0DaBZ7PZ3JIFKpXxZsaLU+luUjV5IUvWqY6L5xmHassio9u3ugtQFYFo7aXz2Gee25O1plQ9Z7LviZm+llUYbZFo5TWRnTPV1nCqy/k7UcknYyIiDbAwJiLSAAtjIiINBE2dsUq9jtV1kZ7bk9Vxyep0zdQtqdS1WVnPa3ScNtU4AtHoRjVW1etpdPuyeSq965m5vqoNEays71ftGdGTlXXvqsej2ruhmX0YxSdjIiINsDAmItIAC2MiIg2wMCYi0oC2CTyVyn3PxIGZCnaVdVUbkBjdPqCWNDQzvJTncv7uFU51PTPDChndp9Hrqbp91WF5PI/T6LUE/J9kkh277Dg9z62/E7mqx22mEZi/8cmYiEgDLIyJiDTAwpiISAMsjImINKBtAk9FU/fgJWu9I0sImGmh5TlPNeEQiB7UZDzPkZlWVroek+z6ylq+GR2Wx0zSU8bfiT6V4/T3sE5WJy6N3rdmXirgkzERkQZYGBMRaYCFMRGRBlgYExFpIGgSeEYr9lWHI1JhdWs1le4IrR7ix5NqgkF1OB+jLa9Uk54qSVQziS0Zz+1b3arQypakqnEYZXSIJVWqXXT6O7kbiEQin4yJiDTAwpiISAM+FcbPPPOMawSO+iktLc31eWVlJXJzc9GyZUvExMRg+PDhKCkpsTxoIqJzjc9Pxp07d8aRI0dc06effur6bOLEiVi5ciWWLl2KgoICHD58GMOGDbM0YCKic5HPCbywsDAkJiZ6zXc6nXj77bexePFi3HjjjQCA+fPno2PHjti6dSuuuuoqU4EGorvAQCRWjCYlrYxNtn0rW5Opdk8oi8NMN6ZGecZrdVetVl5zM8upUE3WeZ4zo+sBatdc9bh1Ge9Oxucn43379iE5ORkXXXQRRo4ciYMHDwIAdu7cidOnTyMrK8u1bFpaGtq3b48tW7Y0uL2qqiqUlZW5TURE5xufCuOMjAwsWLAAa9euxdy5c1FUVIQ+ffqgvLwcxcXFiIiIQFxcnNs6CQkJKC4ubnCb+fn5cDgcrqldu3aGDoSIKJj5VE0xcOBA1/+7deuGjIwMpKSk4K9//SuioqIMBTBp0iTk5eW5fi4rK2OBTETnHVONPuLi4nDppZfi+++/R79+/VBdXY3S0lK3p+OSkhJpHXM9u90Ou90u/ezMeiCjdTj+HorJ3y/Bm2G0UYmpF9cV6gqtPj9G6/YDUS9olJk6UZUGNarnQvV+95ynGr/R3IQqM99XlR4JA9bo4+TJk9i/fz+SkpKQnp6O8PBwbNy40fV5YWEhDh48iMzMTDO7ISI65/n0ZPzYY49hyJAhSElJweHDhzFlyhSEhoZixIgRcDgcuO+++5CXl4cWLVogNjYW48aNQ2Zmpuk3KYiIznU+Fcb//ve/MWLECPz8889o1aoVrrnmGmzduhWtWrUCALz66qsICQnB8OHDUVVVhezsbMyZM8cvgRMRnUtsQrOKs7KyMjgcDgCNvwupQ+iBqDM28y6pvzsiMvp+qRn+fh9c5Z1cf9+LZu6zQNQZewrEu/Gq9edNUWfsdDoRGxt71u1r3WvbmQdm9CV1mUA0IJGR9YSm0kOYlb1MmelVzcoEhur1NfMiv8o+A7F9FWZ6ArTyF6JsWyrHaabhiZWNYowWvID/GxyxoyAiIg2wMCYi0gALYyIiDbAwJiLSgNYJvDOpJAACkYQzkxyxsrVRWJj3pVTZvix+1SGWZDyvgZkkmZVJ20Awej+aSR6pvkHgycx9rDI8lix+K7+vgRiqyuoXAfhkTESkARbGREQaYGFMRKQBFsZERBoImgSeSpNOq4emsWq9plBTU2PZtqxMLPq7C9NAUG2NaPR+aYqhpVS+O0a3BTT98FiBSOBZvU8+GRMRaYCFMRGRBlgYExFpgIUxEZEGgiaBp9I1oEqSz+oYjLZ8s5rsOFW66FQ9P0aTo2YSqP5OmBrt79bKrh9VmTkXKslFM/0Z65BotTqparRFKFvgEREFORbGREQaYGFMRKQBbeuMQ0JC3OpoVF4iV+15SnVYIc/6H9l6TTHGm1Gyc6YSr5Xj+lndmMAo1WNSOU5/j7FnZugko3WiZurxjQ4fpsrosE4yKj3MAf7vZU6GT8ZERBpgYUxEpAEWxkREGmBhTESkAW0TeCoV/lYOu2Rkfw3NszJZYbRhQkPreiYrZMtYOQSPLj3dBdMQP00x3JTKUEz+7o3NTAMMlWGdZMwMaeVvfDImItIAC2MiIg2wMCYi0gALYyIiDWibwPNkNBEkax0kG6LI6Pb93TJKdZ9Wxm8m6WZlUtVKgRiSS5YkkyWLjJ4zq3tys3KfKj3dqcZqZdLNTAs8z2NQvb6q+GRMRKQBFsZERBpgYUxEpAEWxkREGgiaBJ7RJIrqEEgqLd3MdNMnG57JymSOajJKJcFgJummsq6/W0GptC4DrG0daGVrNdUYrBzyy2gSC/B/t6NGz6NqrLJjV9meLC5ZmaE8pJXSUkRE5FcsjImINOBzYfzTTz9h1KhRaNmyJaKiotC1a1fs2LHD9bkQApMnT0ZSUhKioqKQlZWFffv2WRo0EdG5xqfC+MSJE+jduzfCw8OxZs0a7N27Fy+//DLi4+Ndy0ybNg0zZ87EvHnzsG3bNkRHRyM7OxuVlZWWBx8UamqA557Dmtpa/LGuDqGaNIIgIs0IHzzxxBPimmuuafDzuro6kZiYKKZPn+6aV1paKux2u3jvvfeU9uF0OgUArykkJMRrCg0NbXSSrSfbvmxdz2VsNpvXJNtW69atXdOL0dGiFhACELWAeFqy/Nkm1fhlsanGqzJZuS3VY5JN4eHhXlNTH5MsfivPz/kymbm3rbw/ZetaeZ8BEE6ns9Gyz6cn47///e/o2bMnbr/9drRu3RqXX3453nzzTdfnRUVFKC4uRlZWlmuew+FARkYGtmzZIt1mVVUVysrK3KZzSUZ1tevPjxAA1wQyGCLSlk+F8Q8//IC5c+eiQ4cOWLduHcaMGYNHHnkE77zzDgCguLgYAJCQkOC2XkJCguszT/n5+XA4HK6pXbt2Ro5DW9siIlD/Mk0dgE8DGQwRacun94zr6urQs2dPvPDCCwCAyy+/HHv27MG8efOQk5NjKIBJkyYhLy/P9XNZWdk5VSC/1qwZAODyigp8CuCFwIZDRJry6ck4KSkJnTp1cpvXsWNHHDx4EACQmJgIACgpKXFbpqSkxPWZJ7vdjtjYWLfpXFJrs+GV6GhkA/gTAD0GeCEi3fj0ZNy7d28UFha6zfvuu++QkpICAEhNTUViYiI2btyIHj16APj1SXfbtm0YM2aMqUCFhd1ByljZMu3o0aNKy6mwcjw6M6xsrWbmmMys60kWv8r4grIWW7KWb7LljN7HMsHe1amVx2kmftm6Ki0ZZfeKqbiUXnH4r88//1yEhYWJ559/Xuzbt08sWrRINGvWTCxcuNC1zIsvviji4uLEhx9+KL788ktxyy23iNTUVHHq1ClTb1PIMp5WZWLPhcnfx2nmDQgrJ5W3Xvx9nKqZdtW3e4yeVyvfIAj0/RsM955KXA2dV5W3KXwqjIUQYuXKlaJLly7CbreLtLQ08cYbb7h9XldXJ55++mmRkJAg7Ha76Nu3rygsLFTePgtjYxML46Y7ThbGTTvpcu+pxGWmMLYJoVcrhLKyMjgcDq/5sj9VPOdZPWpFMPH3car8+d4UAtHJkOdxykaPYTWF/+hy73nypZrC6XQ2mg8Lml7bZIz2FqXLxVXpXUw1Liu/TEZ75joXqBynrOBVHd5L5TqZuT9lvwBk66rEEYhf8Kr7VOlRUTVW2bVT+QVv9XeCHQUREWmAhTERkQZYGBMRaYCFMRGRBoImgac6lI4n1Uy7SuJANYuuysokitEMv5VvIsiovAUDqCdDZPH6+5hU3jxQbVwkW87z3jZzz6qcH9lyVr6ZobqumQSY5zGZ2ZbR77DVjT74ZExEpAEWxkREGmBhTESkAe3qjBuqY7HyZXOjL4hb3UrJ38dkdLlAxKXzPoyeMyuviZn1/H3NA9F6T4cWg75cc5V4tSuMy8vLpfP93VuXClmLKl2oxqZDSzqrv0g6HJOZRK7R+FXPow7nx2o6HJMv93F5ebm0m4czadc3RV1dHQ4fPozmzZujvLwc7dq1w6FDh4Kyn+P6jvIZf2Aw/sAK9vgB88cghEB5eTmSk5MbfSNMuyfjkJAQtG3bFsD/XpkJ9k7nGX9gMf7ACvb4AXPH0NgTcT0m8IiINMDCmIhIA1oXxna7HVOmTIHdbg90KIYw/sBi/IEV7PEDTXsM2iXwiIjOR1o/GRMRnS9YGBMRaYCFMRGRBlgYExFpQNvCePbs2bjwwgsRGRmJjIwMfP7554EOqUGffPIJhgwZguTkZNhsNqxYscLtcyEEJk+ejKSkJERFRSErKwv79u0LTLAe8vPzceWVV6J58+Zo3bo1hg4disLCQrdlKisrkZubi5YtWyImJgbDhw9HSUlJgCJ2N3fuXHTr1s31Un5mZibWrFnj+lzn2GVefPFF2Gw2TJgwwTVP92N45plnYLPZ3Ka0tDTX57rHDwA//fQTRo0ahZYtWyIqKgpdu3bFjh07XJ83xXdYy8L4/fffR15eHqZMmYIvvvgC3bt3R3Z2No4ePRro0KQqKirQvXt3zJ49W/r5tGnTMHPmTMybNw/btm1DdHQ0srOzUVlZ2cSReisoKEBubi62bt2K9evX4/Tp0+jfvz8qKipcy0ycOBErV67E0qVLUVBQgMOHD2PYsGEBjPp/2rZtixdffBE7d+7Ejh07cOONN+KWW27B119/DUDv2D1t374df/nLX9CtWze3+cFwDJ07d8aRI0dc06effur6TPf4T5w4gd69eyM8PBxr1qzB3r178fLLLyM+Pt61TJN8h4WGevXqJXJzc10/19bWiuTkZJGfnx/AqNQAEMuXL3f9XFdXJxITE8X06dNd80pLS4XdbhfvvfdeACI8u6NHjwoAoqCgQAjxa6zh4eFi6dKlrmW++eYbAUBs2bIlUGGeVXx8vHjrrbeCKvby8nLRoUMHsX79enHdddeJ8ePHCyGC4/xPmTJFdO/eXfpZMMT/xBNPiGuuuabBz5vqO6zdk3F1dTV27tyJrKws17yQkBBkZWVhy5YtAYzMmKKiIhQXF7sdj8PhQEZGhpbH43Q6AQAtWrQAAOzcuROnT592iz8tLQ3t27fXLv7a2losWbIEFRUVyMzMDKrYc3NzMXjwYLdYgeA5//v27UNycjIuuugijBw5EgcPHgQQHPH//e9/R8+ePXH77bejdevWuPzyy/Hmm2+6Pm+q77B2hfHx48dRW1uLhIQEt/kJCQkoLi4OUFTG1cccDMdTV1eHCRMmoHfv3ujSpQuAX+OPiIhAXFyc27I6xf/VV18hJiYGdrsdDz30EJYvX45OnToFRewAsGTJEnzxxRfIz8/3+iwYjiEjIwMLFizA2rVrMXfuXBQVFaFPnz4oLy8Pivh/+OEHzJ07Fx06dMC6deswZswYPPLII3jnnXcANN13WLte2yhwcnNzsWfPHrf6vmBw2WWXYffu3XA6nVi2bBlycnJQUFAQ6LCUHDp0COPHj8f69esRGRkZ6HAMGThwoOv/3bp1Q0ZGBlJSUvDXv/4VUVFRAYxMTV1dHXr27IkXXngBAHD55Zdjz549mDdvHnJycposDu2ejC+44AKEhoZ6ZVtLSkqQmJgYoKiMq49Z9+MZO3YsVq1ahU2bNrm6MAV+jb+6uhqlpaVuy+sUf0REBC655BKkp6cjPz8f3bt3x2uvvRYUse/cuRNHjx7FFVdcgbCwMISFhaGgoAAzZ85EWFgYEhIStD8GT3Fxcbj00kvx/fffB8U1SEpKQqdOndzmdezY0VXV0lTfYe0K44iICKSnp2Pjxo2ueXV1ddi4cSMyMzMDGJkxqampSExMdDuesrIybNu2TYvjEUJg7NixWL58OT7++GOkpqa6fZ6eno7w8HC3+AsLC3Hw4EEt4pepq6tDVVVVUMTet29ffPXVV9i9e7dr6tmzJ0aOHOn6v+7H4OnkyZPYv38/kpKSguIa9O7d2+t1zu+++w4pKSkAmvA7bFkq0EJLliwRdrtdLFiwQOzdu1c88MADIi4uThQXFwc6NKny8nKxa9cusWvXLgFAvPLKK2LXrl3ixx9/FEII8eKLL4q4uDjx4Ycfii+//FLccsstIjU1VZw6dSrAkQsxZswY4XA4xObNm8WRI0dc03/+8x/XMg899JBo3769+Pjjj8WOHTtEZmamyMzMDGDU//Pkk0+KgoICUVRUJL788kvx5JNPCpvNJj766CMhhN6xN+TMtymE0P8YHn30UbF582ZRVFQkPvvsM5GVlSUuuOACcfToUSGE/vF//vnnIiwsTDz//PNi3759YtGiRaJZs2Zi4cKFrmWa4jusZWEshBCvv/66aN++vYiIiBC9evUSW7duDXRIDdq0aZMA4DXl5OQIIX59Nebpp58WCQkJwm63i759+4rCwsLABv1fsrgBiPnz57uWOXXqlHj44YdFfHy8aNasmbj11lvFkSNHAhf0GX7729+KlJQUERERIVq1aiX69u3rKoiF0Dv2hngWxrofw5133imSkpJERESEaNOmjbjzzjvF999/7/pc9/iFEGLlypWiS5cuwm63i7S0NPHGG2+4fd4U32F2oUlEpAHt6oyJiM5HLIyJiDTAwpiISAMsjImINMDCmIhIAyyMiYg0wMKYiEgDLIyJiDTAwpiISAMsjImINMDCmIhIAyyMiYg08P8BtTtoXHyzeCcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_midpoints(image, probability_vector, midpoints, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Visualizes midpoints on an image based on a probability vector.\n",
    "\n",
    "    Parameters:\n",
    "    - image: A 3D tensor representing the image.\n",
    "    - probability_vector: A 1D tensor representing the probabilities associated with midpoints.\n",
    "    - midpoints: A 2D tensor representing the midpoint coordinates (x, y).\n",
    "    - threshold: Probability threshold for visualization.\n",
    "\n",
    "    Returns:\n",
    "    None (displays the image with midpoints).\n",
    "    \"\"\"\n",
    "    # Convert to NumPy arrays for easier handling\n",
    "    image_np = image\n",
    "    prob_vector_np = probability_vector\n",
    "    midpoints_np = midpoints#.numpy() if hasattr(midpoints, 'numpy') else midpoints\n",
    "\n",
    "    # Denormalize image if necessary (adjust based on your normalization method)\n",
    "    denormalized_image = image_np  # Modify if normalization was applied during training\n",
    "\n",
    "    # Visualize the image\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(denormalized_image, cmap='gray')\n",
    "    plt.title(\"Predicted Midpoint Visualization\")\n",
    "\n",
    "    # Plot midpoints based on probability threshold\n",
    "    for i, (y,x) in enumerate(midpoints_np):\n",
    "        prob = prob_vector_np[i]\n",
    "        if prob > threshold:\n",
    "            plt.scatter(y,x, color='red', s=5)\n",
    "            # if i == 0:  # Add label only once to avoid repetition in the legend\n",
    "            #     plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "t = np.random.randint(0,500)\n",
    "# t=7\n",
    "visualize_midpoints(tf.convert_to_tensor(inputs[t]), probabilities[t].numpy().squeeze(), tf.convert_to_tensor(output[1][t,0,:,:])*[64,64]) ##myprediction   \n",
    "\n",
    "def visualize_midpoints2(image, probability_vector, midpoints, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Visualizes midpoints on an image based on a probability vector.\n",
    "\n",
    "    Parameters:\n",
    "    - image: A 3D tensor representing the image.\n",
    "    - probability_vector: A 1D tensor representing the probabilities associated with midpoints.\n",
    "    - midpoints: A 2D tensor representing the midpoint coordinates (x, y).\n",
    "    - threshold: Probability threshold for visualization.\n",
    "\n",
    "    Returns:\n",
    "    None (displays the image with midpoints).\n",
    "    \"\"\"\n",
    "    # Convert to NumPy arrays for easier handling\n",
    "    image_np = image\n",
    "    prob_vector_np = probability_vector\n",
    "    midpoints_np = midpoints#.numpy() if hasattr(midpoints, 'numpy') else midpoints\n",
    "\n",
    "    # Denormalize image if necessary (adjust based on your normalization method)\n",
    "    denormalized_image = image_np  # Modify if normalization was applied during training\n",
    "\n",
    "    # Visualize the image\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(denormalized_image, cmap='gray')\n",
    "    plt.title(\"Ground Truth Midpoint Visualization\")\n",
    "\n",
    "    # Plot midpoints based on probability threshold\n",
    "    for i, (y,x) in enumerate(midpoints_np):\n",
    "        prob = prob_vector_np[i]\n",
    "        if prob > threshold:\n",
    "            plt.scatter(y, x, color='red', s=5)\n",
    "            # if i == 0:  # Add label only once to avoid repetition in the legend\n",
    "            #     plt.legend()\n",
    "\n",
    "    plt.show()     \n",
    "visualize_midpoints2(tf.convert_to_tensor(inputs[t]), probabilities[t].numpy().squeeze(), tf.convert_to_tensor(center_coordinates_np[t,0,:,:])*[64,64]) ##ground truth          \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.05967986, 0.8164797 ],\n",
       "         [0.92239034, 0.707018  ],\n",
       "         [0.63721967, 0.81380445],\n",
       "         [0.2583384 , 0.6136362 ],\n",
       "         [0.27701148, 0.79301757],\n",
       "         [0.25320438, 0.76317984],\n",
       "         [0.56444603, 0.3609054 ],\n",
       "         [0.45196205, 0.7908605 ],\n",
       "         [0.43175274, 0.44677556],\n",
       "         [0.57788014, 0.5339317 ],\n",
       "         [0.52479625, 0.3910867 ],\n",
       "         [0.53623533, 0.51333076]]], dtype=float32),\n",
       " <tf.Tensor: shape=(1, 12, 2), dtype=float64, numpy=\n",
       " array([[[0.0546875, 0.8359375],\n",
       "         [0.9296875, 0.6953125],\n",
       "         [0.       , 0.       ],\n",
       "         [0.       , 0.       ],\n",
       "         [0.       , 0.       ],\n",
       "         [0.       , 0.       ],\n",
       "         [0.       , 0.       ],\n",
       "         [0.       , 0.       ],\n",
       "         [0.       , 0.       ],\n",
       "         [0.       , 0.       ],\n",
       "         [0.       , 0.       ],\n",
       "         [0.       , 0.       ]]])>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[1][3],targets['x_midpoints_reshape'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5167, Recall: 1.0, F1 Score: 0.6813476626887321, MAE: 0.2895562349019795, MSE: 0.15725937873580795\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_model(predictions, ground_truths, probability_threshold=0.9, midpoint_diff_threshold=0.05):\n",
    "    pred_probabilities = predictions[0]\n",
    "    pred_midpoints = predictions[1]\n",
    "    gt_probabilities = ground_truths[0]\n",
    "    gt_midpoints = ground_truths[1]\n",
    "    \n",
    "    # Valid predictions are those above the probability threshold\n",
    "    valid_predictions = pred_probabilities > probability_threshold\n",
    "    no_predictions = pred_probabilities <= probability_threshold\n",
    "\n",
    "    # Calculate differences for midpoint evaluations\n",
    "    midpoint_diff = np.abs(pred_midpoints - gt_midpoints)\n",
    "    is_accurate_prediction = np.all(midpoint_diff <= midpoint_diff_threshold, axis=1)\n",
    "    \n",
    "    # True Positives: Valid predictions close enough to the ground truth\n",
    "    TP = np.sum(np.logical_and(valid_predictions, is_accurate_prediction))\n",
    "    \n",
    "    # False Positives: Valid predictions not close enough to the ground truth\n",
    "    FP = np.sum(np.logical_and(valid_predictions, ~is_accurate_prediction))\n",
    "    \n",
    "    # True Negatives: No predictions where no objects are actually present\n",
    "    TN = np.sum(np.logical_and(no_predictions, gt_probabilities <= probability_threshold))\n",
    "    \n",
    "    # False Negatives: No predictions where objects are actually present\n",
    "    FN = np.sum(np.logical_and(no_predictions, gt_probabilities > probability_threshold))\n",
    "    \n",
    "    # Metrics calculation\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    F1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    MAE = np.mean(midpoint_diff)\n",
    "    MSE = np.mean(np.square(midpoint_diff))\n",
    "    \n",
    "    return precision, recall, F1_score, MAE, MSE\n",
    "\n",
    "# Usage \n",
    "predictions = [output[0][0:800], output[1][0:800]]\n",
    "ground_truths = [targets['x_prob_reshape'][0:800], targets['x_midpoints_reshape'][0:800]]\n",
    "precision, recall, F1_score, MAE, MSE = evaluate_model(predictions, ground_truths)\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F1 Score: {F1_score}, MAE: {MAE}, MSE: {MSE}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "objectdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
