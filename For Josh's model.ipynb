{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Set CUDA device order and visible devices\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7,8,9\"\n",
    "\n",
    "# # Set the device\n",
    "# device = '/cpu:0'\n",
    "# if tf.config.experimental.list_physical_devices('GPU'):\n",
    "#     try:\n",
    "#         # Restrict TensorFlow to only use the second GPU\n",
    "#         gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#         if gpus:\n",
    "#             tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "#             device = '/gpu:0'\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)\n",
    "\n",
    "# print(\"device\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:13:50.132595: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-09 01:13:50.148196: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-09 01:13:50.161925: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-09 01:13:50.166082: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-09 01:13:50.179305: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-09 01:13:50.823299: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:7',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:13:52.045601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79196 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:c9:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"  # Only GPUs 0 and 1 will be visible to TensorFlow\n",
    "\n",
    "# import tensorflow as tf\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:4\"])\n",
    "# # strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"  # Only GPUs 0 and 1 will be visible to TensorFlow\n",
    "\n",
    "import tensorflow as tf\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:7\"])\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# DataLoader Class Definition\n",
    "# -----------------------------\n",
    "class DataLoader:\n",
    "    def __init__(self, h5_filename):\n",
    "        self.h5_filename = h5_filename\n",
    "        self.images, self.centers = self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        with h5py.File(self.h5_filename, 'r') as f:\n",
    "            images = np.array(f['images'])\n",
    "            centers = np.array(f['centers_training'])\n",
    "        return images, centers\n",
    "\n",
    "    def plot_image_with_centers(self, image_index=None):\n",
    "        if image_index is None:\n",
    "            image_index = np.random.randint(0, len(self.images))\n",
    "\n",
    "        image = self.images[image_index]\n",
    "        centers = self.centers[image_index]\n",
    "\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        valid_centers = centers[centers[:, 0] == 1]\n",
    "        for center in valid_centers:\n",
    "            plt.scatter(center[1], center[2], c='red', marker='x')  # center[1] is x and center[2] is y\n",
    "        plt.title('Image with Valid Centers Marked')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_centers(centers):\n",
    "        return centers[np.lexsort((centers[:, 0], centers[:, 1]))]\n",
    "\n",
    "    def normalize_data(self):\n",
    "        normalized_images = self.images / np.max(self.images)\n",
    "        sorted_centers = np.array([self.sort_centers(image_centers[:, 1:]) for image_centers in self.centers])\n",
    "        normalized_centers = sorted_centers / 64\n",
    "\n",
    "        normalized_midpoints = tf.expand_dims(normalized_centers, axis=1)\n",
    "        return normalized_images, normalized_midpoints.numpy()\n",
    "\n",
    "    def split_data(self, train_size=0.8, random_state=42):\n",
    "        normalized_images, normalized_midpoints_np = self.normalize_data()\n",
    "        return train_test_split(normalized_images, normalized_midpoints_np, train_size=train_size, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Utility Function Definition\n",
    "# -----------------------------\n",
    "def plot_transposed_images_with_midpoints(dataset, image_indices=[0, 1, 2, 3]):\n",
    "    \"\"\"\n",
    "    Extracts multiple images and their midpoints from the given dataset, transposes the images, \n",
    "    corrects the midpoints, and plots the transposed images with the corrected midpoints.\n",
    "\n",
    "    Args:\n",
    "    - dataset (tf.data.Dataset): The dataset from which to extract the images and midpoints.\n",
    "    - image_indices (list): The indices of the images in the batch to visualize. Default is [0, 1, 2, 3].\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract a sample image batch and its corresponding midpoints from the dataset\n",
    "    sample_image_batch, sample_midpoints_batch = next(iter(dataset))\n",
    "\n",
    "    # Create a figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(6, 6))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(image_indices):\n",
    "            # Select the specified image and corresponding midpoints from the batch\n",
    "            sample_image = np.array(sample_image_batch[image_indices[i]])\n",
    "            sample_midpoints = np.array(sample_midpoints_batch[image_indices[i]])\n",
    "\n",
    "            # Transpose the image\n",
    "            transposed_image = sample_image.T\n",
    "\n",
    "            # Correct the midpoints by swapping the x and y coordinates\n",
    "            transposed_midpoints_corrected = sample_midpoints[:, :, [1, 0]]\n",
    "\n",
    "            # Plot the transposed image with corrected midpoints\n",
    "            ax.imshow(transposed_image, cmap='gray')\n",
    "            ax.scatter(\n",
    "                transposed_midpoints_corrected[:, :, 0] * 64, \n",
    "                transposed_midpoints_corrected[:, :, 1] * 64, \n",
    "                c='red', marker='o', s=5\n",
    "            )\n",
    "            ax.set_title(f'Image {image_indices[i]} for this batch')\n",
    "        else:\n",
    "            ax.axis('off')  # If fewer than 4 images are requested, hide the unused subplots\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Custom Loss and Callback Definitions\n",
    "# -----------------------------\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def custom_loss(exponent):\n",
    "    def loss(y_true, y_pred):\n",
    "        diff = tf.abs(y_true - y_pred)\n",
    "        powered_diff = tf.pow(diff, exponent)\n",
    "        return tf.reduce_mean(powered_diff)\n",
    "    return loss\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class DynamicExponentCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, initial_exponent, increment, update_frequency):\n",
    "        super().__init__()\n",
    "        self.exponent = initial_exponent\n",
    "        self.increment = increment\n",
    "        self.update_frequency = update_frequency\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.update_frequency == 0:\n",
    "            self.exponent += self.increment\n",
    "            print(f\"\\nEpoch {epoch + 1}: Increasing exponent to {self.exponent}\")\n",
    "            self.model.loss = self.custom_loss(self.exponent)\n",
    "\n",
    "    def custom_loss(self, exponent):\n",
    "        def loss(y_true, y_pred):\n",
    "            diff = tf.abs(y_true - y_pred)\n",
    "            powered_diff = tf.pow(diff, exponent)\n",
    "            return tf.reduce_mean(powered_diff)\n",
    "        return loss\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'initial_exponent': self.exponent,\n",
    "            'increment': self.increment,\n",
    "            'update_frequency': self.update_frequency,\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Josh's model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class ModelBuilder:\n",
    "#     def __init__(self, input_shape=(64, 64, 1), num_classes=5, num_coordinates=2, learning_rate=1e-3, weights_path=None):\n",
    "#         self.input_shape = input_shape\n",
    "#         self.num_classes = num_classes\n",
    "#         self.num_coordinates = num_coordinates\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.model = self.build_model()\n",
    "\n",
    "#         # Load weights if a path is provided\n",
    "#         if weights_path is not None:\n",
    "#             self.model.load_weights(weights_path)\n",
    "\n",
    "#         self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "#         # self.optimizer =tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "#     def build_model(self):\n",
    "        \n",
    "        \n",
    "#         x_input = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "#         x_1 = layers.Conv2D(64, kernel_size=6,strides =1, padding='same', activation='relu')(x_input)\n",
    "        \n",
    "#         x_2 = layers.Conv2D(32, kernel_size=8,strides =3, padding='same', activation='relu')(x_input)\n",
    "        \n",
    "#         x_3 = layers.Conv2D(16, kernel_size=19,strides =5, padding='same', activation='relu')(x_input)\n",
    "        \n",
    "        \n",
    "#         x_1 = layers.Flatten()(x_1)\n",
    "#         x_2 = layers.Flatten()(x_2)\n",
    "#         x_3 = layers.Flatten()(x_3)\n",
    "        \n",
    "#         x = layers.Concatenate()([x_1, x_2, x_3])\n",
    "\n",
    "#         x = layers.Dense(256, activation='relu')(x)\n",
    "#         x = layers.Dropout(0.3)(x)\n",
    "#         x = layers.Dense(128, activation='relu')(x)\n",
    "#         x = layers.Dense(64, activation='relu')(x)\n",
    "        \n",
    "        \n",
    "#         x_midpoints = layers.Dense(self.num_classes * self.num_coordinates, activation='sigmoid', name='x_midpoints')(x)\n",
    "#         x_midpoints_reshape = layers.Reshape((-1, self.num_classes, self.num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "        \n",
    "#         return tf.keras.models.Model(x_input, x_midpoints_reshape)\n",
    "\n",
    "#     def compile_model(self, loss_function):\n",
    "#         self.model.compile(optimizer=self.optimizer, loss=loss_function)\n",
    "\n",
    "#     def train_model(self, train_dataset, val_dataset, epochs, callbacks_list):\n",
    "#         history = self.model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks_list)\n",
    "#         return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "\n",
    "class ModelBuilder:\n",
    "    def __init__(self, input_shape=(64, 64, 1), num_classes=13, num_coordinates=2, learning_rate=1e-3, weights_path=None,l1_reg=0.001,l2_reg =0.01):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.num_coordinates = num_coordinates\n",
    "        self.learning_rate = learning_rate\n",
    "        self.l1_reg = l1_reg\n",
    "        self.l2_reg = l2_reg\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        # Load weights if a path is provided\n",
    "        if weights_path is not None:\n",
    "            self.model.load_weights(weights_path)\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "        # self.optimizer =tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "    def build_model(self):\n",
    "        \n",
    "        l1 = regularizers.l1(self.l1_reg)\n",
    "        l2 = regularizers.l2(self.l2_reg)\n",
    "\n",
    "    \n",
    "        x_input = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "        \n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x_input)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        \n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        \n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.3)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.3)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(128, kernel_size=5, padding='same', activation='relu')(x)\n",
    "        # x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Flatten()(x)\n",
    "        \n",
    "        x_midpoints = layers.Dense(self.num_classes * self.num_coordinates, activation='linear', name='x_midpoints')(x)\n",
    "        x_midpoints_reshape = layers.Reshape((-1, self.num_classes, self.num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "        \n",
    "        return tf.keras.models.Model(x_input, x_midpoints_reshape)\n",
    "\n",
    "    def compile_model(self, loss_function):\n",
    "        self.model.compile(optimizer=self.optimizer, loss=loss_function)\n",
    "\n",
    "    def train_model(self, train_dataset, val_dataset, epochs, callbacks_list):\n",
    "        history = self.model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks_list)\n",
    "        return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Main Script Execution\n",
    "# -----------------------------\n",
    "\n",
    "# Load data\n",
    "h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KNoNoiseFixed-index84_13.h5'             \n",
    "\n",
    "data_loader = DataLoader(h5_filename)\n",
    "images, centers = data_loader.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7f4c25d390>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l=np.random.randint(0,len(centers))\n",
    "data_loader.plot_image_with_centers(l)\n",
    "plt.imshow(images[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the data and split it into training and validation sets\n",
    "train_images, val_images, train_midpoints, val_midpoints = data_loader.split_data()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images: (24000, 64, 64), Train Midpoints: (24000, 1, 13, 2)\n",
      "Validation Images: (6000, 64, 64), Validation Midpoints: (6000, 1, 13, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 500\n",
    "train_dataset = train_dataset.shuffle(buffer_size=8000, reshuffle_each_iteration=True).batch(batch_size)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=8000).batch(batch_size)\n",
    "\n",
    "# Check the shape of the datasets\n",
    "print(f'Train Images: {train_images.shape}, Train Midpoints: {train_midpoints.shape}')\n",
    "print(f'Validation Images: {val_images.shape}, Validation Midpoints: {val_midpoints.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_transposed_images_with_midpoints(train_dataset, image_indices=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set up learning rate scheduler\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.9, patience=10, verbose=1, mode='min', min_lr=3e-5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> \n",
       "\n",
       " max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> \n",
       "\n",
       " conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> \n",
       "\n",
       " conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> \n",
       "\n",
       " conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> \n",
       "\n",
       " conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> \n",
       "\n",
       " conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> \n",
       "\n",
       " max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " batch_normalization              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> \n",
       "\n",
       " max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> \n",
       "\n",
       " max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> \n",
       "\n",
       " max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">819,328</span> \n",
       "\n",
       " batch_normalization_1            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " x_midpoints (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,338</span> \n",
       "\n",
       " x_midpoints_reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " input_layer (\u001b[38;5;33mInputLayer\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d (\u001b[38;5;33mConv2D\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)                \u001b[38;5;34m640\u001b[0m \n",
       "\n",
       " max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)             \u001b[38;5;34m36,928\u001b[0m \n",
       "\n",
       " conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m73,856\u001b[0m \n",
       "\n",
       " conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)           \u001b[38;5;34m147,584\u001b[0m \n",
       "\n",
       " conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)           \u001b[38;5;34m295,168\u001b[0m \n",
       "\n",
       " conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)           \u001b[38;5;34m590,080\u001b[0m \n",
       "\n",
       " conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)         \u001b[38;5;34m1,180,160\u001b[0m \n",
       "\n",
       " max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " batch_normalization              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)             \u001b[38;5;34m2,048\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)         \u001b[38;5;34m2,359,808\u001b[0m \n",
       "\n",
       " max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)           \u001b[38;5;34m2,359,808\u001b[0m \n",
       "\n",
       " max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)           \u001b[38;5;34m1,179,904\u001b[0m \n",
       "\n",
       " max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)             \u001b[38;5;34m819,328\u001b[0m \n",
       "\n",
       " batch_normalization_1            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m512\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " flatten (\u001b[38;5;33mFlatten\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " x_midpoints (\u001b[38;5;33mDense\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)                     \u001b[38;5;34m13,338\u001b[0m \n",
       "\n",
       " x_midpoints_reshape (\u001b[38;5;33mReshape\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m2\u001b[0m)                    \u001b[38;5;34m0\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,059,162</span> (34.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,059,162\u001b[0m (34.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,057,882</span> (34.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,057,882\u001b[0m (34.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> (5.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,280\u001b[0m (5.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# dynamic_exponent_callback = DynamicExponentCallback(1, 1, 50)\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    # Instantiate the model builder\n",
    "    # model_builder = ModelBuilder(weights_path= \"/home/da886/Weights from Josh's model/Josh's5fixedMSE45overfit-1.keras\")\n",
    "    model_builder = ModelBuilder()\n",
    "\n",
    "    # Build the model\n",
    "    model_builder.build_model()\n",
    "\n",
    "    # Display the model architecture\n",
    "    model_builder.model.summary()\n",
    "\n",
    "    # Compile the model using the custom loss function\n",
    "    # model_builder.compile_model(loss_function=dynamic_exponent_callback.custom_loss(1))\n",
    "    model_builder.compile_model(loss_function=tf.keras.losses.MeanSquaredError()) \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:14:46.062641: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2024-10-09 01:14:50.893711: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1728436490.954365 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436490.989347 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436490.990127 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436490.995326 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.006344 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.008780 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.010301 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.011897 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.015325 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.028221 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.030057 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.031563 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.033517 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.035396 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.037693 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.040851 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.043434 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.047864 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.053285 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.060753 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.065401 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.068278 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.076060 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.079991 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.171437 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.172631 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.173798 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.174964 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.176337 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.178233 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.180600 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.182947 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.185282 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.187772 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.192114 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.196475 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.224201 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.225019 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.225933 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.226910 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.227916 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.228922 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.229947 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.231094 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.233348 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.234634 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.235953 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.237660 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.245481 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.247000 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.248338 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.253706 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.257422 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.260208 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.262113 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.264810 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.267980 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.280093 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.281519 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.283105 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.284518 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.285896 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.288105 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.292532 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.296865 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.302287 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.306614 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.310945 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.315609 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.370545 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.371617 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.372804 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.374235 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.375745 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.377365 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.379023 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.380656 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.382645 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.384541 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.386636 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.391918 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.399022 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.401542 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.403822 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.406719 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.412761 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.415221 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.418610 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.423671 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.438148 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.440189 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.442646 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.444695 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.446683 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.450144 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.458715 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.467299 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.475754 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.484188 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.492546 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.501547 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.611104 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.612838 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.614752 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.616906 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.619240 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.621607 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.624046 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.627737 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.630705 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.633734 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.636793 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.645563 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.656878 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.660732 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.664645 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.668870 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.673767 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.678176 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.683578 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.693122 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.715572 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.719040 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.721876 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.725368 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.728883 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.735061 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.738451 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.742377 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.746918 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.750813 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.754266 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.771040 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.787858 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.804399 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.820860 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.837283 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.855129 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436491.872635 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.089778 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.093077 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.096854 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.100630 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.104956 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.109009 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.113946 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.118050 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.122554 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.128505 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.133991 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.139617 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.145265 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.155788 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.163107 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.171207 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.178518 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.184688 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.205053 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.214390 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.223329 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.233599 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.252596 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.268940 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.304052 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.309854 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.314996 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.320900 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.326821 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.334533 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.340475 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.347538 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.354613 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.360662 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.367631 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.402520 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.436608 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.469301 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.502580 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.535102 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.569239 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436492.604188 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.035519 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.041422 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.047821 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.054020 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.061365 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.068700 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.076566 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.084002 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.092004 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.100233 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.110080 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.119976 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.130303 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.146064 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.159286 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.173005 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.186651 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.197528 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.232893 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.250656 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.267793 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.286458 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.323273 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.335058 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.346336 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.356302 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.371676 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.383076 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.396733 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.408369 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.419728 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.433114 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.446893 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.514145 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.579290 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.643279 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.709111 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.774435 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.842057 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436493.911425 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436494.770338 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436494.781927 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436494.792954 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436494.805338 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436494.820809 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436494.835051 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436494.849767 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436494.865516 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436494.879745 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436494.895202 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436494.914035 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436494.933032 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436494.952758 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436494.973797 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436494.999380 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436495.026087 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436495.051983 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436495.086448 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436495.123740 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436495.157755 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436495.505438 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436495.510708 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436495.515555 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436495.520702 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436495.525786 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436495.532667 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436495.538085 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436495.544433 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436495.549764 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436495.556105 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436495.562509 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436495.598168 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436495.632794 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436495.666373 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436495.699492 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436495.732396 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436495.766930 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436495.801939 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.277168 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.282675 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.288219 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.293961 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.300096 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.306692 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.313364 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.320424 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.327515 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.334958 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.344007 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.353117 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.363218 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.373885 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.386450 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.399015 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.412580 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.429030 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.446777 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.463873 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.492042 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.527546 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.529177 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.530671 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.532238 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.534300 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.535893 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.537426 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.539231 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.540774 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.542598 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.544264 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.553365 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.562475 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.571679 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.580884 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.589919 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.599487 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.608919 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.731418 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.733037 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.734666 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.736286 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.738002 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.739700 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.741391 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.743190 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.745010 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.746880 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.749077 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.751250 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.753745 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.756435 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.759413 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.762477 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.766132 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.770248 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.774803 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.783227 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.810585 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.825896 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.826385 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.826874 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.827371 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.827976 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.828464 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.829003 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.829511 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.830005 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.830567 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.831057 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.832658 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.834334 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.836126 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.838911 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.840683 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.842642 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.844664 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.861524 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.862066 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.862531 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.862994 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.863521 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.863986 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.864450 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.864915 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.865358 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.866011 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.866501 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.867006 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.867888 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.868606 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.869173 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.869761 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.870509 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.884418 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.888425 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.890534 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.899019 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.899342 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.899615 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.899898 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.900218 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.901159 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.902620 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.903622 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.904700 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.906730 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.907836 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.909259 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.911373 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.911662 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.911964 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.912260 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.912592 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.912922 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.913252 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.913566 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.913890 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.914217 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.914540 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.914923 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.915315 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.915618 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.916019 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.916439 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.916904 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.920914 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.921449 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436496.922059 1288942 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.168625 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.170095 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.170404 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.170713 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.171028 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.171345 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.171656 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.171970 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.172345 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.172661 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.172981 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.173309 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.173659 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.174013 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.174322 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.174647 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.174984 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.175319 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.175665 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.175973 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.176445 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.176788 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.177148 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.177539 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.179658 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.181810 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.185682 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.188879 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.192055 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.195268 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.198488 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.203416 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.203992 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.205524 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.206513 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.207105 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.207525 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.208086 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.209513 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.210947 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.211305 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.211639 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.214814 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.225726 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.227290 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.229132 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.229430 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.229728 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.230045 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.230359 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.232229 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.232534 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.232922 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.233252 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.233565 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.233886 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.234270 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.234664 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.235336 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.235898 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.236536 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.237147 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.238586 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.255538 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.255879 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.256185 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.256495 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.258579 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.258875 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.259239 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.259532 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.259844 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.262147 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.263737 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.264066 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.264416 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.265790 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.267252 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.267658 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.268072 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.274486 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.279496 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.283552 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.303616 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.304119 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.304587 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.305082 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.305572 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.306079 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.306611 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.307120 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.307677 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.308160 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.308665 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.309162 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.309755 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.310304 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.310874 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.311422 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.311964 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.312525 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.313075 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.314425 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.315071 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.315830 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.316691 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.318824 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.320920 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.325494 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.330015 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.334526 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.339047 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.361516 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.362127 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.362617 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.363181 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.363793 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.364260 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.364844 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.365310 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.365935 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.366592 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.367325 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.369588 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.370399 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.374955 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.379480 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.390688 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.392561 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.392999 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.393439 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.393870 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.394311 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.394806 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.395257 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.395689 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.396179 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.396668 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.397127 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.397598 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.398052 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.398513 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.399082 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.399723 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.400418 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.401826 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.403217 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.405790 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.414944 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.432079 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.446495 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.447030 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.447568 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.448009 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.448456 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.448910 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.449389 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.449887 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.450359 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.450927 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.451384 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.451849 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.452355 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.452926 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.453464 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.454036 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.454660 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.455385 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.456751 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.461929 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.466185 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.484860 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.486760 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.488616 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.490497 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.492358 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.494172 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.496132 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.497985 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.500010 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.502056 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.504112 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.506040 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.508525 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.510954 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.512848 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.515217 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.517772 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.520571 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.522971 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.525531 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.530729 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.533367 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.536168 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.546381 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.556598 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.569694 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.582787 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.595775 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.609144 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.788518 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.790100 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.791834 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.793646 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.795496 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.797869 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.800522 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.803308 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.806376 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.809619 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.813396 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.815913 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.826318 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.840109 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.841671 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.843187 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.844682 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.846184 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.847721 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.849267 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.850882 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.852485 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.853998 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.855707 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.857240 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.858994 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.860944 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.862852 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.864921 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.867189 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.869880 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.878666 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.887442 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.897151 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.915191 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436497.949213 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.060670 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.062196 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.063784 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.065413 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.067018 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.068659 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.070393 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.072122 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.073827 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.075727 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.077683 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.079716 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.081892 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.084303 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.086740 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.089351 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.092440 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.095790 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.104462 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.112621 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.122613 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.154379 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.161102 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.167785 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.174471 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.180811 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.187283 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.194671 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.201463 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.209318 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.217176 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.224502 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.232375 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.241626 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.250833 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.257906 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.267945 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.277125 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.288216 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.297644 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.326524 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.336287 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.346720 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.356832 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.395913 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.434704 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.475052 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.515759 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.556840 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436498.598868 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.307230 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.312545 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.318678 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.325031 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.331637 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.340728 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.350779 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.361853 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.374002 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.387107 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.402159 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.411806 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.454567 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.489065 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.494536 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.499758 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.505000 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.510375 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.515807 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.521346 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.527226 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.533193 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.538691 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.545014 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.550588 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.557332 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.564898 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.572367 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.580195 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.588744 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.599059 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.627152 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.660911 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.694116 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.731931 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.767298 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436499.803643 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.246373 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.251564 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.256891 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.262397 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.268151 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.273829 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.280082 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.286568 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.293260 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.300642 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.308395 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.316258 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.325205 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.335009 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.344723 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.354246 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.366803 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.380295 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.397028 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.431442 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.484993 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.501188 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.515150 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.528540 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.543245 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.556748 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.569996 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.583330 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.598361 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.615233 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.630763 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.649079 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.667206 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.685360 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.706629 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.727869 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.745812 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.771291 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.792233 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.810093 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.831311 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.904917 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.944845 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436500.978634 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436501.055601 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436501.134960 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436501.216431 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436501.300206 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436501.379804 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436501.467628 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436501.554671 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436502.979859 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436502.990849 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.003796 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.017240 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.031665 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.050581 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.072037 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.091931 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.115177 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.137873 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.161101 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.186427 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.218168 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.254230 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.354959 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.370428 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.380887 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.392118 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.404132 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.415558 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.427392 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.439798 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.451468 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.464311 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.475685 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.487091 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.502622 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.517773 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.531559 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.547243 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.564653 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.621801 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.642027 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.707416 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.772508 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.847459 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.918621 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436503.991284 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436504.871482 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436504.882223 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436504.893224 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436504.904925 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436504.917331 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436504.930310 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436504.944274 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436504.958112 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436504.972297 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436504.987645 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.003476 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.019119 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.037372 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.057316 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.076720 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.096287 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.121469 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.148696 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.181729 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.249244 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.345509 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.352858 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.360160 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.367089 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.375369 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.384633 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.395688 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.406040 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.416335 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.428711 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.440774 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.450076 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.463114 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.476153 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.489259 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.504110 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.514928 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.524176 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.533474 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.544376 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.559316 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.576419 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.593396 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.611726 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.626835 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.664113 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.700930 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.740720 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.780511 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.832522 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436505.884625 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.599839 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.606069 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.612911 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.619976 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.627606 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.637198 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.647662 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.658905 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.671044 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.688448 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.705088 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.725037 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.760707 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.809039 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.876845 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.883239 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.888997 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.895089 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.901523 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.907554 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.913840 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.920809 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.927317 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.934530 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.940846 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.948766 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.955083 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.963389 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.970993 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.979670 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436506.989241 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.020595 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.031789 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.065562 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.098553 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.137937 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.176825 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.214332 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.656846 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.662974 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.669171 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.675513 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.682160 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.688998 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.696550 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.703972 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.711850 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.720334 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.729067 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.737755 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.748284 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.760699 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.771444 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.782537 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.796507 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.813976 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.831003 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.865413 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.915922 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.921855 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.925199 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.928735 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.932345 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.936074 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.939940 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.943340 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.946849 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.950496 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.955084 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.960938 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.965532 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.971332 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.975494 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.980189 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.985289 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436507.991652 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.008503 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.026068 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.043089 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.062920 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.082425 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.101513 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.323724 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.327259 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.330788 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.334467 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.338217 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.342144 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.346143 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.350196 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.354759 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.359432 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.364104 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.369905 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.375460 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.381461 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.388051 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.395609 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.404502 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.422383 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.450361 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.454498 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.459389 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.464272 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.468408 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.472525 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.476824 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.481129 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.485786 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.491446 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.497865 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.504065 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.510476 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.517540 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.524593 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.529569 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.536970 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.543371 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.551193 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.559013 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.567983 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.580557 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.599373 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.619551 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.639592 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.659656 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.679819 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.705731 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436508.731991 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.090352 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.094311 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.098382 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.103102 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.108221 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.113769 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.119669 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.126036 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.134160 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.143045 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.154159 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.173563 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.195813 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.226897 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.267888 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.309634 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.313552 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.315840 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.318642 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.321251 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.324112 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.327114 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.330117 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.332962 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.335875 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.339339 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.342420 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.345500 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.349305 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.353497 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.356737 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.359975 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.363022 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.366997 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.370894 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.375407 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.380910 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.386968 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.394210 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.404457 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.414693 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.424875 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.435012 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.450497 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.463494 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.476570 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.655778 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.658495 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.661193 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.664185 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.667357 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.670746 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.674175 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.677901 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.701191 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.707368 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.715235 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.724224 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.735571 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.751448 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.770625 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.811411 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.813440 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.815423 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.817516 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.819658 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.821948 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.824173 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.826232 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.828211 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.830278 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.832687 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.835771 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.838829 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.841134 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.843626 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.846249 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.849726 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.852536 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.861458 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.870083 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.878710 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.889295 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436509.899855 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.012262 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.014445 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.016633 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.018836 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.021100 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.023489 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.025906 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.028405 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.030974 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.033568 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.036174 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.039378 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.042604 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.046056 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.049811 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.054195 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.058745 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.067655 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.078291 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.098580 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.100069 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.101896 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.103712 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.105549 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.107433 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.108965 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.110886 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.112787 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.114724 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.116256 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.118299 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.120441 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.122883 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.128018 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.130636 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.133554 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.136764 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.139665 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.144075 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.148480 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.153825 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.159182 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.215219 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.216728 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.218288 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.219758 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.221315 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.223195 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.225116 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.227015 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.229002 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.231077 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.233091 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.235302 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.237288 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.239702 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.242175 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.244592 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.248093 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.250419 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.254872 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.266753 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.269013 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.271242 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.273505 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.275765 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.278029 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.280239 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.282176 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.284102 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.286494 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.288958 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.290947 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.293440 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.295838 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.297968 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.300630 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.303858 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.307089 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.311382 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.314955 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.318531 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.322331 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.327571 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.332803 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.338036 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.343274 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.351673 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.358340 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.365000 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.372925 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.463348 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.464918 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.466496 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.468406 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.470238 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.472207 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.474454 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.476411 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.489348 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.494975 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.502089 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.510484 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.517158 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.529684 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.531544 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.533220 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.534893 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.536668 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.538447 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.540153 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.541864 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.543643 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.545435 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.546662 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.547908 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.549126 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.550991 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.552482 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.554122 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.558253 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.562336 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.565790 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.569243 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.571421 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.576576 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.581740 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.586901 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.592020 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.637614 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.638833 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.640004 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.641438 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.642792 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.644188 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.645602 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.647334 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.649118 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.652287 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.659981 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.664585 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.669686 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/48\u001b[0m \u001b[37m\u001b[0m \u001b[1m19:27\u001b[0m 25s/step - loss: 0.2996"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728436510.675122 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.681796 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.695926 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.696954 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.698090 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.699237 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.700381 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.701360 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.702548 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.703740 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.704737 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.706059 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.707171 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.708693 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.711739 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.713469 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.715177 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.717485 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.719787 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.722139 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.724582 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.726948 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.731284 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.735981 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.745894 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.773838 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.774883 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.775892 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.776924 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.777978 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.779226 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.780547 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.781850 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.783127 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.784427 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.785781 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.787140 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.788589 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.790112 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.791443 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.793129 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.796746 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.800504 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.811532 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.812483 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.814150 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.816846 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.818802 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.820990 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.822637 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.824359 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.826210 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.828309 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.831445 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.833740 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.843409 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.848054 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436510.859245 1288946 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.4403"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:15:17.279599: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-10-09 01:15:17.536121: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "W0000 00:00:1728436517.724424 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.725426 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.726462 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.727660 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.728919 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.730179 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.731431 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.732898 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.734190 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.735664 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.738549 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.739686 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.740674 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.741746 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.743269 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.745056 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.747041 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.748903 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.750933 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.753034 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.755339 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.757594 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.762341 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.762980 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.763920 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.765251 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.767189 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.770122 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.771692 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.773702 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.775767 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.777452 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.782925 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.785327 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.790977 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.796037 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.798902 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.802618 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.825556 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.826485 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.827344 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.828338 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.829369 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.830276 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.831250 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.834639 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.841265 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.847819 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.855660 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.860852 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.866955 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.873203 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436517.999661 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.000493 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.001432 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.002433 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.003452 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.004576 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.005777 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.006962 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.008117 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.009307 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.010524 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.011897 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.013348 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.015102 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.016684 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.018357 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.020005 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.022954 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.025172 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.027749 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.032325 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.035792 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.045657 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.046755 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.047820 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.049074 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.050333 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.051376 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.052455 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.053716 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.054943 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.056798 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.058413 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.060221 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.065984 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.072404 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.078593 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.091585 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.104411 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.112256 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.120222 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.372391 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.373587 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.374845 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.376122 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.377501 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.378845 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.380215 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.381744 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.383359 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.385065 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.386908 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.388676 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.390682 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.392989 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.395453 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.398037 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.400881 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.403770 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.407620 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.412330 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.419278 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.432722 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.434496 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.436277 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.438409 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.440585 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.442504 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.444280 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.445994 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.448055 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.451335 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.454149 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.457344 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.466762 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.479370 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.491608 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.517515 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.532776 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.558980 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436518.574855 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.081575 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.083603 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.085567 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.087646 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.089738 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.091977 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.094176 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.096480 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.099088 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.101887 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.104609 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.107414 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.110499 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.114181 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.118137 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.130155 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.134393 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.139077 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.144132 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.150264 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.159781 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.182862 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.185789 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.189178 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.192121 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.195818 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.199584 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.202550 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.205401 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.208604 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.211512 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.214859 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.218371 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.236011 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.256108 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.281506 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.305734 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.332019 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.359475 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436519.414189 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.424979 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.428262 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.431767 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.435001 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.438532 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.442330 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.446270 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.450128 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.454677 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.460283 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.465274 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.470431 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.475580 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.482490 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.490139 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.498201 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.519707 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.528463 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.539516 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.549312 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.567674 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.600585 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.605929 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.612243 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.617891 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.623428 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.630439 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.635993 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.643413 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.648883 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.654482 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.661068 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.668082 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.700555 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.739664 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.788906 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.836225 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.888116 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436520.947835 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436521.066420 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.087703 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.093526 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.099434 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.105381 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.111743 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.118444 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.126156 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.133237 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.141944 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.149539 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.158860 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.168326 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.178365 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.192114 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.205823 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.219727 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.256673 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.273608 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.293697 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.317597 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.329562 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.342628 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.352997 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.363796 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.374206 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.386696 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.401241 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.411557 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.422039 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.434466 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.447751 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.508826 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.584253 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.681329 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.775096 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.875868 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436523.996434 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436524.204381 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.239814 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.250402 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.261206 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.272186 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.285192 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.298542 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.313379 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.327102 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.343937 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.358296 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.376123 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.394161 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.413018 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.440055 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.465368 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.492206 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.525190 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.564350 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.608599 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.621133 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.626412 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.631665 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.638614 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.644188 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.649524 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.655998 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.663522 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.668980 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.675482 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.682402 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.724542 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.753074 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.802282 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.849899 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.899444 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436528.956955 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436529.073289 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.002643 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.007936 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.013165 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.018668 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.024528 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.030480 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.036892 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.043386 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.050599 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.057749 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.066536 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.075360 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.085183 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.098185 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.112117 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.124949 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.154449 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.170513 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.189093 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.212937 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.215414 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.216942 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.218490 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.220024 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.221953 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.223443 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.225209 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.227252 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.228761 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.230555 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.232380 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.243115 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.256041 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.268376 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.280639 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.293040 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.318172 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.342299 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.787179 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.788698 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.790204 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.791715 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.793336 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.795027 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.796744 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.798346 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.800126 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.801907 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.804006 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.806095 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.808489 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.811452 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.815000 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.818008 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.844918 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.852699 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.856675 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.861312 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.875436 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.875889 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.876372 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.876856 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.877330 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.877803 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.878269 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.880227 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.882224 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.884458 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.888077 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.890636 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.892834 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.896363 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.923184 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.923637 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.924084 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.924525 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.924970 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.925417 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.925866 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.926334 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.926820 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.927292 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.927862 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.928350 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.928933 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.929454 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.930073 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.930611 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.931247 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.931976 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.932837 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.934858 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.936877 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.940929 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.962161 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.962504 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.962808 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.963080 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.963607 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.964398 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.965194 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.965932 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.966662 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.968124 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.970120 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.971755 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.974078 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.974382 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.974724 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.975026 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.975453 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.975729 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.976020 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.976330 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.976639 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.976951 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.977281 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.977581 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.977946 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.978338 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.978721 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.980027 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.980473 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.980880 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.981385 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728436531.985336 1288938 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 462ms/step - loss: 0.4343 - val_loss: 0.2505 - learning_rate: 0.0010\n",
      "Epoch 2/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:15:32.468976: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 0.0234 - val_loss: 0.2636 - learning_rate: 0.0010\n",
      "Epoch 3/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:15:40.408497: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0190"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:15:48.534721: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 152ms/step - loss: 0.0190 - val_loss: 0.2599 - learning_rate: 0.0010\n",
      "Epoch 4/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - loss: 0.0174 - val_loss: 0.2567 - learning_rate: 0.0010\n",
      "Epoch 5/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:15:56.575910: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 153ms/step - loss: 0.0165 - val_loss: 0.2558 - learning_rate: 0.0010\n",
      "Epoch 6/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - loss: 0.0162 - val_loss: 0.2451 - learning_rate: 0.0010\n",
      "Epoch 7/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0156"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:16:19.557260: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - loss: 0.0156 - val_loss: 0.2391 - learning_rate: 0.0010\n",
      "Epoch 8/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 174ms/step - loss: 0.0152 - val_loss: 0.2351 - learning_rate: 0.0010\n",
      "Epoch 9/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:16:28.489567: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - loss: 0.0149 - val_loss: 0.2260 - learning_rate: 0.0010\n",
      "Epoch 10/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 179ms/step - loss: 0.0145 - val_loss: 0.2024 - learning_rate: 0.0010\n",
      "Epoch 11/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0143"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:16:52.799857: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - loss: 0.0143 - val_loss: 0.1744 - learning_rate: 0.0010\n",
      "Epoch 12/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 172ms/step - loss: 0.0139 - val_loss: 0.1426 - learning_rate: 0.0010\n",
      "Epoch 13/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - loss: 0.0134 - val_loss: 0.1131 - learning_rate: 0.0010\n",
      "Epoch 14/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 160ms/step - loss: 0.0132 - val_loss: 0.0722 - learning_rate: 0.0010\n",
      "Epoch 15/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0130"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:17:26.899304: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - loss: 0.0130 - val_loss: 0.0508 - learning_rate: 0.0010\n",
      "Epoch 16/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 162ms/step - loss: 0.0127 - val_loss: 0.0276 - learning_rate: 0.0010\n",
      "Epoch 17/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:17:36.991217: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 0.0125 - val_loss: 0.0191 - learning_rate: 0.0010\n",
      "Epoch 18/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 0.0121 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 19/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0119"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:18:00.421878: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step - loss: 0.0119 - val_loss: 0.0192 - learning_rate: 0.0010\n",
      "Epoch 20/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - loss: 0.0117 - val_loss: 0.0192 - learning_rate: 0.0010\n",
      "Epoch 21/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 158ms/step - loss: 0.0113 - val_loss: 0.1743 - learning_rate: 0.0010\n",
      "Epoch 22/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 170ms/step - loss: 0.0111 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 23/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0110"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:18:34.126466: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 156ms/step - loss: 0.0110 - val_loss: 0.0226 - learning_rate: 0.0010\n",
      "Epoch 24/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - loss: 0.0107 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 25/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 157ms/step - loss: 0.0106 - val_loss: 0.0192 - learning_rate: 0.0010\n",
      "Epoch 26/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 197ms/step - loss: 0.0104 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 27/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0102"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:19:08.555110: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - loss: 0.0102 - val_loss: 0.0208 - learning_rate: 0.0010\n",
      "Epoch 28/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 169ms/step - loss: 0.0100 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 29/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - loss: 0.0098 - val_loss: 0.0261 - learning_rate: 0.0010\n",
      "Epoch 30/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 0.0097 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 31/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0095"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:19:43.739128: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 187ms/step - loss: 0.0095 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 32/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 0.0093 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 33/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:19:54.274365: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 198ms/step - loss: 0.0091 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 34/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - loss: 0.0089 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 35/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0087"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:20:18.814975: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 195ms/step - loss: 0.0087 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 36/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 0.0086 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 37/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 176ms/step - loss: 0.0083 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 38/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 0.0082 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 39/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0081"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:20:53.754098: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step - loss: 0.0081 - val_loss: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 40/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 0.0079 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 41/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 0.0077 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 42/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 0.0075 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 43/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0072"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:21:25.828531: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 0.0072 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 44/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 166ms/step - loss: 0.0069 - val_loss: 0.0845 - learning_rate: 0.0010\n",
      "Epoch 45/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 158ms/step - loss: 0.0068 - val_loss: 0.0243 - learning_rate: 0.0010\n",
      "Epoch 46/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 0.0065 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 47/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0064"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:21:58.599778: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 165ms/step - loss: 0.0064 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 48/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 0.0061 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 49/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 0.0059 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 50/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 0.0055 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 51/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0053"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:22:29.931600: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 0.0053 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 52/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 0.0050 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 53/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0047\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 0.0047 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 54/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 202ms/step - loss: 0.0043 - val_loss: 0.0158 - learning_rate: 9.0000e-04\n",
      "Epoch 55/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0039"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:23:03.503807: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 0.0039 - val_loss: 0.0250 - learning_rate: 9.0000e-04\n",
      "Epoch 56/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 164ms/step - loss: 0.0036 - val_loss: 0.0128 - learning_rate: 9.0000e-04\n",
      "Epoch 57/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 0.0033 - val_loss: 0.0136 - learning_rate: 9.0000e-04\n",
      "Epoch 58/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 160ms/step - loss: 0.0031 - val_loss: 0.0162 - learning_rate: 9.0000e-04\n",
      "Epoch 59/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0029"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:23:38.732517: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 0.0029 - val_loss: 0.0143 - learning_rate: 9.0000e-04\n",
      "Epoch 60/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 168ms/step - loss: 0.0027 - val_loss: 0.0154 - learning_rate: 9.0000e-04\n",
      "Epoch 61/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 0.0023 - val_loss: 0.0132 - learning_rate: 9.0000e-04\n",
      "Epoch 62/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 0.0022 - val_loss: 0.0157 - learning_rate: 9.0000e-04\n",
      "Epoch 63/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0021"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:24:11.701664: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 0.0021 - val_loss: 0.0126 - learning_rate: 9.0000e-04\n",
      "Epoch 64/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 0.0018 - val_loss: 0.0155 - learning_rate: 8.1000e-04\n",
      "Epoch 65/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:24:20.040969: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 165ms/step - loss: 0.0017 - val_loss: 0.0130 - learning_rate: 8.1000e-04\n",
      "Epoch 66/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 0.0016 - val_loss: 0.0126 - learning_rate: 8.1000e-04\n",
      "Epoch 67/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:24:43.529725: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 0.0014 - val_loss: 0.0139 - learning_rate: 8.1000e-04\n",
      "Epoch 68/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - loss: 0.0013 - val_loss: 0.0171 - learning_rate: 8.1000e-04\n",
      "Epoch 69/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 0.0013 - val_loss: 0.0130 - learning_rate: 8.1000e-04\n",
      "Epoch 70/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - loss: 0.0013 - val_loss: 0.0159 - learning_rate: 8.1000e-04\n",
      "Epoch 71/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:25:17.262938: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 0.0012 - val_loss: 0.0135 - learning_rate: 8.1000e-04\n",
      "Epoch 72/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 166ms/step - loss: 0.0011 - val_loss: 0.0126 - learning_rate: 8.1000e-04\n",
      "Epoch 73/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0011\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 166ms/step - loss: 0.0011 - val_loss: 0.0132 - learning_rate: 8.1000e-04\n",
      "Epoch 74/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 0.0011 - val_loss: 0.0132 - learning_rate: 7.2900e-04\n",
      "Epoch 75/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:25:49.641333: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 0.0010 - val_loss: 0.0134 - learning_rate: 7.2900e-04\n",
      "Epoch 76/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 0.0010 - val_loss: 0.0135 - learning_rate: 7.2900e-04\n",
      "Epoch 77/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 161ms/step - loss: 9.2467e-04 - val_loss: 0.0132 - learning_rate: 7.2900e-04\n",
      "Epoch 78/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 172ms/step - loss: 9.0826e-04 - val_loss: 0.0156 - learning_rate: 7.2900e-04\n",
      "Epoch 79/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 8.9609e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:26:23.764198: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 8.9669e-04 - val_loss: 0.0130 - learning_rate: 7.2900e-04\n",
      "Epoch 80/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - loss: 9.4782e-04 - val_loss: 0.0132 - learning_rate: 7.2900e-04\n",
      "Epoch 81/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - loss: 8.9385e-04 - val_loss: 0.0132 - learning_rate: 7.2900e-04\n",
      "Epoch 82/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 177ms/step - loss: 9.1581e-04 - val_loss: 0.0132 - learning_rate: 7.2900e-04\n",
      "Epoch 83/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 9.1621e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:26:58.236522: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - loss: 9.1615e-04 - val_loss: 0.0125 - learning_rate: 7.2900e-04\n",
      "Epoch 84/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 8.2388e-04 - val_loss: 0.0129 - learning_rate: 6.5610e-04\n",
      "Epoch 85/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 7.6027e-04 - val_loss: 0.0128 - learning_rate: 6.5610e-04\n",
      "Epoch 86/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 7.6192e-04 - val_loss: 0.0130 - learning_rate: 6.5610e-04\n",
      "Epoch 87/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 7.8023e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:27:30.318127: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 7.8016e-04 - val_loss: 0.0132 - learning_rate: 6.5610e-04\n",
      "Epoch 88/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 8.1680e-04 - val_loss: 0.0148 - learning_rate: 6.5610e-04\n",
      "Epoch 89/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 7.6898e-04 - val_loss: 0.0143 - learning_rate: 6.5610e-04\n",
      "Epoch 90/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 7.4535e-04 - val_loss: 0.0129 - learning_rate: 6.5610e-04\n",
      "Epoch 91/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 7.5769e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:28:02.397627: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 162ms/step - loss: 7.5777e-04 - val_loss: 0.0137 - learning_rate: 6.5610e-04\n",
      "Epoch 92/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 7.4740e-04 - val_loss: 0.0128 - learning_rate: 6.5610e-04\n",
      "Epoch 93/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 7.5289e-04\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 7.5288e-04 - val_loss: 0.0129 - learning_rate: 6.5610e-04\n",
      "Epoch 94/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 190ms/step - loss: 7.0434e-04 - val_loss: 0.0132 - learning_rate: 5.9049e-04\n",
      "Epoch 95/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 6.5285e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:28:35.665691: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 6.5285e-04 - val_loss: 0.0139 - learning_rate: 5.9049e-04\n",
      "Epoch 96/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 5.9583e-04 - val_loss: 0.0133 - learning_rate: 5.9049e-04\n",
      "Epoch 97/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 161ms/step - loss: 6.0125e-04 - val_loss: 0.0127 - learning_rate: 5.9049e-04\n",
      "Epoch 98/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 6.3597e-04 - val_loss: 0.0126 - learning_rate: 5.9049e-04\n",
      "Epoch 99/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 6.3940e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:29:09.966696: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - loss: 6.3936e-04 - val_loss: 0.0122 - learning_rate: 5.9049e-04\n",
      "Epoch 100/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 6.2251e-04 - val_loss: 0.0132 - learning_rate: 5.9049e-04\n",
      "Epoch 101/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 161ms/step - loss: 5.7804e-04 - val_loss: 0.0128 - learning_rate: 5.9049e-04\n",
      "Epoch 102/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 6.1312e-04 - val_loss: 0.0123 - learning_rate: 5.9049e-04\n",
      "Epoch 103/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 6.1048e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:29:44.140815: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 161ms/step - loss: 6.1037e-04 - val_loss: 0.0137 - learning_rate: 5.9049e-04\n",
      "Epoch 104/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.6484e-04 - val_loss: 0.0144 - learning_rate: 5.3144e-04\n",
      "Epoch 105/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 162ms/step - loss: 5.5324e-04 - val_loss: 0.0125 - learning_rate: 5.3144e-04\n",
      "Epoch 106/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 5.2343e-04 - val_loss: 0.0129 - learning_rate: 5.3144e-04\n",
      "Epoch 107/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 5.0334e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:30:16.001288: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.0340e-04 - val_loss: 0.0124 - learning_rate: 5.3144e-04\n",
      "Epoch 108/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 161ms/step - loss: 5.2550e-04 - val_loss: 0.0123 - learning_rate: 5.3144e-04\n",
      "Epoch 109/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 172ms/step - loss: 5.3330e-04 - val_loss: 0.0127 - learning_rate: 5.3144e-04\n",
      "Epoch 110/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 5.1361e-04 - val_loss: 0.0127 - learning_rate: 5.3144e-04\n",
      "Epoch 111/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 5.3184e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:30:48.896258: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 192ms/step - loss: 5.3186e-04 - val_loss: 0.0126 - learning_rate: 5.3144e-04\n",
      "Epoch 112/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - loss: 5.3293e-04 - val_loss: 0.0122 - learning_rate: 5.3144e-04\n",
      "Epoch 113/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 5.2320e-04\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 179ms/step - loss: 5.2355e-04 - val_loss: 0.0135 - learning_rate: 5.3144e-04\n",
      "Epoch 114/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.4088e-04 - val_loss: 0.0124 - learning_rate: 4.7830e-04\n",
      "Epoch 115/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 5.0441e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:31:23.824189: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 188ms/step - loss: 5.0430e-04 - val_loss: 0.0123 - learning_rate: 4.7830e-04\n",
      "Epoch 116/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 4.8161e-04 - val_loss: 0.0128 - learning_rate: 4.7830e-04\n",
      "Epoch 117/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 166ms/step - loss: 5.0853e-04 - val_loss: 0.0124 - learning_rate: 4.7830e-04\n",
      "Epoch 118/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 5.3110e-04 - val_loss: 0.0132 - learning_rate: 4.7830e-04\n",
      "Epoch 119/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 5.1767e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:31:57.355493: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 5.1748e-04 - val_loss: 0.0121 - learning_rate: 4.7830e-04\n",
      "Epoch 120/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 168ms/step - loss: 4.7641e-04 - val_loss: 0.0122 - learning_rate: 4.7830e-04\n",
      "Epoch 121/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 164ms/step - loss: 5.0285e-04 - val_loss: 0.0123 - learning_rate: 4.7830e-04\n",
      "Epoch 122/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.2031e-04 - val_loss: 0.0120 - learning_rate: 4.7830e-04\n",
      "Epoch 123/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 5.2503e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:32:29.719295: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.2493e-04 - val_loss: 0.0127 - learning_rate: 4.7830e-04\n",
      "Epoch 124/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 168ms/step - loss: 4.8560e-04 - val_loss: 0.0125 - learning_rate: 4.3047e-04\n",
      "Epoch 125/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 4.3782e-04 - val_loss: 0.0132 - learning_rate: 4.3047e-04\n",
      "Epoch 126/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.3692e-04 - val_loss: 0.0121 - learning_rate: 4.3047e-04\n",
      "Epoch 127/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.0317e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:33:02.469582: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 173ms/step - loss: 4.0312e-04 - val_loss: 0.0132 - learning_rate: 4.3047e-04\n",
      "Epoch 128/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 4.2490e-04 - val_loss: 0.0125 - learning_rate: 4.3047e-04\n",
      "Epoch 129/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:33:11.466329: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 4.2602e-04 - val_loss: 0.0127 - learning_rate: 4.3047e-04\n",
      "Epoch 130/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - loss: 4.0947e-04 - val_loss: 0.0124 - learning_rate: 4.3047e-04\n",
      "Epoch 131/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 4.4874e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:33:35.381863: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 4.4866e-04 - val_loss: 0.0129 - learning_rate: 4.3047e-04\n",
      "Epoch 132/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 4.6398e-04 - val_loss: 0.0127 - learning_rate: 4.3047e-04\n",
      "Epoch 133/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.4795e-04\n",
      "Epoch 133: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.4819e-04 - val_loss: 0.0131 - learning_rate: 4.3047e-04\n",
      "Epoch 134/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 4.4036e-04 - val_loss: 0.0124 - learning_rate: 3.8742e-04\n",
      "Epoch 135/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.1098e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:34:07.472787: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - loss: 4.1100e-04 - val_loss: 0.0119 - learning_rate: 3.8742e-04\n",
      "Epoch 136/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 4.1367e-04 - val_loss: 0.0123 - learning_rate: 3.8742e-04\n",
      "Epoch 137/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 163ms/step - loss: 3.8859e-04 - val_loss: 0.0126 - learning_rate: 3.8742e-04\n",
      "Epoch 138/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.8624e-04 - val_loss: 0.0119 - learning_rate: 3.8742e-04\n",
      "Epoch 139/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.9234e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:34:38.898889: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.9264e-04 - val_loss: 0.0122 - learning_rate: 3.8742e-04\n",
      "Epoch 140/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 161ms/step - loss: 3.9705e-04 - val_loss: 0.0129 - learning_rate: 3.8742e-04\n",
      "Epoch 141/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.9395e-04 - val_loss: 0.0122 - learning_rate: 3.8742e-04\n",
      "Epoch 142/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - loss: 4.1702e-04 - val_loss: 0.0122 - learning_rate: 3.8742e-04\n",
      "Epoch 143/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.9845e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:35:12.682910: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 0.0003486784757114947.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.9858e-04 - val_loss: 0.0124 - learning_rate: 3.8742e-04\n",
      "Epoch 144/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 4.3225e-04 - val_loss: 0.0121 - learning_rate: 3.4868e-04\n",
      "Epoch 145/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.7130e-04 - val_loss: 0.0132 - learning_rate: 3.4868e-04\n",
      "Epoch 146/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.8377e-04 - val_loss: 0.0125 - learning_rate: 3.4868e-04\n",
      "Epoch 147/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 3.7341e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:35:44.377870: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 3.7330e-04 - val_loss: 0.0132 - learning_rate: 3.4868e-04\n",
      "Epoch 148/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.5807e-04 - val_loss: 0.0120 - learning_rate: 3.4868e-04\n",
      "Epoch 149/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 165ms/step - loss: 3.3210e-04 - val_loss: 0.0124 - learning_rate: 3.4868e-04\n",
      "Epoch 150/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.3496e-04 - val_loss: 0.0123 - learning_rate: 3.4868e-04\n",
      "Epoch 151/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.5112e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:36:16.841971: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 176ms/step - loss: 3.5134e-04 - val_loss: 0.0118 - learning_rate: 3.4868e-04\n",
      "Epoch 152/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 3.6364e-04 - val_loss: 0.0130 - learning_rate: 3.4868e-04\n",
      "Epoch 153/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.1665e-04\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 0.00031381062290165574.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 179ms/step - loss: 4.1688e-04 - val_loss: 0.0142 - learning_rate: 3.4868e-04\n",
      "Epoch 154/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.0073e-04 - val_loss: 0.0124 - learning_rate: 3.1381e-04\n",
      "Epoch 155/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.4501e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:36:51.140532: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 175ms/step - loss: 3.4492e-04 - val_loss: 0.0118 - learning_rate: 3.1381e-04\n",
      "Epoch 156/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.1498e-04 - val_loss: 0.0119 - learning_rate: 3.1381e-04\n",
      "Epoch 157/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 180ms/step - loss: 2.9955e-04 - val_loss: 0.0120 - learning_rate: 3.1381e-04\n",
      "Epoch 158/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.2676e-04 - val_loss: 0.0119 - learning_rate: 3.1381e-04\n",
      "Epoch 159/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.2088e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:37:24.127662: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.2094e-04 - val_loss: 0.0121 - learning_rate: 3.1381e-04\n",
      "Epoch 160/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.2429e-04 - val_loss: 0.0118 - learning_rate: 3.1381e-04\n",
      "Epoch 161/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.7059e-04 - val_loss: 0.0123 - learning_rate: 3.1381e-04\n",
      "Epoch 162/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 189ms/step - loss: 3.3215e-04 - val_loss: 0.0116 - learning_rate: 3.1381e-04\n",
      "Epoch 163/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.1933e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:37:56.743844: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 163: ReduceLROnPlateau reducing learning rate to 0.0002824295632308349.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.1940e-04 - val_loss: 0.0120 - learning_rate: 3.1381e-04\n",
      "Epoch 164/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - loss: 3.0748e-04 - val_loss: 0.0120 - learning_rate: 2.8243e-04\n",
      "Epoch 165/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.9255e-04 - val_loss: 0.0119 - learning_rate: 2.8243e-04\n",
      "Epoch 166/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 2.8034e-04 - val_loss: 0.0119 - learning_rate: 2.8243e-04\n",
      "Epoch 167/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.9611e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:38:29.993155: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.9613e-04 - val_loss: 0.0119 - learning_rate: 2.8243e-04\n",
      "Epoch 168/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 183ms/step - loss: 2.9395e-04 - val_loss: 0.0119 - learning_rate: 2.8243e-04\n",
      "Epoch 169/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.9431e-04 - val_loss: 0.0122 - learning_rate: 2.8243e-04\n",
      "Epoch 170/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 209ms/step - loss: 2.9260e-04 - val_loss: 0.0118 - learning_rate: 2.8243e-04\n",
      "Epoch 171/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.0634e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:39:05.148295: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.0625e-04 - val_loss: 0.0119 - learning_rate: 2.8243e-04\n",
      "Epoch 172/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.0114e-04 - val_loss: 0.0118 - learning_rate: 2.8243e-04\n",
      "Epoch 173/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.7022e-04\n",
      "Epoch 173: ReduceLROnPlateau reducing learning rate to 0.00025418660952709616.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.7060e-04 - val_loss: 0.0118 - learning_rate: 2.8243e-04\n",
      "Epoch 174/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.7721e-04 - val_loss: 0.0120 - learning_rate: 2.5419e-04\n",
      "Epoch 175/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.6802e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:39:37.159065: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 171ms/step - loss: 2.6820e-04 - val_loss: 0.0123 - learning_rate: 2.5419e-04\n",
      "Epoch 176/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.7136e-04 - val_loss: 0.0117 - learning_rate: 2.5419e-04\n",
      "Epoch 177/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.6798e-04 - val_loss: 0.0120 - learning_rate: 2.5419e-04\n",
      "Epoch 178/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.6162e-04 - val_loss: 0.0121 - learning_rate: 2.5419e-04\n",
      "Epoch 179/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.5423e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:40:08.627444: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5425e-04 - val_loss: 0.0121 - learning_rate: 2.5419e-04\n",
      "Epoch 180/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 190ms/step - loss: 2.5444e-04 - val_loss: 0.0119 - learning_rate: 2.5419e-04\n",
      "Epoch 181/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5851e-04 - val_loss: 0.0129 - learning_rate: 2.5419e-04\n",
      "Epoch 182/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5994e-04 - val_loss: 0.0122 - learning_rate: 2.5419e-04\n",
      "Epoch 183/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.7354e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:40:41.937552: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 183: ReduceLROnPlateau reducing learning rate to 0.00022876793809700757.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.7359e-04 - val_loss: 0.0118 - learning_rate: 2.5419e-04\n",
      "Epoch 184/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.6018e-04 - val_loss: 0.0119 - learning_rate: 2.2877e-04\n",
      "Epoch 185/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.4768e-04 - val_loss: 0.0118 - learning_rate: 2.2877e-04\n",
      "Epoch 186/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.3531e-04 - val_loss: 0.0119 - learning_rate: 2.2877e-04\n",
      "Epoch 187/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.2869e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:41:14.390005: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 174ms/step - loss: 2.2877e-04 - val_loss: 0.0121 - learning_rate: 2.2877e-04\n",
      "Epoch 188/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.4126e-04 - val_loss: 0.0123 - learning_rate: 2.2877e-04\n",
      "Epoch 189/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.3475e-04 - val_loss: 0.0120 - learning_rate: 2.2877e-04\n",
      "Epoch 190/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 2.4042e-04 - val_loss: 0.0120 - learning_rate: 2.2877e-04\n",
      "Epoch 191/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.7055e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:41:46.307092: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 162ms/step - loss: 2.7036e-04 - val_loss: 0.0125 - learning_rate: 2.2877e-04\n",
      "Epoch 192/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5293e-04 - val_loss: 0.0118 - learning_rate: 2.2877e-04\n",
      "Epoch 193/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 2.5284e-04\n",
      "Epoch 193: ReduceLROnPlateau reducing learning rate to 0.00020589114428730683.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.5275e-04 - val_loss: 0.0123 - learning_rate: 2.2877e-04\n",
      "Epoch 194/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.2924e-04 - val_loss: 0.0119 - learning_rate: 2.0589e-04\n",
      "Epoch 195/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.4146e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:42:17.903412: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 167ms/step - loss: 2.4162e-04 - val_loss: 0.0122 - learning_rate: 2.0589e-04\n",
      "Epoch 196/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 2.3895e-04 - val_loss: 0.0117 - learning_rate: 2.0589e-04\n",
      "Epoch 197/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 179ms/step - loss: 2.2620e-04 - val_loss: 0.0121 - learning_rate: 2.0589e-04\n",
      "Epoch 198/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 171ms/step - loss: 2.5125e-04 - val_loss: 0.0117 - learning_rate: 2.0589e-04\n",
      "Epoch 199/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.2196e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:42:51.345518: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.2190e-04 - val_loss: 0.0122 - learning_rate: 2.0589e-04\n",
      "Epoch 200/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.1857e-04 - val_loss: 0.0117 - learning_rate: 2.0589e-04\n",
      "Epoch 201/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.3405e-04 - val_loss: 0.0115 - learning_rate: 2.0589e-04\n",
      "Epoch 202/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 163ms/step - loss: 2.3658e-04 - val_loss: 0.0117 - learning_rate: 2.0589e-04\n",
      "Epoch 203/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 2.2403e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:43:23.240239: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 203: ReduceLROnPlateau reducing learning rate to 0.00018530203378759326.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.2408e-04 - val_loss: 0.0118 - learning_rate: 2.0589e-04\n",
      "Epoch 204/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.0292e-04 - val_loss: 0.0118 - learning_rate: 1.8530e-04\n",
      "Epoch 205/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 1.8901e-04 - val_loss: 0.0121 - learning_rate: 1.8530e-04\n",
      "Epoch 206/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 1.9201e-04 - val_loss: 0.0121 - learning_rate: 1.8530e-04\n",
      "Epoch 207/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.8750e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:43:55.171565: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 166ms/step - loss: 1.8756e-04 - val_loss: 0.0118 - learning_rate: 1.8530e-04\n",
      "Epoch 208/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 1.9134e-04 - val_loss: 0.0120 - learning_rate: 1.8530e-04\n",
      "Epoch 209/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 168ms/step - loss: 1.9915e-04 - val_loss: 0.0118 - learning_rate: 1.8530e-04\n",
      "Epoch 210/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.0654e-04 - val_loss: 0.0120 - learning_rate: 1.8530e-04\n",
      "Epoch 211/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 1.9684e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:44:27.636743: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 201ms/step - loss: 1.9696e-04 - val_loss: 0.0119 - learning_rate: 1.8530e-04\n",
      "Epoch 212/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 2.1737e-04 - val_loss: 0.0118 - learning_rate: 1.8530e-04\n",
      "Epoch 213/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.2061e-04\n",
      "Epoch 213: ReduceLROnPlateau reducing learning rate to 0.00016677183302817866.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 167ms/step - loss: 2.2047e-04 - val_loss: 0.0119 - learning_rate: 1.8530e-04\n",
      "Epoch 214/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 1.9047e-04 - val_loss: 0.0120 - learning_rate: 1.6677e-04\n",
      "Epoch 215/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.8697e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:45:03.192108: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 1.8692e-04 - val_loss: 0.0118 - learning_rate: 1.6677e-04\n",
      "Epoch 216/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - loss: 1.6374e-04 - val_loss: 0.0118 - learning_rate: 1.6677e-04\n",
      "Epoch 217/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 1.7398e-04 - val_loss: 0.0120 - learning_rate: 1.6677e-04\n",
      "Epoch 218/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 172ms/step - loss: 1.6455e-04 - val_loss: 0.0124 - learning_rate: 1.6677e-04\n",
      "Epoch 219/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.7196e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:45:35.761422: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 1.7200e-04 - val_loss: 0.0119 - learning_rate: 1.6677e-04\n",
      "Epoch 220/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 1.7836e-04 - val_loss: 0.0123 - learning_rate: 1.6677e-04\n",
      "Epoch 221/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 1.8931e-04 - val_loss: 0.0119 - learning_rate: 1.6677e-04\n",
      "Epoch 222/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 1.8420e-04 - val_loss: 0.0118 - learning_rate: 1.6677e-04\n",
      "Epoch 223/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.8514e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:46:06.745267: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 223: ReduceLROnPlateau reducing learning rate to 0.00015009464841568844.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 193ms/step - loss: 1.8507e-04 - val_loss: 0.0118 - learning_rate: 1.6677e-04\n",
      "Epoch 224/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 1.8133e-04 - val_loss: 0.0119 - learning_rate: 1.5009e-04\n",
      "Epoch 225/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 176ms/step - loss: 1.6145e-04 - val_loss: 0.0119 - learning_rate: 1.5009e-04\n",
      "Epoch 226/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 1.6048e-04 - val_loss: 0.0119 - learning_rate: 1.5009e-04\n",
      "Epoch 227/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.6611e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:46:42.459377: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 174ms/step - loss: 1.6609e-04 - val_loss: 0.0118 - learning_rate: 1.5009e-04\n",
      "Epoch 228/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 1.5490e-04 - val_loss: 0.0119 - learning_rate: 1.5009e-04\n",
      "Epoch 229/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - loss: 1.5881e-04 - val_loss: 0.0119 - learning_rate: 1.5009e-04\n",
      "Epoch 230/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 201ms/step - loss: 1.7146e-04 - val_loss: 0.0117 - learning_rate: 1.5009e-04\n",
      "Epoch 231/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 1.4868e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:47:18.724900: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 1.4874e-04 - val_loss: 0.0118 - learning_rate: 1.5009e-04\n",
      "Epoch 232/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 200ms/step - loss: 1.5570e-04 - val_loss: 0.0117 - learning_rate: 1.5009e-04\n",
      "Epoch 233/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.6110e-04\n",
      "Epoch 233: ReduceLROnPlateau reducing learning rate to 0.0001350851875031367.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 1.6117e-04 - val_loss: 0.0119 - learning_rate: 1.5009e-04\n",
      "Epoch 234/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 170ms/step - loss: 1.6613e-04 - val_loss: 0.0119 - learning_rate: 1.3509e-04\n",
      "Epoch 235/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 1.4553e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:47:53.901807: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 167ms/step - loss: 1.4559e-04 - val_loss: 0.0117 - learning_rate: 1.3509e-04\n",
      "Epoch 236/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 178ms/step - loss: 1.5231e-04 - val_loss: 0.0121 - learning_rate: 1.3509e-04\n",
      "Epoch 237/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 1.5114e-04 - val_loss: 0.0118 - learning_rate: 1.3509e-04\n",
      "Epoch 238/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 1.4534e-04 - val_loss: 0.0119 - learning_rate: 1.3509e-04\n",
      "Epoch 239/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 1.5606e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:48:27.246998: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 158ms/step - loss: 1.5609e-04 - val_loss: 0.0119 - learning_rate: 1.3509e-04\n",
      "Epoch 240/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 1.6147e-04 - val_loss: 0.0118 - learning_rate: 1.3509e-04\n",
      "Epoch 241/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 175ms/step - loss: 1.5528e-04 - val_loss: 0.0122 - learning_rate: 1.3509e-04\n",
      "Epoch 242/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 1.4882e-04 - val_loss: 0.0118 - learning_rate: 1.3509e-04\n",
      "Epoch 243/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.4584e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:48:59.488034: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 243: ReduceLROnPlateau reducing learning rate to 0.00012157666351413355.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 167ms/step - loss: 1.4581e-04 - val_loss: 0.0118 - learning_rate: 1.3509e-04\n",
      "Epoch 244/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 1.4076e-04 - val_loss: 0.0117 - learning_rate: 1.2158e-04\n",
      "Epoch 245/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 204ms/step - loss: 1.4187e-04 - val_loss: 0.0117 - learning_rate: 1.2158e-04\n",
      "Epoch 246/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 1.3538e-04 - val_loss: 0.0118 - learning_rate: 1.2158e-04\n",
      "Epoch 247/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.3224e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:49:33.931104: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 178ms/step - loss: 1.3233e-04 - val_loss: 0.0118 - learning_rate: 1.2158e-04\n",
      "Epoch 248/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 167ms/step - loss: 1.4537e-04 - val_loss: 0.0118 - learning_rate: 1.2158e-04\n",
      "Epoch 249/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 180ms/step - loss: 1.4169e-04 - val_loss: 0.0118 - learning_rate: 1.2158e-04\n",
      "Epoch 250/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 1.4308e-04 - val_loss: 0.0117 - learning_rate: 1.2158e-04\n",
      "Epoch 251/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.3128e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:50:07.284056: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 1.3129e-04 - val_loss: 0.0118 - learning_rate: 1.2158e-04\n",
      "Epoch 252/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 1.2857e-04 - val_loss: 0.0118 - learning_rate: 1.2158e-04\n",
      "Epoch 253/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 1.3132e-04\n",
      "Epoch 253: ReduceLROnPlateau reducing learning rate to 0.00010941899454337544.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 1.3144e-04 - val_loss: 0.0119 - learning_rate: 1.2158e-04\n",
      "Epoch 254/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 1.3911e-04 - val_loss: 0.0118 - learning_rate: 1.0942e-04\n",
      "Epoch 255/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.2383e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:50:39.345392: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 1.2382e-04 - val_loss: 0.0118 - learning_rate: 1.0942e-04\n",
      "Epoch 256/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 1.2483e-04 - val_loss: 0.0118 - learning_rate: 1.0942e-04\n",
      "Epoch 257/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:50:47.637994: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 168ms/step - loss: 1.2918e-04 - val_loss: 0.0118 - learning_rate: 1.0942e-04\n",
      "Epoch 258/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 1.2228e-04 - val_loss: 0.0118 - learning_rate: 1.0942e-04\n",
      "Epoch 259/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.2555e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:51:10.757321: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 192ms/step - loss: 1.2561e-04 - val_loss: 0.0119 - learning_rate: 1.0942e-04\n",
      "Epoch 260/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 1.2240e-04 - val_loss: 0.0122 - learning_rate: 1.0942e-04\n",
      "Epoch 261/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 1.2057e-04 - val_loss: 0.0119 - learning_rate: 1.0942e-04\n",
      "Epoch 262/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 1.2495e-04 - val_loss: 0.0119 - learning_rate: 1.0942e-04\n",
      "Epoch 263/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.2272e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:51:44.150370: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 263: ReduceLROnPlateau reducing learning rate to 9.847709443420172e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 167ms/step - loss: 1.2277e-04 - val_loss: 0.0118 - learning_rate: 1.0942e-04\n",
      "Epoch 264/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 1.1978e-04 - val_loss: 0.0120 - learning_rate: 9.8477e-05\n",
      "Epoch 265/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 1.1890e-04 - val_loss: 0.0120 - learning_rate: 9.8477e-05\n",
      "Epoch 266/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 174ms/step - loss: 1.1574e-04 - val_loss: 0.0120 - learning_rate: 9.8477e-05\n",
      "Epoch 267/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.2658e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:52:17.539513: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 1.2664e-04 - val_loss: 0.0119 - learning_rate: 9.8477e-05\n",
      "Epoch 268/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 170ms/step - loss: 1.1974e-04 - val_loss: 0.0117 - learning_rate: 9.8477e-05\n",
      "Epoch 269/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 1.1622e-04 - val_loss: 0.0119 - learning_rate: 9.8477e-05\n",
      "Epoch 270/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 172ms/step - loss: 1.3262e-04 - val_loss: 0.0118 - learning_rate: 9.8477e-05\n",
      "Epoch 271/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.1437e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:52:52.134521: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 1.1439e-04 - val_loss: 0.0118 - learning_rate: 9.8477e-05\n",
      "Epoch 272/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 170ms/step - loss: 1.1040e-04 - val_loss: 0.0119 - learning_rate: 9.8477e-05\n",
      "Epoch 273/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.2367e-04\n",
      "Epoch 273: ReduceLROnPlateau reducing learning rate to 8.862938630045391e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 1.2366e-04 - val_loss: 0.0118 - learning_rate: 9.8477e-05\n",
      "Epoch 274/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 173ms/step - loss: 1.0880e-04 - val_loss: 0.0121 - learning_rate: 8.8629e-05\n",
      "Epoch 275/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 1.1442e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:53:26.875284: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 1.1439e-04 - val_loss: 0.0117 - learning_rate: 8.8629e-05\n",
      "Epoch 276/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 1.0382e-04 - val_loss: 0.0118 - learning_rate: 8.8629e-05\n",
      "Epoch 277/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 1.0071e-04 - val_loss: 0.0119 - learning_rate: 8.8629e-05\n",
      "Epoch 278/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 1.0807e-04 - val_loss: 0.0118 - learning_rate: 8.8629e-05\n",
      "Epoch 279/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.0059e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:53:58.668684: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 171ms/step - loss: 1.0061e-04 - val_loss: 0.0119 - learning_rate: 8.8629e-05\n",
      "Epoch 280/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 1.0456e-04 - val_loss: 0.0118 - learning_rate: 8.8629e-05\n",
      "Epoch 281/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 1.0170e-04 - val_loss: 0.0119 - learning_rate: 8.8629e-05\n",
      "Epoch 282/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 1.0231e-04 - val_loss: 0.0118 - learning_rate: 8.8629e-05\n",
      "Epoch 283/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 9.9720e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:54:30.373206: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 283: ReduceLROnPlateau reducing learning rate to 7.976644701557234e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 197ms/step - loss: 9.9760e-05 - val_loss: 0.0119 - learning_rate: 8.8629e-05\n",
      "Epoch 284/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 1.0422e-04 - val_loss: 0.0119 - learning_rate: 7.9766e-05\n",
      "Epoch 285/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 206ms/step - loss: 9.8779e-05 - val_loss: 0.0121 - learning_rate: 7.9766e-05\n",
      "Epoch 286/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 9.4522e-05 - val_loss: 0.0119 - learning_rate: 7.9766e-05\n",
      "Epoch 287/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 9.9256e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:55:07.611038: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 163ms/step - loss: 9.9324e-05 - val_loss: 0.0119 - learning_rate: 7.9766e-05\n",
      "Epoch 288/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 9.8685e-05 - val_loss: 0.0119 - learning_rate: 7.9766e-05\n",
      "Epoch 289/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 168ms/step - loss: 9.8941e-05 - val_loss: 0.0122 - learning_rate: 7.9766e-05\n",
      "Epoch 290/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 1.0807e-04 - val_loss: 0.0120 - learning_rate: 7.9766e-05\n",
      "Epoch 291/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.0654e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:55:40.407128: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 1.0656e-04 - val_loss: 0.0118 - learning_rate: 7.9766e-05\n",
      "Epoch 292/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 9.7494e-05 - val_loss: 0.0121 - learning_rate: 7.9766e-05\n",
      "Epoch 293/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 9.7004e-05\n",
      "Epoch 293: ReduceLROnPlateau reducing learning rate to 7.178980231401511e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 165ms/step - loss: 9.6987e-05 - val_loss: 0.0117 - learning_rate: 7.9766e-05\n",
      "Epoch 294/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 178ms/step - loss: 9.0087e-05 - val_loss: 0.0118 - learning_rate: 7.1790e-05\n",
      "Epoch 295/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 8.9599e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:56:12.710326: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 8.9666e-05 - val_loss: 0.0119 - learning_rate: 7.1790e-05\n",
      "Epoch 296/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 166ms/step - loss: 9.0171e-05 - val_loss: 0.0119 - learning_rate: 7.1790e-05\n",
      "Epoch 297/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 9.1904e-05 - val_loss: 0.0121 - learning_rate: 7.1790e-05\n",
      "Epoch 298/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 9.0491e-05 - val_loss: 0.0118 - learning_rate: 7.1790e-05\n",
      "Epoch 299/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 8.4754e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:56:46.511663: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 8.4802e-05 - val_loss: 0.0120 - learning_rate: 7.1790e-05\n",
      "Epoch 300/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 197ms/step - loss: 8.6496e-05 - val_loss: 0.0119 - learning_rate: 7.1790e-05\n",
      "Epoch 301/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 9.2004e-05 - val_loss: 0.0119 - learning_rate: 7.1790e-05\n",
      "Epoch 302/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 182ms/step - loss: 8.8169e-05 - val_loss: 0.0120 - learning_rate: 7.1790e-05\n",
      "Epoch 303/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 9.2168e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:57:21.058429: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 303: ReduceLROnPlateau reducing learning rate to 6.461082011810504e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 9.2173e-05 - val_loss: 0.0119 - learning_rate: 7.1790e-05\n",
      "Epoch 304/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 8.3865e-05 - val_loss: 0.0119 - learning_rate: 6.4611e-05\n",
      "Epoch 305/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 171ms/step - loss: 8.8611e-05 - val_loss: 0.0119 - learning_rate: 6.4611e-05\n",
      "Epoch 306/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 8.3862e-05 - val_loss: 0.0119 - learning_rate: 6.4611e-05\n",
      "Epoch 307/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 8.7262e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:57:52.757948: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 168ms/step - loss: 8.7255e-05 - val_loss: 0.0120 - learning_rate: 6.4611e-05\n",
      "Epoch 308/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 8.4048e-05 - val_loss: 0.0118 - learning_rate: 6.4611e-05\n",
      "Epoch 309/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 8.7390e-05 - val_loss: 0.0120 - learning_rate: 6.4611e-05\n",
      "Epoch 310/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 164ms/step - loss: 8.3818e-05 - val_loss: 0.0119 - learning_rate: 6.4611e-05\n",
      "Epoch 311/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 8.0975e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:58:24.891474: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 8.1041e-05 - val_loss: 0.0118 - learning_rate: 6.4611e-05\n",
      "Epoch 312/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 194ms/step - loss: 8.3729e-05 - val_loss: 0.0120 - learning_rate: 6.4611e-05\n",
      "Epoch 313/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 8.0260e-05\n",
      "Epoch 313: ReduceLROnPlateau reducing learning rate to 5.8149741380475466e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 8.0318e-05 - val_loss: 0.0118 - learning_rate: 6.4611e-05\n",
      "Epoch 314/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 182ms/step - loss: 8.1673e-05 - val_loss: 0.0119 - learning_rate: 5.8150e-05\n",
      "Epoch 315/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 8.0055e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:58:59.209343: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 8.0094e-05 - val_loss: 0.0119 - learning_rate: 5.8150e-05\n",
      "Epoch 316/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 8.4542e-05 - val_loss: 0.0118 - learning_rate: 5.8150e-05\n",
      "Epoch 317/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 7.7077e-05 - val_loss: 0.0120 - learning_rate: 5.8150e-05\n",
      "Epoch 318/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 204ms/step - loss: 7.8927e-05 - val_loss: 0.0118 - learning_rate: 5.8150e-05\n",
      "Epoch 319/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 8.1112e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 01:59:33.446081: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 8.1122e-05 - val_loss: 0.0118 - learning_rate: 5.8150e-05\n",
      "Epoch 320/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 8.1894e-05 - val_loss: 0.0118 - learning_rate: 5.8150e-05\n",
      "Epoch 321/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 7.7368e-05 - val_loss: 0.0119 - learning_rate: 5.8150e-05\n",
      "Epoch 322/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 180ms/step - loss: 7.2106e-05 - val_loss: 0.0118 - learning_rate: 5.8150e-05\n",
      "Epoch 323/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 7.7848e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:00:07.725980: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 323: ReduceLROnPlateau reducing learning rate to 5.233476658759173e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 167ms/step - loss: 7.7896e-05 - val_loss: 0.0119 - learning_rate: 5.8150e-05\n",
      "Epoch 324/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 7.5438e-05 - val_loss: 0.0119 - learning_rate: 5.2335e-05\n",
      "Epoch 325/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 7.4276e-05 - val_loss: 0.0119 - learning_rate: 5.2335e-05\n",
      "Epoch 326/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 7.0778e-05 - val_loss: 0.0119 - learning_rate: 5.2335e-05\n",
      "Epoch 327/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 7.4431e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:00:39.466950: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 165ms/step - loss: 7.4446e-05 - val_loss: 0.0119 - learning_rate: 5.2335e-05\n",
      "Epoch 328/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 6.9988e-05 - val_loss: 0.0119 - learning_rate: 5.2335e-05\n",
      "Epoch 329/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 168ms/step - loss: 7.4281e-05 - val_loss: 0.0120 - learning_rate: 5.2335e-05\n",
      "Epoch 330/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 7.8637e-05 - val_loss: 0.0119 - learning_rate: 5.2335e-05\n",
      "Epoch 331/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 7.0752e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:01:12.498360: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 7.0757e-05 - val_loss: 0.0119 - learning_rate: 5.2335e-05\n",
      "Epoch 332/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 6.8901e-05 - val_loss: 0.0119 - learning_rate: 5.2335e-05\n",
      "Epoch 333/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 7.3807e-05\n",
      "Epoch 333: ReduceLROnPlateau reducing learning rate to 4.7101289601414466e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 7.3825e-05 - val_loss: 0.0120 - learning_rate: 5.2335e-05\n",
      "Epoch 334/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 7.6388e-05 - val_loss: 0.0120 - learning_rate: 4.7101e-05\n",
      "Epoch 335/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 6.9983e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:01:43.387430: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 6.9990e-05 - val_loss: 0.0120 - learning_rate: 4.7101e-05\n",
      "Epoch 336/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 7.2537e-05 - val_loss: 0.0121 - learning_rate: 4.7101e-05\n",
      "Epoch 337/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 179ms/step - loss: 7.3441e-05 - val_loss: 0.0119 - learning_rate: 4.7101e-05\n",
      "Epoch 338/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 6.7141e-05 - val_loss: 0.0120 - learning_rate: 4.7101e-05\n",
      "Epoch 339/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 6.9163e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:02:16.416928: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 179ms/step - loss: 6.9126e-05 - val_loss: 0.0119 - learning_rate: 4.7101e-05\n",
      "Epoch 340/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 6.7825e-05 - val_loss: 0.0119 - learning_rate: 4.7101e-05\n",
      "Epoch 341/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 160ms/step - loss: 7.2754e-05 - val_loss: 0.0120 - learning_rate: 4.7101e-05\n",
      "Epoch 342/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 6.6489e-05 - val_loss: 0.0118 - learning_rate: 4.7101e-05\n",
      "Epoch 343/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 7.1885e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:02:50.171172: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 343: ReduceLROnPlateau reducing learning rate to 4.239116096869111e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 191ms/step - loss: 7.1918e-05 - val_loss: 0.0119 - learning_rate: 4.7101e-05\n",
      "Epoch 344/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 6.6503e-05 - val_loss: 0.0120 - learning_rate: 4.2391e-05\n",
      "Epoch 345/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 168ms/step - loss: 6.2022e-05 - val_loss: 0.0120 - learning_rate: 4.2391e-05\n",
      "Epoch 346/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 6.6427e-05 - val_loss: 0.0119 - learning_rate: 4.2391e-05\n",
      "Epoch 347/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 6.5578e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:03:25.605102: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 167ms/step - loss: 6.5575e-05 - val_loss: 0.0120 - learning_rate: 4.2391e-05\n",
      "Epoch 348/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 6.5827e-05 - val_loss: 0.0118 - learning_rate: 4.2391e-05\n",
      "Epoch 349/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 168ms/step - loss: 6.5226e-05 - val_loss: 0.0120 - learning_rate: 4.2391e-05\n",
      "Epoch 350/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 6.6488e-05 - val_loss: 0.0120 - learning_rate: 4.2391e-05\n",
      "Epoch 351/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 6.3198e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:03:58.673104: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 193ms/step - loss: 6.3224e-05 - val_loss: 0.0119 - learning_rate: 4.2391e-05\n",
      "Epoch 352/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 6.6947e-05 - val_loss: 0.0120 - learning_rate: 4.2391e-05\n",
      "Epoch 353/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 6.5699e-05\n",
      "Epoch 353: ReduceLROnPlateau reducing learning rate to 3.815204618149437e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 6.5685e-05 - val_loss: 0.0119 - learning_rate: 4.2391e-05\n",
      "Epoch 354/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 7.0082e-05 - val_loss: 0.0121 - learning_rate: 3.8152e-05\n",
      "Epoch 355/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 6.3709e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:04:31.921226: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 187ms/step - loss: 6.3674e-05 - val_loss: 0.0119 - learning_rate: 3.8152e-05\n",
      "Epoch 356/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 6.4190e-05 - val_loss: 0.0121 - learning_rate: 3.8152e-05\n",
      "Epoch 357/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 165ms/step - loss: 5.8674e-05 - val_loss: 0.0119 - learning_rate: 3.8152e-05\n",
      "Epoch 358/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.9990e-05 - val_loss: 0.0121 - learning_rate: 3.8152e-05\n",
      "Epoch 359/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 6.0365e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:05:05.226747: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 6.0348e-05 - val_loss: 0.0119 - learning_rate: 3.8152e-05\n",
      "Epoch 360/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 6.5761e-05 - val_loss: 0.0120 - learning_rate: 3.8152e-05\n",
      "Epoch 361/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 6.2793e-05 - val_loss: 0.0119 - learning_rate: 3.8152e-05\n",
      "Epoch 362/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 6.5727e-05 - val_loss: 0.0119 - learning_rate: 3.8152e-05\n",
      "Epoch 363/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 6.5977e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:05:37.870563: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 363: ReduceLROnPlateau reducing learning rate to 3.4336842873017304e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 6.5911e-05 - val_loss: 0.0119 - learning_rate: 3.8152e-05\n",
      "Epoch 364/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.6763e-05 - val_loss: 0.0119 - learning_rate: 3.4337e-05\n",
      "Epoch 365/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 6.1579e-05 - val_loss: 0.0121 - learning_rate: 3.4337e-05\n",
      "Epoch 366/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.8858e-05 - val_loss: 0.0120 - learning_rate: 3.4337e-05\n",
      "Epoch 367/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 5.6341e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:06:10.313670: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.6371e-05 - val_loss: 0.0120 - learning_rate: 3.4337e-05\n",
      "Epoch 368/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 6.2640e-05 - val_loss: 0.0119 - learning_rate: 3.4337e-05\n",
      "Epoch 369/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 166ms/step - loss: 5.6606e-05 - val_loss: 0.0119 - learning_rate: 3.4337e-05\n",
      "Epoch 370/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 5.5344e-05 - val_loss: 0.0119 - learning_rate: 3.4337e-05\n",
      "Epoch 371/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 6.4914e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:06:43.358551: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 6.4861e-05 - val_loss: 0.0118 - learning_rate: 3.4337e-05\n",
      "Epoch 372/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 5.8141e-05 - val_loss: 0.0120 - learning_rate: 3.4337e-05\n",
      "Epoch 373/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 5.8096e-05\n",
      "Epoch 373: ReduceLROnPlateau reducing learning rate to 3.0903160222806036e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.8095e-05 - val_loss: 0.0119 - learning_rate: 3.4337e-05\n",
      "Epoch 374/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 5.7844e-05 - val_loss: 0.0120 - learning_rate: 3.0903e-05\n",
      "Epoch 375/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 5.5610e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:07:16.132406: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.5620e-05 - val_loss: 0.0121 - learning_rate: 3.0903e-05\n",
      "Epoch 376/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.5303e-05 - val_loss: 0.0119 - learning_rate: 3.0903e-05\n",
      "Epoch 377/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 162ms/step - loss: 5.7836e-05 - val_loss: 0.0120 - learning_rate: 3.0903e-05\n",
      "Epoch 378/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 176ms/step - loss: 5.8751e-05 - val_loss: 0.0119 - learning_rate: 3.0903e-05\n",
      "Epoch 379/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 5.5831e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:07:47.945537: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 165ms/step - loss: 5.5847e-05 - val_loss: 0.0120 - learning_rate: 3.0903e-05\n",
      "Epoch 380/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 174ms/step - loss: 5.6195e-05 - val_loss: 0.0119 - learning_rate: 3.0903e-05\n",
      "Epoch 381/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.5013e-05 - val_loss: 0.0120 - learning_rate: 3.0903e-05\n",
      "Epoch 382/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 176ms/step - loss: 5.3825e-05 - val_loss: 0.0120 - learning_rate: 3.0903e-05\n",
      "Epoch 383/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 5.3146e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:08:20.665142: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 383: ReduceLROnPlateau reducing learning rate to 3e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.3194e-05 - val_loss: 0.0120 - learning_rate: 3.0903e-05\n",
      "Epoch 384/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 5.4666e-05 - val_loss: 0.0119 - learning_rate: 3.0000e-05\n",
      "Epoch 385/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 165ms/step - loss: 5.5477e-05 - val_loss: 0.0119 - learning_rate: 3.0000e-05\n",
      "Epoch 386/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 174ms/step - loss: 5.8737e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 387/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 5.5769e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:08:53.622167: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 164ms/step - loss: 5.5793e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 388/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 174ms/step - loss: 5.5044e-05 - val_loss: 0.0119 - learning_rate: 3.0000e-05\n",
      "Epoch 389/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.5322e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 390/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 177ms/step - loss: 5.5461e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 391/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 5.3873e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:09:26.289427: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.3894e-05 - val_loss: 0.0119 - learning_rate: 3.0000e-05\n",
      "Epoch 392/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 180ms/step - loss: 5.4297e-05 - val_loss: 0.0119 - learning_rate: 3.0000e-05\n",
      "Epoch 393/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 5.0914e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 394/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 175ms/step - loss: 5.2243e-05 - val_loss: 0.0119 - learning_rate: 3.0000e-05\n",
      "Epoch 395/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 5.5579e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:09:59.216293: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.5552e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 396/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 170ms/step - loss: 5.4752e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 397/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 5.2858e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 398/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 168ms/step - loss: 5.5061e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 399/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 5.2071e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:10:32.788028: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.2059e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 400/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 5.3332e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 401/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.3058e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 402/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 172ms/step - loss: 4.8739e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 403/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 5.2278e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:11:05.635975: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.2303e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 404/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - loss: 5.1584e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 405/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 194ms/step - loss: 5.1205e-05 - val_loss: 0.0119 - learning_rate: 3.0000e-05\n",
      "Epoch 406/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.0758e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 407/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 5.5808e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:11:40.340531: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.5753e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 408/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.9551e-05 - val_loss: 0.0119 - learning_rate: 3.0000e-05\n",
      "Epoch 409/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 5.6315e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 410/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.0964e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 411/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 5.0687e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:12:12.575283: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.0690e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 412/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.1426e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 413/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 178ms/step - loss: 5.5333e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 414/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - loss: 5.1713e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 415/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 5.2115e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:12:46.120682: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 178ms/step - loss: 5.2140e-05 - val_loss: 0.0119 - learning_rate: 3.0000e-05\n",
      "Epoch 416/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 194ms/step - loss: 5.0196e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 417/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 5.0726e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 418/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 5.2472e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 419/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 5.2677e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:13:20.327415: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.2673e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 420/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.0343e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 421/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - loss: 5.0978e-05 - val_loss: 0.0119 - learning_rate: 3.0000e-05\n",
      "Epoch 422/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.7772e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 423/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 5.0192e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:13:51.688143: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 177ms/step - loss: 5.0239e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 424/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 165ms/step - loss: 5.1461e-05 - val_loss: 0.0119 - learning_rate: 3.0000e-05\n",
      "Epoch 425/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 175ms/step - loss: 4.9529e-05 - val_loss: 0.0119 - learning_rate: 3.0000e-05\n",
      "Epoch 426/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 165ms/step - loss: 4.9735e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 427/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.7180e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:14:24.748530: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 173ms/step - loss: 4.7185e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 428/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.8300e-05 - val_loss: 0.0119 - learning_rate: 3.0000e-05\n",
      "Epoch 429/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 172ms/step - loss: 4.6775e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 430/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.0402e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 431/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 5.9313e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:14:58.495091: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 162ms/step - loss: 5.9278e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 432/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.2775e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 433/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 180ms/step - loss: 4.9442e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 434/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.3766e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 435/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 4.7350e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:15:30.933886: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 175ms/step - loss: 4.7333e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 436/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 206ms/step - loss: 4.8057e-05 - val_loss: 0.0119 - learning_rate: 3.0000e-05\n",
      "Epoch 437/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.7846e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 438/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 4.9083e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 439/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 5.1608e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:16:05.869735: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.1587e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 440/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 5.2189e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 441/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - loss: 4.7765e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 442/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.6272e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 443/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 5.1130e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:16:38.807246: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 5.1120e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 444/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 191ms/step - loss: 5.1662e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 445/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 217ms/step - loss: 4.7748e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 446/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.2633e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 447/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 4.6723e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:17:15.743295: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - loss: 4.6719e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 448/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 4.7355e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 449/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 5.0407e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 450/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.6911e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 451/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.5933e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:17:46.649156: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 4.5925e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 452/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 184ms/step - loss: 4.7641e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 453/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 4.9707e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 454/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 164ms/step - loss: 4.4934e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 455/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.5215e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:18:19.825898: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.5195e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 456/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 165ms/step - loss: 4.6843e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 457/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 164ms/step - loss: 4.5208e-05 - val_loss: 0.0119 - learning_rate: 3.0000e-05\n",
      "Epoch 458/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.8719e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 459/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.5474e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:18:51.832378: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 180ms/step - loss: 4.5451e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 460/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 4.3607e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 461/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.6128e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 462/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 4.6787e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 463/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.4785e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:19:24.763739: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.4790e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 464/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 4.3392e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 465/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 167ms/step - loss: 4.5475e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 466/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 163ms/step - loss: 4.5273e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 467/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.8258e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:19:57.759711: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.8265e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 468/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 4.8170e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 469/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 172ms/step - loss: 4.3236e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 470/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 158ms/step - loss: 4.4986e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 471/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.4601e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:20:33.035324: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 4.4592e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 472/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - loss: 4.7152e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 473/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 4.8065e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 474/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 4.7450e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 475/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.6486e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:21:06.702201: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.6450e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 476/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 171ms/step - loss: 4.5174e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 477/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.8065e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 478/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 4.6681e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 479/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.3203e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:21:39.048788: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 4.3203e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 480/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.7462e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 481/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 171ms/step - loss: 4.5461e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 482/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.4606e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 483/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.3157e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:22:10.574982: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.3158e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 484/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 4.1710e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 485/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.1026e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 486/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 176ms/step - loss: 4.4232e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 487/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.6035e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:22:43.267355: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.5986e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 488/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 182ms/step - loss: 4.3765e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 489/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.5210e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 490/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - loss: 4.4323e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 491/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.4487e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:23:18.183819: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 198ms/step - loss: 4.4525e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 492/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 5.0974e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 493/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 194ms/step - loss: 4.2525e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 494/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.0603e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 495/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.4591e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:23:54.392023: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 181ms/step - loss: 4.4639e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 496/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.7642e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 497/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 199ms/step - loss: 4.4404e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 498/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 170ms/step - loss: 4.1604e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 499/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.2040e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:24:30.793704: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - loss: 4.2012e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 500/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 200ms/step - loss: 3.9760e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 501/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.1499e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 502/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 173ms/step - loss: 4.5397e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 503/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.4187e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:25:05.611704: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.4202e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 504/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 196ms/step - loss: 4.3064e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 505/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 4.1294e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 506/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 171ms/step - loss: 4.1513e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 507/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 4.3868e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:25:40.158523: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 4.3866e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 508/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 177ms/step - loss: 3.9946e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 509/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 4.4438e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 510/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 164ms/step - loss: 4.1230e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 511/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.9213e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:26:15.039780: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.9265e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 512/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 170ms/step - loss: 4.3544e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 513/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:26:25.290740: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 4.1181e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 514/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 184ms/step - loss: 4.3251e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 515/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.3818e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:26:49.040989: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 4.3849e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 516/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 174ms/step - loss: 4.0579e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 517/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 4.1167e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 518/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.1344e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 519/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.1725e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:27:22.729361: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 4.1689e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 520/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 209ms/step - loss: 4.0913e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 521/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 4.1525e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 522/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 4.5417e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 523/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.3987e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:27:56.998045: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 4.3977e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 524/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.1836e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 525/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 168ms/step - loss: 3.8762e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 526/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 3.9977e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 527/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 4.0116e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:28:28.246158: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 4.0175e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 528/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.1712e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 529/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.2085e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 530/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.1946e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 531/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.9600e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:29:00.156570: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.9577e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 532/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 183ms/step - loss: 4.0347e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 533/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 4.0800e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 534/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 200ms/step - loss: 3.7891e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 535/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.2815e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:29:35.038924: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.2805e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 536/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 169ms/step - loss: 4.2878e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 537/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.0017e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 538/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 3.9952e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 539/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.7782e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:30:07.965487: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.7825e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 540/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 165ms/step - loss: 4.1479e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 541/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 178ms/step - loss: 3.7746e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 542/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.6930e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 543/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.7535e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:30:40.237311: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.7549e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 544/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 4.4438e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 545/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.7948e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 546/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - loss: 3.9239e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 547/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.9205e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:31:12.591586: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.9191e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 548/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.2544e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 549/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - loss: 3.8366e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 550/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.9790e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 551/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.7342e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:31:45.959190: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 3.7320e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 552/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.7899e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 553/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 173ms/step - loss: 3.7999e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 554/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.8449e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 555/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.6520e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:32:17.519962: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.6539e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 556/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.6797e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 557/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.9440e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 558/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.8090e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 559/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.8094e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:32:49.205177: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.8114e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 560/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.9043e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 561/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 167ms/step - loss: 3.9479e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 562/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.7679e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 563/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.8731e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:33:20.586337: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.8745e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 564/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 4.0700e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 565/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.2586e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 566/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 173ms/step - loss: 3.8490e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 567/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 3.3042e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:33:53.096203: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 3.3070e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 568/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.7709e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 569/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.8824e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 570/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.5779e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 571/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 3.9171e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:34:25.091904: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - loss: 3.9167e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 572/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 166ms/step - loss: 4.1183e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 573/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 180ms/step - loss: 3.7719e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 574/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 4.1483e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 575/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.1193e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:34:58.165149: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.1169e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 576/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.6635e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 577/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.8424e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 578/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 3.6224e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 579/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.6428e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:35:31.449354: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 174ms/step - loss: 3.6455e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 580/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 3.7003e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 581/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 165ms/step - loss: 3.7445e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 582/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 3.3186e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 583/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.5192e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:36:04.481661: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.5209e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 584/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 180ms/step - loss: 3.6891e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 585/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.4702e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 586/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.5296e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 587/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.0226e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:36:36.814102: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.0180e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 588/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 3.7648e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 589/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.6802e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 590/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 3.7831e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 591/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.7323e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:37:08.862511: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.7314e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 592/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 170ms/step - loss: 3.5673e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 593/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.9365e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 594/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.9926e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 595/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.8853e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:37:40.320724: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.8866e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 596/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.7770e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 597/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.9942e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 598/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.7681e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 599/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 3.8138e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:38:11.300710: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.8115e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 600/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.6212e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 601/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 3.8925e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 602/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.7956e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 603/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.3439e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:38:43.307798: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 165ms/step - loss: 3.3472e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 604/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.7991e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 605/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.4882e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 606/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 3.6622e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 607/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 3.2343e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:39:15.406250: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.2354e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 608/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 3.6729e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 609/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.3472e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 610/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 171ms/step - loss: 3.1473e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 611/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.5230e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:39:48.388799: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.5232e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 612/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.9839e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 613/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.4339e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 614/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.8840e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 615/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 3.2280e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:40:19.589223: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.2288e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 616/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.2263e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 617/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.4662e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 618/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 167ms/step - loss: 3.6468e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 619/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 3.8313e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:40:51.677939: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.8273e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 620/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.5019e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 621/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - loss: 3.3368e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 622/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 3.3152e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 623/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.4144e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:41:23.584330: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 166ms/step - loss: 3.4122e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 624/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.5686e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 625/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.6483e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 626/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.2075e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 627/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.4757e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:41:55.986409: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.4746e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 628/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 174ms/step - loss: 3.3876e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 629/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.7255e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 630/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.5761e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 631/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 3.7021e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:42:28.476857: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - loss: 3.6975e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 632/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.8388e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 633/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 166ms/step - loss: 3.3290e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 634/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 3.2626e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 635/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.3137e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:43:00.001797: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.3151e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 636/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.9736e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 637/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.5040e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 638/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 171ms/step - loss: 3.1292e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 639/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.3324e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:43:32.246483: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.3341e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 640/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.3777e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 641/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.5720e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 642/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.9621e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 643/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.2731e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:44:03.219814: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.2753e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 644/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 3.5268e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 645/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 3.8592e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 646/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 163ms/step - loss: 3.0712e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 647/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.6530e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:44:35.737013: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.6476e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 648/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 181ms/step - loss: 2.9241e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 649/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.3018e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 650/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 175ms/step - loss: 3.1125e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 651/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 3.6149e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:45:10.089696: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.6136e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 652/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 169ms/step - loss: 3.1913e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 653/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.5614e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 654/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.3274e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 655/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.3703e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:45:43.799063: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.3697e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 656/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 3.1978e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 657/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 3.4064e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 658/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.2573e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 659/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.4154e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:46:15.092155: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.4130e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 660/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 3.0664e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 661/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.3957e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 662/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 172ms/step - loss: 3.4166e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 663/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.0208e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:46:47.673256: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.0230e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 664/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 165ms/step - loss: 3.4075e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 665/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.5915e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 666/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 163ms/step - loss: 3.7024e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 667/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 3.2784e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:47:22.097444: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 167ms/step - loss: 3.2796e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 668/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 176ms/step - loss: 3.5693e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 669/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.3976e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 670/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.3667e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 671/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.5366e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:47:55.241220: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 3.5335e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 672/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.3051e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 673/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 174ms/step - loss: 2.9187e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 674/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.2428e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 675/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.3799e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:48:27.938292: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 176ms/step - loss: 3.3801e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 676/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.0354e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 677/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 170ms/step - loss: 3.6260e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 678/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.3079e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 679/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.1859e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:49:01.260612: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.1881e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 680/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.3468e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 681/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.2566e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 682/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.0457e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 683/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.3502e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:49:32.957985: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.3475e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 684/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.1890e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 685/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 171ms/step - loss: 3.4232e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 686/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 3.5178e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 687/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.3760e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:50:04.633656: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.3741e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 688/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.9953e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 689/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.2593e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 690/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 170ms/step - loss: 3.2994e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 691/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.1849e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:50:36.838579: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.1845e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 692/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.9262e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 693/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 3.2855e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 694/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.1993e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 695/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.1331e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:51:08.617856: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 167ms/step - loss: 3.1368e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 696/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.5138e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 697/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.9039e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 698/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 161ms/step - loss: 3.6109e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 699/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 3.6934e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:51:41.369962: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.6932e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 700/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.1007e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 701/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.0301e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 702/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.2888e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 703/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 2.9634e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:52:13.336014: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - loss: 2.9640e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 704/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.2113e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 705/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 165ms/step - loss: 3.1139e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 706/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.3852e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 707/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 3.1635e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:52:44.603886: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.1612e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 708/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 3.3224e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 709/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 209ms/step - loss: 2.8795e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 710/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.7321e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 711/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.2889e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:53:18.884219: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.2887e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 712/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.9810e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 713/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.8341e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 714/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 164ms/step - loss: 3.0577e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 715/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.5129e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:53:51.022317: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.5091e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 716/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.4700e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 717/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 3.2917e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 718/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.3516e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 719/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.2346e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:54:22.842247: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 173ms/step - loss: 3.2333e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 720/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.2844e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 721/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 170ms/step - loss: 3.0610e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 722/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.9249e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 723/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.1741e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:54:55.696560: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.1739e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 724/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.8927e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 725/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.7843e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 726/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - loss: 3.1031e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 727/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.8184e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:55:28.534312: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.8193e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 728/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 173ms/step - loss: 3.2535e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 729/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.6046e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 730/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 166ms/step - loss: 3.1496e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 731/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.9006e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:56:02.752521: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.8999e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 732/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 176ms/step - loss: 3.0329e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 733/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.8119e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 734/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 177ms/step - loss: 3.1869e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 735/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.3187e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:56:37.374098: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.3186e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 736/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - loss: 3.0521e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 737/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.2139e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 738/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 166ms/step - loss: 3.2593e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 739/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.2613e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:57:11.192719: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.2594e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 740/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.8723e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 741/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.9301e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 742/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.3385e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 743/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.2174e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:57:43.607978: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 165ms/step - loss: 3.2160e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 744/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.0269e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 745/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 163ms/step - loss: 2.8976e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 746/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.0111e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 747/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.1062e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:58:17.029742: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 180ms/step - loss: 3.1049e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 748/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 3.0050e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 749/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 161ms/step - loss: 2.7893e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 750/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.9320e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 751/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.2684e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:58:53.582854: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 159ms/step - loss: 3.2678e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 752/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.8080e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 753/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 165ms/step - loss: 3.0390e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 754/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.8829e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 755/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.8488e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:59:25.135183: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 2.8534e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 756/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.9971e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 757/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 3.1062e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 758/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 172ms/step - loss: 3.2529e-05 - val_loss: 0.0124 - learning_rate: 3.0000e-05\n",
      "Epoch 759/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.3292e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 02:59:57.394974: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.3297e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 760/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.9369e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 761/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.9582e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 762/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.8268e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 763/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 3.1618e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:00:29.523801: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 173ms/step - loss: 3.1574e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 764/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 3.0400e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 765/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.8153e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 766/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.8437e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 767/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.6389e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:01:02.047456: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.6398e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 768/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - loss: 2.8570e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 769/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.8340e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 770/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 187ms/step - loss: 2.9123e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 771/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.9887e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:01:34.968347: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.9881e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 772/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.9761e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 773/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.7792e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 774/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.6652e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 775/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.2375e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:02:06.807698: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 172ms/step - loss: 3.2334e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 776/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.8534e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 777/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.3247e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 778/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.6813e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 779/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 2.8232e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:02:39.398272: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 2.8267e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 780/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 166ms/step - loss: 2.8627e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 781/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 2.8712e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 782/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.7402e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 783/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.9982e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:03:11.978147: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.9987e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 784/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 2.7065e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 785/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 168ms/step - loss: 3.0385e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 786/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.7755e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 787/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.8418e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:03:43.611205: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 165ms/step - loss: 2.8420e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 788/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 161ms/step - loss: 2.6446e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 789/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5258e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 790/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 3.0007e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 791/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 2.9648e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:04:16.471309: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.9639e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 792/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.7513e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 793/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.5287e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 794/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5158e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 795/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.1028e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:04:48.126718: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 163ms/step - loss: 3.1022e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 796/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 2.8174e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 797/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.5900e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 798/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - loss: 2.7886e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 799/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.4507e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:05:20.388619: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.4432e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 800/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 172ms/step - loss: 2.7807e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 801/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.8917e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 802/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 162ms/step - loss: 3.2176e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 803/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.9507e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:05:53.853711: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.9459e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 804/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 181ms/step - loss: 2.7880e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 805/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5840e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 806/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 170ms/step - loss: 2.8966e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 807/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.8248e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:06:28.547009: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.8273e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 808/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 173ms/step - loss: 2.8298e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 809/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.7745e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 810/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 159ms/step - loss: 2.7541e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 811/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.7416e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:07:04.306276: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.7420e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 812/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - loss: 3.0082e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 813/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 174ms/step - loss: 3.0193e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 814/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5863e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 815/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 3.0366e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:07:40.285211: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 170ms/step - loss: 3.0311e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 816/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 2.6723e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 817/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 2.9184e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 818/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 191ms/step - loss: 2.9136e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 819/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 2.7194e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:08:16.146454: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 2.7225e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 820/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5257e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 821/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 178ms/step - loss: 2.4624e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 822/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 2.5351e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 823/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 2.9272e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:08:47.814668: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 2.9306e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 824/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 163ms/step - loss: 2.6642e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 825/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.6714e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 826/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 193ms/step - loss: 2.7322e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 827/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.0025e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:09:20.752772: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.9988e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 828/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.0678e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 829/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 3.1747e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 830/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.8214e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 831/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.7356e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:09:52.547987: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 164ms/step - loss: 2.7384e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 832/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 3.0185e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 833/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.8827e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 834/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 161ms/step - loss: 2.7628e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 835/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.8918e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:10:24.958100: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.8918e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 836/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 167ms/step - loss: 2.6929e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 837/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.6753e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 838/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.8958e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 839/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.7034e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:10:57.260109: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.7017e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 840/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 2.7282e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 841/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 166ms/step - loss: 2.4613e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 842/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.7094e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 843/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.9542e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:11:28.771176: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.9556e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 844/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 3.0447e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 845/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.8193e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 846/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 167ms/step - loss: 2.7897e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 847/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.6145e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:12:01.020489: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.6149e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 848/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 179ms/step - loss: 2.9486e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 849/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5870e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 850/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.8202e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 851/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.5527e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:12:34.546376: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.5543e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 852/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5813e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 853/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.6502e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 854/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.7836e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 855/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.8153e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:13:06.948970: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.8134e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 856/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.7575e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 857/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.6159e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 858/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5769e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 859/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.6080e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:13:38.945876: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.6112e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 860/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5664e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 861/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.9995e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 862/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 183ms/step - loss: 2.7476e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 863/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 2.8595e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:14:11.571060: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.8605e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 864/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 168ms/step - loss: 2.7747e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 865/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.7522e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 866/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 171ms/step - loss: 2.6901e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 867/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 2.5933e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:14:43.624544: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 168ms/step - loss: 2.5963e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 868/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.6724e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 869/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 178ms/step - loss: 2.3196e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 870/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.3739e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 871/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.8327e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:15:17.580773: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 171ms/step - loss: 2.8324e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 872/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5231e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 873/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 166ms/step - loss: 3.4542e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 874/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 2.4417e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 875/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.3343e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:15:49.796662: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 170ms/step - loss: 2.3371e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 876/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.7241e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 877/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 168ms/step - loss: 3.4521e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 878/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 188ms/step - loss: 2.8349e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 879/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.5285e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:16:24.073149: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5294e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 880/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.8285e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 881/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5429e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 882/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.7761e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 883/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.0008e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:16:57.870974: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.9968e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 884/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.4383e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 885/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.4781e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 886/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 2.4779e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 887/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.6055e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:17:28.863907: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 171ms/step - loss: 2.6042e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 888/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.5062e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 889/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 182ms/step - loss: 2.5657e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 890/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5432e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 891/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.6590e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:18:03.011702: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 171ms/step - loss: 2.6564e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 892/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5456e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 893/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 170ms/step - loss: 2.9416e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 894/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.6627e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 895/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.6793e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:18:35.033925: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - loss: 2.6799e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 896/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5075e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 897/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 166ms/step - loss: 2.6312e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 898/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 173ms/step - loss: 2.6672e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 899/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.8496e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:19:08.470740: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.8500e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 900/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 183ms/step - loss: 2.5819e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 901/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 3.0174e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 902/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.6737e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 903/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.7307e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:19:41.167644: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.7296e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 904/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 176ms/step - loss: 2.6716e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 905/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 175ms/step - loss: 2.6018e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 906/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.8763e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 907/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.9011e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:20:15.288903: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.8990e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 908/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.6345e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 909/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.4883e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 910/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.8705e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 911/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.4823e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:20:47.786505: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 176ms/step - loss: 2.4824e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 912/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 192ms/step - loss: 2.2586e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 913/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.4001e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 914/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.6718e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 915/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.5605e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:21:23.219576: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 2.5629e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 916/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - loss: 2.6887e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 917/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.7891e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 918/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 165ms/step - loss: 3.2470e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 919/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.4483e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:21:55.133029: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 162ms/step - loss: 2.4499e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 920/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 170ms/step - loss: 2.8086e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 921/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 184ms/step - loss: 2.7701e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 922/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.8375e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 923/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.3798e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:22:28.771051: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 183ms/step - loss: 2.3840e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 924/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 190ms/step - loss: 2.8635e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 925/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.6991e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 926/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 178ms/step - loss: 2.4909e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 927/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.4483e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:23:04.259396: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.4500e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 928/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 172ms/step - loss: 2.4680e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 929/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.4648e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 930/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 168ms/step - loss: 2.6368e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 931/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.5523e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:23:36.432356: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5532e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 932/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 171ms/step - loss: 2.7355e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 933/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 175ms/step - loss: 2.7372e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 934/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.2584e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 935/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.6969e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:24:08.721671: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 162ms/step - loss: 2.7020e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 936/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.3956e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 937/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 178ms/step - loss: 2.5766e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 938/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.9014e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 939/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.4123e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:24:42.568788: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 174ms/step - loss: 2.4125e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 940/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.7545e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 941/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.7135e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 942/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.4266e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 943/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.6806e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:25:15.298689: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 2.6826e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 944/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.8327e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 945/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 170ms/step - loss: 2.5472e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 946/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5969e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 947/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 2.8232e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:25:46.946193: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 171ms/step - loss: 2.8210e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 948/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 183ms/step - loss: 2.2796e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 949/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.8089e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 950/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5116e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 951/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.4936e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:26:21.035815: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.4949e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 952/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 178ms/step - loss: 2.5863e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 953/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5597e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 954/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 161ms/step - loss: 2.3903e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 955/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.7568e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:26:54.119186: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 213ms/step - loss: 2.7553e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 956/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 174ms/step - loss: 2.7153e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 957/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.5369e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 958/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.6551e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 959/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.7006e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:27:30.557803: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.7042e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 960/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 166ms/step - loss: 2.5063e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 961/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 179ms/step - loss: 2.4106e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 962/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5606e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 963/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.7822e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:28:03.384257: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 183ms/step - loss: 2.7764e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 964/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.4510e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 965/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 2.7791e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 966/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.6373e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 967/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 2.9577e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:28:36.982214: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.9571e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 968/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.4743e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 969/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 176ms/step - loss: 2.2747e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 970/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.3523e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 971/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.4443e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:29:09.284786: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 171ms/step - loss: 2.4476e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 972/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 162ms/step - loss: 2.5190e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 973/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - loss: 2.4646e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 974/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.6072e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 975/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.4529e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:29:41.444310: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - loss: 2.4548e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 976/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.3271e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 977/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 172ms/step - loss: 2.7349e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 978/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 2.3845e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 979/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.8122e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:30:13.593778: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - loss: 2.8114e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 980/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 181ms/step - loss: 2.6761e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 981/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.5516e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 982/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 180ms/step - loss: 2.4438e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 983/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.6024e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:30:48.043839: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.6014e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 984/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 172ms/step - loss: 2.3677e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 985/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.3172e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 986/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - loss: 2.7102e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 987/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 2.3060e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:31:20.128955: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.3090e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 988/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 171ms/step - loss: 2.6839e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 989/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.2995e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 990/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - loss: 3.0617e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 991/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.5867e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:31:52.124883: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 167ms/step - loss: 2.5870e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 992/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 162ms/step - loss: 2.6606e-05 - val_loss: 0.0124 - learning_rate: 3.0000e-05\n",
      "Epoch 993/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - loss: 2.4675e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 994/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.3188e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 995/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.3925e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:32:24.488720: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 170ms/step - loss: 2.3929e-05 - val_loss: 0.0124 - learning_rate: 3.0000e-05\n",
      "Epoch 996/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5068e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 997/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5209e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 998/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 165ms/step - loss: 2.7708e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 999/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 2.6077e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:32:56.224094: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 190ms/step - loss: 2.6073e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1000/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.4198e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1001/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 176ms/step - loss: 2.3045e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1002/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 207ms/step - loss: 2.5790e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1003/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.3553e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:33:33.060312: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.3551e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1004/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 176ms/step - loss: 2.2237e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1005/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.7414e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 1006/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 2.6294e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1007/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 2.3951e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:34:05.000774: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.3927e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1008/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5151e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1009/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.6716e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1010/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.7495e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1011/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 2.4734e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:34:36.191272: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.4735e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1012/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 161ms/step - loss: 2.2421e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1013/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 163ms/step - loss: 2.3960e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1014/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 174ms/step - loss: 2.5080e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1015/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.3767e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:35:10.781645: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.3767e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1016/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.4123e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1017/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 173ms/step - loss: 2.6592e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1018/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5545e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1019/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.2863e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:35:44.907706: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.2875e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1020/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.4807e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1021/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.8199e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1022/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - loss: 2.5993e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 1023/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.5889e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:36:19.098139: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5881e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1024/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.3817e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1025/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:36:27.770273: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.3043e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1026/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 174ms/step - loss: 2.1913e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1027/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.1233e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:36:52.762352: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.1254e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1028/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 2.4345e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1029/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 186ms/step - loss: 2.1105e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1030/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.2488e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1031/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.7751e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:37:28.794405: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 2.7713e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1032/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 175ms/step - loss: 2.2586e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1033/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 2.3285e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1034/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 2.2815e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1035/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.4806e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:38:00.452618: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 2.4814e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1036/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 158ms/step - loss: 2.8482e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1037/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 158ms/step - loss: 2.7906e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 1038/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5179e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1039/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.3347e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:38:33.691104: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.3346e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1040/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 174ms/step - loss: 2.4161e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1041/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.2758e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1042/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 167ms/step - loss: 2.3833e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1043/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.3963e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:39:06.456730: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 172ms/step - loss: 2.3950e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1044/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.5559e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1045/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - loss: 2.3815e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1046/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 188ms/step - loss: 2.5481e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1047/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.3281e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:39:41.468917: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.3270e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1048/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.1715e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 1049/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 2.9357e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1050/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.9129e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1051/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.3981e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:40:13.927790: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 197ms/step - loss: 2.3985e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1052/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.3168e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1053/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.5431e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1054/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 188ms/step - loss: 2.9804e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1055/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.5945e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:40:49.695352: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 177ms/step - loss: 2.5930e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1056/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.1560e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1057/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 158ms/step - loss: 2.3759e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1058/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 165ms/step - loss: 2.5525e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1059/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.3389e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:41:24.236765: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.3412e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1060/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - loss: 2.3867e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1061/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 173ms/step - loss: 2.2072e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1062/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.3109e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1063/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.4684e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:41:57.968261: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.4702e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1064/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.3787e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1065/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.3182e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1066/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.6334e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1067/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.2101e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:42:28.855759: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.2155e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1068/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 179ms/step - loss: 2.5239e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1069/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.2216e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1070/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 160ms/step - loss: 2.1433e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1071/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.1661e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:43:05.329965: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.1697e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1072/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - loss: 2.0791e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1073/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.2873e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1074/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5611e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1075/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.2755e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:43:37.589223: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.2747e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1076/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.1531e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1077/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.0779e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1078/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.4065e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1079/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.5779e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:44:08.506456: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5764e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1080/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.1604e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1081/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.2620e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1082/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.2960e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 1083/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.2540e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:44:39.491867: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.2564e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1084/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.4135e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 1085/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.3699e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1086/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.4261e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1087/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 2.5196e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:45:11.179258: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 175ms/step - loss: 2.5209e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1088/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 163ms/step - loss: 2.3285e-05 - val_loss: 0.0120 - learning_rate: 3.0000e-05\n",
      "Epoch 1089/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.3962e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1090/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 167ms/step - loss: 2.0724e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1091/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 2.5024e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:45:43.502094: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.5034e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1092/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.2666e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1093/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.2683e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1094/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 167ms/step - loss: 2.5257e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1095/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 2.2723e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:46:15.650449: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - loss: 2.2711e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1096/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 2.0915e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1097/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.2544e-05 - val_loss: 0.0121 - learning_rate: 3.0000e-05\n",
      "Epoch 1098/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 2.4457e-05 - val_loss: 0.0123 - learning_rate: 3.0000e-05\n",
      "Epoch 1099/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 2.4731e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 03:46:46.889794: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 175ms/step - loss: 2.4709e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n",
      "Epoch 1100/1100\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - loss: 2.4437e-05 - val_loss: 0.0122 - learning_rate: 3.0000e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model with the custom callback\n",
    "history = model_builder.train_model(\n",
    "    train_dataset, \n",
    "    val_dataset, \n",
    "    epochs=1100,\n",
    "    callbacks_list=[lr_scheduler]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Extract the losses from the history object\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "train_loss_x_midpoints = history.history.get('x_midpoints_reshape_loss', train_loss)\n",
    "val_loss_x_midpoints = history.history.get('val_x_midpoints_reshape_loss', val_loss)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2,1)\n",
    "plt.plot(train_loss_x_midpoints, label='Train Loss x_midpoints_reshape')\n",
    "plt.plot(val_loss_x_midpoints, label='Validation Loss x_midpoints_reshape')\n",
    "plt.xlabel('Epochs')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss ')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder.model.save(\"/home/da886/Analysis/30KNoNoiseFixed_index84_13_overfit.keras\")\n",
    "# loaded_model = tf.keras.models.load_model(\n",
    "# \"/home/da886/Weights from Josh's model/Josh's5fixedCustomRegularized.keras\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1, batch shape: (800, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 15:33:49.395121: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "W0000 00:00:1728488029.533252 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.533948 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.534290 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.534641 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.534954 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.535281 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.535592 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.535981 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.536323 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.536672 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.536985 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.537336 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.537703 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.538050 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.538408 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.538844 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.539200 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.539572 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.539964 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.540360 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.540760 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.541154 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.541728 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.542050 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.542370 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.542721 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.543131 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.543623 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.544015 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.544432 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.544846 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.545222 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.545692 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.546147 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.546761 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.547356 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.547826 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.548638 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.564284 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.564683 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.564989 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.565305 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.565629 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.565927 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.566207 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.566495 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.566773 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.567212 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.567543 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.568059 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.568832 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.569557 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.570233 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.570971 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.571602 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.572242 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.580649 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.580918 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.581200 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.581502 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.581800 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.582097 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.582394 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.582690 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.582985 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.583295 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.583605 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.583920 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.584249 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.584566 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.584890 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.585300 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.585646 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.586065 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.586532 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.592448 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.592776 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.593070 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.593386 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.593675 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.593998 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.594312 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.594612 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.594918 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.595270 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.595605 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.595942 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.596603 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.597243 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.597889 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.599019 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.600202 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.601001 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.601816 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.618407 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.618704 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.619004 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.619308 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.619628 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.619930 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.620240 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.620565 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.620897 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.621235 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.621575 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.621918 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.622278 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.622645 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.623018 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.623406 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.623808 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.624214 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.624663 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.625206 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.625854 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.626528 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.632953 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.633328 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.633678 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.634025 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.634406 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.634742 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.635148 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.635518 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.635881 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.636343 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.636762 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.637193 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.638065 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.639139 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.640193 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.642277 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.644501 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.645774 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.647062 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.680016 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.680387 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.680751 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.681087 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.681446 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.681823 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.682187 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.682550 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.682951 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.683374 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.683777 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.684179 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.684601 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.685089 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.685578 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.686078 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.686589 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.687196 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.687737 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.688683 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.690227 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.691303 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.698075 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.698523 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.698931 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.699402 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.699798 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.700275 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.700712 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.701155 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.701647 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.702087 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.702516 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.702953 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.704335 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.705854 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.707755 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.709610 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.711535 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.715109 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.717067 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.782667 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.783147 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.783597 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.784021 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.784481 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.784964 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.785434 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.785901 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.786433 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.787018 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.787559 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.788108 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.788650 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.789305 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.790024 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.790780 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.791562 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.792494 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.793312 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.794726 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.797370 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.799154 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.801162 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.810452 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.811053 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.811650 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.812346 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.812920 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.813476 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.814176 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.814917 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.815539 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.816152 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.816788 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.817424 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.819734 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.822513 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.826069 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.829538 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.833129 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.836792 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.843623 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.974047 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.974691 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.975302 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.975910 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.976561 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.977212 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.977879 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.978543 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.979257 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.980028 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.980816 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.981621 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.982449 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.983547 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.984623 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.985717 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.987013 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.988477 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.989833 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488029.994497 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.003304 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.004201 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.005082 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.005949 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.006784 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.007656 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.008715 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.009821 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.010801 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.011654 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.012629 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.013643 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.017832 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.023106 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.029619 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.035957 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.042226 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.048627 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.062013 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.321907 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.322841 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.323778 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.324695 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.325701 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.326733 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.327762 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.328822 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.329958 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.331203 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.332498 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.333815 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.335171 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.336991 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.338884 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.340837 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.343110 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.345770 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.348197 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.362646 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.363299 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.363887 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.364600 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.365307 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.366054 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.366793 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.370248 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.374510 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.377975 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.381623 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.385133 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.388444 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.395495 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.520721 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.521337 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.521931 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.522519 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728488030.523135 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.523753 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.524371 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.525021 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.525678 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.526355 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.527034 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.527707 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.528459 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.529205 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.530105 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.531105 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.532126 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.533337 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.534579 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.535998 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.537355 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.541000 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.543783 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.552888 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.553272 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.553697 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.554054 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.554524 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.555008 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.555564 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.556954 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.557603 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.558810 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.560040 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.561836 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.563608 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.564899 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.566464 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.596530 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.596943 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.597320 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.597702 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.598081 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.598462 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.598851 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.599233 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.599593 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.599956 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.600322 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.600691 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.601079 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.601511 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.601954 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.602412 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.602895 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.603347 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.603879 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.604474 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.605881 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.606681 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.608224 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.615618 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.615935 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.616209 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.616491 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.616775 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.617069 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.617337 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.617634 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.618079 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.618691 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.619308 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.619890 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.620482 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.621492 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.622780 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.625757 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.626021 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.626299 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.626584 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.626870 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.627143 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.627404 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.627662 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.627928 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.628290 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.628655 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.628933 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.629218 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.629511 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.630076 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.630411 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.630761 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.631111 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.631840 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.632213 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.632617 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.633063 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.634164 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.634649 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.641034 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.641337 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.641594 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.641861 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.642375 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.642920 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.643473 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.644151 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.644819 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.646017 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.646624 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.648203 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.649146 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.649383 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.649631 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.649891 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.650139 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.650405 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.650652 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.650928 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.651214 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.651521 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.651782 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.652137 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.652512 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.652879 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.653271 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.653706 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.654111 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.654603 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488030.655159 1288941 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Processing batch 2, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 3, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 4, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 5, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step \n",
      "Processing batch 6, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 7, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 8, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 9, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 10, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 11, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 12, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 13, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 14, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 15, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 16, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 17, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step \n",
      "Processing batch 18, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "Processing batch 19, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 20, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 21, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 22, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 23, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 24, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 25, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 26, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 27, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 28, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 29, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 30, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the function for visualizing midpoints\n",
    "def visualize_midpoints(image, midpoints, title=\"Predicted Midpoint Visualization\"):\n",
    "    \"\"\"\n",
    "    Visualizes midpoints on an image without using a probability vector.\n",
    "\n",
    "    Parameters:\n",
    "    - image: A 3D tensor representing the image.\n",
    "    - midpoints: A 2D tensor representing the midpoint coordinates (x, y).\n",
    "    - title: The title of the plot.\n",
    "\n",
    "    Returns:\n",
    "    None (displays the image with midpoints).\n",
    "    \"\"\"\n",
    "    # Convert to NumPy arrays for easier handling\n",
    "    image_np = image\n",
    "    midpoints_np = midpoints\n",
    "\n",
    "    # Denormalize image if necessary (adjust based on your normalization method)\n",
    "    denormalized_image = image_np  # Modify if normalization was applied during training\n",
    "\n",
    "    # Visualize the image\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(denormalized_image, cmap='gray')\n",
    "    plt.title(title)\n",
    "\n",
    "    # Plot midpoints directly, only if they are not (0, 0)\n",
    "    for i, (x, y) in enumerate(midpoints_np):\n",
    "        if x >= 3 and y >= 3:  # Only plot if the point is not (0, 0)\n",
    "            plt.scatter(x, y, color='red', s=5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Create the validation dataset\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n",
    "# val_dataset = val_dataset.batch(800)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)\n",
    "# # Initialize lists to collect the data\n",
    "all_images = []\n",
    "all_true_midpoints = []\n",
    "all_pred_midpoints = []\n",
    "\n",
    "# # Loop through each batch in the validation dataset, predict, and collect results\n",
    "# for i, (data_batch, midpoints_batch) in enumerate(val_dataset):\n",
    "\n",
    "for i, (data_batch, midpoints_batch) in enumerate(train_dataset):\n",
    "    print(f\"Processing batch {i + 1}, batch shape: {data_batch.shape}\")\n",
    "    \n",
    "    # Get the model predictions\n",
    "    predictions = model_builder.model.predict(data_batch)\n",
    "\n",
    "    # Extend the lists to store data from each batch\n",
    "    all_images.extend(data_batch.numpy())  # Store all images\n",
    "    all_true_midpoints.extend(midpoints_batch.numpy())  # Store all true midpoints\n",
    "    all_pred_midpoints.extend(predictions)  # Store all predicted midpoints\n",
    "\n",
    "# Convert lists to arrays for easier indexing\n",
    "all_images = np.array(all_images)\n",
    "all_true_midpoints = np.array(all_true_midpoints)\n",
    "all_pred_midpoints = np.array(all_pred_midpoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    }
   ],
   "source": [
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "# train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24000, 64, 64), (24000, 1, 5, 2), (24000, 1, 5, 2))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images.shape,all_pred_midpoints.shape,all_true_midpoints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def visualize_midpoints(image, midpoints):\n",
    "#     \"\"\"\n",
    "#     Visualizes midpoints on an image without using a probability vector.\n",
    "\n",
    "#     Parameters:\n",
    "#     - image: A 3D tensor representing the image.\n",
    "#     - midpoints: A 2D tensor representing the midpoint coordinates (x, y).\n",
    "\n",
    "#     Returns:\n",
    "#     None (displays the image with midpoints).\n",
    "#     \"\"\"\n",
    "#     # Convert to NumPy arrays for easier handling\n",
    "#     image_np = image\n",
    "#     midpoints_np = midpoints\n",
    "\n",
    "#     # Denormalize image if necessary (adjust based on your normalization method)\n",
    "#     denormalized_image = image_np  # Modify if normalization was applied during training\n",
    "\n",
    "#     # Visualize the image\n",
    "#     plt.figure(figsize=(4, 4))\n",
    "#     plt.imshow(denormalized_image, cmap='gray')\n",
    "#     plt.title(\"Predicted Midpoint Visualization\")\n",
    "\n",
    "#     # Plot midpoints directly\n",
    "#     for i, (x, y) in enumerate(midpoints_np):\n",
    "#         plt.scatter(x, y, color='red', s=5)\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "# def visualize_midpoints2(image, midpoints):\n",
    "#     \"\"\"\n",
    "#     Visualizes ground truth midpoints on an image without using a probability vector.\n",
    "\n",
    "#     Parameters:\n",
    "#     - image: A 3D tensor representing the image.\n",
    "#     - midpoints: A 2D tensor representing the midpoint coordinates (x, y).\n",
    "\n",
    "#     Returns:\n",
    "#     None (displays the image with midpoints).\n",
    "#     \"\"\"\n",
    "    \n",
    "#     image_np = image\n",
    "#     midpoints_np = midpoints\n",
    "#     denormalized_image = image_np \n",
    "\n",
    "#     # Visualize the image\n",
    "#     plt.figure(figsize=(4, 4))\n",
    "#     plt.imshow(denormalized_image, cmap='gray')\n",
    "#     plt.title(\"Ground Truth Midpoint Visualization\")\n",
    "\n",
    "#     # Plot midpoints directly\n",
    "#     for i, (x, y) in enumerate(midpoints_np):\n",
    "#         plt.scatter(x, y, color='red', s=5)\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "# # Example usage with random data\n",
    "# t = np.random.randint(0, 800)\n",
    "# # t=100\n",
    "\n",
    "# visualize_midpoints(tf.convert_to_tensor(inputs[t]), tf.convert_to_tensor(outputs[t,0,:,:])*64)\n",
    "# visualize_midpoints2(tf.convert_to_tensor(inputs[t]), tf.convert_to_tensor(targets[t,0,:,:])*64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Select an index to visualize from the entire dataset\n",
    "index_to_visualize = np.random.randint(0, len(all_images))\n",
    "\n",
    "# index_to_visualize = 11548\n",
    "# Visualize the selected image with predicted and true midpoints\n",
    "visualize_midpoints(all_images[index_to_visualize], all_pred_midpoints[index_to_visualize, 0, :, :] * 64, title=\"Predicted Midpoints\")\n",
    "visualize_midpoints(all_images[index_to_visualize], all_true_midpoints[index_to_visualize, 0, :, :] * 64, title=\"Ground Truth Midpoints\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_loss = val_images[2]\n",
    "validation_loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Functional.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"IteratorGetNext:0\", shape=(32, 64), dtype=float32). Expected shape (None, 64, 64, 1), but input has incompatible shape (32, 64)\u001b[0m\n\nArguments received by Functional.call():\n   inputs=tf.Tensor(shape=(32, 64), dtype=float32)\n   training=False\n   mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mloaded_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation_loss\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/keras/src/models/functional.py:244\u001b[0m, in \u001b[0;36mFunctional._adjust_input_rank\u001b[0;34m(self, flat_inputs)\u001b[0m\n\u001b[1;32m    242\u001b[0m             adjusted\u001b[38;5;241m.\u001b[39mappend(ops\u001b[38;5;241m.\u001b[39mexpand_dims(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    243\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input shape for input \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but input has incompatible shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    247\u001b[0m     )\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# Add back metadata.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(flat_inputs)):\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Functional.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"IteratorGetNext:0\", shape=(32, 64), dtype=float32). Expected shape (None, 64, 64, 1), but input has incompatible shape (32, 64)\u001b[0m\n\nArguments received by Functional.call():\n   inputs=tf.Tensor(shape=(32, 64), dtype=float32)\n   training=False\n   mask=None"
     ]
    }
   ],
   "source": [
    "loaded_model.evaluate(validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "def custom_loss(exponent):\n",
    "    def loss(y_true, y_pred):\n",
    "        diff = tf.abs(y_true - y_pred)\n",
    "        powered_diff = tf.pow(diff, exponent)\n",
    "        return tf.reduce_mean(powered_diff)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed loss: 0.0044106729328632355\n"
     ]
    }
   ],
   "source": [
    "dynamic_exponent_callback = DynamicExponentCallback(1, 1, 50)\n",
    "loss_fn = dynamic_exponent_callback.custom_loss(exponent=2)\n",
    "\n",
    "\n",
    "\n",
    "y_true = train_midpoints # Ground truth\n",
    "y_pred = all_pred_midpoints  # Predictions\n",
    "\n",
    "\n",
    "computed_loss = loss_fn(y_true, y_pred)\n",
    "\n",
    "print(f\"Computed loss: {computed_loss.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize variables to track the min and max MSE\n",
    "min_mse = float('inf')\n",
    "max_mse = float('-inf')\n",
    "min_mse_index = -1\n",
    "max_mse_index = -1\n",
    "\n",
    "# Loop through each prediction to calculate the MSE\n",
    "for i in range(len(all_pred_midpoints)):\n",
    "    mse = np.mean((all_pred_midpoints[i] - all_true_midpoints[i]) **2)\n",
    "    \n",
    "    if mse < min_mse:\n",
    "        min_mse = mse\n",
    "        min_mse_index = i\n",
    "    \n",
    "    if mse > max_mse:\n",
    "        max_mse = mse\n",
    "        max_mse_index = i\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot an image with its centers\n",
    "def plot_image_with_centers(image, true_center, predicted_center, title):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image.squeeze(), cmap='gray')  # Display the image\n",
    "\n",
    "    # Plot the actual center (Groundtruth)\n",
    "    plt.scatter(true_center[:, 0], true_center[:, 1], color='green', label='Groundtruth', s=10)\n",
    "\n",
    "    # Plot the predicted center\n",
    "    plt.scatter(predicted_center[:, 0], predicted_center[:, 1], color='red', label='Predictions', s=10)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the image with the least MSE\n",
    "plot_image_with_centers(all_images[min_mse_index],\n",
    "                        all_true_midpoints[min_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[min_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        f'Image with Least MSE. MSE: {min_mse:.4f}')\n",
    "\n",
    "# Plotting the image with the largest MSE\n",
    "plot_image_with_centers(all_images[max_mse_index],\n",
    "                        all_true_midpoints[max_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[max_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        f'Image with Largest MSE. MSE: {max_mse:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11548"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_mse_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "objectdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
