{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Set CUDA device order and visible devices\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7,8,9\"\n",
    "\n",
    "# # Set the device\n",
    "# device = '/cpu:0'\n",
    "# if tf.config.experimental.list_physical_devices('GPU'):\n",
    "#     try:\n",
    "#         # Restrict TensorFlow to only use the second GPU\n",
    "#         gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#         if gpus:\n",
    "#             tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "#             device = '/gpu:0'\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)\n",
    "\n",
    "# print(\"device\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 15:37:37.522563: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-09 15:37:37.538186: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-09 15:37:37.551802: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-09 15:37:37.555911: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-09 15:37:37.569007: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-09 15:37:38.202640: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 15:37:42.157388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79196 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:45:00.0, compute capability: 8.0\n",
      "2024-10-09 15:37:42.158944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 79196 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:46:00.0, compute capability: 8.0\n",
      "2024-10-09 15:37:42.160354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 79194 MB memory:  -> device: 2, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:49:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"  # Only GPUs 0 and 1 will be visible to TensorFlow\n",
    "\n",
    "import tensorflow as tf\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\",\"/gpu:2\"])\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# DataLoader Class Definition\n",
    "# -----------------------------\n",
    "class DataLoader:\n",
    "    def __init__(self, h5_filename):\n",
    "        self.h5_filename = h5_filename\n",
    "        self.images, self.centers = self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        with h5py.File(self.h5_filename, 'r') as f:\n",
    "            images = np.array(f['images'])\n",
    "            centers = np.array(f['centers_training'])\n",
    "        return images, centers\n",
    "\n",
    "    def plot_image_with_centers(self, image_index=None):\n",
    "        if image_index is None:\n",
    "            image_index = np.random.randint(0, len(self.images))\n",
    "\n",
    "        image = self.images[image_index]\n",
    "        centers = self.centers[image_index]\n",
    "\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        valid_centers = centers[centers[:, 0] == 1]\n",
    "        for center in valid_centers:\n",
    "            plt.scatter(center[1], center[2], c='red', marker='o',s=5)  # center[1] is x and center[2] is y\n",
    "        plt.title('Image with Valid Centers Marked')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_centers(centers):\n",
    "        return centers[np.lexsort((centers[:, 0], centers[:, 1]))]\n",
    "\n",
    "    def normalize_data(self):\n",
    "        normalized_images = self.images / np.max(self.images)\n",
    "        sorted_centers = np.array([self.sort_centers(image_centers[:, 1:]) for image_centers in self.centers])\n",
    "        normalized_centers = sorted_centers / 64\n",
    "\n",
    "        normalized_midpoints = tf.expand_dims(normalized_centers, axis=1)\n",
    "        return normalized_images, normalized_midpoints.numpy()\n",
    "\n",
    "    def split_data(self, train_size=0.8, random_state=42):\n",
    "        normalized_images, normalized_midpoints_np = self.normalize_data()\n",
    "        return train_test_split(normalized_images, normalized_midpoints_np, train_size=train_size, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Utility Function Definition\n",
    "# -----------------------------\n",
    "def plot_transposed_images_with_midpoints(dataset, image_indices=[0, 1, 2, 3]):\n",
    "    \"\"\"\n",
    "    Extracts multiple images and their midpoints from the given dataset, transposes the images, \n",
    "    corrects the midpoints, and plots the transposed images with the corrected midpoints.\n",
    "\n",
    "    Args:\n",
    "    - dataset (tf.data.Dataset): The dataset from which to extract the images and midpoints.\n",
    "    - image_indices (list): The indices of the images in the batch to visualize. Default is [0, 1, 2, 3].\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract a sample image batch and its corresponding midpoints from the dataset\n",
    "    sample_image_batch, sample_midpoints_batch = next(iter(dataset))\n",
    "\n",
    "    # Create a figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(6, 6))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(image_indices):\n",
    "            # Select the specified image and corresponding midpoints from the batch\n",
    "            sample_image = np.array(sample_image_batch[image_indices[i]])\n",
    "            sample_midpoints = np.array(sample_midpoints_batch[image_indices[i]])\n",
    "\n",
    "            # Transpose the image\n",
    "            transposed_image = sample_image.T\n",
    "\n",
    "            # Correct the midpoints by swapping the x and y coordinates\n",
    "            transposed_midpoints_corrected = sample_midpoints[:, :, [1, 0]]\n",
    "\n",
    "            # Plot the transposed image with corrected midpoints\n",
    "            ax.imshow(transposed_image, cmap='gray')\n",
    "            ax.scatter(\n",
    "                transposed_midpoints_corrected[:, :, 0] * 64, \n",
    "                transposed_midpoints_corrected[:, :, 1] * 64, \n",
    "                c='red', marker='o', s=5\n",
    "            )\n",
    "            ax.set_title(f'Image {image_indices[i]} for this batch')\n",
    "        else:\n",
    "            ax.axis('off')  # If fewer than 4 images are requested, hide the unused subplots\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Custom Loss and Callback Definitions\n",
    "# -----------------------------\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def custom_loss(exponent):\n",
    "    def loss(y_true, y_pred):\n",
    "        diff = tf.abs(y_true - y_pred)\n",
    "        powered_diff = tf.pow(diff, exponent)\n",
    "        return tf.reduce_mean(powered_diff)\n",
    "    return loss\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class DynamicExponentCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, initial_exponent, increment, update_frequency):\n",
    "        super().__init__()\n",
    "        self.exponent = initial_exponent\n",
    "        self.increment = increment\n",
    "        self.update_frequency = update_frequency\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.update_frequency == 0:\n",
    "            self.exponent += self.increment\n",
    "            print(f\"\\nEpoch {epoch + 1}: Increasing exponent to {self.exponent}\")\n",
    "            self.model.loss = self.custom_loss(self.exponent)\n",
    "\n",
    "    def custom_loss(self, exponent):\n",
    "        def loss(y_true, y_pred):\n",
    "            diff = tf.abs(y_true - y_pred)\n",
    "            powered_diff = tf.pow(diff, exponent)\n",
    "            return tf.reduce_mean(powered_diff)\n",
    "        return loss\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'initial_exponent': self.exponent,\n",
    "            'increment': self.increment,\n",
    "            'update_frequency': self.update_frequency,\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my NEW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import layers, regularizers\n",
    "\n",
    "# class ModelBuilder:\n",
    "#     def __init__(self, input_shape=(64, 64, 1), num_classes=3, num_coordinates=2, learning_rate=3e-5, weights_path=None, l2_reg=0.001):\n",
    "#         self.input_shape = input_shape\n",
    "#         self.num_classes = num_classes\n",
    "#         self.num_coordinates = num_coordinates\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.l2_reg = l2_reg\n",
    "#         self.model = self.build_model()\n",
    "\n",
    "#         # Load weights if a path is provided\n",
    "#         if weights_path is not None:\n",
    "#             self.model.load_weights(weights_path)\n",
    "\n",
    "#         self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "#         # self.optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "#     def build_model(self):\n",
    "#         l2 = regularizers.l2(self.l2_reg)\n",
    "        \n",
    "#         x_input = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "#         # First branch\n",
    "#         x_1 = layers.Conv2D(64, kernel_size=6, strides=1, padding='same', activation='relu')(x_input)\n",
    "#         x_1 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(x_1)\n",
    "#         x_1 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu')(x_1)\n",
    "#         x_1 = layers.Conv2D(16, kernel_size=3, strides=3, padding='same', activation='relu', kernel_regularizer=l2)(x_1)\n",
    "#         # x_1 = layers.Dropout(0.1)(x_1)\n",
    "#         # x_1 = layers.BatchNormalization()(x_1)\n",
    "\n",
    "#         # Second branch\n",
    "#         x_2 = layers.Conv2D(32, kernel_size=8, strides=3, padding='same', activation='relu')(x_input)\n",
    "#         x_2 = layers.Conv2D(64, kernel_size=4, strides=1, padding='same', activation='relu')(x_2)\n",
    "#         x_2 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2)(x_2)\n",
    "#         # x_2 = layers.Dropout(0.1)(x_2)\n",
    "#         # x_2 = layers.BatchNormalization()(x_2)\n",
    "\n",
    "#         # Concatenate branches\n",
    "#         x_3 = layers.concatenate([x_1, x_2])\n",
    "#         x_3 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu')(x_3)\n",
    "#         x_3 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(x_3)\n",
    "#         x_3 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2)(x_3)\n",
    "#         # x_3 = layers.Dropout(0.1)(x_3)\n",
    "#         # x_3 = layers.BatchNormalization()(x_3)\n",
    "\n",
    "#         # Third branch\n",
    "#         x_4 = layers.Conv2D(64, kernel_size=19, strides=5, padding='same', activation='relu', kernel_regularizer=l2)(x_input)\n",
    "        \n",
    "#         # Flatten and concatenate\n",
    "#         x_3 = layers.Flatten()(x_3)\n",
    "#         x_4 = layers.Flatten()(x_4)\n",
    "#         x = layers.Concatenate()([x_3, x_4])\n",
    "\n",
    "#         # Dense layers with L2 regularization\n",
    "#         x = layers.Dense(256, activation='relu', kernel_regularizer=l2)(x)\n",
    "#         # x = layers.Dropout(0.1)(x)\n",
    "\n",
    "#         # Output layer for midpoints\n",
    "#         x_midpoints = layers.Dense(self.num_classes * self.num_coordinates, activation='sigmoid', name='x_midpoints')(x)\n",
    "#         x_midpoints_reshape = layers.Reshape((-1, self.num_classes, self.num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "        \n",
    "#         return tf.keras.models.Model(x_input, x_midpoints_reshape)\n",
    "\n",
    "#     def compile_model(self, loss_function):\n",
    "#         self.model.compile(optimizer=self.optimizer, loss=loss_function)\n",
    "\n",
    "#     def train_model(self, train_dataset, val_dataset, epochs, callbacks_list):\n",
    "#         history = self.model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks_list)\n",
    "#         return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "\n",
    "class ModelBuilder:\n",
    "    def __init__(self, input_shape=(64, 64, 1), num_classes=13, num_coordinates=2, learning_rate=1e-3, weights_path=None,l1_reg=0.001,l2_reg =0.01):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.num_coordinates = num_coordinates\n",
    "        self.learning_rate = learning_rate\n",
    "        self.l1_reg = l1_reg\n",
    "        self.l2_reg = l2_reg\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        # Load weights if a path is provided\n",
    "        if weights_path is not None:\n",
    "            self.model.load_weights(weights_path)\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "        # self.optimizer =tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "    def build_model(self):\n",
    "        \n",
    "        l1 = regularizers.l1(self.l1_reg)\n",
    "        l2 = regularizers.l2(self.l2_reg)\n",
    "\n",
    "    \n",
    "        x_input = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "        \n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x_input)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        \n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        \n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.3)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.3)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(128, kernel_size=5, padding='same', activation='relu')(x)\n",
    "        # x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Flatten()(x)\n",
    "        \n",
    "        x_midpoints = layers.Dense(self.num_classes * self.num_coordinates, activation='linear', name='x_midpoints')(x)\n",
    "        x_midpoints_reshape = layers.Reshape((-1, self.num_classes, self.num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "        \n",
    "        return tf.keras.models.Model(x_input, x_midpoints_reshape)\n",
    "\n",
    "    def compile_model(self, loss_function):\n",
    "        self.model.compile(optimizer=self.optimizer, loss=loss_function)\n",
    "\n",
    "    def train_model(self, train_dataset, val_dataset, epochs, callbacks_list):\n",
    "        history = self.model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks_list)\n",
    "        return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Main Script Execution\n",
    "# -----------------------------\n",
    "\n",
    "# Load data\n",
    "# h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KFixed_Mixed_13.h5'             \n",
    "# h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KNoFalsePositivesFixed-index84_13.h5'\n",
    "h5_filename = '/home/da886/Final Electron counting project/Images and Labels/100analysis.h5'\n",
    "data_loader = DataLoader(h5_filename)\n",
    "images, centers = data_loader.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l=np.random.randint(0,len(centers))\n",
    "data_loader.plot_image_with_centers(l)\n",
    "plt.imshow(images[l]),l\n",
    "plt.grid(True),l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[l]),l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.765625, 0.140625],\n",
       "        [0.625   , 0.171875],\n",
       "        [0.65625 , 0.234375],\n",
       "        [0.65625 , 0.28125 ],\n",
       "        [0.171875, 0.296875],\n",
       "        [0.453125, 0.359375],\n",
       "        [0.78125 , 0.375   ],\n",
       "        [0.625   , 0.453125],\n",
       "        [0.546875, 0.578125],\n",
       "        [0.796875, 0.59375 ],\n",
       "        [0.46875 , 0.671875],\n",
       "        [0.625   , 0.71875 ],\n",
       "        [0.203125, 0.765625]]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.random.randint(0, len(images))\n",
    "train_midpoints[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the data and split it into training and validation sets\n",
    "train_images, val_images, train_midpoints, val_midpoints = data_loader.split_data()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images: (24000, 64, 64), Train Midpoints: (24000, 1, 13, 2)\n",
      "Validation Images: (6000, 64, 64), Validation Midpoints: (6000, 1, 13, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 1000\n",
    "train_dataset = train_dataset.shuffle(buffer_size=8000, reshuffle_each_iteration=True).batch(batch_size)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=8000).batch(batch_size)\n",
    "\n",
    "# Check the shape of the datasets\n",
    "print(f'Train Images: {train_images.shape}, Train Midpoints: {train_midpoints.shape}')\n",
    "print(f'Validation Images: {val_images.shape}, Validation Midpoints: {val_midpoints.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAJOCAYAAAC++60XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAACuxUlEQVR4nO2de3xUxd3/P2c3yeYC2QBCAkIwWsrFS7EgGBJFIYpItQjFVu1PtFaqBhSwrUUfrmICUqu1XvBWtFVLi33UYh+lGhALIgpKvVARFYWKCWrJBgOEsDu/PyDr2ZPdOWfOJbvZfN6v175gz2Vmzsyc707me9OEEAKEEEIIIWmIL9kNIIQQQgjxCi50CCGEEJK2cKFDCCGEkLSFCx1CCCGEpC1c6BBCCCEkbeFChxBCCCFpCxc6hBBCCElbuNAhhBBCSNrChQ4hhBBC0hYudIiUN954AyNGjEBeXh40TcOWLVuS0o7jjjsO3/ve90yve/nll6FpGl5++WXHdZ511lk46aSTHJfjFvPmzYOmafjyyy+T3RRCksL27dtx7rnnIhgMQtM0PPPMM0lph1XZ8Mknn0DTNDz66KOO67ziiivQqVMnx+W4xaOPPgpN07Bp06ZkN8WUDrvQaU+D5JRHHnkEAwcORHZ2Nvr164ff/e53lu5rbm7GpEmT8N///hd33nkn/vjHP6Jv376etXPr1q2YN28ePvnkE8/qSCb79+/HvHnzXFmEkfSio8ij+++/H5MmTUJxcTE0TcMVV1yhdP/kyZPxzjvv4LbbbsMf//hHDB061JuGAti9ezfmzZuXtD/u2oKqqqqkLRbbkoxkN4B4ywMPPIBrrrkGEydOxMyZM/HPf/4T119/Pfbv34+bbrpJeu9HH32ETz/9FA899BB++tOfet7WrVu3Yv78+TjrrLNw3HHH2SrjzDPPxIEDB5CVleVu41xg//79mD9/PoAjfxES0tFYvHgx9u3bh2HDhuHzzz9XuvfAgQPYsGEDbrnlFkydOtWjFn7D7t27MX/+fBx33HEYPHiwrTL69u2LAwcOIDMz093GuURVVRV+8IMfYPz48cluiqdwoZPGHDhwALfccgvGjRuHp556CgBw9dVXIxKJ4NZbb8WUKVPQpUuXhPfv2bMHAFBQUOBamxobG5GXl+daeUZ8Ph+ys7M9K58QYp+1a9dGd3NU1TBffPEFgPYljzRNozxKATqs6ioeLTrQnTt34nvf+x46deqEY489Fvfeey8A4J133sGoUaOQl5eHvn374sknn4y5/7///S9+/vOf4+STT0anTp2Qn5+PsWPH4l//+leruj799FNceOGFyMvLQ48ePTBjxgysWrUqrn3Jxo0bcd555yEYDCI3NxcjR47E+vXrTZ9nzZo1+Oqrr3DdddfFHK+srERjYyP+/ve/S/ti5MiRAIBJkyZB07SYXYjVq1fjjDPOQF5eHgoKCvD9738f//73v2PKaLEp2bp1Ky699FJ06dIF5eXlcet79NFHMWnSJADA2WefDU3T4vbFunXrMGzYMGRnZ+P444/HH/7wh5jz8Wx0tm/fjokTJ6KoqAjZ2dno3bs3fvSjHyEUCiV8fj2bN2/GiBEjkJOTg5KSEixdujTm/KFDhzBnzhwMGTIEwWAQeXl5OOOMM7BmzZroNZ988gm6d+8OAJg/f370+ebNmxe95v3338fFF1+M7t27IycnB/3798ctt9zSqj319fW44oorUFBQgGAwiCuvvBL79++39Cyk/ZBu8gg4ssOhaZpyX8ybNy+qNv/FL34BTdNidn3feustjB07Fvn5+ejUqRNGjx6N1157LaaMFvXg2rVrcd1116FHjx7o3bt33PpefvllnHbaaQCAK6+8Mvq+Gm1ttm7dirPPPhu5ubk49thjcfvtt8ecj2ejU1tbiyuvvBK9e/dGIBBAz5498f3vf9+yyv7jjz/GmDFjkJeXh169emHBggUQQsRc8+tf/xojRoxAt27dkJOTgyFDhkT/2G1B0zQ0Njbiscceiz6fXpX42Wef4aqrrkKvXr0QCARQUlKCa6+9FocOHYopp6mpCTNnzkT37t2Rl5eHiy66KLooTRW4o2MgHA5j7NixOPPMM3H77bfjiSeewNSpU5GXl4dbbrkFl112GSZMmIClS5fi8ssvR2lpKUpKSgAcmYDPPPMMJk2ahJKSEtTV1eGBBx7AyJEjsXXrVvTq1QvAkb8iRo0ahc8//xw33HADioqK8OSTT8b8MLawevVqjB07FkOGDMHcuXPh8/mwbNkyjBo1Cv/85z8xbNiwhM/y1ltvAUArPfaQIUPg8/nw1ltv4cc//nHce3/2s5/h2GOPRVVVFa6//nqcdtppKCwsBAC89NJLGDt2LI4//njMmzcPBw4cwO9+9zuUlZXhzTffbKV2mjRpEvr164eqqqpWL2QLZ555Jq6//nrcfffduPnmmzFw4EAAiP4LAB9++CF+8IMf4KqrrsLkyZPx+9//HldccQWGDBmCE088MW65hw4dwpgxY9DU1IRp06ahqKgIn332GZ577jnU19cjGAwm7D8A2Lt3L84//3xcfPHFuOSSS/CXv/wF1157LbKysvCTn/wEANDQ0ICHH34Yl1xyCa6++mrs27cPjzzyCMaMGYPXX38dgwcPRvfu3XH//ffj2muvxUUXXYQJEyYAAE455RQAwNtvv40zzjgDmZmZmDJlCo477jh89NFHWLlyJW677baYNl188cUoKSlBdXU13nzzTTz88MPo0aMHFi9eLH0W0v5IJ3nkhAkTJqCgoAAzZszAJZdcgvPPPz+6I/Tee+/hjDPOQH5+Pn75y18iMzMTDzzwAM466yysXbsWw4cPjynruuuuQ/fu3TFnzhw0NjbGrW/gwIFYsGAB5syZgylTpuCMM84AAIwYMSJ6zd69e3HeeedhwoQJuPjii/HUU0/hpptuwsknn4yxY8cmfJaJEyfivffew7Rp03Dcccdhz549ePHFF7Fz505TlX04HMZ5552H008/HbfffjteeOEFzJ07F4cPH8aCBQui1/32t7/FhRdeiMsuuwyHDh3C8uXLMWnSJDz33HMYN24cAOCPf/wjfvrTn2LYsGGYMmUKAOCEE04AcERtN2zYMNTX12PKlCkYMGAAPvvsMzz11FPYv39/jGnAtGnT0KVLF8ydOxeffPIJ7rrrLkydOhV//vOfpc/SpogOyrJlywQA8cYbb0SPTZ48WQAQVVVV0WN79+4VOTk5QtM0sXz58ujx999/XwAQc+fOjR47ePCgCIfDMfXs2LFDBAIBsWDBguixO+64QwAQzzzzTPTYgQMHxIABAwQAsWbNGiGEEJFIRPTr10+MGTNGRCKR6LX79+8XJSUl4pxzzpE+Y2VlpfD7/XHPde/eXfzoRz+S3r9mzRoBQKxYsSLm+ODBg0WPHj3EV199FT32r3/9S/h8PnH55ZdHj82dO1cAEJdccom0nhZWrFgR8/x6+vbtKwCIV155JXpsz549IhAIiBtvvLFVm1vKeOutt+I+gxVGjhwpAIg77rgjeqypqSn6/IcOHRJCCHH48GHR1NQUc+/evXtFYWGh+MlPfhI99sUXX7SaMy2ceeaZonPnzuLTTz+NOa4f95b+1JcphBAXXXSR6Natm/LzkdShI8gjI3l5eWLy5MmWr9+xY4cAIJYsWRJzfPz48SIrK0t89NFH0WO7d+8WnTt3FmeeeWb0WEsfl5eXi8OHD5vW98YbbwgAYtmyZa3OtciGP/zhD9FjTU1NoqioSEycOLFVm1vK2Lt3b9xnsELLfJg2bVr0WCQSEePGjRNZWVniiy++iB7fv39/zL2HDh0SJ510khg1alTM8URjcPnllwufzxczH/V1CvFNf1ZUVMTMhxkzZgi/3y/q6+uVn9ErqLqKg97wtqCgAP3790deXh4uvvji6PH+/fujoKAAH3/8cfRYIBCAz3ekS8PhML766it06tQJ/fv3x5tvvhm97oUXXsCxxx6LCy+8MHosOzsbV199dUw7tmzZgu3bt+PSSy/FV199hS+//BJffvklGhsbMXr0aLzyyiuIRCIJn0NmlJudnY0DBw5Y7JFv+Pzzz7FlyxZcccUV6Nq1a/T4KaecgnPOOQf/93//1+qea665RrmeeAwaNCj6lxUAdO/eHf37948ZAyMtOzarVq2ypd7JyMjAz372s+j3rKws/OxnP8OePXuwefNmAIDf74/2cyQSwX//+18cPnwYQ4cOjRn3RHzxxRd45ZVX8JOf/ATFxcUx5+Jt8xv784wzzsBXX32FhoYG5ecjqU+6yCMvCIfD+Mc//oHx48fj+OOPjx7v2bMnLr30Uqxbt67Ve3H11VfD7/c7rrtTp04xO+JZWVkYNmyYVB7l5OQgKysLL7/8Mvbu3WurXr0htqZpmDp1Kg4dOoSXXnoppp4W9u7di1AohDPOOMOSPIpEInjmmWdwwQUXxPVqM8qkKVOmxBw744wzEA6H8emnnyo9l5dwoWMgOzs7akvRQjAYRO/evVsNcDAYjJmskUgEd955J/r164dAIIBjjjkG3bt3x9tvvx1jD/Lpp5/ihBNOaFXet771rZjv27dvB3DEpbJ79+4xn4cffhhNTU1SO5OcnJxW+tQWDh48GPMyWKVl8vbv37/VuYEDB0YFn56WrXSnGBcBANClSxepwCgpKcHMmTPx8MMP45hjjsGYMWNw7733WrbP6dWrVytjxW9/+9sAEKNTf+yxx3DKKacgOzsb3bp1Q/fu3fH3v//dUj0tgtFqzB5jP7QYlNsVnCR1SSd55AVffPEF9u/fn1AeRSIR7Nq1K+a4W/Io3hiYyaNAIIDFixfj+eefR2FhYVQlWVtba6lOn88Xs6AD4suj5557Dqeffjqys7PRtWvXqOrcyvh88cUXaGhoSCt5RBsdA4lW+omOC53NSVVVFWbPno2f/OQnuPXWW9G1a1f4fD5Mnz7d1l86LfcsWbIkoXujzHOhZ8+eCIfD2LNnD3r06BE9fujQIXz11VdRHb3X2FlQxcPKGMTjjjvuwBVXXIFnn30W//jHP3D99dejuroar732WkJjRBUef/xxXHHFFRg/fjx+8YtfoEePHvD7/aiursZHH33kuHwjdvuBtD/SSR6lCsmWR9OnT8cFF1yAZ555BqtWrcLs2bNRXV2N1atX49RTT3Xcrn/+85+48MILceaZZ+K+++5Dz549kZmZiWXLlrUyWHeD9iCPuNBxkaeeegpnn302HnnkkZjj9fX1OOaYY6Lf+/bti61bt0IIEfMXwYcffhhzX4thWH5+PioqKpTb0yKMNm3ahPPPPz96fNOmTYhEIrZiQ7R4Pmzbtq3Vuffffx/HHHOMbXdNO94YVjn55JNx8skn43/+53/w6quvoqysDEuXLsXChQul9+3evbuVC+oHH3wAAFHDwaeeegrHH388/vd//zfmGebOnRtTVqLna/kL7d1331V+LkISkWryyAu6d++O3NzchPLI5/OhT58+tsr2Uh6dcMIJuPHGG3HjjTdi+/btGDx4MO644w48/vjj0vsikQg+/vjj6C4O0Foe/fWvf0V2djZWrVqFQCAQvW7ZsmWtyov3jN27d0d+fn5aySOqrlzE7/e3WsWuWLECn332WcyxMWPG4LPPPsPf/va36LGDBw/ioYceirluyJAhOOGEE/DrX/8aX3/9dav6zFz4Ro0aha5du+L++++POX7//fcjNzc3an2vQs+ePTF48GA89thjqK+vjx5/99138Y9//CNmQaVKy2JCX65TGhoacPjw4ZhjJ598Mnw+H5qamkzvP3z4MB544IHo90OHDuGBBx5A9+7dMWTIEADf/EWjH/uNGzdiw4YNMWXl5uYCaP183bt3x5lnnonf//732LlzZ8y5VPqriLQvUk0eeYHf78e5556LZ599NkZ1U1dXhyeffBLl5eXIz8+3VbYX8mj//v04ePBgzLETTjgBnTt3tiSPAOCee+6J/l8IgXvuuQeZmZkYPXo0gCN9omkawuFw9LpPPvkkbgTkvLy8Vs/n8/kwfvx4rFy5Mm6k7vYok7ij4yLf+973sGDBAlx55ZUYMWIE3nnnHTzxxBOtdKo/+9nPcM899+CSSy7BDTfcgJ49e+KJJ56IBpZqWWX7fD48/PDDGDt2LE488URceeWVOPbYY/HZZ59hzZo1yM/Px8qVKxO2JycnB7feeisqKysxadIkjBkzBv/85z/x+OOP47bbbosxJlZhyZIlGDt2LEpLS3HVVVdF3cuDwWBMXBhVBg8eDL/fj8WLFyMUCiEQCGDUqFExajdVVq9ejalTp2LSpEn49re/jcOHD+OPf/wj/H4/Jk6caHp/r169sHjxYnzyySf49re/jT//+c/YsmULHnzwwWi00+9973v43//9X1x00UUYN24cduzYgaVLl2LQoEExPwg5OTkYNGgQ/vznP+Pb3/42unbtipNOOgknnXQS7r77bpSXl+O73/0upkyZgpKSEnzyySf4+9//ntYh6Il3pJo8AoCVK1dG4/g0Nzfj7bffju6qXnjhhdFwCyosXLgQL774IsrLy3HdddchIyMDDzzwAJqamlrFtVHhhBNOQEFBAZYuXYrOnTsjLy8Pw4cPd2Tj88EHH2D06NG4+OKLMWjQIGRkZODpp59GXV0dfvSjH5nen52djRdeeAGTJ0/G8OHD8fzzz+Pvf/87br755qgt17hx4/Cb3/wG5513Hi699FLs2bMH9957L771rW/h7bffjilvyJAheOmll/Cb3/wGvXr1QklJCYYPH46qqir84x//wMiRIzFlyhQMHDgQn3/+OVasWIF169a5GrSxTUiGq1cqkMidMy8vr9W1I0eOFCeeeGKr43379hXjxo2Lfj948KC48cYbRc+ePUVOTo4oKysTGzZsECNHjhQjR46Muffjjz8W48aNEzk5OaJ79+7ixhtvFH/9618FAPHaa6/FXPvWW2+JCRMmiG7duolAICD69u0rLr74YlFTU2PpWR988EHRv39/kZWVJU444QRx5513xrgDJiKRe7kQQrz00kuirKxM5OTkiPz8fHHBBReIrVu3xlzT4g6td3s046GHHhLHH3+88Pv9Ma6txr5uwdi3Rvfyjz/+WPzkJz8RJ5xwgsjOzhZdu3YVZ599tnjppZdM29Iy7ps2bRKlpaUiOztb9O3bV9xzzz0x10UiEVFVVSX69u0rAoGAOPXUU8Vzzz0nJk+eLPr27Rtz7auvviqGDBkisrKyWrkDv/vuu+Kiiy4SBQUFIjs7W/Tv31/Mnj07ej5Rf7bM5R07dpg+E0lNOoo8anGRjveJ58atJ5F7uRBCvPnmm2LMmDGiU6dOIjc3V5x99tni1VdfjbkmXh+b8eyzz4pBgwaJjIyMmDYmGgPjO290L//yyy9FZWWlGDBggMjLyxPBYFAMHz5c/OUvfzFtS8t8+Oijj8S5554rcnNzRWFhoZg7d26rMAKPPPKI6NevnwgEAmLAgAFi2bJlUfmh5/333xdnnnmmyMnJEQBiXM0//fRTcfnll4vu3buLQCAgjj/+eFFZWRkNpZGoP40yOBXQhGiH+1Bpyl133YUZM2bgP//5D4499thkN4cQ0oGhPCLpAhc6SeLAgQMx1v8HDx7EqaeeinA4HDUuI4SQtoDyiKQztNFJEhMmTEBxcTEGDx6MUCiExx9/HO+//z6eeOKJZDeNENLBoDwi6QwXOklizJgxePjhh/HEE08gHA5j0KBBWL58OX74wx8mu2mEkA4G5RFJZ6i6IoQQQkjawjg6hBBCCElbPFvo3HvvvTjuuOOQnZ2N4cOH4/XXX/eqKkIIkUJ5REjHxRPV1Z///GdcfvnlWLp0KYYPH4677roLK1aswLZt20yDv0UiEezevRudO3f2NAQ3IUQdIQT27duHXr16RTNjpzpO5BFAmURIqmJZHnkRnGfYsGGisrIy+j0cDotevXqJ6upq03t37dqVMKAUP/zwkxqfXbt2eSE6PMGJPBKCMokfflL9YyaPXPe6OnToEDZv3oxZs2ZFj/l8PlRUVLTK/QMATU1NMTk+xNENJp/PF/3rSZ+zwy1U/jITDja99PUYyzG2wWo9xmyxxv7Rn/ei78za1FZ1qiAbBzfKdLNcGWZj7wXx+q5z586e1+sGqvIISCyT3ECfZLGlrhbMZJLddsjmqVdzWFaucQ7LMqk7aU9LihbgSLqJVEM/F4x5rvR9ZOyftpAzRpIhd1Qwk0eu7z1/+eWXCIfDKCwsjDleWFiI2traVtdXV1cjGAxGP8XFxQCOvCgtHy/Ql2/2caseszbYbbtKnV6RjDpV8KJ9bs6T9lZnqo6zEVV5BCSWSW4gGz+v5JBKnW7h5DnbQvamAiq/Dcl+llRogwyzNiVdyT5r1iyEQqHoZ9euXcluEiGkA0OZREh64brq6phjjoHf70ddXV3M8bq6OhQVFbW6PhAItNrOBY5s1+mz5uqPJyIjI/ZxjNfqv8vKMWI0crJ7r5M69d8PHz4svdZ4Xnat1TZlZWVJ63DybHbLkWGcC7I+sYtKW439p7/Xi7a5iVtjkgxU5RGQWCYlQjbXzN43Fflg971ROacid2TI6jQrx6qRu7HfjRw6dMhSOSr1GNuuImeMMuDgwYMJr001maDSHpU+yc7Ojv5f1h9GWuaIEMKSKs/1HZ2srCwMGTIENTU10WORSAQ1NTUoLS11uzpCCEkI5REhxJMUEDNnzsTkyZMxdOhQDBs2DHfddRcaGxtx5ZVXelEdIYQkhPKIkI6NJwudH/7wh/jiiy8wZ84c1NbWYvDgwXjhhRdaGQTK0G9J6bcyc3NzY67Tb3fJVFXGcoznZNttKlv3KtvYsq1Ms/bpkbVPthVtvFd2zq1tYLM63cKtrV+7/eWkPU7UllbnQntWR6nihjxSQabqMGJ3HJyMn2weqKhXvJpPsnJl55y0Qf/cRlknk1Eq77VMhqqoe5yoSq1iVo7s98hunxjnnso4mJFyua4aGhoQDAZjjukfUK/TA+QvolsLHRXcWugYkb2IMswWOl68JCoko04V3FroqNhXtIeFTigUQn5+vqMy2gvxZJIeFaFvJsxluDV+snJU5KtXCx3ZQtEr+z6ZfLUre1XoqAsdfT3GMq0sdFo2RMzkUdK9rgghhBBCvIILHUIIIYSkLZ7Y6LiBPjCRftts//79tstUcbO06vZmtsUn2/Y0fpdt2dp13zbbDpTVYXebWGX71K1yjNeqPLf+XjNX/bbYVlexPVAJt5BqLqvpgpN+VZkzVueQ2Xtjdz7J6kmGytlMXqmomfXywXitXXWVihrQLRs+t8bBrByVECayclXsQB2pa23fSQghhBCS4nChQwghhJC0JWVVV5YjHiq4Ssq2xmQeULJtT5XonMZrc3JyYr43NjYmLEe/VWgWAVp/XqYeM97rxMVeJXqo1QjVKh4hxjpk26eyeWE8J2uTMdSBEX25bkXi9sql3Yi+P/V1WH0v0xG/3x9Vp1v1ijFeJ4u4bDZH9HPTqAaRqciNCQ/1csZMVeuWa7WKelhWrlsRoGXtU7lOVq5xjNzykHTL80tFtWZExc2/LbzWzOCODiGEEELSFi50CCGEEJK2cKFDCCGEkLQlZW10rCLTW9u1yVHBzA1cpp/ct29fwnJl7tJmek6rrtRAbPtl9jxO0mDI7jXaucjCB8h03sa2G8vVj4PMDsHYVtm1xraaRaG2ilfpP1Rc0e1mrU5nIpFI1EZHZssl6zvjO6+3k1Bxr1WxPzTa/lm1kTOjLdzL2ypEgtX2O3lOJyEm3EI/ZmY2RLL2qIy9VbscL6Pkc0eHEEIIIWkLFzqEEEIISVu40CGEEEJI2tLubXSsxrsxopIFWiWOjlmaB6uY2YrYxa79jpmu3G77nIQ+l42vzNZHVo6xf1RiTaiE2ldJJWG3b2U6dxU7KnIEfQwh2Xuk71uzfpbJLyNW61SZh3azlZuVa8RuHCmVFCxWyzRrj+xaJ7HZZNm4VdqjIh+M46uSAkhWp+ycXXtOs/G0O/YAd3QIIYQQksZwoUMIIYSQtCVlVVf6cOt6jFtWsizjTlIaWC1Xth0Z73ui9pih4l5u1+1T5tasouoz265XyVgrK0eGrH0qW7QqYQeM28T6PnMS5l5ly9ZqaPZkhWJvz2RmZkZlkiy1i36MjOoLlRQLXrnbylyMjcjCY6iEPbDr0i5T05j1j0ydZ7ffzeS93WvN2mAXYxus9r2ZDLeaAsV4rxOTjHi/MUIIhMNh03u5o0MIIYSQtIULHUIIIYSkLVzoEEIIISRtSVkbHSt6N0DununEJVumu7arV3SiY/fKlkWPzNbAieu+TJcvwywVgqx9du0bVO4zs7+wOk/M6pTZfMh08MZyZekGnNgFdRT0KSBkLtAyu5Z4ZbbgJN2BXZlkNvdk7W+LeeHEjsWu/HJi16ivx0wm2XX1dsutX8WG1UmdboXZcPJbyh0dQgghhKQtXOgQQgghJG3hQocQQgghaUvK2ugEAoGoPtxqWPK2SG1v/G7UKzqJESHTV6ro1WXlqMS+kJ1zYrMjQ6bjVok9ozIOepsKs+fUfzeLKyKz1bA7b53YaqnEBKJdTmus2g3axcsQ+IlwIjPtpp0ww+q74WZMIhW7Kj3Gd77lu18I1N90E3zr1yNSVobITTehc5cuCe9Vsd9xguy3S4+T8ZPJUJn9oVdxowAbOzqvvPIKLrjgAvTq1QuapuGZZ56JOS+EwJw5c9CzZ0/k5OSgoqIC27dvd6u9hBAShfKIpCK/DIfhv/VW+Gpqjvy7eHGym9ShUV7oNDY24jvf+Q7uvffeuOdvv/123H333Vi6dCk2btyIvLw8jBkzRumvSUIIsQLlEUlFRoTD0I4mgNWEgG/9+iS3qIMjHABAPP3009HvkUhEFBUViSVLlkSP1dfXi0AgIP70pz9ZKjMUCgkACT9ZWVkxH/05n88X85GVk5GREfOR1SMrp6mpSTQ1NormOXNEePRoMUfTRKamtWqLz+cT2dnZMR9jWVbbrvIxPqdZGxLdazYOXrQ9FT5m86SjfkKhkBPR4QmA+/JICHOZ5NYnnsxI9F7J5KBZuVbvAyByc3OjH5U6ZO+Nk3dKJmdU5L9bdRrHoUWuzs/IEGFACECEATHbQZ3G/nLynIlktpvluCUzVdpnJo9ctdHZsWMHamtrUVFRET0WDAYxfPhwbNiwAT/60Y9a3dPU1ISmpqbo94aGBjeb1Cb4Fi+G/9ZboQmBuQCgaViY7EYR0sGxI4+A9JBJJLnc7vfj8OHDKAewDkBVshvUwXHV66q2thYAUFhYGHO8sLAwes5IdXU1gsFg9NOnTx83m9Qm+Navj25T+gCUH/0/ISR52JFHQHrIJJJcwpqGWwGMAXArAG/N2IkZSXcvnzVrFkKhUPSza9euZDdJmUhZGcRRD7EIgHVxsq4TQtoH6SCTCCHf4KrqqqioCABQV1eHnj17Ro/X1dVh8ODBce8JBAIIBAKW61AJmy0L0W/mdm3VtS0nJwd+ITALOLJNqWmoTlCOmQGkW6kbZC7QRhc+mVulzPVPNg5O0jG45VJoHHu74cNlc8ostIBVd2An4QJUsBtuvb1iRx4BiWWS3++PhryQpeXQ37tv376Yc8FgMOZ7KBSK/r+twgyo3Ku/VhYOwywsgx4z2as/ryLbVNyajcjaK3tvnIQXkaGSGkT2nMZ79X0m+80zSzUjGyOvQlM4CSXj6o5OSUkJioqKUFNTEz3W0NCAjRs3orS01M2qUoqwpmGhpuE8nw8LNQ1h7ugQknQ6qjwihMSivKPz9ddf48MPP4x+37FjB7Zs2YKuXbuiuLgY06dPx8KFC9GvXz+UlJRg9uzZ6NWrF8aPH+9muwkhhPKIEGKOqgvnmjVr4rp3TZ48OerSOXv2bFFYWCgCgYAYPXq02LZtmyNXTrdc4mDTdc34UXGds+pO7sR9NF1doN10F9X3pUp/eTXfrLoRe9WfTstKFfdyr+WREM5CXrg532V1yNx7VUJKuDWfnIQBsetiL3tOvZu8mau8k/fYjXng5GMm2+zOL5VwAbI+8UrWmckjTYjUchFqaGhopcdWsYuwihObBBWbiezs7Oj/jTY6sjaY6UgTtcdKm9oLbtqNyNI8OLGfsYrMBsBIW6QycVpHKBRCfn6+0ya1C+LJJD0q76oMs7lmNaWIzJYGUEsFIkM2n2R9YvacsndFJiON9+mfMzc3N+bc/v37E9Yhw+w91ve1V2kcrNYPqNnzyOaXih2Vio2hW7LOTB4l3euKEEIIIcQruNAhhBBCSNqSstnL9a6c+m00vSoIiN36MnOltutibERF1aHihm31WVRUVSpbrSoqHZVyZH2t4tbvRNWnfxbZVrmxDmMfyLZ3ZW1wktXeC5fVtqozndA0LSqT9P2jMkdkmPW5TP2jx8wFWsUd2aqKQubGDMS61etd6uNhde6ZqVf0qKiqZM+pMkZm2FUly8bIyXjKXM9lIQHMfieszlsjbsok7ugQQgghJG3hQocQQgghaQsXOoQQQghJW1LWRicc/iYNml5Xp+IaKdPpGd0NjeVatWcw0xvqz7sV6t9MN21XpyzTcctC1wPydBEyVOyLZN/NdONWQ6qbtV1Wj1v6edlzuhU6wOw53XRFTxcyMjLi2g2qpFjwKhSEk7QmemTtkZ0zq7+xsTH6f6MtmxG7btluhYkwS49itVyzsZa1wWpqHmMbnDynSoqYRPfF+67/bVX5rXJT7nBHhxBCCCFpCxc6hBBCCElbUlZ1pXcvl6ko7G6xm7kbWo0gqaLycpJB1+52sxGZC7SsHDOXUD0qUVJVXLJV3MLd2p5PhqqhLTKUUx2lTnNzc9zjKlF37YZsMN7rVbgClSjPKmEZZO74dnHV/VjybtgNy+DkOWX9LptvbRU2xS0Vp0x1ZcXEQAgBK8kduKNDCCGEkLSFCx1CCCGEpC1c6BBCCCEkbUlZGx29e7kemU5UJSuumUuvTNdp1cbEeN4sxYJVna5Khlojdl03zZ5T1rcyd3gnGX7bInO9E5dVqzZXTY2N8C1eDN/69YiUlSF7wQLEn/3mbXDiAqxHJcR7R0SfisZuJmwz2sIezJhSx274DpUwG2bo2+Qk07rKHLaaFsOJC7ST3y49Tuabil2V1XOyOozfZeWY/a7ZTa0CpPBCh5COgm/xYvhvvRWaENBWr8bNAG5NdqMIISRNoOqKkCTjW78e2lHPAU0IlCe5PYQQkk5woUNIkomUlUEcDaUgNA3rktweQghJJzRhxQm9DWloaGiVbsAqKjEgjMh0pE702G7hlc2E1bgrKvrctqL5wAFoixZBW78e8156CVWAZduWVMIP4GYA5QDWAUrP4ST9hx7VmCShUAj5+fmWy2/PmMkkJ3JHhrFc2djKYnu5NUdUcGKP0haxoDp37hzzfd++fQmvVUmNYNfuxohb9qR222eWfkeWNseLOE1m5ZrJI9rokHaLtmgRfAsWQBMC844ea4+2LWG0z3YTQkh7gKor0m7RdLYtPoC2LYQQQlqRsjs6mqZFU0BY3W5T2TJWCe0v2wpW2cpUwavtcCP69hvr1J/zSlWlkvbC2L55L72EeTiyyIkArti2uLUt7CaybWyvXJDdcvFNV2QyQD9Pc3JyYs4ZVSQqoQ2sXmuWHdzqO29Wpx4z9b6KyslqiAQzGa5vk1F+ylRVxj6RjbVKyh8VeSEznZCF9nASYkWGWypEWfgVs77Vj4M+BUSi1Cwx91puISEpRtXRf/W2LYQQQogeLnRIu4W2LYQQQsygjQ4hhBBC0pZ2t6Pjls2Eio2Oir2MWy69brndqeAkvLkeFddElbQJslQSZrYqVq9V0au71e9mc9GLOW/WX7TLaY3f74/aDcr6Tz9PZTYJxnLM5pNs/GTuvjKc2P7p6zGbL7K0Lyp2elbPWWlTIozt039XSdeikqpHZo9iFi5AxU7PqixxM6WHDJX558QeUWlHp7q6Gqeddho6d+6MHj16YPz48di2bVvMNQcPHkRlZSW6deuGTp06YeLEiairq7PdQEIIiQflEWlrWtK1+Gpq4L/1Vtyc7AYRSygtdNauXYvKykq89tprePHFF9Hc3Ixzzz0XjY2N0WtmzJiBlStXYsWKFVi7di12796NCRMmuN5wQkjHhvKItDVM19JOEQ7Ys2ePACDWrl0rhBCivr5eZGZmihUrVkSv+fe//y0AiA0bNlgqMxQKCQAiEAiI7OxskZ2dLQC48vH5fAk/KuW0tCs7O1tapmq5dj8ZGRkxH7fqb+vncPOjMg5ejZ/dcozjKbs2Kysr5iO7T6U9ZvWHQiEnosMTvJBHQnwjk/x+v6UxcWteGj96uWMc92S/b2Zztj3LEv1nNiDCgBBH/52dAn0r+6jINq/GyGq5Zs8Z73dX0zQBmMsjRzY6oVAIANC1a1cAwObNm9Hc3IyKioroNQMGDEBxcTE2bNiA008/vVUZTU1NaGpqin5vaGhw0iRCSAfFDXkEUCaRxDCkRfvEttdVJBLB9OnTUVZWhpNOOgkAUFtbi6ysLBQUFMRcW1hYiNra2rjlVFdXIxgMRj99+vSx2yRCSAfFLXkEUCaRxLSEtBhz9N/2mFuvI2J7oVNZWYl3330Xy5cvd9SAWbNmIRQKRT+7du1yVB4hpOPhljwCKJMISTdsqa6mTp2K5557Dq+88gp69+4dPV5UVIRDhw6hvr4+5q+ouro6FBUVxS0rEAggEAi0Oq7fOrYbbloWOtusHFmddl0e2yo8t0pYbRnJSGnglsu4St+qPKdK++xmf5elvpC5vhrbZ1ZuorYa26cvUwiBcDi1/o51Ux4BiWVSoud2K/yErBw/gH2//GVCt2ZZyo7c3NyY7/v370/YBruZqM3chN3KOq4vx9hfTtJOyNJFeCUHreLErVolfEcy0t2ozCEnIS+UdnSEEJg6dSqefvpprF69GiUlJTHnhwwZgszMTNTU1ESPbdu2DTt37kRpaantRhJCiJGOJI9uBujWTIhNlHZ0Kisr8eSTT+LZZ59F586do3ruYDCInJwcBINBXHXVVZg5cya6du2K/Px8TJs2DaWlpQkN/wghxA4dSR6VA3RrJsQmSgud+++/HwBw1llnxRxftmwZrrjiCgDAnXfeCZ/Ph4kTJ6KpqQljxozBfffd50pjCSGkhY4kj9YBOEfToAkBoWlYd3TRQwgxRxMitd6YhoYGBIPBhOdVwl/L9Ipu6RzN2uOWzYn+XE5OTsy5ffv2WWusCZ07d/akXBlOQuKrYNVexkl4df29fiFwcM4cYN06oLwcGXPnprSHhoqdCXDElTs/P9/LJqUMLTLJagoIPWZyRt/vxnP6Ovw4or5qcWtepGkIH21LvHv1GG0V9eXand/Ge1We0y17HpV31Uk6Bq9oqdMvBA7OnQtt3TqI8nJg1ixk6mS8sT3G8dTbrjiRXyrYtX9SsbMxrgNawkfEw0wetbtcV4S0B34lBDBv3pHQYi+9hJvBTOvEPi1uzS34dIsc0r6ZBUCbP/+IarKmBim185AmcKFDiAeU6f/KoU0FISQB5UKgZdmqCXFkF5i4Srtb6Kioqozot9CcuCPLVEwqbsRGdYFMtaYvR+96b4aZSkJ/Xp8jKF4bErXViNn2qWwbW1+nmVusyjjo2ytzwVZxGZe5qa/TNIwWAj4AERxRN1gpM165smtV5psMJ1msOyJWM4SbbevLVLWyeaEir9zKRK/yzjsJ4eCF6sjsvZCpEPXvhhPVkHE8W8p6NRzG6HA4KivmvfQSfLp6VMZTZvKg0l6ZjARin8UsG73d8TSqquyqwIB2uNAhpD1QDQCahnIhsE7TUJVapnCEkBRhsc+HcDgck1aCikl34UKHEA8IaxoWAsBRW4oIFzqEkDiENa2V/R5/mN3FdgoIQgghhJBUp10sHK26spnpuFX0erJ6VNwqZajYReh1pmZh//XtM9Of2nXnltn+mOmBrYbIl4WqN15rdk6mU5ahMr52ddFO7BeSHZ6+I2En9YUT+SCzDWyreWA1PIaZTEr1eSr7bdCPoRMbPiMyOeTWb4zd8Ctmtj4qaU7s2v/JfqtazgkhYCVCDnd0CCGEEJK2cKFDCCGEkLSFCx1CCCGEpC3twkbHKk5Cghv1gVb1iir6UrMYKDI7Ev2zqITrVwl9roJXdi5271NNYZCoHjPbB5VQ9irX2i1HZfy8sjXoKNhJAeEmVu0tvArJb5xrdue3k/fabr+b1Wm1/8zkjEoMLKtxidpqrsnqdJJeQ49X9kZmcEeHEEIIIWkLFzqEEEIISVvaherK6vaWSvhrJ9tgdrds3XIJVanT7DmtbrXKXF3N6vTK7VrmDqlallVkfd984AC0RYugrV8PUVaGwPz5rmQsV3HllCFLMUK3dXP07uX6+S9TH6qEglDBiQpARV0la5+sHFl7zFK76FGZ+yopM8zKsluOvg0qLtlG3HIvl6na3HrnVdLvuJUKpKVvhRCWwj60i4UOIe0BbdEi+BYsgCYERE0NM5YTQkgKQNUVIS6hrV9/JPswjmQhZsZyQghJPlzoEOISoqwM4qhXjtA0acZyQgghbUNaqa7c0n+bIdO16l03jdfKQloDcvc+u+6+TvS7idoWr1z9cxp18EZdvlW7ILP+krVPdq1Vt06zcowE5s/HzcCRLMRCoEp3zsk4qIy9VbdUu3p+IQSam5st35uu2JUtsvuMssP43shsA2U2czJbFhX7CiMqNnz67yo2Qm3lumwVMztQ2bVG9OOt8q7K0muYpV+QjZmKnJHZpanIV/21TmyazEirhQ4hySQM2uQQQkiqQdUVIYQQQtKWDrWj41a0SZUIkrJtRZUMvyrbsFZVYCp1qNRvlnXcavtUxshsm1OW+VmGbDvcTNVgdZv4wL598C1eDN/69YiUlSF7wYIYt3T9vSqRWWXb6iqRwN3cQm7PuBEZWRZdWDZ/AOvZrs2QzQsVZO+RihyUIZMPxnfBiUrMqpxWiRhshkp79chkiVkkaTsy3g/g4Jw5UfkUuekmBPLyFFsdvw79dzM5Y/e3AehgCx1CUhHf4sXw33orNCGgrV5Nt3RCSMpwMxAjn9ojVF0RkmR8dEsnhKQo5UCMfPKtX5/cBtmACx1CkkyEbumEkBRlHRAjnyJlZcltkA00IY4u1VKEhoYGBINBy9frXZllGb+NGHWZRt2hXd2rkyzaVjFzudTbjqhk15WVa1anzAYmndIJ2LVxktn6+IFv3NIBVAGWU0cYy7WrxzazNzISCoWQn59vufz2TItM0jQtaqMjS6ehR8XlORlhI5xgN+SFkxAOdl2g21vfynDSf3bSFzmRT160Jx5m8khpR+f+++/HKaecgvz8fOTn56O0tBTPP/989PzBgwdRWVmJbt26oVOnTpg4cSLq6upsN56QjkCLW/qYo/+6JUTSHcojQrwnHeST0kKnd+/eWLRoETZv3oxNmzZh1KhR+P73v4/33nsPADBjxgysXLkSK1aswNq1a7F7925MmDDBk4YTQjo2lEeEEEsIh3Tp0kU8/PDDor6+XmRmZooVK1ZEz/373/8WAMSGDRsslxcKhQQAy5/c3NzoJyMjI+Yjuy8rKyvmo3KvSrl2y5F9zNqanZ0d/fh8vpiP3XLN6tSfU6mzvX2Mz2b1Ob3qE2O5duewfs5kZ2ebXh8KhZyKDk9wWx4J8Y1M0jQt7vjJ5oTxvbE7f9pqPtltg8p9TmStSp3tuW+96j+vf5tUP261x0we2XYvD4fDWLFiBRobG1FaWorNmzejubkZFRUV0WsGDBiA4uJibNiwAaeffrrdqqTIYrbIdJlm+kC7ukOVa1V0+/q2m8XG0dtXqMTqkel6zfTAMnseWZwYr/ThMlspJ3XabZ+TcOsq5doty25Mj1ShLeSREAIijkmjW3Y3RmR2hHbtWpy2yYtyvKrTrXdVhixujVlMG9m1bsVMMuKWzagstpBKWgx9e1TsQD2Po/POO++gtLQUBw8eRKdOnfD0009j0KBB2LJlC7KyslBQUBBzfWFhIWpraxOW19TUhKampuj3hoYG1SaRFIdxYohXuC2PAMokQtINZffy/v37Y8uWLdi4cSOuvfZaTJ48GVu3brXdgOrqagSDweinT58+tssiqQnjxBCvcFseAZRJhKQbjt3LKyoqcMIJJ+CHP/whRo8ejb1798b8FdW3b19Mnz4dM2bMiHt/vL+e+vTpYzncut4t1sn2u2x7125GX7NrZfemmkujE+ZoGuYKAR+ACIB5+GZHR+bWbNaXsv6y6+bf1NgoTcdgF6+yyLuVikC1PanqXu5UHgGJZZJVVLbY28Jd2ohMLe9VeAy7ctqt8AlOUiO41Xa30vjI6nHrd0M13ESi9hjb5NX8MpNHjlNARCIRNDU1YciQIcjMzERNTQ0mTpwIANi2bRt27tyJ0tLShPcHAgEEAgGnzSApTDUAaBrKhcA6TUNVaoVuioFqtvaNU3kEUCYRkm4oLXRmzZqFsWPHori4GPv27cOTTz6Jl19+GatWrUIwGMRVV12FmTNnomvXrsjPz8e0adNQWlrqmSEyaR+ENQ0LAaAl2FoqL3SoZms3UB4RQqygtNDZs2cPLr/8cnz++ecIBoM45ZRTsGrVKpxzzjkAgDvvvBM+nw8TJ05EU1MTxowZg/vuu8+ThhPiBZGyMmirV0MT4kg6hhRelHV0KI8IIVZoFykgrOpI3XSj1KeWkLmwe4VbzxJuagKqq6GtWwdRXo5Ot92G8NGdFUCuI5X1u4pNkwzjc3lVp0yPrf8e8PvxKyFQFolgvc+HhZGIZRsdmR2AE/dyL3TwKrY++muFEAiHwylro+MFLTLJqt2gV8jcdvWYufvqz6d6ugO7KVfMcMvWzSucuFKnGlafxWxM9HOh5f9W5ZFjGx2S4lRXQ5s//4g6pqYGN/l8qPL7k92qlCWsabhN04CjL1I4xQQ/IYQQNZi9PM3R1q2LsTkp4w83IYSQDgQXOmmOKC+HOLrdLjQN6xXUSoQQkm74AdwSieD/Dh/GLZEI/KllvUE8oF3Y6LhFW9hFOIk/YLVco12NrH1Gm5MqIWJsdFJZJ283BlE8Uu05VWiL+CmyOvX/78g2OnYwS8GSl5cX/X9jY6P0XrfSmLiFV3G/vLZPmQ1ggaYBQhzxBJ03D9rcua7XY4Zd+yMVW8BUwGq6CDtpTVrSstBGp4NjtDlJxReBEELainLgyCKn5d9165LZHNIGUI9BCCGkw7AOiMb0gqYB5YyWle6klepKJby0k/QCXmF1G8/NbWt9ncZy9f0nmpuBqqojf/2UlyNj7lzLbtcqIcFlGZqduK3rcSsMeVupD5Lhamo2/6m6skYqqJjcQubeLpMdxvPJ7gM/gJtxZGdnHYAqwJU0L0BsWBKj2YJXz62ikraKm+73Xow9VVfEG6qqgHnzjmz1vvQSUyMQQtolYVB2dTSouiLWWLcuRq/NzV5CCCHtAS50iDXKy2P02jTfI4QQ0h5o96orvf7PqJ802mLIdIUyl20VPbsTOyGrelBj/bI6zexaZOHg9XSqqsIv/X6MCIfxqt+PReEwfAnc1I3lyMpVsd+Rja8srYPxWtmYmOmmnbpDxmuf8TlVyrE7h1Tc8Y3u5Slm1pfSpHp6D1l7jG0ye8f0uBVmQ0WeummjqUflnbebLkj2XpvVmWphB4xYneMqKSBUn6vdL3RI2xDWNFRnZABHJyNTIxBCCGkPUHVFCCGEkLQlZXd0NE2LZgqWbVPJzqmoKFS2bFWwmjXbiN5NEZBvibq5xZcIla1nFXWKk8jRKq6U+mtlqiKZWyxgXw0gC1/gxCXUOI+tbrOnwpZ2e0Y/h4z9bFe1bVedaDznRFUlw9h2/bvbuXPnmHNNTU2269E/i9133IgTlU6ia/0ADs6ZA9/69YiUlSFy000I6CJdm2H3t8FqmfGQzSG97JDJK1mZ8a61Oh+9DJ2RsgsdQgghJFW5GYD/1luhCQFt9epkN4dIoOqKEEIIUaQcgHbUMF8TAr7165PbIJIQLnQIIYQQRdYBEEfNK4SmIVJWltwGkYSkrOoqIyMjaqMjc4G2q9dzUo7MDsKtENwy2xU3w3PrcSuVhFe6VpmeXUUHrzJGTvrE6r1mGa5VnkXFVd0qtOdpjVV7EK/mjywdg/G+trDV2rdvn/S8W/JB9txe2Srq3ym9XK4CosFT1wmBqgULpOW4Jbfdss8yomLjJMMt+yIrdkJWw12k7EKHEEIISVWYSqL9QNUVIYQQQtIWLnQIIYQQkrakrOoqEolEbXSMx60i04k6saXx0t+/BdlzytISxDuvx6sQ4cnuk/ZmRyKL0ySz2TELc++WjVginTxTQLRG5f0zjo9d2xVZvCc33wV9uU5iXqm0SfYsMntNmWwzpqSQpfwxIntulfgyRmRjbzdOk0r8NbuxhIzxg7IXLEBYd61KKg6V9jiy7bJ9JyGEEEI6FMb4QTcj9W2VqLoihBBCiCWM8YPKk9scS6Tsjk44HI57XMXNTbYdaCzHybasDC/crlNBVSWrx606nLRdpY9kmc1laiSVzPAqyNxk3VJNmdHeVIHJRCZnzK61O6ftppkA7LsKq6hUVdQ9dtMfmIUIkWUAtzu/3crKbsRMDadHNg5m8kHFPT9Re9YLgQoh4AMQwZF4QnraQka1tMeqKt3Rjs6iRYugaRqmT58ePXbw4EFUVlaiW7du6NSpEyZOnIi6ujon1RBCiCmUR4R4TzWA+ZqGF4/+W5XsBlnA9kLnjTfewAMPPIBTTjkl5viMGTOwcuVKrFixAmvXrsXu3bsxYcIExw0lhJBEUB4R0jaENQ0LNQ3n+XxYqGmIr3tJLWwtdL7++mtcdtlleOihh9ClS5fo8VAohEceeQS/+c1vMGrUKAwZMgTLli3Dq6++itdee821RhNCSAuUR4QQGbZsdCorKzFu3DhUVFRg4cKF0eObN29Gc3MzKioqoscGDBiA4uJibNiwAaeffrrjBqvopo06R7s2Eyoue0ZkdRr1vfprZS7kMl00ILc5MaK/VubKaab3l7ly2k1nYabL19ejois31inrIxW9vxGZnl02RnZtFozlGpE9p+zdSXV7nWTKI0BuK2LsO6MsUXk3rIZXMLP3kL3zKmkA9M9p9v7J3hu7qRHMbKP0z+LWHDY+p4r8kj2XsRwVeWbXblBmryOrw3ivWd/adcF3UyYpL3SWL1+ON998E2+88Uarc7W1tcjKykJBQUHM8cLCQtTW1sYtr6mpCU1NTdHvDQ0Nqk0ihHRQ3JZHAGUSIemGkupq165duOGGG/DEE0+0+qvdLtXV1QgGg9FPnz59XCmXEJLeeCGPAMokQtINpYXO5s2bsWfPHnz3u99FRkYGMjIysHbtWtx9993IyMhAYWEhDh06hPr6+pj76urqUFRUFLfMWbNmIRQKRT+7du2y/TCEkI6DF/IIoExqS/wAbolE8H+HD+OWSAR+Rt0mXiAUaGhoEO+8807MZ+jQoeLHP/6xeOedd0R9fb3IzMwUTz31VPSe999/XwAQGzZssFRHKBQSAITf7xcZGRkiIyNDAOCnDT4+ny/mk4w2ZGVlRT/J7g8v+6Rlbjud320xZvryNU0TAEQoFFIRHZ7QFvJIiG9kkp3+au/vhlvzNFE5swER0TQhjv57eO5c233r5F2wWq5b42ccQ2PbZf2uP5eRkZHwPrMxk7XH7JOdnR39qPS7kzGK98xW5ZGSjU7nzp1x0kknxRzLy8tDt27dosevuuoqzJw5E127dkV+fj6mTZuG0tJS1wz/CCEEoDxKB4xRdrX165PbIJKWuB4Z+c4774TP58PEiRPR1NSEMWPG4L777nO7GkIIMYXyKLVZB+AcTYMmBISmQZSVAS+9lOxmkTRDEyK1lKINDQ0IBoPQNM1x9nIjKmkKZNfKXIOdZLPV36viAu0kVYLVZ0mGi7HZc6mMQzLar+LmL0PFldOt5zRLXRIKhZCfn+9KXalOi0zSk+yUJ201v71IYaPHjyNJIstxZNFTBdgOQGfXTd14r5PnVEknY7eethh7s9AGyf49MNZvJo9SNtcVIYSQ9CaM1M98Tdo/zF5OCCGEkLSFCx1CCCGEpC0pq7oSuvTrZmGtraKiV5RdK7O3cEt3qWLTYaxTxX5ApieW3etE3ywbT5UUC/o+MktRYReZPtws1L5VuyonY2TELVsDL+wxiBwV24u2spGQzXf9Oa/ePyOy+Z2M+a6S5sEtGSlLx+DWe6syv9rKtsyJXRx3dAghhBCStnChQwghhJC0JWVVV3r021RuueiZZTpPVL+XuFWPWyo6Pcb+cqIus5uFWeZyb1an1ezvKm6UTsbLqzkly05sd+tc/38hBMJhuw7A6YPK9rzsPhW1vNU5bFanCjLZq5L9WnafbF7K5LSZGsStEAD6PGpGlVxbhACQ3ecHcODmm+Fbvx6RsjJ0uu02hOOEZVFtgxe/IfGulc0hN1WT7WKhQwghhJBYbgbgv/XWI1GlV6/GrzQNt0kWOh0Vqq4IIYSQdogxhUZZEgL5tQe40CGEEELaIesAiKM7OELTsN4lD+V0o92prmR6OjPdr15naub+qL9W5jrplruc6r12sesiamybyjio2L0ksg0xtseImf7Wqg1Wbm5uzLn9+/cnvC8V0kwY0Y+hk3clkW0GbXTMUQmRoO9nM/sFmf2V1fYYyzGzEdK3ScW2TSZLzPpE1n8q4R3svo9O7IJk7VGxR7Fql1oFAEIcSaEhBKqEQFjSJr290cGDBxNeZ0Q2nk5sAdsqjEW7W+gQQgghhCk0rMJ9LkIIIYSkLVzoEEIIIR7iFwI3h8P4e3Mzbg6H4T9qQEzahrRSXanoflVivcjKNeph8/LyYr7r7RmM9h52dchmuml9e1XiBRltYFRsDazWYURFb62CTG8s07Or1GkWE8Wq/ZOZnYT+WYxjpGJTpEflOb0K558uuBXbS6VcFXsZGV7FglKRmXbbZPb+uRVHR2U89e+5/r2ZBWCOpkETAqMjEcyePRv+efNcqV/lOWV2ObJynNhH6rErl433qr5jabXQIYQQQlINoxs41q1LboM6GFRdEUIIIR5idAMX5eXJbVAHQxMitZSFDQ0NCAaDbV6vSpbqRNfFQ7+VaeaibXULUiVTsFvbxG6ib7+xfSouj3q8cvVWKdfutqze5ROw3wduYpYCIhQKIT8/PxlNa3PclEmpGJJAj1tzsXPnzjHf9+3bF/2/VzLJKBdlZaqo1lRcyBOp+/04EsW4HEcWPVU44jFlpVwVFblbeKWONeKWetFMHlF1RQghhHgI3cCTC1VXhBBCCElbuNAhhBBCSNqSsqorv98P7ajxllX9oBPdqiyEuYp7rUraArs2HSrpK2Su5/HOJ6pTVofZtUb0bTDepxKiXN9/xr40tk/vdu3EXkaWYsFqmgkjTvTfKvZaeszGT5aagMiRucE6eafshu9Xwa1yZWlCvLKfk4XHUAmz4cQ9X8W2UiYHZeW0hf2h2e+EShv074PM3khFJqnCHR1CCCGEpC1c6BBCCCEkbeFChxBCCFHED2A2gFVH//UntzlEhlBg7ty5AkDMp3///tHzBw4cENddd53o2rWryMvLExMmTBC1tbUqVYhQKCQACE3ThM/nEz6fL6a+rKysmE/LNT6fT2RkZMR8srOzYz7Gtus/+nKMdZpda/U+Y/tk52V1yuow9pFXfWAch0RjotqXZs+WqA127zO21+xeq+MX77zV9qiMvdm9dj9mfRIKhZTeay9oC3kkxDcyyc77KJMVRplld3yMbTDOQ9m1xnN23w2z91jlOd0qx+vPbEBENE2Io/82z5njWtmy8ZPJGeM5r+SD7ONWnbLnbOkLTdMEYC6PlHd0TjzxRHz++efRzzpdKOsZM2Zg5cqVWLFiBdauXYvdu3djwoQJqlUQQoglKI9IsjCmdfCtX5/cBpGEKHtdZWRkoKioqNXxUCiERx55BE8++SRGjRoFAFi2bBkGDhyI1157Daeffrrz1hJCiA7KI5Is1gE452iiTqFpiJSVATU1yW4WiYPyQmf79u3o1asXsrOzUVpaiurqahQXF2Pz5s1obm5GRUVF9NoBAwaguLgYGzZsUBYsQgiIONkpZO6zXmXidaseJ27EKqGyZZmxZW7YKm70bZHR2iwMud02OGm7vg0qYdJl15q1RzbeKuk/2iqrdVvSVvLILrIMzIDanLGKmZyRlWs3nYzKczpJq+LVvLQTZqMKgIZv0jpU33qr7RAAZmFArLQnHsbxlI293TFSqdP4XLJzsjFpOSeOpqQxQ+lNGj58OB599FH0798fn3/+OebPn48zzjgD7777Lmpra5GVlYWCgoKYewoLC1FbW5uwzKamJjQ1NUW/NzQ0qDSJENJB8UIeAZRJxBphAAs1DTga7w2gQXKqorTQGTt2bPT/p5xyCoYPH46+ffviL3/5C3Jycmw1oLq6GvPnz7d1LyGk4+KFPAIokwhJNxy5lxcUFODb3/42PvzwQxQVFeHQoUOor6+Puaauri6uDr2FWbNmIRQKRT+7du1y0iRCSAfFDXkEUCYRkm44SgHx9ddf46OPPsL/+3//D0OGDEFmZiZqamowceJEAMC2bduwc+dOlJaWJiwjEAggEAhYrtNuygKvcKLLNCLTy+rPNTU2wrd4MXzr1yNSVobcW29FWLd9qm+Diu5XhoptgQpepUZoC1TCpCfjWWTh1mXnjOjPWdWJJwM35BGQWCZpmhZNS2P3PZf1s9k7JrNnUEF2r2wOq8wZu3WY1amCrH1G7NZjvM+tvrWL2bywOm/Mxtpuyh+77XF6n9JC5+c//zkuuOAC9O3bF7t378bcuXPh9/txySWXIBgM4qqrrsLMmTPRtWtX5OfnY9q0aSgtLaWHg8v4Fi+G/9ZboQkBbfVqzAKwMNmNIqSNoTwihFhBaaHzn//8B5dccgm++uordO/eHeXl5XjttdfQvXt3AMCdd94Jn8+HiRMnoqmpCWPGjMF9993nScM7Mr7162PiN5QDMQZxhHQEKI8IIVbQRDwf7iTS0NCAYDAYc8yqe5pZtlOVrXu3thJV3A2tZkyf6/NhTiQCH4AIgPmadsT6Pw5eqfPcclO36u4Y71qVbXX991RTibmpFrQ6h5zO91AohPz8fLXGtVPiySS3kMk2WWZ6/Tm/EGiYNSuqys5esAB65aJbss2rcrxSrzvJFO9FOV6p/2V1uJkBXFaPHq/GT/+9Zf4LIdDc3GwqjxzZ6JDksEjTAJ8PZZEI1vt8qE6ttSohpA25KRKJUWXfDODWZDeKkBSCC512SFjTcNvRxQ7QfoK7EULcpywSaa3KJoREYfZyQghpx6z3+SCOqq6FpmGdyfWEdDTaxY6OW+5pKnpYu27sepscQC0MuMymQq+TN3NrVukTuy6rMvsZmW2BWTmJyox3rb6vjeeM363uepm5pHqxe+bEFkmlr2V6de4KuodsXhrnlyxdi2ws9eduxZEoveUA1gmB2/1+ZOhs9py8YyqpZ2TI5Ixbc8+JPYosJIdKnTLawjbQrTrMbI+8eBaVMlXT+LSLhQ4hhJD4hBFrk5NBD0xCYqDqihBCCCFpCxc6ScQPYDaAVUf/tZsQzi8EbolE8H+HD+OWSISJ5QghhJCjtAvVldX4N050vUbbGrs6SKNNjr59RnuKr2+6Cb4FC6AJgXM0DRAiugWtoq//es6cI+6lACqEQASJ3Utl9jwq9h5G2kJnK+sTlbhIxufU16Myh5zEFdHfa7STUOl3lWvtvh/69qVyCoi2RCZ3ZPPSOPf0uGWromJjYvbeujFnjOV4ZQfn5N21GmerLWLhpAJe2ew5+Y2JZ6cqhICVUIDc0UkiWrwIxzaIGymZEEIIIVzoJBNRVuaKW2jEpXIIIYSQdKNdpIBIBm6pxGT4AdyMo26hAH6dmRnNQq4Svl+LRGLKqQJA5YJ12mKs2wpZShT9ObMt40TqhZat4o6eAiIZcyaV56lXKXTcQkVd5pV6KtX7yC28ek7Z/GcKiBTG6BaaZdMt1FgOIYQQQo5A1RUhhBBC0hYudAghhBCStrR71ZVXeuu20J/aTd0gs70wlpMMd0i3dLQqbrJmfZmbmxv9//79+2POeTXWybCpkKWL0NvlyNx/jd/1oReEEGhqanKlre0Z2XjaTavipE6v8GIOJ0MmqaROkT2nLDSFE4zhTTIzM6P/P3DggCd1OnH1ls0Lt0ISuDkvuKNDCCGEkLSFCx1CCCGEpC1c6BBCCCEkbWn3Njoq+kC9TlIljojdOoz1ONGJJmobINdlOtFz2u0DJ6HYZeXI+s/Mnsdol5OoDbLQ8MbvxvGzm57EWIdMV23Wt7J4IInKjNcGfV8b05oQ+diqvHOyMTJi912W2cyZ2dNZtVdxki5GZi/mJOWP3u7FOIftpnkw3qdiz2PsI/15Yzn79u1LWK4KMtkia4/ZeMrkjCyljeyc2byIl65ICIHm5mZpWwHu6BBCCCEkjeFChxBCCCFpS7tQXVndrjTbKlTZ+lVRNciQqTpUSLarshEn2+GyZ5GlMJD1n5M+kW2VG1EZB9l8i5eJtwXjc8rmm8o2uwyVvibuvYOyMVKRM3pUVOQqoSqMqKSpkfWXTGUhU6WZ1SFTucraY3wufXuM/SOrw+w9tvqOmY1J586do/9vbGyMOefVey0LoWB3zhhxqxyAOzqEEEIISWO40CGEEEJI2sKFDiGEEELSlpS10dE0DdrRbN5W7SLcsoExq0elDXb17Cp1GlGxI7HrAu2kTqvh883O6fXjMjsg43cVuwi7aTrMcMvGw61yVNz8Sdtgt9/NZJCKbJO5aMvsNJzMGaspbJzYAhqxmtJAJdSCWfusunObhYLQu6IbzxlTS+jbL3P19gq3woko16t6w2effYYf//jH6NatG3JycnDyySdj06ZN0fNCCMyZMwc9e/ZETk4OKioqsH37dtsNJISQRFAeEULMUFro7N27F2VlZcjMzMTzzz+PrVu34o477kCXLl2i19x+++24++67sXTpUmzcuBF5eXkYM2YMg44RQlyF8ogQYgmhwE033STKy8sTno9EIqKoqEgsWbIkeqy+vl4EAgHxpz/9yVIdoVBIAEibj8/ni35k5+Kd96JOu5+srKyYT0ZGRsxHf63sXHv7GJ+7LcbP+NH3pUqdxmv1H9lzGeuMV3YoFFIRHZ7QFvJIiLaTScb3xjhmVt+pVJyXsrbL5mkqPGdb1JHqdcr6OhnzzXjOTB4p7ej87W9/w9ChQzFp0iT06NEDp556Kh566KHo+R07dqC2thYVFRXRY8FgEMOHD8eGDRviltnU1ISGhoaYDyGEmOGFPAIokwhJN5QWOh9//DHuv/9+9OvXD6tWrcK1116L66+/Ho899hgAoLa2FgBQWFgYc19hYWH0nJHq6moEg8Hop0+fPnaegxDSwfBCHgGUSYSkG0oLnUgkgu9+97uoqqrCqaeeiilTpuDqq6/G0qVLbTdg1qxZCIVC0c+uXbtsl0UI6Th4IY8AyiRC0g0l9/KePXti0KBBMccGDhyIv/71rwCAoqIiAEBdXR169uwZvaaurg6DBw+OW2YgEEAgEGh1XO9eLgv7rUfmGgnEutapuFzKrjW66DlJjWDV3VAlTLtbOAndrdJ/drMKe4XxuWXutjJkbTd7LreeU5a52Ehb9K1TvJBHQGKZlAgVWSLDrM9VZIkeJ9dadbs2SyWh8s7LZLxb4TqMrsv6Nqj0j/E3Zv/+/QmvVZFf+jaYuVm7JZMS1R/vu9VzqYLSrCkrK8O2bdtijn3wwQfo27cvAKCkpARFRUWoqamJnm9oaMDGjRtRWlrqQnMJIeQIlEeEECso7ejMmDEDI0aMQFVVFS6++GK8/vrrePDBB/Hggw8COLILM336dCxcuBD9+vVDSUkJZs+ejV69emH8+PFetJ8Q0kGhPCKEWEFpoXPaaafh6aefxqxZs7BgwQKUlJTgrrvuwmWXXRa95pe//CUaGxsxZcoU1NfXo7y8HC+88EKrLT5CCHEC5REhxAqaEEIkuxF6GhoaEAwG4ff749royPSBKiGj3dKrq9C5c+eY7/rQ3SqYpSnQ48TWQiWEulX7IlkdxnLawlbFrFwnNld2ScbcVCUUCiE/Pz/ZzWgTWmRSIlTGyy07M69knd13w2yOytJFyGird8Gq7Y9bKXWc4FaftNW8tTr2xj8+jHNa1j4zecSknoQQQghJW7jQIYQQQkjakrLZy30+X1R1ZXWbTEVlYpbt2qo7pMr2X2Njo7ROlfYlao/ZtTKXe7M2yLC7BW+soy1yEMn6y8ytUuaSacTulrKTLWTZ2OvVHcZ+bg/qsmSjV6fL5rtdNa4ZKuEB9DiZT25lKHdLPqiowPRz2sn8VnGNl5WrEu7ErrxX+V0zIutbJ2YDVtWfZrI/Xp8IIWDF+oY7OoQQQghJW7jQIYQQQkjaknKqq5ZtqLZ2BpPVZ/eck2u9qserfk0x5z0lUr1vVepoi3ls5/r2jJlMMh73ao540edO5lMysPuuqoyRW/Wr3OukfW6988kYa6fPaXW9kHILnRaX67YOQS/rqHA4bOs+J9d6VU9TU5PtNtitM9VRabtsLrQFZvXbHXvV8du3b5/U5TqdaJFJiewbjH3X3NycsCwn88eLuWdWZrLnuxGV9ujHxa3ncFKOyvtn9zmdnEvGWLv1u2Ymj1Iujk4kEsHu3bshhEBxcTF27drVYeJ1qNDQ0IA+ffqwfySwj+TY6R8hBPbt24devXq5lnco1YlEIti2bRsGDRrEuSSB75sc9o8cL+VRyu3o+Hw+9O7dGw0NDQCA/Px8TgoJ7B9z2EdyVPuno+zktODz+XDssccC4FyyAvtIDvtHjhfyqGP8SUYIIYSQDgkXOoQQQghJW1J2oRMIBDB37lwEAoFkNyUlYf+Ywz6Sw/6xDvvKHPaRHPaPHC/7J+WMkQkhhBBC3CJld3QIIYQQQpzChQ4hhBBC0hYudAghhBCStqTsQufee+/Fcccdh+zsbAwfPhyvv/56spuUFKqrq3Haaaehc+fO6NGjB8aPH49t27bFXHPw4EFUVlaiW7du6NSpEyZOnIi6uroktTi5LFq0CJqmYfr06dFjHb1/PvvsM/z4xz9Gt27dkJOTg5NPPhmbNm2KnhdCYM6cOejZsydycnJQUVGB7du3J7HFqQfl0REoj9SgPGpNUuSRSEGWL18usrKyxO9//3vx3nvviauvvloUFBSIurq6ZDetzRkzZoxYtmyZePfdd8WWLVvE+eefL4qLi8XXX38dveaaa64Rffr0ETU1NWLTpk3i9NNPFyNGjEhiq5PD66+/Lo477jhxyimniBtuuCF6vCP3z3//+1/Rt29fccUVV4iNGzeKjz/+WKxatUp8+OGH0WsWLVokgsGgeOaZZ8S//vUvceGFF4qSkhJx4MCBJLY8daA8+gbKI+tQHrUmWfIoJRc6w4YNE5WVldHv4XBY9OrVS1RXVyexVanBnj17BACxdu1aIYQQ9fX1IjMzU6xYsSJ6zb///W8BQGzYsCFZzWxz9u3bJ/r16ydefPFFMXLkyKhg6ej9c9NNN4ny8vKE5yORiCgqKhJLliyJHquvrxeBQED86U9/aosmpjyUR4mhPIoP5VF8kiWPUk51dejQIWzevBkVFRXRYz6fDxUVFdiwYUMSW5YahEIhAEDXrl0BAJs3b0Zzc3NMfw0YMADFxcUdqr8qKysxbty4mH4A2D9/+9vfMHToUEyaNAk9evTAqaeeioceeih6fseOHaitrY3pn2AwiOHDh3eI/jGD8kgO5VF8KI/ikyx5lHILnS+//BLhcBiFhYUxxwsLC1FbW5ukVqUGkUgE06dPR1lZGU466SQAQG1tLbKyslBQUBBzbUfqr+XLl+PNN99EdXV1q3MdvX8+/vhj3H///ejXrx9WrVqFa6+9Ftdffz0ee+wxAIj2Ad+3+FAeJYbyKD6UR4lJljxKuaSeJDGVlZV49913sW7dumQ3JWXYtWsXbrjhBrz44ovIzs5OdnNSjkgkgqFDh6KqqgoAcOqpp+Ldd9/F0qVLMXny5CS3jrRnKI9aQ3kkJ1nyKOV2dI455hj4/f5WVuh1dXUoKipKUquSz9SpU/Hcc89hzZo16N27d/R4UVERDh06hPr6+pjrO0p/bd68GXv27MF3v/tdZGRkICMjA2vXrsXdd9+NjIwMFBYWduj+6dmzJwYNGhRzbODAgdi5cycARPuA71t8KI/iQ3kUH8ojOcmSRym30MnKysKQIUNQU1MTPRaJRFBTU4PS0tIktiw5CCEwdepUPP3001i9ejVKSkpizg8ZMgSZmZkx/bVt2zbs3LmzQ/TX6NGj8c4772DLli3Rz9ChQ3HZZZdF/9+R+6esrKyV++8HH3yAvn37AgBKSkpQVFQU0z8NDQ3YuHFjh+gfMyiPYqE8kkN5JCdp8si2GbOHLF++XAQCAfHoo4+KrVu3iilTpoiCggJRW1ub7Ka1Oddee60IBoPi5ZdfFp9//nn0s3///ug111xzjSguLharV68WmzZtEqWlpaK0tDSJrU4uei8HITp2/7z++usiIyND3HbbbWL79u3iiSeeELm5ueLxxx+PXrNo0SJRUFAgnn32WfH222+L73//+3Qv10F59A2UR+pQHn1DsuRRSi50hBDid7/7nSguLhZZWVli2LBh4rXXXkt2k5ICgLifZcuWRa85cOCAuO6660SXLl1Ebm6uuOiii8Tnn3+evEYnGaNg6ej9s3LlSnHSSSeJQCAgBgwYIB588MGY85FIRMyePVsUFhaKQCAgRo8eLbZt25ak1qYmlEdHoDxSh/IolmTII2YvJ4QQQkjaknI2OoQQQgghbsGFDiGEEELSFi50CCGEEJK2cKFDCCGEkLSFCx1CCCGEpC1c6BBCCCEkbeFChxBCCCFpCxc6hBBCCElbuNAhhBBCSNrChQ4hhBBC0hYudAghhBCStnChQwghhJC0hQsdQgghhKQtXOgQQgghJG3hQocQQgghaQsXOoQQQghJW7jQIYQQQkjawoUOkbJ9+3ace+65CAaD0DQNzzzzTFLacdZZZ+Gkk04yve6TTz6Bpml49NFHHdd5xRVXoFOnTo7LcYtHH30UmqZh06ZNyW4KIUmB8ojyyA4ddqHTngbJLrt27cL8+fMxbNgwdOnSBccccwzOOussvPTSS5bLmDx5Mt555x3cdttt+OMf/4ihQ4d61t7du3dj3rx52LJli2d1JJuqqqqkCWeSunQEeXTgwAFcddVVOOmkkxAMBtGpUyd85zvfwW9/+1s0NzdbKoPyyF06ijzKSHYDiHc8++yzWLx4McaPH4/Jkyfj8OHD+MMf/oBzzjkHv//973HllVdK7z9w4AA2bNiAW265BVOnTvW8vbt378b8+fNx3HHHYfDgwbbK6Nu3Lw4cOIDMzEx3G+cSVVVV+MEPfoDx48cnuymEtCkHDhzAe++9h/PPPx/HHXccfD4fXn31VcyYMQMbN27Ek08+aXo/5ZG7dBR5xIVOGnP22Wdj586dOOaYY6LHrrnmGgwePBhz5swxXeh88cUXAICCggLX2tTY2Ii8vDzXyjOiaRqys7M9K58QYo+uXbvitddeizl2zTXXIBgM4p577sFvfvMbFBUVJbyf8ojYpcOqruLRogPduXMnvve976FTp0449thjce+99wIA3nnnHYwaNQp5eXno27dvq79A/vvf/+LnP/85Tj75ZHTq1An5+fkYO3Ys/vWvf7Wq69NPP8WFF16IvLw89OjRAzNmzMCqVaugaRpefvnlmGs3btyI8847D8FgELm5uRg5ciTWr19v+jwnnnhizCIHAAKBAM4//3z85z//wb59+xLeO2/ePPTt2xcA8Itf/AKapuG4446Lnn/rrbcwduxY5Ofno1OnThg9enQrIdayHb927Vpcd9116NGjB3r37h23vpdffhmnnXYaAODKK6+Epmlxddtbt27F2WefjdzcXBx77LG4/fbbY87H04nX1tbiyiuvRO/evREIBNCzZ098//vfxyeffJLw+fV8/PHHGDNmDPLy8tCrVy8sWLAAQoiYa379619jxIgR6NatG3JycjBkyBA89dRTMddomobGxkY89thj0ee74oorouc/++wzXHXVVejVqxcCgQBKSkpw7bXX4tChQzHlNDU1YebMmejevTvy8vJw0UUXRX8ESPqQbvIoES1ypb6+PuE1lEffQHmkDnd0DITDYYwdOxZnnnkmbr/9djzxxBOYOnUq8vLycMstt+Cyyy7DhAkTsHTpUlx++eUoLS1FSUkJgCMT8JlnnsGkSZNQUlKCuro6PPDAAxg5ciS2bt2KXr16ATjyV8SoUaPw+eef44YbbkBRURGefPJJrFmzplV7Vq9ejbFjx2LIkCGYO3cufD4fli1bhlGjRuGf//wnhg0bpvyMtbW1yM3NRW5ubsJrJkyYgIKCAsyYMQOXXHIJzj///Kgh3HvvvYczzjgD+fn5+OUvf4nMzEw88MADOOuss7B27VoMHz48pqzrrrsO3bt3x5w5c9DY2Bi3voEDB2LBggWYM2cOpkyZgjPOOAMAMGLEiOg1e/fuxXnnnYcJEybg4osvxlNPPYWbbroJJ598MsaOHZvwWSZOnIj33nsP06ZNw3HHHYc9e/bgxRdfxM6dO2OEZTzC4TDOO+88nH766bj99tvxwgsvYO7cuTh8+DAWLFgQve63v/0tLrzwQlx22WU4dOgQli9fjkmTJuG5557DuHHjAAB//OMf8dOf/hTDhg3DlClTAAAnnHACgCPb5MOGDUN9fT2mTJmCAQMG4LPPPsNTTz2F/fv3IysrK1rXtGnT0KVLF8ydOxeffPIJ7rrrLkydOhV//vOfpc9C2h/pKI8OHTqEhoYGHDhwAJs2bcKvf/1r9O3bF9/61rcS3kN5dATKI5uIDsqyZcsEAPHGG29Ej02ePFkAEFVVVdFje/fuFTk5OULTNLF8+fLo8ffff18AEHPnzo0eO3jwoAiHwzH17NixQwQCAbFgwYLosTvuuEMAEM8880z02IEDB8SAAQMEALFmzRohhBCRSET069dPjBkzRkQikei1+/fvFyUlJeKcc85Rfu7t27eL7Oxs8f/+3/8zvXbHjh0CgFiyZEnM8fHjx4usrCzx0UcfRY/t3r1bdO7cWZx55pnRYy19XF5eLg4fPmxa3xtvvCEAiGXLlrU6N3LkSAFA/OEPf4gea2pqEkVFRWLixImt2txSxt69e+M+gxVa5sO0adOixyKRiBg3bpzIysoSX3zxRfT4/v37Y+49dOiQOOmkk8SoUaNijufl5YnJkye3quvyyy8XPp8vZj7q6xTim/6sqKiImQ8zZswQfr9f1NfXKz8jSQ06kjz605/+JABEP0OHDhVvv/226X2UR5RHdqHqKg4//elPo/8vKChA//79kZeXh4svvjh6vH///igoKMDHH38cPRYIBODzHenScDiMr776Cp06dUL//v3x5ptvRq974YUXcOyxx+LCCy+MHsvOzsbVV18d044tW7Zg+/btuPTSS/HVV1/hyy+/xJdffonGxkaMHj0ar7zyCiKRiOXn2r9/PyZNmoScnBwsWrTIeofoCIfD+Mc//oHx48fj+OOPjx7v2bMnLr30Uqxbtw4NDQ0x91x99dXw+/226tPTqVMn/PjHP45+z8rKwrBhw2LGwEhOTg6ysrLw8ssvY+/evbbq1Rs+apqGqVOn4tChQzHeazk5OdH/7927F6FQCGeccUbMuCciEongmWeewQUXXBDXi0TTtJjvU6ZMiTl2xhlnIBwO49NPP1V6LtI+SDd5dPbZZ+PFF1/EihUrcM011yAzMzPhzooZlEeUR1ag6spAdnY2unfvHnMsGAyid+/erQY4GAzGTNZIJILf/va3uO+++7Bjxw6Ew+HouW7dukX//+mnn+KEE05oVZ5x63b79u0AjrhUJiIUCqFLly6mzxUOh/GjH/0IW7duxfPPPx/dtlbliy++wP79+9G/f/9W5wYOHIhIJIJdu3bhxBNPjB5v2Up3Srwx6NKlC95+++2E9wQCASxevBg33ngjCgsLcfrpp+N73/seLr/8cqnhYws+ny9GgALAt7/9bQCI0ak/99xzWLhwIbZs2YKmpqbocWN74/HFF1+goaHBUlwOACguLo753jL+dgUnSV3SUR4VFhaisLAQAPCDH/wAVVVVOOecc7B9+3ZL76QeyiPKIytwR8dAopV+ouNCZwRWVVWFmTNn4swzz8Tjjz+OVatW4cUXX8SJJ56otPPSQss9S5YswYsvvhj3YzWA1NVXX43nnnsOjz76KEaNGqXcFifo/7pwgpUxiMf06dPxwQcfoLq6GtnZ2Zg9ezYGDhyIt956y5V2/fOf/8SFF16I7Oxs3Hffffi///s/vPjii7j00ktN22YHu/1A2h/pKo/0/OAHP8DXX3+NZ599VvleO1AeuUt7kEfc0XGRp556CmeffTYeeeSRmOP19fUx3k99+/bF1q1bIYSIWWF/+OGHMfe1GIbl5+ejoqLCdrt+8YtfYNmyZbjrrrtwySWX2C4HALp3747c3Fxs27at1bn3338fPp8Pffr0sVW2lb827HLCCSfgxhtvxI033ojt27dj8ODBuOOOO/D4449L74tEIvj444+jfzUBwAcffADgG2+Rv/71r8jOzsaqVasQCASi1y1btqxVefGesXv37sjPz8e7775r59EIiUuqyiMjBw4cAHBkN0gVyiPKIytwR8dF/H5/q1XsihUr8Nlnn8UcGzNmDD777DP87W9/ix47ePAgHnrooZjrhgwZghNOOAG//vWv8fXXX7eqz4oL35IlS/DrX/8aN998M2644QaVx4mL3+/Hueeei2effTZmq7Surg5PPvkkysvLkZ+fb6vslngWMjdTVfbv34+DBw/GHDvhhBPQuXPnmC1dGffcc0/0/0II3HPPPcjMzMTo0aMBHOkTTdNiVAOffPJJ3IijeXl5rZ7P5/Nh/PjxWLlyZdzIuKn0lxFpP6SaPPryyy/jzuWHH34YAGxFOaY8ojyyAnd0XOR73/seFixYgCuvvBIjRozAO++8gyeeeKKVTvVnP/sZ7rnnHlxyySW44YYb0LNnTzzxxBPRwFItq2yfz4eHH34YY8eOxYknnogrr7wSxx57LD777DOsWbMG+fn5WLlyZcL2PP300/jlL3+Jfv36YeDAga3+WjjnnHOiunIVFi5ciBdffBHl5eW47rrrkJGRgQceeABNTU2t4kiocMIJJ6CgoABLly5F586dkZeXh+HDhzvSqX/wwQcYPXo0Lr74YgwaNAgZGRl4+umnUVdXhx/96Eem92dnZ+OFF17A5MmTMXz4cDz//PP4+9//jptvvjlqOzFu3Dj85je/wXnnnYdLL70Ue/bswb333otvfetbrfT1Q4YMwUsvvYTf/OY36NWrF0pKSjB8+HBUVVXhH//4B0aOHIkpU6Zg4MCB+Pzzz7FixQqsW7fO1SBppGOQavLo8ccfx9KlS6OGw/v27Yuq0y644ALbKnXKI8ojU9rczytFSOTOmZeX1+rakSNHihNPPLHV8b59+4px48ZFvx88eFDceOONomfPniInJ0eUlZWJDRs2iJEjR4qRI0fG3Pvxxx+LcePGiZycHNG9e3dx4403ir/+9a8CgHjttddirn3rrbfEhAkTRLdu3UQgEBB9+/YVF198saipqZE+49y5c2PcOI2fFrfRRCRy5xRCiDfffFOMGTNGdOrUSeTm5oqzzz5bvPrqqzHXxOtjM5599lkxaNAgkZGREeOWmWgMJk+eLPr27duqzS33ffnll6KyslIMGDBA5OXliWAwKIYPHy7+8pe/mLalZT589NFH4txzzxW5ubmisLBQzJ07t5Xb7iOPPCL69esnAoGAGDBggFi2bFm0//W8//774swzzxQ5OTkCQIxr56effiouv/xy0b17dxEIBMTxxx8vKisrRVNTkxAicX+uWbPG0niS1KUjyKM33nhDTJo0SRQXF4tAICDy8vLEd7/7XfGb3/xGNDc3m/YR5RHlkV00IdrhPlSactddd2HGjBn4z3/+g2OPPTbZzSGEdGAoj0i6wIVOkjhw4ECM9f/Bgwdx6qmnIhwOR43LCCGkLaA8IukMbXSSxIQJE1BcXIzBgwcjFArh8ccfx/vvv48nnngi2U0jhHQwKI9IOsOFTpIYM2YMHn74YTzxxBMIh8MYNGgQli9fjh/+8IfJbhohpINBeUTSGaquCCGEEJK2MI4OIYQQQtIWzxY69957L4477jhkZ2dj+PDheP31172qihBCpFAeEdJx8WSh8+c//xkzZ87E3Llz8eabb+I73/kOxowZgz179nhRHSGEJITyiJCOjSc2OsOHD8dpp50WDVUdiUTQp08fTJs2Db/61a+k90YiEezevRudO3f2NNcIIUQdIQT27duHXr16wedrH5pvJ/Ko5XrKJEJSD6vyyHWvq0OHDmHz5s2YNWtW9JjP50NFRQU2bNhgev/u3bttJ2EjhLQNu3btQu/evZPdDFOcyiOAMomQVMdMHrm+0Pnyyy8RDodb5VAqLCzE+++/3+r6pqammGRmbeUEZkwtr0+ApoLxLzyV9sv+OszKyor5Lkv45qQNbpGZmRn9f3Nzs/RafXuNbdWPi90xMdZhxK3+cWsOtUc6d+6c7CZYQlUeAYllks/ni84r/Vjr5z5gPv+tYpzD+r9YI5FIzDmVOe3WO2a1DiPGOr16j1RkgEwmyWSbV7JX1p5UK1c21oD18TTrS1nbzeRR0veeq6urEQwGo5/i4uI2qVfTtJhPMsox3iv7tMWzOEGlftm1bj2H3b50UkdHIp2fN5FMSjTWbTW/3JrTbTFnVdqajP6TXWv3nFdtd5NkzFO75ai03awe13d0jjnmGPj9ftTV1cUcr6urQ1FRUavrZ82ahZkzZ0a/NzQ0KG0T6//KyciIfZzDhw/HfNf/FWQ8JyvX+NdTojKdoi/r4MGDtu4DYvvB+JwyPaaTZzl06FDCc8ZxkbVHNi6ycoyYja9VZHPKzEZFNodkYyQrxwyrY2h8Lln7ZGOb6qjKIyCxTMrIyIgKVP2Yqcx9fZoFANi3b1/Ce1XeDavyyqwcGcZdZtlzG+sw3mu3Pfr+NHtO2XkVmSR7TicyU2XM7JQZr1xZPbL2yMpVqUOlTrPfcxVc39HJysrCkCFDUFNTEz0WiURQU1OD0tLSVtcHAgHk5+fHfAghxA1U5RFAmURIuuFJCoiZM2di8uTJGDp0KIYNG4a77roLjY2NuPLKK72ojhBCEkJ5REjHxpOFzg9/+EN88cUXmDNnDmprazF48GC88MILrQwCvcaJusDuFp9MJZCdnR1zbv/+/dI26MnNzbV1nxG3tkjNVB+yc/r+M26JyvrWydalythbxUylI1P/2G2Dm6pSWbn69urHRAiRFGN3J7gljxI5BMhUOsZ+lTkVGFGZI22h+jDOYRXVS6L5ZOVePW69u8Zy9LJZpu5XUemY4ZZJhFvt089jYx9YVZuatUFFzeWmrEu5XFcNDQ0IBoOWr5fZ6BhfTLd+7FJ9oePFj7qsDsD+iymzQ3BzotvtEyd6Yr3gcGLn4oUuX+W54i10QqFQh1HpmMkk2ULHOL/NZFSyUflhtDsvnSwOvEK20JHZo6TCs7i10JH1gYrtpMpCUYZK283kUdK9rgghhBBCvIILHUIIIYSkLZ7Y6LiNTO3glX7XLb2iTMcto1OnTjHfv/76a8v3eqWuslqHylamTO+vglmddvtEpss3CwEgG2+V7Vy7W7+yPkmG/Ue6YhxnvSpLZvvkJipzRDaHrdpwAGrP0hbz3Qmy96Gt7Ej0qMgZfRucpGVRCWmSqH4z8vLyYr43NjZaLteJSQZ3dAghhBCStnChQwghhJC0JWVVV5mZmdEopDIvHf32qXFrVeaebPSAsruFa9y+Vdluk6kWjKoqt9zLZX1kV7Vn/G5Wjiy6sL49ZuooFa8mq55esvuM9Zh5BciiuLrlKaESsVSlDpWt845CovDzxndK31/GOSyb02bzXT8mTlRi+txEZqoE2XutP2eM+Gx0o/dCVeqmx5NsHLxCJgNk75yKesque7kTFavst9WY90rFa1rf9pa2CiEs5Zbjjg4hhBBC0hYudAghhBCStnChQwghhJC0JWVtdPR6N73uTmYbouKC7cTuQMX2QWaPIrM5MZ6T2eWo6GFl0aKNqLj129WPq7huOokqK0vHYNfd1ojM/smt0PBG7NroqGS4bu8pINwiUfZy45xRsVeT2d2ozHcVWwe9HY6ZvYfMdVl/zmjbY2yDXRs5q20zQ+U53Yrsq9ImJ/Z0snKMtlMy+WA3TYfxWuP7oJ8Lst9ds1Aj8cbIqizijg4hhBBC0hYudAghhBCStnChQwghhJC0JWVtdPRYjbtiRKaXdaJrtWv7oGIXIbvWSeZwWVmytAkqMWPMdO4ymytZHTLduZneX2bfYNdGwElmc7tj5qROFVsDu/ZF6czhw4fjxvaymhEaaG2jIIu545YdnAyzMmXvtawPZDHDZOVYaVO8MuOVa6dM1XuN4yuL6yaz/5M9i1nb9fUY65ClWJDhZmolq7GizN4Vu+0DuKNDCCGEkDSGCx1CCCGEpC0pq7ry+/1xXTllrnVmbpV2Q3vLtpCN222ybViz9lh1H5W5pZuVY8RqqHG77sjx7nUru7qK2lLWf05SX+hRGQeVeavHrK0ydZ5XLu4dBb1rvVUVtcp4mamq7LojG5GF+rerGnXyztt1E3cyR1Xkg/6cMWXGvn37EtZhFsJEJQyBDLdStKj0rSwkh7FvZao1PWbl6KHqihBCCCHkKFzoEEIIISRt4UKHEEIIIWlLytroGNO520ElHYNdZKnkjRjtebxyDVZx9Zbp663qVlXbZxUzewGV53SrTTK3a7t6dhWbKjNbCLtu4U7seUgsVt+peOdlWLXLMXtX3Qq1IHOP9mr+yFK5uOVuLivH6K5tHE/9tcb0C8Z73bJVVMHq3DT7XVOxC9JfK5v/KuEVWq4VQlhaK3BHhxBCCCFpCxc6hBBCCElbuNAhhBBCSNqSsjY6icjNzY35vn///uj/3dJ3A7H6QpWYFbJrZenr45WlR6bPVXlulXtldTqxNbCKWah4t2ycZGOtYmugYiNg16ZJ1nazOlXK1duT6cdWH0uGqONkPrllf6WPBSOLA6OCzH7OeN7JnM3MzIz+3yhznNi8yOyN9O+CSmoZo02OV6kuVGwV9e01tkf/++TEhtXuc6qMn+pYKz/NK6+8ggsuuAC9evWCpml45plnYs4LITBnzhz07NkTOTk5qKiowPbt21WrIYQQUyiPCCFmKC90Ghsb8Z3vfAf33ntv3PO333477r77bixduhQbN25EXl4exowZ41r0RkIIaYHyiBBiinAAAPH0009Hv0ciEVFUVCSWLFkSPVZfXy8CgYD405/+ZKnMUCgkAMR8fD5f9GM859UnIyMj+mmrOlP5k52dHfPRj4mTcZGV41YdsrHNyMjwbH55MYeMbffqObOysqIf/X2apgkAIhQKOREdngC4L4+EiC+T9P3j1Tvm1nsju1b/HE6exWxeyuqQ3Wv3nLEf3HznEr1TbfX7ZHVszZ5Fdq+KnPHquVTuNZNHrhoj79ixA7W1taioqIgeCwaDGD58ODZs2OBmVYQQIoXyiBACuGyMXFtbCwAoLCyMOV5YWBg9Z6SpqQlNTU3R7w0NDW42iRDSQbEjjwDKJELSjaS7l1dXVyMYDEY/ffr0SXaTCCEdGMokQtILV3d0ioqKAAB1dXXo2bNn9HhdXR0GDx4c955Zs2Zh5syZ0e8NDQ3o06cPAoEANE0DYD3ctJm7tt4lzczlTZYuwolrp+yc/rvRfc5uSHVj2gljX+rdxGV1qvSBcRyM3+26ojsZB30bVNzUnTy3XfdR2X0q7uVO3G31Y6QP6SCEwIEDB2yX25bYkUdAYpmkR98/TkItqKRu0L/Lxmtl52SYhXCwOt/N5rrdMBaycp3Mb5Xn9CpVg1shJvSYuaJbfRaz61Tarp+bxmv180KlD1rKFELE7L4mwtUdnZKSEhQVFaGmpiZ6rKGhARs3bkRpaWncewKBAPLz82M+hBDiFDvyCKBMIiTdUN7R+frrr/Hhhx9Gv+/YsQNbtmxB165dUVxcjOnTp2PhwoXo168fSkpKMHv2bPTq1Qvjx493s92EEEJ5RAgxR9GDU6xZsyaue9fkyZOjLp2zZ88WhYWFIhAIiNGjR4tt27Y5cuWUuZxZPefz+ZTcKO268Bnd8hK56cYr58CBA9GP0e3TLVc/Mzdxu26Ldj9u1WPsr7ZwqVX5OHHXtOpyrNIGlfFOZfdyr+WREOYyyfjp3Llz9KMy/53MS305KnPN7P2ze07WBifvvFvvgkr/qfzG6M+ZjafsnOw5ncgSt2S63fnm9nhZlUeaEKkVz72hoQHBYDDmmEwfaPUcEKu/NNOjy2xrVHSkKnY3B/btg//22+Fbvx4L167FYp8P4aN2SvprneiMjTY7Vu0J7NoImeHE7kaP0U5C1tdtkb7CiJOw93btL2RtMOvnRPZZ4mgKiFAo1GFUOmYyyYhKigV9OU5s2fTluGmDZlf2yua7k3ferXfBiKz/ZKk3ZNeayRn9eeM52XM6kSV27YJk5ajMN7doqdOqPGp3ua7SGf/ttyNj4UJoQmD20WNVfn9S20QIIYS0Z5LuXk6+wbd+PbSjG2w+AGUe7aIQQgghHYV2saMjyyyrsi0r2wq2q6oyotIe4/f5q1djHo4sciIA1mlatG6V7UDZlqhb273GbVnZ9q5KtnC7qGzzq8wDle16mSu/7Dllcw+Iba+T+a+yBe/WFne6IpNJKhnB9eWYzWGZOkOmIjciU5e5FWLCLfWFijpP5d1QuVbl3ZWNpyyMhLEcWSZxu6o+Y7lGVN55t2SCSp1OZFK7WOh0FKqO/lsO4FWfD4uO2ucQQgghxB5c6KQQYQC3Hv1/hslf+YQQQggxh7+mhBBCCElbUnZHJzMzM5oCQo+KLYZR76rXkXqVYkGm67XrBmj87iTcukqdsnrs2jsB1vvBiRulXYzPrE9/AAD79+9PeK9M/y2ziTFzz1Sxv7AL7XDs41YKESf16M8Z3xsZxvfYrq2i3qUeABobG6P/9wNomjsX2vr1EGVlCMyfj7CkTlkoDZl9n8o4GK+V2TV27tw5+n+j/ZXsXTVrnywtjeydN5OvemSu6W7JErupeMza4Kb8T9mFDiGEkPbPzQB8CxZAEwKipgY34xsVPSFtAVVXhBBCPKMciIbN0IRAeXKbQzogKbujc/jw4ajqSrZVp7LVanfbWLa1quKubbYVZ1e1JssWblaO1WjRKpGHVaKk2nXJNmK2nWu1LGM5MlWVWeRTq3PTiSunigu5TKVB1ZU5fr8/KpNk75j+u5N3QeV9lF3rJDO21cjIelWVkXUAKqALm+GgfXqMfWBElhlbFh7DiEq4AJXo+yqqNj2yZzH7zbPrRm9EJktU1IIy3FTTp+xChxBCSPtHHzZjne47IW0FFzqEEEI8Qx82g5BkQBsdQgghhKQtKbuj05KVFLBun2Kmn1TJLCtz/dMj00cCsTYnZjpHmYuoLFy4zEbALAS4Vb2smYuj3ezgXtkWGJHpie26XJrpm63a1jixRXIrPQkxJxz+xinaal+qhA4wy1Itc7uW1SELgWGWYkE2v7yy67Lqou3kXTBLz6BH339m/WM347zst8rsOVVCfVi1lzGr066cVLE9ctO9nDs6hBBCCElbuNAhhBBCSNrChQ4hhBBC0paUtdHRI9Of6vV/xutUQovLYliohKmWxVKRxaEwa59dmw6z2C6yWBSyeCAq6SFUYr2o0BgKIWPJEvhffRXzV69GFRATWj5Rm2Th1o3nzMY3UTmAe3Gb3ChTFS9CxacrMrnjxI7LrdQSMrsSs1g0dpHZ6ZnZXsieRV+um/NSVpZKrDS78t7NVCGycqzaEKm03Yhb8t5NWdcuFjqExCNjyRJk3nYbNCEw7+gxurESQgjRQ9UVabf4X301GlreBzC0PCGEkFa0ix0dmUuhHjNXTj3GbTHZ9qRsq1XF7dqsDXbLUcFYjj7FgXG7WbYN29TUFPM9EAhYrlOPLDu4WVqH+atXYx6+CS2/XtPgi5Px3qwNMhWdiruo8V69OtRJqhCVOWS1ThX3Uf21+rAPHQ1N0+KmpXHiAq2iIpSpWO2GdzCTK16EXlDJvi1THau8J25hNp525b2T3wJZiBWVemSojJlXv1VOaBcLHZKCHD4M3+LF8K1fj0hZGfxIbB/jFfrQ8us1DdVtXD8hhJDUhwsdYgvf4sXw33orNCGgrV6Nm9H29jH60PKJdnIIIYR0bGijQ2zhW78+ah+jCUH7GEIIISlJu9vRUXGjlKFiA6Oim7aariLetTI9u1sujrJrZf1nbM+8mpoY+5h1unMqobv1NjnG9rSVK+K+vXstu6mrYNU2wom7rSwsglu0lUt7qpPIPslJmgTZu2F852TuyPp5oBJKXyUtjRGvUqe0PJtfCByaPRtYtw4oLwduvhl+nS2gik2Tkzls9znNQnnoZXqi3yM/gIO33AJt/XqIsjKIX/0KecFgzLVu2UNZtTtzgux310yWORlDpR2d6upqnHbaaejcuTN69OiB8ePHY9u2bTHXHDx4EJWVlejWrRs6deqEiRMnoq6uznYDSWpSBWAegH8c/bdKdnGK0+Km7j9q3HxzshtELEF5lN7MAoB584AXXzzyb1V7ljL2uBmAb8EC+F56Cb4FC6AtWpTsJrVLlBY6a9euRWVlJV577TW8+OKLaG5uxrnnnovGxsboNTNmzMDKlSuxYsUKrF27Frt378aECRNcbzhJLi32MWOO/tvWhshuQjf19gnlUXpTLgTQsoMmxJGdnQ5GORBjIqCtX5/cBrVXhAP27NkjAIi1a9cKIYSor68XmZmZYsWKFdFr/v3vfwsAYsOGDZbKDIVCAoDQNE34fD7h8/kEgOgnOzs75qM/p/JpKbvlk5GRkfCjUm5WVlbMx277VD7GPnHrWdzqW9l5Wf+52SZZubMBET4iSkX46Hc7dRj7Wv+cxnnRFmMiG3vjOWP7ZGMEQIRCISeiwxO8kEdCfCOTEvWfW2PipJxEY5do/NyYM17P03jvpUxmq8helT7Ky8uLfmSy1eydlz13ovbE6wOjvPeiT5yMn8pvtNXfCbM2mckjRzY6oVAIANC1a1cAwObNm9Hc3IyKioroNQMGDEBxcTE2bNiA008/3Ul1hHiC3k19Hdq3Gq4jQ3mUXvC9jN8HmclrTrvF9kInEolg+vTpKCsrw0knnQQAqK2tRVZWFgoKCmKuLSwsRG1tbdxympqaYoLPNTQ02G0SIbbQu6mT9olb8gigTEoV4r2XHc1NOF4fcKGjju15U1lZiXfffRfLly931IDq6moEg8Hop0+fPo7KI4R0PNySRwBlEiHphq0dnalTp+K5557DK6+8gt69e0ePFxUV4dChQ6ivr4/5K6qurg5FRUVxy5o1axZmzpwZ/d7Q0IA+ffrEuHLq3ftU3KyN7moydz6j+1ynTp2i///6669jzsncDVWylxuxeq2Z67m+HJmLqvG7zA3VzAVaJauwXXdcFbd1I7Ls5XbdFmXzC4htr1tu326G97dajr5OIQSam5stl9sWuCmPgMQySZ8Cwu6cMaZKkc0RYx1W3zHjfUGDO3KLig9QS5sjO2ecE5mZ1vcd7Lpsm6XfycvLi/5fb6AOqIVsMN5rFbN33q7Ltuw30Cy0gL6PnKTQkI2DW+FYzDKoA7CckkZpR0cIgalTp+Lpp5/G6tWrUVJSEnN+yJAhyMzMRE1NTfTYtm3bsHPnTpSWlsYtMxAIID8/P+ZDCCFmeCGPAMokWxw+DG3hQvjGjoW2cCH8yW4PITqUdnQqKyvx5JNP4tlnn0Xnzp2jeu5gMIicnBwEg0FcddVVmDlzJrp27Yr8/HxMmzYNpaWlNPwjhLgK5VHqoC1adCTOixAQNTVJSQlDSCKUFjr3338/AOCss86KOb5s2TJcccUVAIA777wTPp8PEydORFNTE8aMGYP77rvPlcYSQkgLlEepg8aUMCSF0YQVBVcb0tDQ0EqnbBejTk+mD5fZbchsQ1RsJtwiGXV6hazf3bKlMZalop93K+WIW5jZBVlFxd5Jf60QAuFwGKFQqMOodNyUSTLcnO9tgb69t0QiMSlhFvh8uE13XpZqxq3nVilHxR4x0XWqdSYDJ3aNMtyyPXUrTYeZPGp3ua4IIYSkFsZ4L7cfNdomJBXgQocQQogjjPFeMrjQISlEyi50/H5/1JVTv92msnVv3FbUb5m65aZrtt0m2waVuXrLUNniy83NjflufE6rW5nG/nKyBWrV7drYd7Jr3VLpGOuQjZ8Z+nuN5dhtn937ALUQAHrc2u5u7+jdy/XIwj0YzxmxqjI0u1bWHpmqyG5263jl6lHJym7Xvdyu/DSrU6Ucs1AfeuyquVTmgUq4ACeo9JEsHIusHFdNF2zfSQghhBCS4nChQwghhJC0hQsdQgghhKQtKWujEw6H4x53Sweq4hosK8dMB+qFjlSlzP3798d8N7MZ0CNzCZVda6ZLtdr3KnWa2a7YtX9y4kKuHyeVMfPKJdTus+j72WrI9XQk0bPbtVUBnNn/JcLM7kZfrlmYff15fUoFwP58UrGtkb0Lxra6ZZ8ia0/zgQPQFi2Ctn49RFkZAvPnI/4vlXs2JrJUIEDsOHjl3q5iy+WWDHXzWVJ2oUMIIYSkEowA3T6h6ooQQgixACNAt0+40CGEEEIsIMrKII6GGBCahnVJbg+xRlqprsxS1MuuTQZ2bTGc6H7t2iaZ1Sm7ViUejgptESpedu++vXuRsWQJ/K++ivCIEchduDBGXy+LHyE7p3KtTHfuVrj1VHhXUgF9HB2ZnYs+ppOZ7ZhKugEZ+rF1YtMlG+vGxkZL9ccrx62UATJUnltm5yIbk8D8+bgZRyNACxGNCB3vXmN77KbuMfZBMuJamdlyydD3iYp9lrEOff+pxhNLq4UOIW1JxpIlyLztNmhCwLdmDfX1hKQ5xgjQpH1A1RUhNvG/+ir19YQQkuK0ix0du9lPVUJle5VVVYaKikJPMlQJKuonM/dCt/pWRaUjUzUkKtOM+atXx2RsNurrZa6wKiHyvXBBJupYda3Xb6ubyRm7aohkuBgbUXmPZaptq/epnDPiJH2FSntl45kMlX1bZFc3K9MtN38n6W/axUKHkFTEmLHZqK8nhBCSfLjQIcQm1NcTQkjqQxsdQgghhKQt7WJHJxl6RRlWbWmM15q51lm125DZvMQr1w2c6Jdl7ZPZo5i5Z8rqsNseFfdHJ+XKkM0Ls5AEMrsJ2vO4h76fZfZXxjmrYmfgVioQYxtk7TO+51bll7GtsmtV7HlUcPL+2bUDVUEmv5zIV304AyNO7FqsYpaKQ48T+yc9quPAHR1CCCGEpC1c6BBCCCEkbUlZ1VWiKKRG2iJbq5OsuG2ReTrVVBJmW5myLWWVbXW7bVKZTypqQbvj4ERFobL1q+9PYx2pNodSEauRkfXj6UR1IJsHKqEzjO+NSuRmfT1O5r5M9a4y/62qmIznVTK6G3FLJqlcK+svI16op9yMhC9rnyyit5smGdzRIYQQQkjawoUOIYQQQtIWLnQIIYQQkrakrI2OPty6VXduo25QJey3Ebu2NW5lIzZi18XR6HpoV59rpi9VydqrP98WIdOB1LZBUdFNO8mILMvQnMr9kyokSgGhkjbELZy4UstkgFvywoh+7jmxc7FrJ+TW/DaT4W65orsl+2RzU8XuRqVvVeaMSqojlbAuRrijQwghhJC0RWmhc//99+OUU05Bfn4+8vPzUVpaiueffz56/uDBg6isrES3bt3QqVMnTJw4EXV1da43mhBCKI8IIVZQWuj07t0bixYtwubNm7Fp0yaMGjUK3//+9/Hee+8BAGbMmIGVK1dixYoVWLt2LXbv3o0JEyZ40nBCSMeG8ogQYgnhkC5duoiHH35Y1NfXi8zMTLFixYrouX//+98CgNiwYYPl8kKhkAAQ8/H5fNFPRkZGzCfRdarXGj/GNrjxkbUnFT+y/jE+i6zvsrKyEn5kdTppn8p9ye5nlXnj1dhmZ2fHfMzuD4VCTkWHJ7gtj4SIL5M64sfJe2NVLgMQeXl50Y+sTuOcTYZ8datO2XOq1KEyRkZZnOzfJie/yWbyyLaNTjgcxvLly9HY2IjS0lJs3rwZzc3NqKioiF4zYMAAFBcXY8OGDQnLaWpqQkNDQ8yHEEJUcEseAZRJhKQbygudd955B506dUIgEMA111yDp59+GoMGDUJtbS2ysrJQUFAQc31hYSFqa2sTllddXY1gMBj99OnTR/khCCEdE7flEUCZREi6oewX2b9/f2zZsgWhUAhPPfUUJk+ejLVr19puwKxZszBz5szo94aGhlaCRRYmWo/RHU3m1uxWFlozNzeZa7AK+j4wugyquCLK3AZlLsdmWZhlIdbNsq0nqtMM2bUyF1ZZ6HiVdB+y+WWGynOGQqHo//Py8izfp1K/m678bYnb8giwJpOsouKma7zWSeZzWTn6sfYqxYmK+7txTjc2Nkb/L5NJbZGZ2wzjO2/XBdot93eVctoipY4KXoa4UF7oZGVl4Vvf+hYAYMiQIXjjjTfw29/+Fj/84Q9x6NAh1NfXx/wVVVdXh6KiooTlBQIBBAIB9ZYT0gHwA8iorob/1VcRHjECfgDhZDcqhXBbHgGUSYSkG47j6EQiETQ1NWHIkCHIzMxETU1N9Ny2bduwc+dOlJaWOq2GkA7JzQAyb7sN/tWrkXnbbbg52Q1KcSiPCCFGlHZ0Zs2ahbFjx6K4uBj79u3Dk08+iZdffhmrVq1CMBjEVVddhZkzZ6Jr167Iz8/HtGnTUFpaitNPP92r9hOS1pQD0I5G49WEQHlym5NSUB4RQqygtNDZs2cPLr/8cnz++ecIBoM45ZRTsGrVKpxzzjkAgDvvvBM+nw8TJ05EU1MTxowZg/vuu89xI/W6TqPuV2a/Y9Th6vWnMjsN43lZagkzmw4vUjc4sclRse+R6cNl5Zq1z64utjEUQsaSJVE1Tu7ChVE1joptjRHZHDKOg/7ZjM+p7wO/EPj6llvgW78ekbIyZC9YEKNy0j/L/NWrUQXEfZb1QqBCCPgARACss/xUrZHZD6jYaqQKbS2PMjMzoWkaAG/s/YxjIHvnZHYuBw4ciDln9R03tseIzNZOlk7ADGN79W1QqVMmM41yz4m9pF1k75jRTqm5uTn6f2MfdO7cOeb7vn37bNWpgsrvo1t2S26iCREneUsSaWhoQDAYTHheZaFjxIuFjrHOtljoqKCy0FERBk4WOnZp+p//QeZtt0ETAkLTMFcI3JqgPUZkfS97EWULHVkullsiEcwVIm5bjc8SATAPiPssfiEwC0C5EFinabhNCNs2OrLnVP0hCIVCyM/Pt9mS9kWLTLKz0DH7oWmLhY6K3HFroaOCiixJ9YWO3T8muNBxhpk8StmknoQY8b/6artR45RFItCO/j9eW/XP4gMSPktY07AQAI7+wEZS6+8SQghJeZjUk7QbwiNGQBz9wRea5kiN4zXrfT5pW/XP4lQlRQghJDEpq7oKBALRbWKZukAFme7XK7zY3nUSR8eN+gG56k+m0gGsb18a7xOHD+NmHNn9WAfE2LW4hZnKUH/e+JxNjY1AVRWwbh1QWop5CxZgRIK2+oHos6zXNFTjyO4NILc3ksVEMd6rMkaqdETVld/vj8okq/Fm3LR98iJ2iRHjO6fHTBWjR6V9slg5MlliJkesvgtm7ZHFHZJhZv9kN56REb1MUjFxUDEDkV1rZp/lheqqpS+FEGhubqbqiqQPYSDGziXlqKoC5s0DhABeegkRAGMSXKp/Fp+mJbiKEEKIU6i6IsQt1q07ssgBgBS3ISKEkI5Cyu7oNDU1Rf8vU9vYDbPdVlb4XoTHdlNVZdVLwKjS2b9/f8L2malXrOLUM0iPvv0yTzlZSIJ45/XMefFFzAMsuYK7ta1ufBa31CZtoSZpb0QiEUuqK+M9epy8G1Y9B43jrlKHzOvQiQu53qtIn+IhHlbLNb4LdkNnGHHiXSYLPSILR+Hk98euR25OTk7Md6O3nh4nY+/Fb6vqb0rKLnQIaW9UHf1Xb0NECCEkuXChQ4hLpLwNESGEdEBoo0MIIYSQtCVld3T0UUj1+kAVfZ8Tmw4vXOLMbCZkkZvt2knIojqrtM9ok5ObmxvzXZYaQcWtUm8TYKzTie2KXo+t4iLqZOzthsiX1WnsExkqtj+ye/X3CSGQYhEp2oxEz26c37JwAHajHQOxti2yEAQyF/F49+oxtkGWfkfFLk9ml6PyjsnaI7NXU0Fm+2McPyc2V7Ixk/WJSvtkrvtmtlIyZC7tKuECVH6P4o29VXnEHR1CCCGEpC1c6BBCCCEkbUlZ1ZXeldPuFp8Mswi4MjfdRNcB8q1Ms61Ur1Rkidqjcp8RlbaquFXKVDN23UUB6y6iKi7ZxrFWUU8lI5O4SniFRG6yQgiEw27Ho27fyMbd2K8q6ih9iA2zOvWYvZteuAbLXLKNdeoTVgJHzBQSoSJ77YZPMN4rCz/hJEK8SntUTCdkpgAyl3snkZplLu0qyaCtRhhXORe3XqWrCSGEEJv4AWgLF8I3diy0hQsBj+KXEaInZXd0CCGEpBc3A/AtWABNCIiaGjAUJWkLuKNDCCGkTSgHoB31ktGEgLZ+fXIbRDoEKbujo7cDsJuRWWZ3YOYGaNU2w1iOW3Y2B/btg//22+Fbvx6RsjLkLVwYzW5tpp+UufMZkbm0y/pW1n9mLpcynbcMmX5XpU/cuA5wlopDNk9kdl8qdcr6VsWOgykgWiML9S+zr1DJ7NwW/W7VZsIPoGnuXGjr10OUlUH86lfI1KUQsFrOOgAV+CZNyq1r1rS6xm5oD6Pdpcw+UmUcnLxHVjELyWG1TrNwBlbLkfWP8bzKPFWxj1S514yUXeh0dPy3346MhQuhCQHfmjWYBWBhshtFCOmQuKVyqgLg9/tRFolgvc+HxT4fQON24jFc6KQovvXrY7Z4ywHg6I4OIYS0JW6pnMIAqvx+wO93r3GEmEAbnRQlUlYGcXRhIzQN67jIIYQkiXVAjDwSZWXJbRAhCmgixeK5NzQ0IBgMQtO0aBwdPW7p+LyKVSJDpc5MTcMsAOVCYJ2mYbHPF7XRcZIGw27sCSfxZezalbg5Jm6l11Bpn13bMqtlqt4rQ5Y2IN58C4VCyM/Pd6XuVKdFJnmNcWzNUhxYxY3YY34cUV+V48iipwpHdmc6Om7FdXOrHDOsplzwqn6vMJNHVF2lKGFNO2KTc3Rx4+OODiEkSYQB3JrsRhBiE6quCCGEEJK2pOyOTkZGRlR1JQtNrcetrV6vcBL+2mo6ASD2uVVcJWXlmvWl7NpOnTrFfP/6668TlmNXFWM3M7dquW65UtrFSZltERaBxGI2f2Rj4tb8kckAt+owunYb0bs5u6VON+JE/SPrE5naWyXdgez3ycn7pzKebqZVsEMyTEYA7ugQQgghJI1xtNBZtGgRNE3D9OnTo8cOHjyIyspKdOvWDZ06dcLEiRNRV1fntJ2EECKF8ogQEg/bC5033ngDDzzwAE455ZSY4zNmzMDKlSuxYsUKrF27Frt378aECRMcN5QQQhJBeUQISYQtG52vv/4al112GR566CEsXPhNvN5QKIRHHnkETz75JEaNGgUAWLZsGQYOHIjXXnsNp59+uuU6fD5f1EZHr9eThbi2a38CtNaPW3UNVsGoh3XLpdAr+wq7Om4jRpsc/XMb+0AWslyGim7aia2UHichy1VsrmT3qYSnt5u2Q98eIURMepZUoC3kEQBkZmbGtRt0gmz8ZPJBNoedzEtZnbJzKrYrTuwGZZjJV9m1sj6R9YERmYu2Sr8HAoHo/xsbG6V12rU5lNkMqchIs2v151XmkJW5aFUe2ZphlZWVGDduHCoqKmKOb968Gc3NzTHHBwwYgOLiYmzYsCFuWU1NTWhoaIj5EEKIVdyURwBlEiHphvKOzvLly/Hmm2/ijTfeaHWutrYWWVlZKCgoiDleWFiI2trauOVVV1dj/vz5qs0ghBDX5RFAmURIuqG0o7Nr1y7ccMMNeOKJJ0zdCa0ya9YshEKh6GfXrl2ulEsISW+8kEcAZRIh6YbSjs7mzZuxZ88efPe7340eC4fDeOWVV3DPPfdg1apVOHToEOrr62P+iqqrq0NRUVHcMgOBQIw+soVDhw5F9eF63Z3dtPOAWohrt+INqNhQyGLRqNgMqejrZeXI9LlGVGwWrMb58SrGglvlmsVtUolDJCtHhl17C7M620M4eC/kEZBYJkUikbhpaYyovKuy90bW726lFFGpU6U9yYg3JXsfzWxrrGJmX2Q3PY/xPpm9jMxOVVYHENvXbskrFftIu78Ticq0msFKafRHjx6Nd955J+bYlVdeiQEDBuCmm25Cnz59kJmZiZqaGkycOBEAsG3bNuzcuROlpaUqVRFCiBTKI0KIFZQWOp07d8ZJJ50UcywvLw/dunWLHr/qqqswc+ZMdO3aFfn5+Zg2bRpKS0uVPRwIIUQG5REhxAqup4C488474fP5MHHiRDQ1NWHMmDG47777lMvRu5fLVDH6bTwz12S7Kh0ZZuoBlW1Z/b1GmwNZCHUZbm0hm21lykLZG9G3X6Z2c1N15dbWvopKx+r2r5Ow6HZDFCQrFHtb45Y8ApDQjdXYl/oxUUnr4Fa6EVmoAK9wc87afVedyK9kYLVNXqWdkLXHK5lk95wRVXmlCatKrjaioaEBwWAQfr8/utCxqq9UicHilqB3KxaOEScLHbcWCyoCx4uFjpvCyYuFjle2BW0hVJzO/1AohPz8fKV72istMikRKgsdGW7JpGQsdFTa7tVCJxkk4w8GlffaLF5cIlJ9oWPETB4x1xUhhBBC0hYudAghhBCStrhuo+MWifThxi00/Vack9D+sm0z2VawV7pf4xajXdc/M9zaJlYZh7bQl3u1fS/rI5U6Vfpddq1dPbaTOom8f+zONbf6WaX+5gMHoC1aBG39eoiyMgTmz4edBB8qslclDIgT920vcJIawYjd8ZaV62QuqpgfyNpjN1SFm3agRlJ2oUMIIcRbtEWL4FuwAJoQEDU1uBnArcluFCEuQ9UVIYR0ULT166Ed9UfRhEB5kttDiBe0+x0duxGDjbjlyubEWl32LCrZt1W2fvX3yjy9jKhkBpa5PLaV6k/WHn0fyCKJxvuux240UbPxtLvF7Zbni/7/qZi9PBlYVe2pvKtuqa7MvDJjvHTOOAOoqQGEADQN62w64R44cCDme2ZmZsx32XOqyB0V9YVdVYdMBW32G6PHzDxCJndkskT2LGblNDc3R/9vjP6tYn4g61sV+ariKq+vRzV7ebtf6BBCCLHJL38JvPwy8K9/Ad/5DhavWWOvnMOHY2x9/IAtWx/iHX4A2sKF34yREAhbSGmSDnChQwghHZXbbz+y0BECePll3AR7Njq09Ul9bgZixmgWgIXJblQbQRsdQgjpqKxbd2SRAwAObHRo65P6lAOxY5RasYI9pd3v6KjYRcj0xGa2GYnKMSIr10wHv2/vXmQsWQL/q69i4dq1WOzzRbcW9c/pZvZyfcTXUCgkvTZRHUZSIb2AW6kl3MpULyvXq/5RsaOSnXcr83N7R9O0uNHaZahkdjai8l7LzslsKOa+9BLm4shfvBEA6yRtkLV13ksvYZ6kHJmdhgpuZb82on9OYx16GyKj/ZCKzY4T12o3WAegAt+M0T+ReEzNfh9l9jwyVCIjWwmP4Un2cuItGUuWIPO226AJgdlHj1X5/UltEyEkfakGAE1DuRBYp2mosvlXftXRf8tx5Ae1SnItSQ5VOLJYdzrW7REudFII/6uvRrcWfQDKIhGACx1CiEeENe2InUZLAmWbP35h0CYn1QkDWKhpjse6PUIbnRQiPGIERMskBLDepQzrhBBCSEclrXZ0nGTFNd6r18U6saFQCcPf6bbbMAtHt381DdWRCMJHV91e2cQ0NjZaKtdMF+2WrZQelZgLsmv9AJr+53/gf/VVhEeMQO7ChTGur7K4PsaYGrL2uBX/xohKrBW3UoUksi2zqhNPR4QQcZ/fSVoA2dxTkR0qsansXutWDCCz53QS6t8usvarxJdRicll9fdIZV6YjadbMbnsjpHRxsmuvFJ9jrRa6LR3jNvIxB1uBqK2T741a+j6SgghHQjqRkja08qtMrnNIYQQ0oa0+x0d2daXTL1iPGfcUtNvzalsHRqRuX2qqGZkqKSvkPWJSnuM52QumCp1ytw8ZcjaanSrlLm+mqFvkzF0vVfb7E7UAnZJdpbo9oTsvTbOCRX1piwVgRGv5ohXqXFk5Vh9j7xKnWJEpRyZ67yKK3q8dAd2UFGXWU1BZGyfE9pKzrT7hQ4hZtD1lRBCOi5c6JC0h66vhBDScaGNDiGEEELSlpTd0dGHW9dj1BXatU8xC1tt13VShiyMtleY6YXdckfW2+U4sfWxi5m+3qotl8pYG22R7OLEPVlF7293HuvLTORi3ZGR2aCZ2dno7byM89J4rSydjIp9hf5at2SSm/YyVt9HszJl8t7Y127JQbv2T8Z5oj9nZnvqVkobt+zF3MJYp/65VWUvd3QIIYQQkrZwoUMIIYSQtIULHUIIIYSkLSlro6PHDdsCYzlmZXphf+FEr6kSL8huTA1ZOUZdvixlhkz/He+8F8jqNAvNrkc2Zsb+MuqU9X3iRMetEpvD6tib9YHKu9LRkY2l8ZxZ/C7ZtbL3RsXOTD8Xncg5WZ2y+W4WT0x/rbEcfT1mclCPmcyxKpPMbDvtvisyeyy36nCCihy0a2NoPGf27qigdOe8efOiRsItnwEDBkTPHzx4EJWVlejWrRs6deqEiRMnoq6uznbjCCEkEZRHhBArKC+RTjzxRHz++efRz7p138SZnTFjBlauXIkVK1Zg7dq12L17NyZMmOBqgwkhpAXKI0KIGcqqq4yMDBQVFbU6HgqF8Mgjj+DJJ5/EqFGjAADLli3DwIED8dprr+H0009XqseqG6uKW6XVcszulbl5qmSztboVbXatWxnAZX1gtrUrU63ZrdPsWtl9djP8OlHpyNQATsL3280ML6snXVI8tJU8AgC/3x8NeWF1Dpmlj1Fxa5bJOpXxVFGX2c2urjLfZdeqvKtO5rQshY0elXAOTlBRHbvlGp+oTLNyvXJvd2KSYUR5lLZv345evXrh+OOPx2WXXYadO3cCADZv3ozm5mZUVFRErx0wYACKi4uxYcOGhOU1NTWhoaEh5kMIIVZwWx4BlEmEpBtKC53hw4fj0UcfxQsvvID7778fO3bswBlnnIF9+/ahtrYWWVlZKCgoiLmnsLAQtbW1Ccusrq5GMBiMfvr06WPrQQghHQsv5BFAmURIuqGkuho7dmz0/6eccgqGDx+Ovn374i9/+QtycnJsNWDWrFmYOXNm9HtDQwMFCyHEFC/kEUCZREi64ci9vKCgAN/+9rfx4Ycf4pxzzsGhQ4dQX18f81dUXV1dXB16C4FAAIFAwHYbnITLt3rOiF09qMp9Krp8mT5VRe+vkhrBLV2wW/pdr3BSp9411miHIDtntcx493oRiqG9pIBwQx4BiWVSOBy21A5ZKAMV+7VUmO/JDi3glsw2Q2aXo2Jzleg+QO4+7cTeyAt7O0f2MC7a1uhxYovkyJLq66+/xkcffYSePXtiyJAhyMzMRE1NTfT8tm3bsHPnTpSWljqphhBCTKE8IoTEQ2lH5+c//zkuuOAC9O3bF7t378bcuXPh9/txySWXIBgM4qqrrsLMmTPRtWtX5OfnY9q0aSgtLbXl4UAIITIojwghVlBa6PznP//BJZdcgq+++grdu3dHeXk5XnvtNXTv3h0AcOedd8Ln82HixIloamrCmDFjcN9993nScCsYt8ysuhAakUWpNNtCk2Undmt7UnZORdXhZMvR7raiSjRmJ+XKVHSJ6letQ+Y2m5ubG3Nu//79luuR1Slzh3fiyuyFy6rbtLU8aglKCFhXmZupmVXciL3IOu4ElTAbKqEhZNhV+TohGSE5VFCJip3oPuO9TtRNdu81k/dO2qSJFFO4NzQ0IBgMelJ2e17o2EUl9QAXOu6FMzfi1kJHP58AuTBQWeio9lcoFEJ+fr7FVrdvWmSSnYWObAyM57nQMScZCx0ZyZCZsjZ4FTuuLXAi783kEZN6EkIIISRt4UKHEEIIIWlLu8he7tbWnF5d5cT1XKUNKioyu6o1t3CydWl369UtN0azlBkyWyQ9KioBlbYbVVV6VZaKGktlXqioLVPNrTjVsety7ERFoS/XK7WNigrTrXferprZiFvqMav4ATTNng1t/XqIsjKIX/0Kmbr4TWa/McmwfWtpk18IHJC0PdF9LXjRn17KnHax0CGEEEJSiZsB+BYsgCYERE0N2tOfBrPQfttuBy50CCGEEEXKAWhHfXk0IaCtX5/cBilQLgS0o/9vb223A210CCGEEEXWARBHvfCEpkGUlSW3QQqs07R223Y7tDv3cquh6uPhhQ7QzA5C5g5pV++pcp8Tl722QGU8ncSFkaHismrXXkwFmQuyEa/akMj+SQiBcDjcId3L/X5/1L1cP99U3kejvNCXo+JeLrNzSUX7KrfaZ9e93OydstMmP46or8pxZNFTBUCfJMRsXljtE1l4E0BtLrb0n18I/Ly5OabtwuL8MmtvW9DSnpaUNGbyiKorQgghRJEwgFuT3QibhDWtVdvTWb2Tzs9GCCGEkA5Ou9vRUdnGV3GvtYtZmW65J7txnxO82Po1u8+sTLeiFrs1L+xGVTa7z4uM5EZkKs5kb1OnComyl6v0j5O5lgwVplW8msNG7PZfMsInOJFfetw0N9D3n5MQKzJUzCXsqjRVx487OoQQQghJW7jQIYQQQkjawoUOIYQQQtKWdmGjY9etsi2y28rClwNqmbJloc9VdJlWy7FSltVyVHDLTbYtbBZk/WWWkVyW0kOWpd2ttquUY3Wetrhzkm+Quf+6lcLAeF5WrpOQEnblg5s2L16kwjFrn6xOr7KDy8rV25eqpBiRheAwluVVpnNje632rRE3QyhwR4cQQgghaQsXOoQQQghJW7jQIYQQQkjakrI2OpqmRcOtW41HYqa3cyt8uL5OYzlOYgF4EXdFRe/vJC6NLB1Dly5dYr7v3bs3YT0q4fNlYyhrr0o5Mt250SbHiFX7AmP9XtnsqKBvQ7JjtKQibtnL5OXlRf/f2NiYsA6zclXGSGYzYXw39OdVbAqNqMhp2XujL0fWVjOM/Se7VyUtjbFNemQpgIzluGWDZTf+jdlvk1u/pbI63IQ7OoQQQghJW7jQIYQQQkjakrKqK6turCquk3bdzb1y5bTbBpkqDYjdAmwrV2VZBl3jlrwM/b3G51QZP69cz70IWWAWkkBlu94t1/1Uy3KfargVvl/2bqjMYRWXbNl54zmZStqtkP0qLsb672YhL2TqfrvqFrPxVClXJtPdUkfZDTFhZvKg8pwy9acKdC8nhBBCCIkDFzqEEEIISVu40CGEEEJI2pKyNjp6rLqy6fXUgHU3RcCZa3VbY6Yntuv6Z0Smm5alP3CSikN/r8p9TkKUu1Wu7FonodhV+qQt0mJ0VPQhL/TI+lXF9kLFfkHmXm42Z1XsefTtNcpX/VxUSUtj5rosc7mX3Wc3XAdgPY2HSloHI3btOc3mhUzOGLFap5l9pIrdkgyVMXJSj/KOzmeffYYf//jH6NatG3JycnDyySdj06ZN0fNCCMyZMwc9e/ZETk4OKioqsH37dtsNJISQRFAeEULMUFro7N27F2VlZcjMzMTzzz+PrVu34o477ogJCHf77bfj7rvvxtKlS7Fx40bk5eVhzJgxriVnI4QQgPKIEGIRocBNN90kysvLE56PRCKiqKhILFmyJHqsvr5eBAIB8ac//clSHaFQSACw9cnKyor52C0HgMjIyIh+fD5fzEd/nexcsj4q7WlPbVfpa/34ZWRktEnbk1GnG/1s1tfx7g+FQiqiwxPaQh4J8Y1M0jQtZd4V2VxLdZmk0j63ZLpZnW3x3sr6QKVPnFzrxbxw8iwqH9kYmckjpR2dv/3tbxg6dCgmTZqEHj164NRTT8VDDz0UPb9jxw7U1taioqIieiwYDGL48OHYsGGDSlWEECKF8ogQYgWlhc7HH3+M+++/H/369cOqVatw7bXX4vrrr8djjz0GAKitrQUAFBYWxtxXWFgYPWekqakJDQ0NMR9CCDHDC3kEUCYRkm4oeV1FIhEMHToUVVVVAIBTTz0V7777LpYuXYrJkyfbakB1dTXmz59v615CSMfFC3kEUCYRkm4oLXR69uyJQYMGxRwbOHAg/vrXvwIAioqKAAB1dXXo2bNn9Jq6ujoMHjw4bpmzZs3CzJkzo98bGhrQp08flWZFMXO9VQk1rkfFNVh2rRNXU6/c32Vun3ZdCFUy/BqvdctIVBYeXvacZn2nb7uxrcY63XLz12M2h1Rch9s7XsgjILFMysjIiLqX68ezrd5V2djKZJveXRtQS8kiQ2V+q7hA63HLrdmrlCfGlCyyFBV2U7IY63ASdkPWHruYleOWK7qelucSFlNFKamuysrKsG3btphjH3zwAfr27QsAKCkpQVFREWpqaqLnGxoasHHjRpSWlsYtMxAIID8/P+ZDCCFmeCGPAMokQtINpR2dGTNmYMSIEaiqqsLFF1+M119/HQ8++CAefPBBAEcCak2fPh0LFy5Ev379UFJSgtmzZ6NXr14YP368F+0nhHRQKI8IIVZQWuicdtppePrppzFr1iwsWLAAJSUluOuuu3DZZZdFr/nlL3+JxsZGTJkyBfX19SgvL8cLL7zQKqomIYQ4gfKIEGIFTVhRcLUhDQ0NCAaDCc/LdNxOdJkqqOgcrYYWV7lWJSR4W9kE2LULkp1zS5/rBFmo/VRPqWA35LwR/Zi06MRDoVCHUemYySQZRplkRPZeu2XD55VtoApu2avJ7FpkKYBUUjd49V6rjIOK3aAKdstSsfWxKt8BuQ2rDGPfmckjJvUkhBBCSNrChQ4hhBBC0pZ2kb1cj1vbeDKVhFf1qGQKlmXXdeJWqbIFKdtidrLFnewM28a2y9RlqaA+s4tbbU91FV1boc9eLlMP67+rqGnM3lWr4+BEZemVO7IbalOzNsjkq0oYECN6tZuTjOkqfZAM9aIMlTpkmc9lc9xLWcsdHUIIIYSkLVzoEEIIISRtSTnVlRMnMJV7jdc6udeta2X3ueUc51bbU8xZTwmv+rYj0ZH6rOVZEz1zMt5Vr97NVJA7XtTvpFz9takgO1L93WuL30fVclJuobNv3z7b9zY3N1u+NhwO265H5d6mpiZbdRgHzkl7ZeXavdat9iQDr/q2I7Fv3z7bLtftDb1MivdOJONd9erd9OpdSLWFjspzqvyutAWpvtBR6S+3nsVMHqVcHJ1IJILdu3dDCIHi4mLs2rWrw8TrUKEl/w77JzHsIzl2+kcIgX379qFXr16m8ZzShUgkgm3btmHQoEGcSxL4vslh/8jxUh6l3I6Oz+dD79690dDQAADMNWMC+8cc9pEc1f7pKDs5Lfh8Phx77LEAOJeswD6Sw/6R44U86hh/khFCCCGkQ8KFDiGEEELSlpRd6AQCAcydOxeBQCDZTUlJ2D/msI/ksH+sw74yh30kh/0jx8v+STljZEIIIYQQt0jZHR1CCCGEEKdwoUMIIYSQtIULHUIIIYSkLVzoEEIIISRtSdmFzr333ovjjjsO2dnZGD58OF5//fVkNykpVFdX47TTTkPnzp3Ro0cPjB8/Htu2bYu55uDBg6isrES3bt3QqVMnTJw4EXV1dUlqcXJZtGgRNE3D9OnTo8c6ev989tln+PGPf4xu3bohJycHJ598MjZt2hQ9L4TAnDlz0LNnT+Tk5KCiogLbt29PYotTD8qjI1AeqUF51JqkyCORgixfvlxkZWWJ3//+9+K9994TV199tSgoKBB1dXXJblqbM2bMGLFs2TLx7rvvii1btojzzz9fFBcXi6+//jp6zTXXXCP69OkjampqxKZNm8Tpp58uRowYkcRWJ4fXX39dHHfcceKUU04RN9xwQ/R4R+6f//73v6Jv377iiiuuEBs3bhQff/yxWLVqlfjwww+j1yxatEgEg0HxzDPPiH/961/iwgsvFCUlJeLAgQNJbHnqQHn0DZRH1qE8ak2y5FFKLnSGDRsmKisro9/D4bDo1auXqK6uTmKrUoM9e/YIAGLt2rVCCCHq6+tFZmamWLFiRfSaf//73wKA2LBhQ7Ka2ebs27dP9OvXT7z44oti5MiRUcHS0fvnpptuEuXl5QnPRyIRUVRUJJYsWRI9Vl9fLwKBgPjTn/7UFk1MeSiPEkN5FB/Ko/gkSx6lnOrq0KFD2Lx5MyoqKqLHfD4fKioqsGHDhiS2LDUIhUIAgK5duwIANm/ejObm5pj+GjBgAIqLiztUf1VWVmLcuHEx/QCwf/72t79h6NChmDRpEnr06IFTTz0VDz30UPT8jh07UFtbG9M/wWAQw4cP7xD9YwblkRzKo/hQHsUnWfIo5RY6X375JcLhMAoLC2OOFxYWora2NkmtSg0ikQimT5+OsrIynHTSSQCA2tpaZGVloaCgIObajtRfy5cvx5tvvonq6upW5zp6/3z88ce4//770a9fP6xatQrXXnstrr/+ejz22GMAEO0Dvm/xoTxKDOVRfCiPEpMseZRy2ctJYiorK/Huu+9i3bp1yW5KyrBr1y7ccMMNePHFF5GdnZ3s5qQckUgEQ4cORVVVFQDg1FNPxbvvvoulS5di8uTJSW4dac9QHrWG8khOsuRRyu3oHHPMMfD7/a2s0Ovq6lBUVJSkViWfqVOn4rnnnsOaNWvQu3fv6PGioiIcOnQI9fX1Mdd3lP7avHkz9uzZg+9+97vIyMhARkYG1q5di7vvvhsZGRkoLCzs0P3Ts2dPDBo0KObYwIEDsXPnTgCI9gHft/hQHsWH8ig+lEdykiWPUm6hk5WVhSFDhqCmpiZ6LBKJoKamBqWlpUlsWXIQQmDq1Kl4+umnsXr1apSUlMScHzJkCDIzM2P6a9u2bdi5c2eH6K/Ro0fjnXfewZYtW6KfoUOH4rLLLov+vyP3T1lZWSv33w8++AB9+/YFAJSUlKCoqCimfxoaGrBx48YO0T9mUB7FQnkkh/JITtLkkW0zZg9Zvny5CAQC4tFHHxVbt24VU6ZMEQUFBaK2tjbZTWtzrr32WhEMBsXLL78sPv/88+hn//790WuuueYaUVxcLFavXi02bdokSktLRWlpaRJbnVz0Xg5CdOz+ef3110VGRoa47bbbxPbt28UTTzwhcnNzxeOPPx69ZtGiRaKgoEA8++yz4u233xbf//736V6ug/LoGyiP1KE8+oZkyaOUXOgIIcTvfvc7UVxcLLKyssSwYcPEa6+9luwmJQUAcT/Lli2LXnPgwAFx3XXXiS5duojc3Fxx0UUXic8//zx5jU4yRsHS0ftn5cqV4qSTThKBQEAMGDBAPPjggzHnI5GImD17tigsLBSBQECMHj1abNu2LUmtTU0oj45AeaQO5VEsyZBHmhBC2N8PIoQQQghJXVLORocQQgghxC240CGEEEJI2sKFDiGEEELSFi50CCGEEJK2cKFDCCGEkLSFCx1CCCGEpC1c6BBCCCEkbeFChxBCCCFpCxc6hBBCCElbuNAhhBBCSNrChQ4hhBBC0hYudAghhBCStvx/Cz1VhoTxuRoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_transposed_images_with_midpoints(train_dataset, image_indices=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set up learning rate scheduler\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.9, patience=10, verbose=1, mode='min', min_lr=3e-5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">819,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,338</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m1,179,904\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m819,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │        \u001b[38;5;34m13,338\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m2\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,059,162</span> (34.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,059,162\u001b[0m (34.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,057,882</span> (34.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,057,882\u001b[0m (34.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> (5.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,280\u001b[0m (5.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "dynamic_exponent_callback = DynamicExponentCallback(2, 1, 400)\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    # Instantiate the model builder\n",
    "    model_builder = ModelBuilder(weights_path= \"/home/da886/Weights from Josh's model/Josh's5fixedMSE45overfit-1.keras\")\n",
    "    # model_builder = ModelBuilder()\n",
    "\n",
    "    # Build the model\n",
    "    model_builder.build_model()\n",
    "\n",
    "    # Display the model architecture\n",
    "    model_builder.model.summary()\n",
    "\n",
    "    # Compile the model using the custom loss function\n",
    "    model_builder.compile_model(loss_function=dynamic_exponent_callback.custom_loss(2))\n",
    "    # model_builder.compile_model(loss_function=tf.keras.losses.MeanSquaredError()) \n",
    "    \n",
    "    # model_builder.compile_model(loss_function=custom_loss(3))e\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 15:39:10.742979: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-09 15:39:10.751902: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-09 15:39:10.779763: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1728488350.859074 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.862443 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.862592 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.928220 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.928220 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.928570 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.929010 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.929008 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.929334 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.935217 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.935224 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.935934 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.954257 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.954257 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.954690 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.956637 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.956872 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.957358 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.957978 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.957971 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.958535 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.959204 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.959211 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.959751 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.962407 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.962423 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.963093 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.981022 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.981152 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.982767 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.982799 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.983125 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.984208 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.984374 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.984703 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.985968 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.986283 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.986482 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.987467 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.987832 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.988167 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.989288 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.989820 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.989992 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.991708 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.992529 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.992521 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.994100 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.994861 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.994855 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.995586 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.998397 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.998488 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488350.998811 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.002701 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.002785 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.003046 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.008155 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.008359 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.008592 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.010883 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.010899 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.011286 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.012941 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.019527 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.019552 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.019559 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.023104 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.023204 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.023297 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.116791 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.117752 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.118667 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.119552 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.120552 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.121892 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.123568 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.125213 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.126860 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.128655 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.131611 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.134586 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.153242 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.153891 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.154596 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.155334 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.156120 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.156878 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.157674 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.158524 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.160201 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.161178 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.162151 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.163809 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.170913 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.172020 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.172998 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.176913 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.178908 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.181024 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.182952 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.185160 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.187564 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.198311 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.199351 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.200470 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.201490 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.202473 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.203991 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.207006 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.210033 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.213015 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.215949 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.218896 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.222113 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.258956 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.259766 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.260661 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.261706 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.262803 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.263966 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.265168 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.266345 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.267766 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.269114 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.270599 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.274470 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.279633 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.281411 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.283023 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.285035 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.286981 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.288713 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.292165 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.296355 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.308432 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.309917 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.311643 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.313120 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.314536 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.316901 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.322710 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.328445 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.334284 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.339941 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.345600 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.351810 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.395616 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.396571 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.397458 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.398349 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.399364 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.400728 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.402410 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.404070 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.404099 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.405073 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.405740 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.405982 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.406868 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.407528 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.407898 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.409265 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.410530 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.410962 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.412621 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.413535 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.414292 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.416050 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.419034 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.422033 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.424906 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.426177 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.427549 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.429119 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.430753 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.432624 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.432626 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.433300 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.434016 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.434373 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.434778 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.435565 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.436139 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.436348 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.437134 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.438001 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.438413 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.439005 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.439963 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.440553 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.440843 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.440996 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.441516 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.442104 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.442337 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.442727 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.443099 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.443883 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.444467 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.444664 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.445523 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.445642 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.446412 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.446838 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.447588 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.448556 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.449214 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.449542 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.450497 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.450982 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.451938 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.453240 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.453961 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.455136 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.455240 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.456141 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.457515 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.457683 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.459437 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.459973 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.460401 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.460732 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.462049 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.463146 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.463445 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.465368 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.466095 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.467594 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.469475 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.470027 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.470999 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.472058 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.472586 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.473205 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.474379 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.475374 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.476903 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.479101 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.479972 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.481230 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.482297 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.483044 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.483439 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.484450 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.485450 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.486073 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.486993 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.489060 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.490050 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.492050 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.493179 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.495320 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.496198 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.497037 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.499160 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.499508 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.501519 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.502147 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.503984 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.505388 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.506960 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.509403 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.511755 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.514473 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.517863 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.520276 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.522969 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.532513 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.533336 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.534482 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.534504 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.535560 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.536657 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.537831 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.539042 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.540228 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.541656 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.542334 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.543067 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.543250 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.544154 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.544586 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.545234 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.545857 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.546352 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.547508 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.548495 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.548711 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.549897 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.551324 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.552687 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.553718 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.554183 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.555519 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.557183 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.557365 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.558060 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.559218 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.561170 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.562907 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.563267 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.565051 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.566365 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.566683 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.568584 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.568754 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.570708 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.570825 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.572576 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.574969 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.578478 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.579686 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.582699 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.582746 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.584195 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.585917 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.587394 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.588821 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.591205 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.591793 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.594885 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.596383 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.597033 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.598141 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.599636 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.601075 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.602781 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.603551 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.603731 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.608626 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.609492 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.614280 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.615346 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.619948 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.621298 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.626157 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.627075 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.632856 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.639143 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.699786 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.701064 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.702450 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.704009 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.705655 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.707341 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.709087 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.710847 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.712945 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.713315 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.714600 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.715088 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.716008 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.717270 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.717589 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.719241 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.720907 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.722657 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.723806 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.724432 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.726518 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.728646 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.730797 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.732199 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.734917 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.737341 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.737660 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.740603 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.743980 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.745836 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.747031 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.748581 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.749446 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.751344 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.751778 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.753653 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.754425 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.754540 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.757210 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.757921 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.760251 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.761090 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.763158 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.764896 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.766494 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.769275 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.771609 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.771616 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.772335 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.774101 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.776131 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.776800 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.778602 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.780624 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.781640 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.784094 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.784565 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.786479 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.788490 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.789218 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.789722 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.792094 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.792281 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.794381 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.794559 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.795722 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.796889 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.797312 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.799911 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.800786 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.802384 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.804765 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.806405 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.807522 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.808847 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.810381 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.811506 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.812830 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.815641 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.815809 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.820244 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.827388 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.831055 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.831856 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.837445 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.838911 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.843222 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.843585 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.850711 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.854596 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.856419 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.862008 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.866806 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.868525 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.873301 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.878877 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.885474 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.894915 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.897470 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.898975 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.902568 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.906662 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.910699 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.915967 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.920015 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.924782 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.929544 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.933642 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.938437 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.961790 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488351.984967 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.007668 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.025100 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.027445 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.029564 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.030129 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.032801 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.035816 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.038668 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.042014 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.042868 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.044826 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.045220 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.048041 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.048115 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.050753 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.051449 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.051774 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.053767 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.055517 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.056611 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.059420 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.059985 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.062802 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.063380 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.065896 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.069545 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.070672 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.073289 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.075402 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.075793 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.077171 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.081148 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.081435 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.086479 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.088470 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.090701 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.093610 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.098478 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.099348 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.104451 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.105953 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.108723 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.112348 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.118316 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.124156 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.130624 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.131247 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.136681 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.143664 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.143837 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.156932 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.169166 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.170203 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.174294 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.177912 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.182021 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.186053 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.191238 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.195169 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.195596 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.199763 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.199870 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.203399 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.204682 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.207533 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.208867 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.211572 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.213708 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.216728 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.220767 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.225564 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.230369 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.234503 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.237401 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.239310 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.260846 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.263134 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.283684 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.286586 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.305745 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.309401 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.327620 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.331294 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.351591 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.353116 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.374767 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.376851 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.387135 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.391213 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.395649 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.400072 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.400082 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.404988 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.409791 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.414877 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.419671 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.425176 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.430863 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.437551 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.444373 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.451576 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.462551 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.471710 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.481324 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.490765 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.498200 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.525064 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.536925 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.548437 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.577667 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.585172 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.592732 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.599267 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.609441 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.617132 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.626386 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.634366 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.642214 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.651411 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.660895 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.665366 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.669462 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.673915 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.678235 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.683125 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.688123 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.689619 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.693792 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.693974 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.698622 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.698975 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.703137 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.704579 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.707827 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.708205 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.710385 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.713084 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.717075 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.718251 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.723111 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.723865 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.728676 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.731038 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.734366 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.741060 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.741947 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.747949 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.751038 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.752038 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.755317 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.760554 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.766511 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.770134 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.775792 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.777579 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.785494 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.795120 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.795212 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.802785 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.804638 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.816520 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.827929 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.830027 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.839388 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.842015 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.853793 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.857256 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.864756 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.866764 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.872470 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.879263 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.883207 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.889434 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.896294 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.897191 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.903937 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.906465 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.911702 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.914508 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.918551 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.922385 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.928248 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.928860 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.931569 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.936660 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.941124 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.945978 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.954058 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.961958 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.971205 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.974867 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.980704 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488352.987816 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.028648 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.032183 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.072811 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.075407 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.116962 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.119982 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.159845 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.164045 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.203882 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.209562 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.249403 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.256631 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.296371 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.550171 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.558137 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.565524 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.573960 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.584080 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.593528 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.603418 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.614110 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.623656 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.634073 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.646828 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.659845 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.673518 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.687863 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.705768 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.724260 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.741823 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.764879 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.788060 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.831237 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.835454 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.843444 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.850851 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.859306 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.869528 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.872611 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.879005 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.880659 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.892120 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.892136 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.900452 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.902892 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.910017 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.912486 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.918896 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.922967 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.928658 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.935726 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.939364 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.948783 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.949100 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.959730 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.962556 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.972969 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.976878 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.986347 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488353.994591 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.000414 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.013102 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.015074 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.030831 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.033351 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.052195 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.054050 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.070176 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.077474 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.093467 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.118891 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.120749 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.142528 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.163930 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.167590 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.170933 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.182113 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.185771 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.186147 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.189265 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.193956 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.198155 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.201724 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.205830 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.209855 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.232463 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.255277 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.278072 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.300526 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.322465 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.345733 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.369777 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.449586 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.453277 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.456631 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.460316 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.466387 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.469888 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.474606 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.478828 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.482421 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.486687 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.490894 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.514065 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.517458 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.521176 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.524585 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.528223 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.531945 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.536675 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.536908 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.540210 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.544423 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.548204 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.552560 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.556820 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.559964 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.580675 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.582628 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.604089 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.604606 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.627326 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.627927 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.650177 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.651936 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.672361 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.687067 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.691042 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.694806 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.695655 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.698772 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.703041 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.707399 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.711735 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.716331 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.719606 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.720837 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.725748 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.731780 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.737837 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.744526 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.751537 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.760086 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.768828 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.778362 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.789761 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.801341 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.822794 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.851639 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.852799 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.853972 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.855508 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.856706 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.857864 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.859153 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.860628 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.861990 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.863203 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.864468 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.870589 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.876687 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.882939 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.889269 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.895542 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.902225 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.908689 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.970937 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.974921 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.978702 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.982663 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.986911 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.990540 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.991230 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.991783 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.992975 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.994211 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.995590 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.995717 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.996833 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.998182 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488354.999527 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.000433 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.000786 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.002099 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.003652 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.005162 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.005271 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.007076 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.009130 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.010138 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.011261 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.013170 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.015791 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.016301 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.021619 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.022431 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.024447 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.029209 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.030052 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.036234 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.036362 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.040265 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.044102 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.044982 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.048129 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.052451 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.053643 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.056719 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.057189 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.057637 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.058135 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.058520 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.059632 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.060849 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.061041 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.062068 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.063220 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.063316 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.064662 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.065557 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.067041 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.068671 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.070109 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.074585 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.075193 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.080101 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.080523 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.080976 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.081357 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.081528 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.081957 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.082424 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.082832 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.083226 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.083622 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.084130 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.084611 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.085109 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.085505 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.085900 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.086243 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.086567 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.087054 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.087602 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.087710 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.089603 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.091068 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.092343 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.094478 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.095436 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.101726 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.107790 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.110467 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.111820 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.112150 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.112437 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.113198 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.113938 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.114883 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.116327 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.117338 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.118383 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.119193 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.120389 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.121883 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.122156 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.122454 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.122745 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.123041 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.123355 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.123678 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.124010 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.124315 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.124632 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.124967 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.125360 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.125759 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.126078 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.126500 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.126907 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.127373 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.128852 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.130450 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.130981 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.131557 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.132664 3196740 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.136283 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.137458 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.138642 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.140231 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.140431 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.141442 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.142603 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.143903 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.145388 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.146771 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.147992 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.149888 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.152763 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.156034 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.162154 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.164584 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.168438 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.174774 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.181065 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.186239 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.187770 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.194253 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.214728 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.216031 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.217371 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.219091 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.220466 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.221788 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.223273 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.224941 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.226471 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.227872 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.229352 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.235570 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.241726 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.248072 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.254479 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.260789 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.267518 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.274038 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.276290 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.277537 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.278735 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.279977 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.281232 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.282464 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.283810 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.285160 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.286414 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.287732 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.289293 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.290852 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.292658 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.294749 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.296894 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.298805 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.301516 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.307397 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.310210 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.315800 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.343325 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.343769 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.344274 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.344662 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.345793 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.346990 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.348206 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.349386 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.350749 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.352265 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.353901 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.356402 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.357658 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.358871 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.360114 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.361372 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.362612 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.363978 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.365422 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.365446 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.365877 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.366329 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.366829 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.366906 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.367338 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.367810 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.368292 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.368368 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.368771 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.369175 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.369723 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.369903 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.370222 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.370719 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.371123 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.371600 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.371676 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.372328 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.372831 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.373557 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.373636 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.375693 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.375777 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.377176 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.377956 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.378478 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.379908 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.381598 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.382571 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.388464 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.391310 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.397004 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.398099 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.398440 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.398733 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.399487 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.400139 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.400280 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.401235 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.402690 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.403702 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.404752 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.406747 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.408240 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.408525 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.408829 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.409123 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.409427 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.409747 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.410081 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.410417 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.410723 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.411039 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.411376 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.411777 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.412176 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.412495 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.412922 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.413331 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.413802 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.416874 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.417410 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.417996 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.419110 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.427620 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.428068 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.428571 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.428977 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.430120 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.431331 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.432566 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.433769 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.435145 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.436659 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.438291 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.449794 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.450219 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.450663 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.451082 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.451506 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.451976 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.452384 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.452781 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.453178 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.453683 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.454162 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.454652 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.455055 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.455451 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.456097 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.456596 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.457189 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.459148 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.460616 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.461916 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.465009 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.481399 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.481724 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.482012 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.482770 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.483520 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.484458 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.485918 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.486933 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.487986 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.489981 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.491489 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.491772 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.492074 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.492358 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.492657 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.492966 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.493302 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.493633 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.493932 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.494248 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.494574 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.494974 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.495379 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.495697 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.496123 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.496529 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.497006 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.500099 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.500627 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.501217 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.502340 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.683097 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.685294 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.685375 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.686652 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.687737 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.687755 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.688147 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.688163 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.691979 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.692000 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.692553 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.692570 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.692972 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.693059 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.693428 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.693686 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.693910 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.694267 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.694493 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.694698 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.694940 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.695190 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.695362 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.695746 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.695850 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.696260 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.696416 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.696705 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.697018 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.697393 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.697698 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.698064 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.698058 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.698708 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.698815 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.699057 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.699986 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.700102 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.700231 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.700749 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.701427 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.701527 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.701806 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.702161 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.702678 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.702762 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.702831 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.703062 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.703431 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.703793 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.704327 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.704705 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.705090 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.705532 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.705978 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.706682 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.707298 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.707986 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.708638 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.712717 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.728041 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.728257 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.728282 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.728463 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.728781 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.728995 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.729103 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.729410 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.729602 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.729687 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.729928 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.730054 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.732933 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.732963 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.733098 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.733393 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.733453 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.733720 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.733949 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.734066 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.734529 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.734537 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.734612 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.735134 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.735153 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.735155 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.735495 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.738297 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.738327 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.738447 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.741025 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.741109 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.741143 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.741584 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.741674 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.741775 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.742065 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.742259 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.742372 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.744191 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.744217 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.744376 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.746409 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.746440 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.746556 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.747045 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.747200 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.747324 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.747542 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.747777 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.747890 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.757154 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.757293 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.757379 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.761302 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.761381 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.761445 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.764683 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.764828 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.764982 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.789560 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.789572 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.789643 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.795889 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.795897 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.796004 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.796566 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.796572 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.796719 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.797286 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.797338 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.797423 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.797986 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.797997 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.798115 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.798668 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.798685 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.799173 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.799815 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.799899 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.799909 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.800473 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.800484 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.800599 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.801132 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.801147 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.801260 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.801798 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.801806 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.801914 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.802435 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.802450 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.802553 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.803064 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.803149 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.803162 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.803712 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.803727 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.803830 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.804351 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.804366 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.804467 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.805120 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.805132 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.805250 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.805846 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.805861 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.805964 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.806567 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.806582 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.806682 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.807325 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.807332 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.807434 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.808015 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.808030 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.808132 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.808720 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.808729 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.808831 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.811176 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.811192 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.811214 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.813814 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.813833 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.813856 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.814642 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.814660 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.814682 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.815505 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.815522 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.815551 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.816361 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.816382 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.816396 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.817238 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.817260 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.817273 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.820645 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.820723 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.820737 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.823120 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.823236 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.823250 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.827832 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.827842 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.827856 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.828862 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.828898 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.828970 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.831050 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.831160 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.831239 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.832039 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.832166 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.832235 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.833130 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.833197 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.833255 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.833898 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.833976 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.833991 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.834558 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.834636 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.834651 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.836786 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.836783 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.836800 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.839293 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.839376 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.839757 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.839907 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.839925 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.840532 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.840552 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.840586 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.840902 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.854696 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.855158 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.855823 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.856285 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.856940 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.857710 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.858049 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.858125 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.858618 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.858842 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.858855 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.859070 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.859385 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.859465 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.859585 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.860163 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.860246 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.860261 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.860923 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.861001 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.861017 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.861694 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.861773 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.861789 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.862488 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.862568 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.862583 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.863282 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.863367 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.863383 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.864086 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.864162 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.864177 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.864873 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.864958 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.864972 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.865629 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.865710 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.865725 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.866404 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.866482 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.866497 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.867228 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.867304 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.867320 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.869714 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.869930 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.869945 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.870204 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.870666 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.870691 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.870813 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.871424 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.871450 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.871568 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.872316 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.872329 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.872351 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.873158 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.873194 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.873270 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.874069 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.874112 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.874177 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.874875 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.874892 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.875432 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.876350 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.876365 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.876666 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.877835 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.877853 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.877968 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.879335 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.879371 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.879436 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.880730 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.880746 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.889147 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.889570 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.890022 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.890575 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.890695 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.890722 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.891126 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.891294 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.891320 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.891630 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.892017 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.892101 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.892209 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.892642 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.892866 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.892895 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.893095 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.893570 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.893628 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.893727 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.894341 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.894382 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.894457 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.895148 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.895166 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.895236 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.895919 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.896006 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.896017 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.896482 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.896716 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.896823 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.897144 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.897295 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.897410 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.897774 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.897969 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.898103 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.898274 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.898511 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.898735 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.898956 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.899068 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.899405 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.899640 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.899737 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.900252 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.900365 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.900910 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.901012 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.901261 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.901511 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.902838 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.903360 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.904847 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.906400 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.906963 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.907811 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.909348 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.909937 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.923077 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.923550 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.923966 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.924400 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.924704 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.924859 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.925234 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.925415 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.925426 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.925664 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.926184 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.926316 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.926334 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.926776 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.926945 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.926964 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.927284 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.927676 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.927748 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.927857 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.928543 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.928615 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.928631 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.929407 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.929425 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.929460 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.930137 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.930173 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.930248 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.930886 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.930977 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.930987 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.931704 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.931785 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.931797 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.932522 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.932532 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.932642 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.933384 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.933386 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.933487 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.934140 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.934180 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.934254 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.934999 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.935088 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.935100 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.935769 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.935782 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.936064 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.936513 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.936552 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.936662 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.937301 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.937343 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.937408 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.937847 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.938047 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.938286 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.939104 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.939181 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.939195 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.939907 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.939920 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.940707 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.940720 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.941641 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.941713 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.941726 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.942409 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.943854 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.943970 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.944613 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.946110 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.946769 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.947026 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.949285 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.949982 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.950153 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.952420 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.953136 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.953293 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.955548 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.956280 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.956464 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.958671 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.959386 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.971674 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.972238 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.972680 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.973173 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.973733 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.973913 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.974164 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.974520 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.974916 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.975005 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.975096 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.975339 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.975827 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.975845 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.975965 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.976555 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.976647 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.976752 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.977321 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.977415 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.977516 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.978087 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.978179 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.978755 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.978767 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.979658 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.979665 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.979685 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.980202 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.980429 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.980531 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.980748 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.981042 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.981432 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.982032 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.982416 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.983053 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.983304 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.983666 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.983957 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.986206 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.986761 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.987107 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.989331 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.990219 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.996942 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.998142 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.999271 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488355.999403 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.000164 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.000483 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.000675 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.001383 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.001676 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.001861 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.002520 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.003138 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.003152 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.003677 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.004429 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.004530 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.004827 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.005793 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.005890 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.006122 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.007028 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.007244 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.007416 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.008326 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.008562 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.008734 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.009557 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.009894 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.010066 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.010801 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.011063 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.011321 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.012089 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.012362 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.012615 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.013257 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.013882 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.013899 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.014546 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.015314 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.015392 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.015959 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.016741 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.016999 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.017329 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.018120 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.018885 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.018989 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.019735 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.020906 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.020929 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.021578 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.022826 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.023498 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.027396 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.028836 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.029576 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.033459 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.034846 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.035647 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.039527 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.041312 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.042182 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.051733 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.053478 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.054459 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.074407 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.076096 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.077273 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.149209 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.150173 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.150381 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.151334 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.151696 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.152123 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.152650 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.152922 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.153298 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.153870 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.154122 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.154619 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.155072 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.155354 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.155843 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.156290 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.156645 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.157042 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.157583 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.157931 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.158274 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.158853 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.159202 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.159568 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.160125 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.160618 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.160854 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.161531 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.162172 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.162250 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.162945 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.163702 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.163879 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.164543 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.165123 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.165458 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.166121 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.166734 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.167193 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.167835 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.168333 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.168883 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.169519 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.170072 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.170696 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.171322 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.171768 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.172855 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.173735 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.173748 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.175224 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.176060 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.176154 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.178483 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.181361 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.182215 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.184664 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.187009 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.187763 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.190339 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.193904 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.194540 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.197544 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.218729 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.219004 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.220156 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.220417 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.221550 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.221775 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.222391 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.223102 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.223217 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.223822 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.224640 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.224658 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.225201 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.226198 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.226301 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.226606 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.227665 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.227886 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.228055 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.229053 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.229325 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.229500 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.230537 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.230874 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.231040 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.232031 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.232525 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.232606 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.233453 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.234015 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.234190 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.234928 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.235572 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.235739 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.236747 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.237188 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.237440 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.238150 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.238735 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.238915 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.239915 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.240622 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.240797 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.241639 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.242052 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.242566 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.243443 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.243863 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.244386 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.245153 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.245611 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.246114 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.247123 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.247438 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.248097 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.248920 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.249170 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.249925 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.251166 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.252494 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.253002 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.253489 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.254349 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.255468 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.256300 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.256615 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.257341 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.258492 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.260453 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.263138 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.264287 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.267355 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.269983 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.271243 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.274265 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.278735 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.280159 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.283133 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.287483 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.289006 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.292013 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.296245 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.297912 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.300886 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.305003 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.307005 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.309697 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.424823 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.426004 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.427262 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.427560 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.428647 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.428816 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.430128 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.430228 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.430728 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.431581 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.432082 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.432097 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.432936 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.433382 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.433988 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.434792 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.434872 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.435971 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.436240 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.436710 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.438074 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.438180 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.438702 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.440006 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.440469 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.440885 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.442012 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.443232 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.443330 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.444208 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.445029 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.445971 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.446509 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.447759 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.449160 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.450943 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.452046 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.454812 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.458344 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.463494 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.466323 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.466992 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.469851 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.469933 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.470448 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.473495 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.473571 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.473890 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.477091 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.477182 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.477520 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.480796 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.480873 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.481187 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.484498 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.484873 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.484882 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.488171 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.488597 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.488704 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.491759 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.492667 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.492677 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.495493 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.496244 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.496590 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.499323 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.500285 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.500466 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.503127 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.504178 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.504531 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.507349 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.508297 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.508665 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.511097 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.512865 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.513578 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.515634 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.517852 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.518802 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.520600 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.523187 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.523852 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.526009 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.528261 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.529815 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.531105 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.534267 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.536726 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.537124 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.541285 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.544132 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.558289 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.563028 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.565950 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.581325 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.586186 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.589091 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.603791 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.608872 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.611788 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.629053 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.634331 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.637234 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.652657 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.657892 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.660977 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.677096 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.682306 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.685399 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.972564 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.976161 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.977782 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.979895 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.981401 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.983833 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.983897 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.985171 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.987534 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.987793 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.988911 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.991305 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.991656 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.992896 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.995068 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.995902 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.996778 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488356.999051 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.000022 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.001058 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.002953 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.004561 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.005193 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.007392 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.009548 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.009831 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.011748 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.014663 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.014952 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.016238 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.019862 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.020226 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.021168 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.025605 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.025832 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.026367 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.031797 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.031823 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.032356 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.037895 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.038497 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.038869 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.044578 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.045246 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.045429 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.051184 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.051887 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.053925 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.057734 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.060515 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.063079 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.066289 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.069913 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.074445 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.075557 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.081503 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.087152 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.097706 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.105361 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.110618 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.129116 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.133764 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.136929 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.138374 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.141554 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.142011 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.142961 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.146151 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.146669 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.147427 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.150720 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.151286 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.151852 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.155135 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.155874 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.156784 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.159495 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.160264 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.161359 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.164386 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.164615 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.166597 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.168941 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.169652 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.171836 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.174334 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.174517 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.177193 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.179693 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.179875 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.182122 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.185226 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.185308 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.188459 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.190216 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.190636 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.194774 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.195567 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.196623 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.199601 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.201857 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.203031 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.205936 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.207934 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.208149 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.212954 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.213070 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.214235 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.219304 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.220569 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.221067 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.226072 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.226954 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.228610 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.233563 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.234866 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.239926 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.244651 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.249879 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.251207 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.255249 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.256469 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.258357 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.261901 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.263635 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.265080 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.269145 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.270483 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.275974 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.292411 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.296617 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.303682 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.319717 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.322685 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.331153 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.347116 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.349887 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.358542 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.373244 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.377152 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.384562 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.399414 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.404667 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.410596 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.426839 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.432263 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.437872 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.898829 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.902527 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.906762 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.907080 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.910770 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.911166 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.913009 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.914982 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.915726 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.916749 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.919377 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.920999 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.921665 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.923897 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.925419 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.928186 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.929828 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.930799 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.935479 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.936510 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.936995 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.943569 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.943852 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.944061 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.951276 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.952414 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.952518 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.959410 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.961425 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.962599 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.968184 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.969236 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.971860 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.978468 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.978658 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.985176 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488357.998404 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.008300 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.014433 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.032522 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.040517 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.040862 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.046967 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.047812 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.047992 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.054174 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.055021 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.055371 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.061298 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.062489 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.063283 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.068742 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.070590 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.070795 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.076614 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.078130 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.078556 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.084355 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.086061 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.086921 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.092275 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.094539 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.094765 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.100728 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.102553 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.103459 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.108636 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.111081 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.111398 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.117422 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.118841 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.119189 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.125132 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.127041 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.129261 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.132958 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.137533 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.139537 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.143380 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.147921 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.148865 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.153709 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.157364 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.159541 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.163107 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.168036 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.171241 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.173785 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.179672 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.185573 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.185680 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.193824 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.199977 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.228202 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.236221 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.242613 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.271986 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.280851 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.286712 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.315408 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.324724 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.330586 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.366242 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.373680 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.380990 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.415470 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.424592 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.429763 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.463344 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.473773 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488358.476956 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.051920 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.059238 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.066632 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.068194 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.070725 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.074212 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.075564 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.078110 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.082390 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.083013 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.085662 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.091066 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.091070 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.093496 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.099478 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.100189 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.101686 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.107922 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.109474 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.110396 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.117404 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.119021 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.119792 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.126855 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.129580 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.129594 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.136609 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.139436 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.140326 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.147207 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.150128 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.151007 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.158130 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.161245 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.163488 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.168986 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.172235 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.177178 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.181489 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.184934 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.190288 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.195149 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.198655 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.203601 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.208576 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.211989 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.220584 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.222099 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.225443 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.238937 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.239301 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.242602 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.257711 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.261025 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.261209 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.279997 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.283306 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.306558 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.325420 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.328995 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.367482 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.378957 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.386476 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.388411 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.390208 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.398149 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.398161 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.401784 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.407454 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.407931 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.411187 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.416981 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.417448 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.420770 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.426889 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.426909 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.430536 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.436623 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.436643 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.440055 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.446003 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.446805 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.449409 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.455557 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.457490 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.458950 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.465750 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.467233 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.469099 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.476487 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.477790 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.479801 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.486557 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.486569 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.489581 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.497262 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.497364 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.500096 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.506110 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.507263 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.508742 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.516097 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.516787 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.521985 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.526664 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.526911 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.531944 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.535818 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.538987 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.540707 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.546387 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.551210 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.552408 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.558491 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.563512 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.566631 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.571796 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.576918 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.580070 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.586163 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.591280 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.593537 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.599709 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.604841 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.610701 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.612944 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.618233 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.627726 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.630137 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.635478 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.641703 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.647171 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.652586 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.656389 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.661171 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.666617 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.675903 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.681433 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.706104 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.725764 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.731607 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.759265 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.778795 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.784777 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.812462 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.831795 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.838040 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.866930 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.887463 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.893411 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.921839 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.943815 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.948881 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488359.991036 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488360.012604 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488360.018730 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488360.934216 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488360.941678 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488360.950263 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488360.958244 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488360.959355 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488360.965700 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488360.968895 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488360.970380 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488360.974320 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488360.977904 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488360.981545 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488360.983167 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488360.986590 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488360.993034 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488360.995488 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488360.995904 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.005199 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.005967 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.009425 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.018047 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.020891 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.024201 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.032738 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.034794 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.039873 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.046483 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.049820 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.057357 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.061366 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.065872 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.077221 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.079184 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.083621 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.094701 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.103773 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.105691 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.116351 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.130532 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.140762 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.175587 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.180594 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.184591 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.188802 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.193061 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.197056 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.201073 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.201442 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.206194 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.206809 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.210602 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.210866 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.212365 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.215100 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.215521 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.218107 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.219406 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.219846 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.222141 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.223432 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.225228 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.226388 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.227819 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.229596 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.230653 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.232581 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.234654 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.235282 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.237027 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.238768 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.240505 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.241968 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.243405 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.246370 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.246556 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.247809 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.251885 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.252713 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.253017 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.256351 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.256999 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.262362 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.262693 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.267307 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.267867 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.273224 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.274118 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.277098 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.278678 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.280776 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.284881 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.285011 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.291406 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.304957 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.308171 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.312655 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.315225 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.322892 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.330589 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.336189 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.345963 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.356792 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.358955 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.368380 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.382842 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.385257 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.394857 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.408321 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.411538 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.421036 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.437133 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.446597 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.704353 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.708610 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.712808 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.717170 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.721742 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.726328 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.731337 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.733004 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.736273 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.737295 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.741445 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.741629 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.744149 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.746026 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.747235 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.748421 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.750665 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.752662 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.753180 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.755253 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.757056 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.759102 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.760268 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.761660 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.765208 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.766253 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.766377 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.770317 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.771460 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.774888 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.776196 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.776612 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.781944 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.782477 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.782495 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.787633 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.788526 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.790114 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.793611 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.795779 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.799593 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.799922 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.804312 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.806844 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.812084 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.812110 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.815352 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.819757 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.822811 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.823859 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.829546 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.830548 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.840369 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.841558 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.847166 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.852601 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.853392 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.864520 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.876926 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.882365 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.887925 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.888286 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.892915 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.897602 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.903101 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.909528 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.911938 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.916732 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.917331 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.922333 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.923541 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.923945 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.927046 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.928978 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.931489 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.932599 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.934021 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.938762 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.939051 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.939985 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.944375 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.946290 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.948157 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.950623 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.953521 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.954638 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.957787 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.961085 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.963651 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.964964 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.969605 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.972563 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.972800 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.977801 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.981020 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.981967 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.984310 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.989200 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.992116 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.993361 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.995724 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488361.999597 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.002462 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.004745 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.005971 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.011572 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.013388 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.013817 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.019753 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.021746 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.022822 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.029227 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.029768 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.032956 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.035625 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.040418 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.041374 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.043139 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.046850 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.049541 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.052919 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.054295 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.059671 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.060743 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.065388 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.070743 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.071455 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.075617 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.082222 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.083068 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.093698 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.095657 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.100840 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.106141 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.106291 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.116639 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.125972 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.131409 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.141781 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.152996 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.156538 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.166857 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.179755 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.183412 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.193631 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.210246 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.214164 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.220585 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.244911 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.248862 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.255371 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.279973 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.290330 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.721535 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.725846 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.730506 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.735248 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.740359 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.746655 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.753751 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.753887 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.758263 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.761512 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.762948 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.767219 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.767721 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.769897 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.771557 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.772854 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.776244 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.779187 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.781079 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.781871 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.786341 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.786460 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.792703 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.793543 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.794202 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.799640 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.802566 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.807223 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.807497 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.814684 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.815963 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.826271 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.828046 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.831308 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.839728 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.840106 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.853523 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.864343 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.877788 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.883695 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.916056 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.918413 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.929875 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.950920 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.964370 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.967484 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.969899 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.972258 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.974735 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.977212 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.979805 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.982632 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.985082 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.987397 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.989822 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.992777 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.996571 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.999669 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488362.999849 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.002513 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.002626 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.004902 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.006552 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.007406 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.009794 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.009974 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.012581 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.013111 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.013329 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.015227 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.015764 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.017757 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.017857 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.018137 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.020201 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.020636 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.022728 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.023124 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.025757 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.025945 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.028397 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.029946 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.030248 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.030851 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.033256 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.033336 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.035764 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.036179 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.038731 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.040203 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.042159 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.042656 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.043513 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.045782 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.047134 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.048671 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.051549 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.052633 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.053985 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.055880 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.059440 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.063763 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.064182 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.067403 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.076289 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.076484 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.080530 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.088193 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.088404 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.093359 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.100219 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.101944 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.113796 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.115400 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.127043 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.128469 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.139986 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.243234 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.245753 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.248249 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.250817 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.253466 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.256191 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.258994 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.261889 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.264911 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.268009 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.271111 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.274914 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.278626 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.278692 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.281175 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.282713 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.283679 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.286265 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.287209 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.288926 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.290782 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.291690 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.292367 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.293311 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.294513 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.295823 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.297359 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.298561 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.298663 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.300319 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.301220 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.303382 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.303969 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.306475 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.306778 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.309614 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.310466 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.310785 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.312592 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.314285 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.315658 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.318391 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.318712 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.322499 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.322907 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.326307 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.328124 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.330407 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.331437 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.334279 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.334461 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.334892 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.337904 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.340082 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.341311 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.344163 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.346104 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.346617 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.347033 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.350026 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.353018 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.356238 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.358208 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.360185 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.364597 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.367447 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.368989 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.370396 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.373238 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.373802 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.377199 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.378090 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.378718 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.380103 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.381686 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.383075 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.383176 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.385077 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.386212 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.386501 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.388454 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.389226 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.391329 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.391590 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.392472 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.394216 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.396016 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.396436 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.397232 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.400235 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.400872 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.401430 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.403478 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.405301 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.406789 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.407418 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.409584 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.411846 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.412930 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.414489 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.416286 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.419384 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.420540 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.421521 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.422854 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.425402 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.428006 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.430285 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.432406 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.433741 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.434231 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.438007 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.438989 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.443535 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.443549 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.447978 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.448945 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.449688 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.454329 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.458262 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.460494 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.461630 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.469062 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.471065 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.475264 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.481902 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.484746 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.488903 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.495661 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.498429 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.506410 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.509406 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.512110 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.523143 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.523904 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.525782 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.536880 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.543519 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.554528 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.561257 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.572173 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.761542 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.764308 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.767141 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.770404 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.773923 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.777661 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.781643 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.785987 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.791541 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.797646 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.799432 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.802364 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.805629 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.805656 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.809094 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.810362 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.812770 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.813326 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.816345 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.816618 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.818865 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.819673 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.820594 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.823192 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.824879 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.826983 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.830342 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.831052 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.833768 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.835415 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.836550 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.840997 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.844331 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.847083 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.854780 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.854890 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.857785 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.868077 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.872902 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.882158 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.883022 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.894130 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.904166 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.915090 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.916604 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.918057 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.919582 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.921156 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.921431 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.922839 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.924359 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.925789 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.927401 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.928908 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.930613 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.931381 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.932778 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.934432 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.936197 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.938368 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.940223 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.942621 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.944626 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.951285 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.954184 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.955704 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.957321 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.957429 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.958970 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.960539 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.962188 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.963193 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.963708 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.964462 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.965149 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.966000 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.966789 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.967471 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.968304 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.968996 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.970021 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.970543 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.970650 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.972229 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.972404 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.974022 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.974103 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.975540 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.975803 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.977166 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.977798 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.977970 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.978690 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.979828 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.980411 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.982227 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.982592 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.984378 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.984454 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.986231 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.988403 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.990271 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.990893 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.992689 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.994709 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488363.996782 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.001354 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.002676 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.007243 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.009979 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.013115 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.017287 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.020354 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.027624 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.053084 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.054694 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.056272 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.057843 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.059480 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.061173 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.062896 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.064671 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.066490 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.068323 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.070170 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.072415 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.074664 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.077061 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.079611 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.082572 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.085624 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.091546 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.093531 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.095135 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.096713 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.098288 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.098762 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.099937 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.101634 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.103364 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.104085 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.105146 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.105709 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.106976 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.107305 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.108960 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.109035 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.110719 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.110896 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.112423 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.112821 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.113158 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.114167 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.114603 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.115438 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.115961 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.116245 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.117838 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.118017 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.118236 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.119692 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.120089 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.120679 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.121849 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.122126 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.123748 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.124233 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.124341 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.126684 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.126700 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.126950 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.128612 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.129127 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.130658 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.131754 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.133212 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.133310 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.134867 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.135395 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.137565 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.138024 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.140221 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.140567 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.142506 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.144090 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.144791 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.147698 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.149818 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.151339 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.152590 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.154832 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.155303 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.156632 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.158318 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.158481 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.160304 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.162255 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.162348 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.164297 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.165440 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.166618 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.166638 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.167234 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.168790 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.168976 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.170735 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.170969 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.171607 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.172938 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.173022 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.175134 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.175245 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.177272 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.177695 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.178611 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.179399 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.179905 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.181411 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.182581 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.183471 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.184876 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.185607 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.185932 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.187172 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.188149 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.190102 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.190429 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.192235 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.192600 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.193115 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.195032 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.195418 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.197841 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.197923 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.199590 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.200810 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.201157 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.202957 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.204966 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.205771 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.208715 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.208730 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.209139 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.211913 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.214128 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.215716 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.217556 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.219883 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.221127 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.224811 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.228188 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.228285 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.231837 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.235255 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.238853 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.242234 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.245880 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.251131 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.252890 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.260032 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.261861 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.270687 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.270835 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.281499 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.347411 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.349366 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.351254 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.353336 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.355576 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.357923 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.360300 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.362877 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.378469 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.382368 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.387301 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.390908 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.392877 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.393057 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.394776 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.396866 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.399113 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.400433 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.401542 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.401787 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.403722 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.403949 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.405628 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.406535 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.407750 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.410019 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.410948 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.412397 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.414803 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.417398 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.421965 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.423657 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.426016 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.431127 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.432842 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.437102 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.437171 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.442471 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.444609 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.448585 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.453076 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.454200 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.455302 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.455494 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.456373 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.456788 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.458134 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.459416 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.460542 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.461910 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.463265 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.464384 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.465774 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.467358 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.467467 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.468078 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.468881 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.470593 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.472454 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.474623 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.476626 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.480372 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.480613 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.482410 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.485392 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.488358 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.492015 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.495694 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.497829 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.498966 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.500263 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.501556 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.502904 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.504299 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.505453 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.506830 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.508202 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.509351 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.510743 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.510748 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.511885 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.512215 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.513203 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.513751 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.514518 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.515485 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.515890 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.517234 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.517416 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.518385 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.519657 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.519834 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.521212 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.521696 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.522353 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.523768 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.525245 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.525461 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.526802 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.527503 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.528554 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.530561 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.530641 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.532849 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.532961 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.533657 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.534088 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.534907 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.535240 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.536330 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.537478 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.537593 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.538719 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.538961 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.540350 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.540778 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.541165 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.541738 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.543178 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.543824 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.544669 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.546111 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.546867 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.547695 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.549118 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.550609 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.550846 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.552594 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.554532 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.554542 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.556950 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.558584 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.561617 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.565309 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.574724 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.576343 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.577921 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.578288 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.579598 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.579622 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.580752 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.581258 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.581896 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.582878 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.583077 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.584582 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.584592 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.586147 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.586163 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.587740 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.587758 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.589192 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.589450 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.590675 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.590891 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.592218 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.592439 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.592633 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.593579 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.593793 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.594332 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.594742 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.595226 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.595854 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.596120 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.597178 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.597194 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.597640 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.598564 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.598937 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.599517 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.599974 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.600674 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.601359 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.601780 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.602817 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.603068 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.604039 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.604316 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.604718 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.605774 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.607043 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.607358 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.607775 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.608795 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.609525 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.610533 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.611435 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.612008 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.612329 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.614063 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.614644 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.616567 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.618476 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.618490 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.620965 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.621557 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.622067 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.622579 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.624154 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.625282 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.625773 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.625851 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.627449 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.629022 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.629360 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.630633 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.632013 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.633391 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.634761 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.635254 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.635277 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.636392 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.636683 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.637997 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.638416 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.639579 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.639806 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.640112 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.641212 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.641859 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.642810 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.643382 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.644566 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.644577 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.645250 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.645988 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.647376 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.647799 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.649082 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.649925 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.650160 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.650525 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.652263 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.653096 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.654009 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.655757 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.656020 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.657734 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.658376 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.659806 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.661164 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.662271 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.664793 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.665070 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.667933 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.668837 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.670600 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.672445 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.673130 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.675776 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.676029 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.679395 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.680547 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.682995 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.685064 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.686594 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.690189 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.690867 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.696108 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.696265 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.700673 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.705223 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.710049 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.710621 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.711218 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.712382 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.713782 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.715083 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.716496 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.718091 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.719498 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.728264 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.732042 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.736873 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.742574 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.747151 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.756101 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.757261 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.758428 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.758857 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.759710 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.759863 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.760570 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.761187 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.761441 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.762195 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.762618 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.763097 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.763951 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.764233 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.764856 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.765721 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.765836 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.766715 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.767548 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.768670 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.769912 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.771160 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.771424 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.772578 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.773433 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.773764 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.774465 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.775221 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.775315 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.776631 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.776864 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.778092 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.778280 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.778538 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.779719 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.780311 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.781150 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.782001 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.783132 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.785007 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.788241 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.788816 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.789888 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.793432 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.793708 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.795234 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.798521 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.804157 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.805284 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.806093 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.806945 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.807802 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.808603 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.808763 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.809506 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.810377 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.811268 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.812015 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.812988 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.813823 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.814237 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.815190 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.815209 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.815989 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.816452 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.816790 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.817671 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.817775 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.818621 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.819608 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.820034 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.820323 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.820609 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.821134 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.821618 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.821802 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.822012 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.822629 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.822879 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.823505 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.823887 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.823904 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.824922 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.825073 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.825233 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.825799 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.826155 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.826706 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.826994 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.827418 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.827521 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.828672 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.828688 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.828813 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.829553 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.829940 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.830684 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.831856 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.832058 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.832533 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.833311 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.835323 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.835339 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.835685 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.837328 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.839049 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.840711 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.841788 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.842458 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.843312 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.844132 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.844665 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.845872 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.847329 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.847340 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.848617 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.849892 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.850576 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.851127 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.852357 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.853626 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.854907 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.855829 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.856760 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.857021 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.857703 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.859022 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.860133 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.860681 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.861369 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.861545 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.862324 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.863108 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.863909 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.864216 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.864853 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.865832 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.866602 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.866827 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.867775 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.868742 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.869398 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.869754 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.870755 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.871916 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.872013 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.873136 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.873467 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.874137 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.875365 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.875974 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.876775 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.876974 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.877582 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.877937 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.878385 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.879182 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.880109 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.880567 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.880586 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.881112 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.882091 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.883045 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.884238 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.884405 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.885261 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.886269 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.887334 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.887972 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.888466 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.888808 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.889459 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.890172 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.890709 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.891379 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.892583 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.893300 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.893863 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.895129 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.895947 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.896361 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.897592 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.898851 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.900134 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.901066 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.901984 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.902915 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.903887 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.904245 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.905299 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.905458 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.906556 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.906728 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.907782 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.909069 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.909550 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.910354 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.911589 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.912345 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.912840 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.914122 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.914733 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.915420 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.916353 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.917160 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.917316 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.918256 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.918550 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.918718 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.919585 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.919693 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.920475 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.920821 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.921536 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.922037 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.922223 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.922535 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.923566 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.924629 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.924855 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.925741 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.925935 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.927438 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.927448 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.929269 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.929648 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.930281 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.932825 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.932897 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.934380 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.934916 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.937924 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.938287 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.941464 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.941792 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.945008 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.945521 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.948532 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.950082 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.961346 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.962101 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.963447 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.963454 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.964367 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.965305 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.965411 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.966368 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.966828 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.967620 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.968447 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.968665 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.969784 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.969885 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.971070 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.971227 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.972580 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.972682 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.974209 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.974894 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.976403 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.978023 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.979392 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.980090 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.980319 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/24\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:13\u001b[0m 24s/step - loss: 0.2570"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728488364.983380 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.983562 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.984479 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.984645 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.985498 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.986537 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.987073 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.987341 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.987617 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.988884 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.990172 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.990788 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.992389 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.994920 3196734 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.995355 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488364.997628 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.001015 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.005281 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.005876 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.006638 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.007827 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.009010 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.009728 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.011127 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.012710 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.013636 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.013909 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.015145 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.016515 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.018115 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.020302 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.023429 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.024182 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.028963 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.029952 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.030190 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.032099 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.032735 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.033521 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.035138 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.036331 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.037576 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.038960 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.040227 3196737 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.040584 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.042811 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.044440 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.051003 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.053800 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488365.061430 3196726 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.8077"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 15:39:27.483404: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-10-09 15:39:27.483550: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "2024-10-09 15:39:27.483636: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "W0000 00:00:1728488368.203331 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.204215 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.205123 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.205914 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.206853 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.207786 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.208718 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.209794 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.209937 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.210148 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.211091 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.211111 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.211246 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.212265 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.212423 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.212456 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.213182 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.213371 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.214474 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.214588 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.215072 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.215562 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.215674 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.215949 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.216733 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.216866 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.216874 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.217740 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.218081 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.218196 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.218900 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.219286 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.219402 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.220229 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.220642 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.221135 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.221828 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.222073 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.222464 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.223028 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.223278 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.223502 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.223900 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.224332 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.224907 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.225100 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.225268 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.226430 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.226600 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.226631 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.227843 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.228064 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.228313 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.229415 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.229727 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.229983 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.230899 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.231205 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.232408 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.232725 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.233295 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.233874 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.234119 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.234327 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.234616 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.235651 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.235899 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.236093 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.237056 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.237605 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.237850 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.239125 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.240277 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.240972 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.241193 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.241549 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.241837 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.241842 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.242330 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.242631 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.243499 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.243678 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.243794 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.244746 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.245292 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.245403 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.246458 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.247525 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.247638 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.248800 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.248994 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.250419 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.250602 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.250705 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.252229 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.252335 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.253618 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.253731 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.253927 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.255376 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.255959 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.257321 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.258543 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.259158 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.259262 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.262768 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.262934 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.264781 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.266473 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.267396 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.268492 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.271075 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.277690 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.278459 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.279128 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.280660 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.281466 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.282149 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.282895 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.284717 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.285391 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.285567 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.286232 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.286981 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.287768 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.288098 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.288447 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.288834 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.289199 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.289513 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.289953 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.290267 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.291063 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.291697 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.291859 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.292607 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.294523 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.295055 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.296227 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.297866 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.299588 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.300767 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.301505 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.304225 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.304326 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.305815 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.307691 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.307888 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.310029 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.311284 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.312184 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.315591 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.316358 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.319791 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.395511 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.396166 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.396889 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.397647 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.398417 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.399242 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.400138 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.400819 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.401038 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.401484 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.401934 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.402217 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.402962 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.403071 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.404078 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.404097 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.404804 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.405248 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.405289 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.405457 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.406366 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.406580 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.406585 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.407135 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.407500 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.407987 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.408062 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.408399 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.408903 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.409238 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.409345 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.409810 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.410384 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.410491 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.410694 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.411452 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.411726 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.411804 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.412597 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.412695 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.413611 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.414108 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.414122 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.414631 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.415243 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.415713 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.415966 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.416461 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.416988 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.417668 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.418117 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.419404 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.419495 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.419742 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.420701 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.421579 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.421857 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.422766 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.424464 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.424912 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.426314 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.427335 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.429643 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.430692 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.431549 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.432061 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.432361 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.433306 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.434241 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.435027 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.435853 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.436084 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.436930 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.437053 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.438094 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.438108 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.439047 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.439438 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.439990 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.440404 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.440757 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.440855 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.441283 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.441690 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.442190 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.442277 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.442645 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.443231 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.443549 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.444173 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.444921 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.445104 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.446055 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.446151 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.446401 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.447011 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.447464 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.447930 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.449259 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.450424 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.450830 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.451816 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.451909 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.455101 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.456114 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.456277 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.460631 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.460734 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.463974 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.464975 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.469416 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.472758 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.473771 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.478346 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.478353 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.482806 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.483834 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.483950 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.488287 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.489297 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.493752 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.654439 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.655357 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.656307 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.657299 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.657845 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.658320 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.658764 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.659332 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.659722 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.660375 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.660725 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.661512 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.661741 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.662942 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.662955 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.663291 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.663983 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.664274 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.664422 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.665122 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.665407 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.665642 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.666440 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.666545 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.666969 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.667698 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.667812 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.668426 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.668708 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.669196 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.669728 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.670097 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.670505 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.670856 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.672231 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.672245 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.672343 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.673596 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.673940 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.674146 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.674941 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.675689 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.676310 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.676385 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.677529 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.677834 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.678362 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.679653 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.679674 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.681419 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.681878 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.681891 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.683273 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.685167 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.685353 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.686391 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.687394 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.689635 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.690085 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.691188 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.693343 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.694386 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.697882 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.702579 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.702689 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.703900 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.705184 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.705769 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.706744 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.707082 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.708684 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.708689 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.710197 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.710302 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.711521 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.711858 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.712769 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.713264 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.714256 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.714359 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.714569 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.715805 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.715912 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.716544 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.717107 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.717389 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.718562 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.718738 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.719652 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.720297 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.720824 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.721746 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.721846 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.723145 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.723990 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.724389 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.725860 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.727796 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.728138 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.730102 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.730914 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.732349 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.736315 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.739243 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.739417 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.744576 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.747640 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.747826 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.756042 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.761994 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.764885 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.773346 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.779193 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.781890 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.789482 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.790407 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.792107 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.799914 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.800638 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.802452 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488368.811004 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.139800 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.141269 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.141354 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.142937 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.142947 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.144592 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.144606 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.146309 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.146323 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.147941 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.148050 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.149822 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.149993 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.151174 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.151583 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.151872 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.152703 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.153400 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.153917 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.154312 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.155426 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.156118 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.156239 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.157589 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.157860 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.158360 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.159867 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.159891 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.160561 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.161583 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.162046 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.162929 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.163380 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.164392 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.165563 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.165738 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.166974 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.167566 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.168547 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.169501 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.169744 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.171505 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.173665 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.176209 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.177374 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.178530 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.178968 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.180310 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.181439 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.183529 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.184629 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.186977 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.187752 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.188047 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.190668 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.193279 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.193866 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.194308 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.197301 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.201441 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.207830 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.208402 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.209559 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.210486 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.211647 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.212576 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.213725 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.214941 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.216078 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.217512 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.218624 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.219592 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.220694 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.221604 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.222684 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.223120 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.224247 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.225393 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.225419 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.226512 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.227489 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.227696 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.228563 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.229774 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.229947 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.230918 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.232105 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.232515 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.233366 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.234668 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.234764 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.236752 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.239371 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.241613 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.243648 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.246023 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.246230 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.247404 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.248472 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.259457 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.260487 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.261079 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.274395 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.276393 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.277294 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.291415 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.292665 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.293444 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.307732 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.310247 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.310870 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.325191 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.328800 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.329284 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.343148 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.365257 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.366380 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488369.379752 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.039122 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.041428 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.043868 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.046143 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.046986 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.048613 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.049330 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.051249 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.051804 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.054103 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.054215 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.056954 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.056964 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.057654 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.059618 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.060095 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.060211 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.062429 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.062614 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.063973 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.064912 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.065150 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.067329 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.067507 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.068330 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.070152 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.070767 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.072117 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.072896 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.074161 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.075503 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.075679 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.078725 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.079040 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.079115 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.082580 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.082812 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.083821 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.086138 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.087201 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.089155 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.089588 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.092311 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.093082 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.097828 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.097911 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.103043 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.104774 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.108463 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.110660 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.113554 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.117110 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.119528 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.124248 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.126148 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.129337 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.130232 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.137761 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.138535 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.144334 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.153349 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.157051 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.157235 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.161519 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.164631 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.165392 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.168350 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.169143 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.172656 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.173787 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.176538 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.177476 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.180310 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.181168 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.182381 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.185055 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.185128 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.186090 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.188851 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.189411 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.189860 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.193330 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.193724 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.194257 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.197118 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.197351 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.198858 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.201018 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.201817 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.205410 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.205579 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.209968 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.210523 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.214293 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.218110 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.222659 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.222783 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.227321 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.233248 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.249150 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.251249 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.259317 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.278052 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.282317 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.292375 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.311642 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.314011 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.324403 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.343631 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.348190 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.358752 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.378447 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.384865 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.395997 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.416360 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.465104 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.475810 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488370.494476 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.812433 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.816487 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.820538 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.824610 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.828995 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.833510 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.838578 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.839694 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.840504 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.843285 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.843700 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.844582 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.847764 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.848672 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.848994 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.851846 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.852803 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.853925 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.856274 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.857209 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.860105 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.860808 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.861812 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.865757 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.866400 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.866844 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.870428 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.871455 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.873010 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.876229 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.877086 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.881262 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.882382 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.882403 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.887414 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.888692 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.891642 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.893764 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.895080 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.900494 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.901092 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.901878 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.909809 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.911195 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.919120 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.920617 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.928719 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.928917 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.930201 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.940442 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.956604 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.958589 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.959961 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.966584 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.968136 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.970146 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.973346 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.982271 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.983523 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.986046 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.989237 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.992845 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.996414 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488371.999740 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.003345 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.004736 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.008647 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.010183 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.011556 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.015623 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.017113 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.021091 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.022807 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.026171 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.028161 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.030972 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.033471 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.036461 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.037982 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.040585 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.045199 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.047712 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.049188 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.054855 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.056254 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.063288 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.066065 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.072106 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.073241 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.081733 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.090291 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.090642 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.118637 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.136550 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.140768 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.170428 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.187702 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.205684 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.235631 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.252829 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.267946 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.298555 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.315858 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.332243 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.364112 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.380877 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.410969 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.444369 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.462456 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.561365 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.593803 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488372.608170 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.252766 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.259915 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.267174 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.274523 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.282711 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.291374 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.297805 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.301024 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.305022 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.310131 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.312350 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.318198 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.319775 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.321254 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.325404 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.328262 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.330853 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.332761 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.337202 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.340208 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.342744 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.347086 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.348330 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.354912 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.356266 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.356779 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.366631 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.367656 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.367786 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.375782 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.377605 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.385434 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.387094 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.389694 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.396840 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.401984 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.402509 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.408853 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.414830 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.420541 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.421010 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.432916 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.433861 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.450181 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.452080 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.468523 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.469237 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.471334 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.487486 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.493368 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.520171 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.523032 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.530871 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.534406 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.537951 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.538782 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.542278 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.542718 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.546430 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.550866 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.554420 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.559379 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.560907 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.563093 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.567379 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.568757 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.571905 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.591031 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.598985 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.599162 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.599636 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.602752 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.606373 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.607213 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.610817 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.611123 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.614499 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.614710 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.619045 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.619306 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.621287 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.622606 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.622918 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.627225 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.627529 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.630886 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.631230 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.635493 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.635977 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.639770 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.640037 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.644175 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.648808 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.654476 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.667626 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.677122 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.686181 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.689332 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.699110 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.718586 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.722583 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.732882 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.754191 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.754515 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.765226 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.786890 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.797803 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.822277 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.832525 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.833395 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.903061 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488375.909405 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.120938 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.124747 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.128317 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.132095 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.136106 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.140117 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.144363 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.148373 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.152889 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.157632 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.163438 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.169273 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.175748 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.184409 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.193845 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.199069 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.202642 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.202717 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.202958 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.206713 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.206827 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.210314 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.210693 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.214110 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.214751 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.218163 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.218860 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.222194 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.223243 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.224887 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.226486 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.227368 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.230739 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.231969 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.235599 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.235896 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.236513 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.240393 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.242348 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.246209 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.248323 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.252123 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.253262 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.254443 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.254969 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.255551 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.256786 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.257887 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.258716 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.259035 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.260455 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.261942 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.263486 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.263752 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.264706 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.266013 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.267584 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.267604 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.273414 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.274997 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.277147 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.282261 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.283658 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.285944 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.292096 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.300285 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.305020 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.308723 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.308851 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.316238 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.319675 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.325374 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.328892 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.337136 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.338331 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.339454 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.340714 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.342053 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.342063 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.343229 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.344680 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.346187 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.346682 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.347824 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.348020 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.349211 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.349291 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.350674 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.350755 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.351936 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.352113 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.353131 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.354606 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.356134 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.357737 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.358992 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.359604 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.360340 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.361702 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.368438 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.369342 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.376981 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.378357 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.385309 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.386963 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.393777 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.395384 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.403953 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.410249 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.420649 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.426531 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.437203 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.638060 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.639238 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.640374 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.641497 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.642696 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.643972 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.645234 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.646400 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.647700 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.648973 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.650475 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.651958 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.653696 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.655749 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.658298 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.660411 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.680572 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.686466 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.689210 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.700571 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.701002 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.701399 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.701811 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.702223 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.702701 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.703174 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.704462 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.705926 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.707541 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.709232 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.711285 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.713695 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.715587 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.724057 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.725232 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.726392 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.727520 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.728727 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.730014 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.731288 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.732478 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.733990 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.734138 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.734269 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.734556 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.734940 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.735660 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.735670 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.735766 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.736084 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.736497 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.737146 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.737355 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.737360 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.737608 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.738057 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.738507 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.738611 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.738994 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.739103 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.739489 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.739967 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.740065 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.740448 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.740794 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.740985 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.741399 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.741501 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.741977 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.742744 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.742895 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.743002 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.743336 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.744084 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.745173 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.745444 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.745615 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.746676 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.746835 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.747778 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.748359 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.749931 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.750025 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.751787 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.753860 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.756429 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.758549 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.765455 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.765797 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.766089 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.766372 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.766904 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.767665 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.768044 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.768437 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.769169 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.769898 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.771361 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.773342 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.773997 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.774996 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.776753 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.776860 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.777088 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.777419 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.777722 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.778157 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.778441 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.778836 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.778838 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.779157 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.779469 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.779744 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.780034 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.780335 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.780715 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.781113 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.781508 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.782783 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.783243 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.783656 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.784172 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.784757 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.787239 3196703 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.787519 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.788422 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.788873 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.789280 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.789701 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.790119 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.790737 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.790817 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.791227 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.792526 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.793999 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.795607 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.797318 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.799391 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.801819 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.802158 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.802606 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.803009 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.803430 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.803764 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.803954 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.804431 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.804909 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.806210 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.807672 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.809169 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.810887 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.812974 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.815401 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.817321 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.822169 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.822575 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.822963 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.823352 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.823753 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.824162 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.824578 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.825002 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.825446 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.825820 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.826303 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.826686 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.827169 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.827553 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.828063 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.828460 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.828937 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.829571 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.830146 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.832008 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.833463 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.835637 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.836051 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.836484 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.836645 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.836897 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.837304 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.837715 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.838125 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.838550 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.838990 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.839366 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.839838 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.840217 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.840705 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.841097 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.841610 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.842012 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.842488 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.843118 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.843690 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.845534 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.847014 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.850138 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.852227 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.852578 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.852869 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.853164 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.853697 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.854462 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.855228 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.855971 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.856712 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.858217 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.860392 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.862232 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.864051 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.864561 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.865086 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.865566 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.865780 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.866328 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.866458 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.866822 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.867082 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.867331 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.867609 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.867858 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.868456 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.868574 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.869019 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.869553 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.869671 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.870156 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.870555 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.870811 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.871493 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.871570 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.872045 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.872471 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.873288 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.873950 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.874216 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.874558 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.875250 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.876241 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.877909 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.878409 3196709 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.879586 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.879914 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.880256 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.880564 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.881001 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.881287 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.881587 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.881904 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.882218 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.882495 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.882783 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.883078 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.883463 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.883857 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.884252 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.885287 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.885743 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.886152 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.886667 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728488377.889700 3196695 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 568ms/step - loss: 0.7884 - val_loss: 0.3118 - learning_rate: 0.0010\n",
      "Epoch 2/1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 15:39:38.069662: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0268"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 15:39:40.985103: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 0.0268 - val_loss: 0.1427 - learning_rate: 0.0010\n",
      "Epoch 3/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 218ms/step - loss: 0.0245 - val_loss: 0.0522 - learning_rate: 0.0010\n",
      "Epoch 4/1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 15:39:47.585403: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 0.0239 - val_loss: 0.0706 - learning_rate: 0.0010\n",
      "Epoch 5/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 0.0227 - val_loss: 0.1822 - learning_rate: 0.0010\n",
      "Epoch 6/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0211"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 15:39:56.955488: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0211 - val_loss: 0.2721 - learning_rate: 0.0010\n",
      "Epoch 7/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 203ms/step - loss: 0.0200 - val_loss: 0.3697 - learning_rate: 0.0010\n",
      "Epoch 8/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 0.0191 - val_loss: 0.3544 - learning_rate: 0.0010\n",
      "Epoch 9/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 0.0181 - val_loss: 0.3440 - learning_rate: 0.0010\n",
      "Epoch 10/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 0.0174 - val_loss: 0.3379 - learning_rate: 0.0010\n",
      "Epoch 11/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 0.0170 - val_loss: 0.3788 - learning_rate: 0.0010\n",
      "Epoch 12/1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 15:40:20.753465: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 0.0166 - val_loss: 0.4060 - learning_rate: 0.0010\n",
      "Epoch 13/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0165\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 0.0165 - val_loss: 0.4081 - learning_rate: 0.0010\n",
      "Epoch 14/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 0.0163 - val_loss: 0.3942 - learning_rate: 9.0000e-04\n",
      "Epoch 15/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 0.0160 - val_loss: 0.3857 - learning_rate: 9.0000e-04\n",
      "Epoch 16/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 0.0163 - val_loss: 0.4299 - learning_rate: 9.0000e-04\n",
      "Epoch 17/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 224ms/step - loss: 0.0157 - val_loss: 0.3691 - learning_rate: 9.0000e-04\n",
      "Epoch 18/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 0.0156 - val_loss: 0.3673 - learning_rate: 9.0000e-04\n",
      "Epoch 19/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - loss: 0.0153 - val_loss: 0.2783 - learning_rate: 9.0000e-04\n",
      "Epoch 20/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 0.0152 - val_loss: 0.2833 - learning_rate: 9.0000e-04\n",
      "Epoch 21/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - loss: 0.0150 - val_loss: 0.1981 - learning_rate: 9.0000e-04\n",
      "Epoch 22/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0150"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 15:41:13.109673: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 215ms/step - loss: 0.0150 - val_loss: 0.1822 - learning_rate: 9.0000e-04\n",
      "Epoch 23/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0148\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 0.0148 - val_loss: 0.0939 - learning_rate: 9.0000e-04\n",
      "Epoch 24/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 0.0146 - val_loss: 0.0826 - learning_rate: 8.1000e-04\n",
      "Epoch 25/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 0.0144 - val_loss: 0.0900 - learning_rate: 8.1000e-04\n",
      "Epoch 26/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 226ms/step - loss: 0.0143 - val_loss: 0.0974 - learning_rate: 8.1000e-04\n",
      "Epoch 27/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0141 - val_loss: 0.0316 - learning_rate: 8.1000e-04\n",
      "Epoch 28/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0139 - val_loss: 0.0458 - learning_rate: 8.1000e-04\n",
      "Epoch 29/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 170ms/step - loss: 0.0137 - val_loss: 0.0346 - learning_rate: 8.1000e-04\n",
      "Epoch 30/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 222ms/step - loss: 0.0137 - val_loss: 0.0428 - learning_rate: 8.1000e-04\n",
      "Epoch 31/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 0.0135 - val_loss: 0.0340 - learning_rate: 8.1000e-04\n",
      "Epoch 32/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 224ms/step - loss: 0.0134 - val_loss: 0.0321 - learning_rate: 8.1000e-04\n",
      "Epoch 33/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 225ms/step - loss: 0.0133 - val_loss: 0.0455 - learning_rate: 8.1000e-04\n",
      "Epoch 34/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - loss: 0.0131 - val_loss: 0.0615 - learning_rate: 8.1000e-04\n",
      "Epoch 35/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 0.0130 - val_loss: 0.0886 - learning_rate: 8.1000e-04\n",
      "Epoch 36/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - loss: 0.0129 - val_loss: 0.0873 - learning_rate: 8.1000e-04\n",
      "Epoch 37/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0129\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 224ms/step - loss: 0.0128 - val_loss: 0.2109 - learning_rate: 8.1000e-04\n",
      "Epoch 38/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.0127 - val_loss: 0.0814 - learning_rate: 7.2900e-04\n",
      "Epoch 39/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0125 - val_loss: 0.0783 - learning_rate: 7.2900e-04\n",
      "Epoch 40/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 191ms/step - loss: 0.0124 - val_loss: 0.1529 - learning_rate: 7.2900e-04\n",
      "Epoch 41/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 0.0122 - val_loss: 0.0405 - learning_rate: 7.2900e-04\n",
      "Epoch 42/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 0.0122 - val_loss: 0.1141 - learning_rate: 7.2900e-04\n",
      "Epoch 43/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 0.0120 - val_loss: 0.0813 - learning_rate: 7.2900e-04\n",
      "Epoch 44/1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 15:42:55.502380: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 0.0120 - val_loss: 0.0191 - learning_rate: 7.2900e-04\n",
      "Epoch 45/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - loss: 0.0119 - val_loss: 0.0165 - learning_rate: 7.2900e-04\n",
      "Epoch 46/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 218ms/step - loss: 0.0119 - val_loss: 0.0206 - learning_rate: 7.2900e-04\n",
      "Epoch 47/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 222ms/step - loss: 0.0117 - val_loss: 0.0155 - learning_rate: 7.2900e-04\n",
      "Epoch 48/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 0.0117 - val_loss: 0.0226 - learning_rate: 7.2900e-04\n",
      "Epoch 49/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0116 - val_loss: 0.0377 - learning_rate: 7.2900e-04\n",
      "Epoch 50/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 143ms/step - loss: 0.0115 - val_loss: 0.0304 - learning_rate: 7.2900e-04\n",
      "Epoch 51/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 0.0114 - val_loss: 0.0172 - learning_rate: 7.2900e-04\n",
      "Epoch 52/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - loss: 0.0112 - val_loss: 0.0200 - learning_rate: 7.2900e-04\n",
      "Epoch 53/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 0.0112 - val_loss: 0.0141 - learning_rate: 7.2900e-04\n",
      "Epoch 54/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 0.0112 - val_loss: 0.0188 - learning_rate: 7.2900e-04\n",
      "Epoch 55/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0111 - val_loss: 0.0180 - learning_rate: 7.2900e-04\n",
      "Epoch 56/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0110 - val_loss: 0.0250 - learning_rate: 7.2900e-04\n",
      "Epoch 57/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - loss: 0.0109 - val_loss: 0.0182 - learning_rate: 7.2900e-04\n",
      "Epoch 58/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 0.0108 - val_loss: 0.0294 - learning_rate: 7.2900e-04\n",
      "Epoch 59/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 0.0107 - val_loss: 0.0127 - learning_rate: 7.2900e-04\n",
      "Epoch 60/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 0.0106 - val_loss: 0.0286 - learning_rate: 7.2900e-04\n",
      "Epoch 61/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 0.0106 - val_loss: 0.0160 - learning_rate: 7.2900e-04\n",
      "Epoch 62/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 0.0105 - val_loss: 0.0235 - learning_rate: 7.2900e-04\n",
      "Epoch 63/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 141ms/step - loss: 0.0105 - val_loss: 0.0263 - learning_rate: 7.2900e-04\n",
      "Epoch 64/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0104 - val_loss: 0.0145 - learning_rate: 7.2900e-04\n",
      "Epoch 65/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - loss: 0.0103 - val_loss: 0.0193 - learning_rate: 7.2900e-04\n",
      "Epoch 66/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 0.0101 - val_loss: 0.0148 - learning_rate: 7.2900e-04\n",
      "Epoch 67/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0102 - val_loss: 0.0145 - learning_rate: 7.2900e-04\n",
      "Epoch 68/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 0.0101 - val_loss: 0.0154 - learning_rate: 7.2900e-04\n",
      "Epoch 69/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0101\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - loss: 0.0101 - val_loss: 0.0134 - learning_rate: 7.2900e-04\n",
      "Epoch 70/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 0.0098 - val_loss: 0.0141 - learning_rate: 6.5610e-04\n",
      "Epoch 71/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 0.0097 - val_loss: 0.0143 - learning_rate: 6.5610e-04\n",
      "Epoch 72/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0098 - val_loss: 0.0130 - learning_rate: 6.5610e-04\n",
      "Epoch 73/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 142ms/step - loss: 0.0096 - val_loss: 0.0186 - learning_rate: 6.5610e-04\n",
      "Epoch 74/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 0.0096 - val_loss: 0.0150 - learning_rate: 6.5610e-04\n",
      "Epoch 75/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 237ms/step - loss: 0.0095 - val_loss: 0.0173 - learning_rate: 6.5610e-04\n",
      "Epoch 76/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 0.0094 - val_loss: 0.0190 - learning_rate: 6.5610e-04\n",
      "Epoch 77/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - loss: 0.0094 - val_loss: 0.0168 - learning_rate: 6.5610e-04\n",
      "Epoch 78/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0094 - val_loss: 0.0172 - learning_rate: 6.5610e-04\n",
      "Epoch 79/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0092\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 242ms/step - loss: 0.0092 - val_loss: 0.0186 - learning_rate: 6.5610e-04\n",
      "Epoch 80/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 0.0090 - val_loss: 0.0137 - learning_rate: 5.9049e-04\n",
      "Epoch 81/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 0.0089 - val_loss: 0.0130 - learning_rate: 5.9049e-04\n",
      "Epoch 82/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 0.0090 - val_loss: 0.0139 - learning_rate: 5.9049e-04\n",
      "Epoch 83/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 0.0088 - val_loss: 0.0135 - learning_rate: 5.9049e-04\n",
      "Epoch 84/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0088 - val_loss: 0.0138 - learning_rate: 5.9049e-04\n",
      "Epoch 85/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 143ms/step - loss: 0.0087 - val_loss: 0.0147 - learning_rate: 5.9049e-04\n",
      "Epoch 86/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0086"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 15:46:21.158806: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 0.0086 - val_loss: 0.0190 - learning_rate: 5.9049e-04\n",
      "Epoch 87/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 190ms/step - loss: 0.0085 - val_loss: 0.0145 - learning_rate: 5.9049e-04\n",
      "Epoch 88/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 0.0084 - val_loss: 0.0166 - learning_rate: 5.9049e-04\n",
      "Epoch 89/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0083\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 0.0083 - val_loss: 0.0166 - learning_rate: 5.9049e-04\n",
      "Epoch 90/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 0.0082 - val_loss: 0.0141 - learning_rate: 5.3144e-04\n",
      "Epoch 91/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 236ms/step - loss: 0.0081 - val_loss: 0.0153 - learning_rate: 5.3144e-04\n",
      "Epoch 92/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 223ms/step - loss: 0.0080 - val_loss: 0.0140 - learning_rate: 5.3144e-04\n",
      "Epoch 93/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 223ms/step - loss: 0.0079 - val_loss: 0.0135 - learning_rate: 5.3144e-04\n",
      "Epoch 94/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0078 - val_loss: 0.0121 - learning_rate: 5.3144e-04\n",
      "Epoch 95/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.0077 - val_loss: 0.0137 - learning_rate: 5.3144e-04\n",
      "Epoch 96/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - loss: 0.0077 - val_loss: 0.0157 - learning_rate: 5.3144e-04\n",
      "Epoch 97/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 0.0075 - val_loss: 0.0139 - learning_rate: 5.3144e-04\n",
      "Epoch 98/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 0.0074 - val_loss: 0.0143 - learning_rate: 5.3144e-04\n",
      "Epoch 99/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 0.0074 - val_loss: 0.0302 - learning_rate: 5.3144e-04\n",
      "Epoch 100/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 0.0086 - val_loss: 0.0897 - learning_rate: 5.3144e-04\n",
      "Epoch 101/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 223ms/step - loss: 0.0075 - val_loss: 0.0280 - learning_rate: 5.3144e-04\n",
      "Epoch 102/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.0072 - val_loss: 0.0230 - learning_rate: 5.3144e-04\n",
      "Epoch 103/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.0070 - val_loss: 0.0197 - learning_rate: 5.3144e-04\n",
      "Epoch 104/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0069\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - loss: 0.0069 - val_loss: 0.0170 - learning_rate: 5.3144e-04\n",
      "Epoch 105/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 0.0068 - val_loss: 0.0147 - learning_rate: 4.7830e-04\n",
      "Epoch 106/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 0.0066 - val_loss: 0.0164 - learning_rate: 4.7830e-04\n",
      "Epoch 107/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 0.0065 - val_loss: 0.0149 - learning_rate: 4.7830e-04\n",
      "Epoch 108/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 0.0063 - val_loss: 0.0147 - learning_rate: 4.7830e-04\n",
      "Epoch 109/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 223ms/step - loss: 0.0061 - val_loss: 0.0164 - learning_rate: 4.7830e-04\n",
      "Epoch 110/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0060 - val_loss: 0.0176 - learning_rate: 4.7830e-04\n",
      "Epoch 111/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 0.0059 - val_loss: 0.0178 - learning_rate: 4.7830e-04\n",
      "Epoch 112/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - loss: 0.0058 - val_loss: 0.0151 - learning_rate: 4.7830e-04\n",
      "Epoch 113/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 0.0057 - val_loss: 0.0148 - learning_rate: 4.7830e-04\n",
      "Epoch 114/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0055\n",
      "Epoch 114: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.0055 - val_loss: 0.0134 - learning_rate: 4.7830e-04\n",
      "Epoch 115/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.0054 - val_loss: 0.0143 - learning_rate: 4.3047e-04\n",
      "Epoch 116/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 194ms/step - loss: 0.0058 - val_loss: 0.0131 - learning_rate: 4.3047e-04\n",
      "Epoch 117/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 225ms/step - loss: 0.0053 - val_loss: 0.0144 - learning_rate: 4.3047e-04\n",
      "Epoch 118/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 0.0051 - val_loss: 0.0141 - learning_rate: 4.3047e-04\n",
      "Epoch 119/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 0.0049 - val_loss: 0.0148 - learning_rate: 4.3047e-04\n",
      "Epoch 120/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 0.0048 - val_loss: 0.0136 - learning_rate: 4.3047e-04\n",
      "Epoch 121/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 0.0046 - val_loss: 0.0166 - learning_rate: 4.3047e-04\n",
      "Epoch 122/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 253ms/step - loss: 0.0045 - val_loss: 0.0140 - learning_rate: 4.3047e-04\n",
      "Epoch 123/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0043 - val_loss: 0.0147 - learning_rate: 4.3047e-04\n",
      "Epoch 124/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0043\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 248ms/step - loss: 0.0043 - val_loss: 0.0178 - learning_rate: 4.3047e-04\n",
      "Epoch 125/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 0.0041 - val_loss: 0.0152 - learning_rate: 3.8742e-04\n",
      "Epoch 126/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 0.0039 - val_loss: 0.0138 - learning_rate: 3.8742e-04\n",
      "Epoch 127/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 0.0038 - val_loss: 0.0142 - learning_rate: 3.8742e-04\n",
      "Epoch 128/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 0.0037 - val_loss: 0.0138 - learning_rate: 3.8742e-04\n",
      "Epoch 129/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 0.0036 - val_loss: 0.0139 - learning_rate: 3.8742e-04\n",
      "Epoch 130/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 0.0036 - val_loss: 0.0137 - learning_rate: 3.8742e-04\n",
      "Epoch 131/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 224ms/step - loss: 0.0034 - val_loss: 0.0140 - learning_rate: 3.8742e-04\n",
      "Epoch 132/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 0.0033 - val_loss: 0.0140 - learning_rate: 3.8742e-04\n",
      "Epoch 133/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 0.0032 - val_loss: 0.0138 - learning_rate: 3.8742e-04\n",
      "Epoch 134/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0031\n",
      "Epoch 134: ReduceLROnPlateau reducing learning rate to 0.0003486784757114947.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 0.0031 - val_loss: 0.0143 - learning_rate: 3.8742e-04\n",
      "Epoch 135/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 0.0030 - val_loss: 0.0135 - learning_rate: 3.4868e-04\n",
      "Epoch 136/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 0.0028 - val_loss: 0.0137 - learning_rate: 3.4868e-04\n",
      "Epoch 137/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 0.0028 - val_loss: 0.0137 - learning_rate: 3.4868e-04\n",
      "Epoch 138/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 224ms/step - loss: 0.0027 - val_loss: 0.0141 - learning_rate: 3.4868e-04\n",
      "Epoch 139/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 0.0026 - val_loss: 0.0133 - learning_rate: 3.4868e-04\n",
      "Epoch 140/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 0.0025 - val_loss: 0.0137 - learning_rate: 3.4868e-04\n",
      "Epoch 141/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 0.0024 - val_loss: 0.0149 - learning_rate: 3.4868e-04\n",
      "Epoch 142/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 0.0024 - val_loss: 0.0136 - learning_rate: 3.4868e-04\n",
      "Epoch 143/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 0.0023 - val_loss: 0.0146 - learning_rate: 3.4868e-04\n",
      "Epoch 144/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0023\n",
      "Epoch 144: ReduceLROnPlateau reducing learning rate to 0.00031381062290165574.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 0.0023 - val_loss: 0.0144 - learning_rate: 3.4868e-04\n",
      "Epoch 145/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 222ms/step - loss: 0.0022 - val_loss: 0.0138 - learning_rate: 3.1381e-04\n",
      "Epoch 146/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0021 - val_loss: 0.0141 - learning_rate: 3.1381e-04\n",
      "Epoch 147/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - loss: 0.0020 - val_loss: 0.0142 - learning_rate: 3.1381e-04\n",
      "Epoch 148/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 243ms/step - loss: 0.0020 - val_loss: 0.0138 - learning_rate: 3.1381e-04\n",
      "Epoch 149/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 0.0019 - val_loss: 0.0144 - learning_rate: 3.1381e-04\n",
      "Epoch 150/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 0.0019 - val_loss: 0.0136 - learning_rate: 3.1381e-04\n",
      "Epoch 151/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - loss: 0.0018 - val_loss: 0.0143 - learning_rate: 3.1381e-04\n",
      "Epoch 152/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 206ms/step - loss: 0.0018 - val_loss: 0.0141 - learning_rate: 3.1381e-04\n",
      "Epoch 153/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - loss: 0.0017 - val_loss: 0.0146 - learning_rate: 3.1381e-04\n",
      "Epoch 154/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0017\n",
      "Epoch 154: ReduceLROnPlateau reducing learning rate to 0.0002824295632308349.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 0.0017 - val_loss: 0.0142 - learning_rate: 3.1381e-04\n",
      "Epoch 155/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - loss: 0.0016 - val_loss: 0.0140 - learning_rate: 2.8243e-04\n",
      "Epoch 156/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 0.0016 - val_loss: 0.0141 - learning_rate: 2.8243e-04\n",
      "Epoch 157/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 0.0015 - val_loss: 0.0141 - learning_rate: 2.8243e-04\n",
      "Epoch 158/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 0.0015 - val_loss: 0.0138 - learning_rate: 2.8243e-04\n",
      "Epoch 159/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 0.0015 - val_loss: 0.0139 - learning_rate: 2.8243e-04\n",
      "Epoch 160/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 0.0014 - val_loss: 0.0144 - learning_rate: 2.8243e-04\n",
      "Epoch 161/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 0.0014 - val_loss: 0.0143 - learning_rate: 2.8243e-04\n",
      "Epoch 162/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 0.0014 - val_loss: 0.0148 - learning_rate: 2.8243e-04\n",
      "Epoch 163/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 0.0014 - val_loss: 0.0151 - learning_rate: 2.8243e-04\n",
      "Epoch 164/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0014\n",
      "Epoch 164: ReduceLROnPlateau reducing learning rate to 0.00025418660952709616.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 0.0014 - val_loss: 0.0137 - learning_rate: 2.8243e-04\n",
      "Epoch 165/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 0.0013 - val_loss: 0.0138 - learning_rate: 2.5419e-04\n",
      "Epoch 166/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 236ms/step - loss: 0.0012 - val_loss: 0.0141 - learning_rate: 2.5419e-04\n",
      "Epoch 167/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 211ms/step - loss: 0.0012 - val_loss: 0.0139 - learning_rate: 2.5419e-04\n",
      "Epoch 168/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0012 - val_loss: 0.0142 - learning_rate: 2.5419e-04\n",
      "Epoch 169/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 174ms/step - loss: 0.0012 - val_loss: 0.0140 - learning_rate: 2.5419e-04\n",
      "Epoch 170/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 240ms/step - loss: 0.0012 - val_loss: 0.0146 - learning_rate: 2.5419e-04\n",
      "Epoch 171/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 0.0012 - val_loss: 0.0137 - learning_rate: 2.5419e-04\n",
      "Epoch 172/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 15:53:49.299688: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 0.0011 - val_loss: 0.0148 - learning_rate: 2.5419e-04\n",
      "Epoch 173/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 0.0011 - val_loss: 0.0139 - learning_rate: 2.5419e-04\n",
      "Epoch 174/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0011\n",
      "Epoch 174: ReduceLROnPlateau reducing learning rate to 0.00022876793809700757.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 0.0011 - val_loss: 0.0139 - learning_rate: 2.5419e-04\n",
      "Epoch 175/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 167ms/step - loss: 0.0011 - val_loss: 0.0141 - learning_rate: 2.2877e-04\n",
      "Epoch 176/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.0010 - val_loss: 0.0139 - learning_rate: 2.2877e-04\n",
      "Epoch 177/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 128ms/step - loss: 0.0010 - val_loss: 0.0139 - learning_rate: 2.2877e-04\n",
      "Epoch 178/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 212ms/step - loss: 9.9662e-04 - val_loss: 0.0148 - learning_rate: 2.2877e-04\n",
      "Epoch 179/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 223ms/step - loss: 0.0010 - val_loss: 0.0138 - learning_rate: 2.2877e-04\n",
      "Epoch 180/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 9.8401e-04 - val_loss: 0.0147 - learning_rate: 2.2877e-04\n",
      "Epoch 181/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 9.9056e-04 - val_loss: 0.0139 - learning_rate: 2.2877e-04\n",
      "Epoch 182/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 9.7348e-04 - val_loss: 0.0144 - learning_rate: 2.2877e-04\n",
      "Epoch 183/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 9.7926e-04 - val_loss: 0.0141 - learning_rate: 2.2877e-04\n",
      "Epoch 184/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 9.6841e-04\n",
      "Epoch 184: ReduceLROnPlateau reducing learning rate to 0.00020589114428730683.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 9.6567e-04 - val_loss: 0.0143 - learning_rate: 2.2877e-04\n",
      "Epoch 185/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 9.2426e-04 - val_loss: 0.0151 - learning_rate: 2.0589e-04\n",
      "Epoch 186/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 225ms/step - loss: 9.1900e-04 - val_loss: 0.0138 - learning_rate: 2.0589e-04\n",
      "Epoch 187/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 8.9046e-04 - val_loss: 0.0138 - learning_rate: 2.0589e-04\n",
      "Epoch 188/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 8.7098e-04 - val_loss: 0.0139 - learning_rate: 2.0589e-04\n",
      "Epoch 189/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 222ms/step - loss: 8.7765e-04 - val_loss: 0.0139 - learning_rate: 2.0589e-04\n",
      "Epoch 190/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 8.5084e-04 - val_loss: 0.0148 - learning_rate: 2.0589e-04\n",
      "Epoch 191/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 8.5978e-04 - val_loss: 0.0137 - learning_rate: 2.0589e-04\n",
      "Epoch 192/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 226ms/step - loss: 8.3691e-04 - val_loss: 0.0145 - learning_rate: 2.0589e-04\n",
      "Epoch 193/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 8.7016e-04 - val_loss: 0.0143 - learning_rate: 2.0589e-04\n",
      "Epoch 194/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 8.2980e-04\n",
      "Epoch 194: ReduceLROnPlateau reducing learning rate to 0.00018530203378759326.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 8.2818e-04 - val_loss: 0.0140 - learning_rate: 2.0589e-04\n",
      "Epoch 195/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 8.0926e-04 - val_loss: 0.0137 - learning_rate: 1.8530e-04\n",
      "Epoch 196/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 226ms/step - loss: 7.8806e-04 - val_loss: 0.0136 - learning_rate: 1.8530e-04\n",
      "Epoch 197/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - loss: 8.0678e-04 - val_loss: 0.0142 - learning_rate: 1.8530e-04\n",
      "Epoch 198/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 235ms/step - loss: 8.0691e-04 - val_loss: 0.0145 - learning_rate: 1.8530e-04\n",
      "Epoch 199/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 225ms/step - loss: 7.7049e-04 - val_loss: 0.0137 - learning_rate: 1.8530e-04\n",
      "Epoch 200/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 7.5018e-04 - val_loss: 0.0138 - learning_rate: 1.8530e-04\n",
      "Epoch 201/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 7.8473e-04 - val_loss: 0.0144 - learning_rate: 1.8530e-04\n",
      "Epoch 202/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 7.9076e-04 - val_loss: 0.0140 - learning_rate: 1.8530e-04\n",
      "Epoch 203/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 7.6549e-04 - val_loss: 0.0146 - learning_rate: 1.8530e-04\n",
      "Epoch 204/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 7.4691e-04\n",
      "Epoch 204: ReduceLROnPlateau reducing learning rate to 0.00016677183302817866.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 226ms/step - loss: 7.4736e-04 - val_loss: 0.0143 - learning_rate: 1.8530e-04\n",
      "Epoch 205/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 7.3025e-04 - val_loss: 0.0137 - learning_rate: 1.6677e-04\n",
      "Epoch 206/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 7.1599e-04 - val_loss: 0.0142 - learning_rate: 1.6677e-04\n",
      "Epoch 207/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 7.1627e-04 - val_loss: 0.0147 - learning_rate: 1.6677e-04\n",
      "Epoch 208/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 7.2592e-04 - val_loss: 0.0142 - learning_rate: 1.6677e-04\n",
      "Epoch 209/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - loss: 7.2093e-04 - val_loss: 0.0141 - learning_rate: 1.6677e-04\n",
      "Epoch 210/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 6.9740e-04 - val_loss: 0.0140 - learning_rate: 1.6677e-04\n",
      "Epoch 211/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 6.9202e-04 - val_loss: 0.0144 - learning_rate: 1.6677e-04\n",
      "Epoch 212/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 6.9917e-04 - val_loss: 0.0147 - learning_rate: 1.6677e-04\n",
      "Epoch 213/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 222ms/step - loss: 6.8719e-04 - val_loss: 0.0140 - learning_rate: 1.6677e-04\n",
      "Epoch 214/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 7.1806e-04\n",
      "Epoch 214: ReduceLROnPlateau reducing learning rate to 0.00015009464841568844.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 7.1619e-04 - val_loss: 0.0144 - learning_rate: 1.6677e-04\n",
      "Epoch 215/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 6.6655e-04 - val_loss: 0.0140 - learning_rate: 1.5009e-04\n",
      "Epoch 216/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 6.4099e-04 - val_loss: 0.0141 - learning_rate: 1.5009e-04\n",
      "Epoch 217/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 6.4358e-04 - val_loss: 0.0146 - learning_rate: 1.5009e-04\n",
      "Epoch 218/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 6.4295e-04 - val_loss: 0.0141 - learning_rate: 1.5009e-04\n",
      "Epoch 219/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 6.4760e-04 - val_loss: 0.0141 - learning_rate: 1.5009e-04\n",
      "Epoch 220/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 6.5231e-04 - val_loss: 0.0148 - learning_rate: 1.5009e-04\n",
      "Epoch 221/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 6.7770e-04 - val_loss: 0.0143 - learning_rate: 1.5009e-04\n",
      "Epoch 222/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 6.3788e-04 - val_loss: 0.0146 - learning_rate: 1.5009e-04\n",
      "Epoch 223/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 6.3086e-04 - val_loss: 0.0142 - learning_rate: 1.5009e-04\n",
      "Epoch 224/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 6.3486e-04\n",
      "Epoch 224: ReduceLROnPlateau reducing learning rate to 0.0001350851875031367.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 218ms/step - loss: 6.3521e-04 - val_loss: 0.0141 - learning_rate: 1.5009e-04\n",
      "Epoch 225/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 6.2472e-04 - val_loss: 0.0139 - learning_rate: 1.3509e-04\n",
      "Epoch 226/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 6.0627e-04 - val_loss: 0.0148 - learning_rate: 1.3509e-04\n",
      "Epoch 227/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 6.1445e-04 - val_loss: 0.0144 - learning_rate: 1.3509e-04\n",
      "Epoch 228/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 211ms/step - loss: 6.1259e-04 - val_loss: 0.0139 - learning_rate: 1.3509e-04\n",
      "Epoch 229/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 6.1270e-04 - val_loss: 0.0139 - learning_rate: 1.3509e-04\n",
      "Epoch 230/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 5.9906e-04 - val_loss: 0.0141 - learning_rate: 1.3509e-04\n",
      "Epoch 231/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 5.9702e-04 - val_loss: 0.0140 - learning_rate: 1.3509e-04\n",
      "Epoch 232/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 5.8277e-04 - val_loss: 0.0143 - learning_rate: 1.3509e-04\n",
      "Epoch 233/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 5.8867e-04 - val_loss: 0.0140 - learning_rate: 1.3509e-04\n",
      "Epoch 234/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 5.8167e-04\n",
      "Epoch 234: ReduceLROnPlateau reducing learning rate to 0.00012157666351413355.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 170ms/step - loss: 5.8195e-04 - val_loss: 0.0144 - learning_rate: 1.3509e-04\n",
      "Epoch 235/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 6.0866e-04 - val_loss: 0.0143 - learning_rate: 1.2158e-04\n",
      "Epoch 236/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 246ms/step - loss: 5.7697e-04 - val_loss: 0.0142 - learning_rate: 1.2158e-04\n",
      "Epoch 237/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 5.6502e-04 - val_loss: 0.0142 - learning_rate: 1.2158e-04\n",
      "Epoch 238/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 5.6900e-04 - val_loss: 0.0141 - learning_rate: 1.2158e-04\n",
      "Epoch 239/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 5.6546e-04 - val_loss: 0.0144 - learning_rate: 1.2158e-04\n",
      "Epoch 240/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 241ms/step - loss: 5.7068e-04 - val_loss: 0.0139 - learning_rate: 1.2158e-04\n",
      "Epoch 241/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 5.7740e-04 - val_loss: 0.0142 - learning_rate: 1.2158e-04\n",
      "Epoch 242/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 5.6393e-04 - val_loss: 0.0142 - learning_rate: 1.2158e-04\n",
      "Epoch 243/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 5.6010e-04 - val_loss: 0.0140 - learning_rate: 1.2158e-04\n",
      "Epoch 244/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 5.6182e-04\n",
      "Epoch 244: ReduceLROnPlateau reducing learning rate to 0.00010941899454337544.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 5.6164e-04 - val_loss: 0.0145 - learning_rate: 1.2158e-04\n",
      "Epoch 245/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - loss: 5.5858e-04 - val_loss: 0.0144 - learning_rate: 1.0942e-04\n",
      "Epoch 246/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 5.3682e-04 - val_loss: 0.0142 - learning_rate: 1.0942e-04\n",
      "Epoch 247/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 225ms/step - loss: 5.4291e-04 - val_loss: 0.0139 - learning_rate: 1.0942e-04\n",
      "Epoch 248/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 5.4452e-04 - val_loss: 0.0143 - learning_rate: 1.0942e-04\n",
      "Epoch 249/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 147ms/step - loss: 5.5863e-04 - val_loss: 0.0144 - learning_rate: 1.0942e-04\n",
      "Epoch 250/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 5.6193e-04 - val_loss: 0.0138 - learning_rate: 1.0942e-04\n",
      "Epoch 251/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - loss: 5.1440e-04 - val_loss: 0.0137 - learning_rate: 1.0942e-04\n",
      "Epoch 252/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 5.1732e-04 - val_loss: 0.0144 - learning_rate: 1.0942e-04\n",
      "Epoch 253/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 5.3425e-04 - val_loss: 0.0145 - learning_rate: 1.0942e-04\n",
      "Epoch 254/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 5.5692e-04\n",
      "Epoch 254: ReduceLROnPlateau reducing learning rate to 9.847709443420172e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 5.5610e-04 - val_loss: 0.0140 - learning_rate: 1.0942e-04\n",
      "Epoch 255/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 5.3683e-04 - val_loss: 0.0144 - learning_rate: 9.8477e-05\n",
      "Epoch 256/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 5.0843e-04 - val_loss: 0.0138 - learning_rate: 9.8477e-05\n",
      "Epoch 257/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 245ms/step - loss: 5.1009e-04 - val_loss: 0.0141 - learning_rate: 9.8477e-05\n",
      "Epoch 258/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 5.0265e-04 - val_loss: 0.0147 - learning_rate: 9.8477e-05\n",
      "Epoch 259/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 5.0927e-04 - val_loss: 0.0143 - learning_rate: 9.8477e-05\n",
      "Epoch 260/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 4.9398e-04 - val_loss: 0.0147 - learning_rate: 9.8477e-05\n",
      "Epoch 261/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 5.1150e-04 - val_loss: 0.0145 - learning_rate: 9.8477e-05\n",
      "Epoch 262/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 4.8788e-04 - val_loss: 0.0144 - learning_rate: 9.8477e-05\n",
      "Epoch 263/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 147ms/step - loss: 5.0107e-04 - val_loss: 0.0141 - learning_rate: 9.8477e-05\n",
      "Epoch 264/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 5.2903e-04\n",
      "Epoch 264: ReduceLROnPlateau reducing learning rate to 8.862938630045391e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 5.2989e-04 - val_loss: 0.0145 - learning_rate: 9.8477e-05\n",
      "Epoch 265/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - loss: 5.2475e-04 - val_loss: 0.0145 - learning_rate: 8.8629e-05\n",
      "Epoch 266/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 4.8916e-04 - val_loss: 0.0145 - learning_rate: 8.8629e-05\n",
      "Epoch 267/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 4.8708e-04 - val_loss: 0.0140 - learning_rate: 8.8629e-05\n",
      "Epoch 268/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 225ms/step - loss: 4.9263e-04 - val_loss: 0.0143 - learning_rate: 8.8629e-05\n",
      "Epoch 269/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 4.7852e-04 - val_loss: 0.0140 - learning_rate: 8.8629e-05\n",
      "Epoch 270/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 4.7818e-04 - val_loss: 0.0139 - learning_rate: 8.8629e-05\n",
      "Epoch 271/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 4.9761e-04 - val_loss: 0.0142 - learning_rate: 8.8629e-05\n",
      "Epoch 272/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - loss: 4.7565e-04 - val_loss: 0.0144 - learning_rate: 8.8629e-05\n",
      "Epoch 273/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - loss: 4.8508e-04 - val_loss: 0.0143 - learning_rate: 8.8629e-05\n",
      "Epoch 274/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 4.7084e-04\n",
      "Epoch 274: ReduceLROnPlateau reducing learning rate to 7.976644701557234e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 4.6997e-04 - val_loss: 0.0139 - learning_rate: 8.8629e-05\n",
      "Epoch 275/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 4.5880e-04 - val_loss: 0.0141 - learning_rate: 7.9766e-05\n",
      "Epoch 276/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 4.6075e-04 - val_loss: 0.0142 - learning_rate: 7.9766e-05\n",
      "Epoch 277/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 4.5123e-04 - val_loss: 0.0142 - learning_rate: 7.9766e-05\n",
      "Epoch 278/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 4.5220e-04 - val_loss: 0.0144 - learning_rate: 7.9766e-05\n",
      "Epoch 279/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 4.5289e-04 - val_loss: 0.0141 - learning_rate: 7.9766e-05\n",
      "Epoch 280/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - loss: 4.6106e-04 - val_loss: 0.0145 - learning_rate: 7.9766e-05\n",
      "Epoch 281/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 4.5360e-04 - val_loss: 0.0139 - learning_rate: 7.9766e-05\n",
      "Epoch 282/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 4.5025e-04 - val_loss: 0.0146 - learning_rate: 7.9766e-05\n",
      "Epoch 283/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 4.6086e-04 - val_loss: 0.0148 - learning_rate: 7.9766e-05\n",
      "Epoch 284/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 4.5246e-04\n",
      "Epoch 284: ReduceLROnPlateau reducing learning rate to 7.178980231401511e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 208ms/step - loss: 4.5236e-04 - val_loss: 0.0140 - learning_rate: 7.9766e-05\n",
      "Epoch 285/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 4.5111e-04 - val_loss: 0.0141 - learning_rate: 7.1790e-05\n",
      "Epoch 286/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - loss: 4.4530e-04 - val_loss: 0.0145 - learning_rate: 7.1790e-05\n",
      "Epoch 287/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 4.4602e-04 - val_loss: 0.0143 - learning_rate: 7.1790e-05\n",
      "Epoch 288/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 4.4808e-04 - val_loss: 0.0138 - learning_rate: 7.1790e-05\n",
      "Epoch 289/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 4.3713e-04 - val_loss: 0.0140 - learning_rate: 7.1790e-05\n",
      "Epoch 290/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 4.3045e-04 - val_loss: 0.0141 - learning_rate: 7.1790e-05\n",
      "Epoch 291/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 4.3572e-04 - val_loss: 0.0144 - learning_rate: 7.1790e-05\n",
      "Epoch 292/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - loss: 4.3938e-04 - val_loss: 0.0143 - learning_rate: 7.1790e-05\n",
      "Epoch 293/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 4.4378e-04 - val_loss: 0.0145 - learning_rate: 7.1790e-05\n",
      "Epoch 294/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 4.5087e-04\n",
      "Epoch 294: ReduceLROnPlateau reducing learning rate to 6.461082011810504e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 4.5013e-04 - val_loss: 0.0143 - learning_rate: 7.1790e-05\n",
      "Epoch 295/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 4.2924e-04 - val_loss: 0.0139 - learning_rate: 6.4611e-05\n",
      "Epoch 296/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 4.2839e-04 - val_loss: 0.0141 - learning_rate: 6.4611e-05\n",
      "Epoch 297/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 4.2173e-04 - val_loss: 0.0143 - learning_rate: 6.4611e-05\n",
      "Epoch 298/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 4.2194e-04 - val_loss: 0.0141 - learning_rate: 6.4611e-05\n",
      "Epoch 299/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 4.2833e-04 - val_loss: 0.0142 - learning_rate: 6.4611e-05\n",
      "Epoch 300/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - loss: 4.1715e-04 - val_loss: 0.0145 - learning_rate: 6.4611e-05\n",
      "Epoch 301/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - loss: 4.1913e-04 - val_loss: 0.0140 - learning_rate: 6.4611e-05\n",
      "Epoch 302/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 4.2821e-04 - val_loss: 0.0144 - learning_rate: 6.4611e-05\n",
      "Epoch 303/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 225ms/step - loss: 4.3387e-04 - val_loss: 0.0140 - learning_rate: 6.4611e-05\n",
      "Epoch 304/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 4.1392e-04\n",
      "Epoch 304: ReduceLROnPlateau reducing learning rate to 5.8149741380475466e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 4.1414e-04 - val_loss: 0.0147 - learning_rate: 6.4611e-05\n",
      "Epoch 305/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 4.2139e-04 - val_loss: 0.0141 - learning_rate: 5.8150e-05\n",
      "Epoch 306/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 143ms/step - loss: 3.9854e-04 - val_loss: 0.0142 - learning_rate: 5.8150e-05\n",
      "Epoch 307/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 4.0954e-04 - val_loss: 0.0145 - learning_rate: 5.8150e-05\n",
      "Epoch 308/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - loss: 4.1279e-04 - val_loss: 0.0143 - learning_rate: 5.8150e-05\n",
      "Epoch 309/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 4.0859e-04 - val_loss: 0.0141 - learning_rate: 5.8150e-05\n",
      "Epoch 310/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 3.9591e-04 - val_loss: 0.0142 - learning_rate: 5.8150e-05\n",
      "Epoch 311/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 4.1454e-04 - val_loss: 0.0145 - learning_rate: 5.8150e-05\n",
      "Epoch 312/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - loss: 4.0309e-04 - val_loss: 0.0141 - learning_rate: 5.8150e-05\n",
      "Epoch 313/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 3.9916e-04 - val_loss: 0.0140 - learning_rate: 5.8150e-05\n",
      "Epoch 314/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 4.1083e-04\n",
      "Epoch 314: ReduceLROnPlateau reducing learning rate to 5.233476658759173e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 4.1062e-04 - val_loss: 0.0145 - learning_rate: 5.8150e-05\n",
      "Epoch 315/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - loss: 3.9184e-04 - val_loss: 0.0143 - learning_rate: 5.2335e-05\n",
      "Epoch 316/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 4.0958e-04 - val_loss: 0.0142 - learning_rate: 5.2335e-05\n",
      "Epoch 317/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 3.9459e-04 - val_loss: 0.0140 - learning_rate: 5.2335e-05\n",
      "Epoch 318/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 3.9776e-04 - val_loss: 0.0146 - learning_rate: 5.2335e-05\n",
      "Epoch 319/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 4.1066e-04 - val_loss: 0.0145 - learning_rate: 5.2335e-05\n",
      "Epoch 320/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 4.0291e-04 - val_loss: 0.0139 - learning_rate: 5.2335e-05\n",
      "Epoch 321/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 3.9321e-04 - val_loss: 0.0144 - learning_rate: 5.2335e-05\n",
      "Epoch 322/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 4.0660e-04 - val_loss: 0.0144 - learning_rate: 5.2335e-05\n",
      "Epoch 323/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 4.0513e-04 - val_loss: 0.0142 - learning_rate: 5.2335e-05\n",
      "Epoch 324/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 3.9356e-04\n",
      "Epoch 324: ReduceLROnPlateau reducing learning rate to 4.7101289601414466e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - loss: 3.9323e-04 - val_loss: 0.0142 - learning_rate: 5.2335e-05\n",
      "Epoch 325/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 4.0021e-04 - val_loss: 0.0142 - learning_rate: 4.7101e-05\n",
      "Epoch 326/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 3.8284e-04 - val_loss: 0.0145 - learning_rate: 4.7101e-05\n",
      "Epoch 327/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 225ms/step - loss: 3.9233e-04 - val_loss: 0.0141 - learning_rate: 4.7101e-05\n",
      "Epoch 328/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 3.7764e-04 - val_loss: 0.0142 - learning_rate: 4.7101e-05\n",
      "Epoch 329/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 223ms/step - loss: 3.8867e-04 - val_loss: 0.0142 - learning_rate: 4.7101e-05\n",
      "Epoch 330/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - loss: 3.8630e-04 - val_loss: 0.0144 - learning_rate: 4.7101e-05\n",
      "Epoch 331/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 141ms/step - loss: 3.7974e-04 - val_loss: 0.0142 - learning_rate: 4.7101e-05\n",
      "Epoch 332/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 3.8328e-04 - val_loss: 0.0140 - learning_rate: 4.7101e-05\n",
      "Epoch 333/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 193ms/step - loss: 3.7257e-04 - val_loss: 0.0144 - learning_rate: 4.7101e-05\n",
      "Epoch 334/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 3.8176e-04\n",
      "Epoch 334: ReduceLROnPlateau reducing learning rate to 4.239116096869111e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 3.8184e-04 - val_loss: 0.0142 - learning_rate: 4.7101e-05\n",
      "Epoch 335/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 3.7081e-04 - val_loss: 0.0143 - learning_rate: 4.2391e-05\n",
      "Epoch 336/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 3.7006e-04 - val_loss: 0.0140 - learning_rate: 4.2391e-05\n",
      "Epoch 337/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 3.6088e-04 - val_loss: 0.0143 - learning_rate: 4.2391e-05\n",
      "Epoch 338/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - loss: 3.7260e-04 - val_loss: 0.0142 - learning_rate: 4.2391e-05\n",
      "Epoch 339/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - loss: 3.8046e-04 - val_loss: 0.0141 - learning_rate: 4.2391e-05\n",
      "Epoch 340/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 224ms/step - loss: 3.6809e-04 - val_loss: 0.0138 - learning_rate: 4.2391e-05\n",
      "Epoch 341/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 3.6868e-04 - val_loss: 0.0144 - learning_rate: 4.2391e-05\n",
      "Epoch 342/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 3.6175e-04 - val_loss: 0.0142 - learning_rate: 4.2391e-05\n",
      "Epoch 343/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 3.7636e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 16:08:22.979135: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - loss: 3.7643e-04 - val_loss: 0.0143 - learning_rate: 4.2391e-05\n",
      "Epoch 344/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 3.7443e-04\n",
      "Epoch 344: ReduceLROnPlateau reducing learning rate to 3.815204618149437e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 212ms/step - loss: 3.7432e-04 - val_loss: 0.0141 - learning_rate: 4.2391e-05\n",
      "Epoch 345/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 3.6568e-04 - val_loss: 0.0139 - learning_rate: 3.8152e-05\n",
      "Epoch 346/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 3.5209e-04 - val_loss: 0.0143 - learning_rate: 3.8152e-05\n",
      "Epoch 347/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 3.5551e-04 - val_loss: 0.0142 - learning_rate: 3.8152e-05\n",
      "Epoch 348/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 3.6195e-04 - val_loss: 0.0141 - learning_rate: 3.8152e-05\n",
      "Epoch 349/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 3.6425e-04 - val_loss: 0.0142 - learning_rate: 3.8152e-05\n",
      "Epoch 350/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 3.5923e-04 - val_loss: 0.0142 - learning_rate: 3.8152e-05\n",
      "Epoch 351/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 3.6126e-04 - val_loss: 0.0144 - learning_rate: 3.8152e-05\n",
      "Epoch 352/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 190ms/step - loss: 3.6337e-04 - val_loss: 0.0144 - learning_rate: 3.8152e-05\n",
      "Epoch 353/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 3.6464e-04 - val_loss: 0.0142 - learning_rate: 3.8152e-05\n",
      "Epoch 354/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 3.6165e-04\n",
      "Epoch 354: ReduceLROnPlateau reducing learning rate to 3.4336842873017304e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 3.6098e-04 - val_loss: 0.0139 - learning_rate: 3.8152e-05\n",
      "Epoch 355/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 3.5433e-04 - val_loss: 0.0139 - learning_rate: 3.4337e-05\n",
      "Epoch 356/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.5720e-04 - val_loss: 0.0143 - learning_rate: 3.4337e-05\n",
      "Epoch 357/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 3.5845e-04 - val_loss: 0.0141 - learning_rate: 3.4337e-05\n",
      "Epoch 358/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - loss: 3.4252e-04 - val_loss: 0.0141 - learning_rate: 3.4337e-05\n",
      "Epoch 359/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 3.4901e-04 - val_loss: 0.0143 - learning_rate: 3.4337e-05\n",
      "Epoch 360/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - loss: 3.4917e-04 - val_loss: 0.0142 - learning_rate: 3.4337e-05\n",
      "Epoch 361/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 3.5426e-04 - val_loss: 0.0142 - learning_rate: 3.4337e-05\n",
      "Epoch 362/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 3.6222e-04 - val_loss: 0.0144 - learning_rate: 3.4337e-05\n",
      "Epoch 363/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 223ms/step - loss: 3.4984e-04 - val_loss: 0.0142 - learning_rate: 3.4337e-05\n",
      "Epoch 364/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 3.4726e-04\n",
      "Epoch 364: ReduceLROnPlateau reducing learning rate to 3.0903160222806036e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 226ms/step - loss: 3.4763e-04 - val_loss: 0.0142 - learning_rate: 3.4337e-05\n",
      "Epoch 365/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - loss: 3.4095e-04 - val_loss: 0.0140 - learning_rate: 3.0903e-05\n",
      "Epoch 366/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 3.4190e-04 - val_loss: 0.0141 - learning_rate: 3.0903e-05\n",
      "Epoch 367/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 3.5043e-04 - val_loss: 0.0143 - learning_rate: 3.0903e-05\n",
      "Epoch 368/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 3.4344e-04 - val_loss: 0.0140 - learning_rate: 3.0903e-05\n",
      "Epoch 369/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 3.3382e-04 - val_loss: 0.0143 - learning_rate: 3.0903e-05\n",
      "Epoch 370/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 3.4810e-04 - val_loss: 0.0143 - learning_rate: 3.0903e-05\n",
      "Epoch 371/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 191ms/step - loss: 3.3816e-04 - val_loss: 0.0142 - learning_rate: 3.0903e-05\n",
      "Epoch 372/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 3.3941e-04 - val_loss: 0.0140 - learning_rate: 3.0903e-05\n",
      "Epoch 373/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 225ms/step - loss: 3.4047e-04 - val_loss: 0.0142 - learning_rate: 3.0903e-05\n",
      "Epoch 374/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 3.4838e-04\n",
      "Epoch 374: ReduceLROnPlateau reducing learning rate to 3e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 3.4796e-04 - val_loss: 0.0142 - learning_rate: 3.0903e-05\n",
      "Epoch 375/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 3.3608e-04 - val_loss: 0.0140 - learning_rate: 3.0000e-05\n",
      "Epoch 376/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - loss: 3.3612e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 377/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 3.2961e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 378/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 3.3582e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 379/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - loss: 3.4162e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 380/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 3.2772e-04 - val_loss: 0.0141 - learning_rate: 3.0000e-05\n",
      "Epoch 381/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 3.3580e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 382/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 3.3927e-04 - val_loss: 0.0141 - learning_rate: 3.0000e-05\n",
      "Epoch 383/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 3.4216e-04 - val_loss: 0.0141 - learning_rate: 3.0000e-05\n",
      "Epoch 384/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 3.4148e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 385/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - loss: 3.2567e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 386/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 225ms/step - loss: 3.3652e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 387/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 3.3382e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 388/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 3.4417e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 389/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - loss: 3.4485e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 390/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 3.2792e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 391/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 3.3308e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 392/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 3.2443e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 393/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - loss: 3.3234e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 394/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 3.3510e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 395/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 3.3711e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 396/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 3.4090e-04 - val_loss: 0.0141 - learning_rate: 3.0000e-05\n",
      "Epoch 397/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 3.3804e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 398/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 3.2692e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 399/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 214ms/step - loss: 3.3701e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 400/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3.3032e-04\n",
      "Epoch 400: Increasing exponent to 3\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 3.3036e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 401/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 3.3296e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 402/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 244ms/step - loss: 3.3239e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 403/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 226ms/step - loss: 3.3252e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 404/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 3.2948e-04 - val_loss: 0.0139 - learning_rate: 3.0000e-05\n",
      "Epoch 405/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 3.2211e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 406/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 3.3553e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 407/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 3.2707e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 408/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 3.2870e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 409/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 235ms/step - loss: 3.3915e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 410/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 225ms/step - loss: 3.1944e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 411/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 3.2614e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 412/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 3.2512e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 413/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - loss: 3.2880e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 414/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 226ms/step - loss: 3.3185e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 415/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 3.2463e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 416/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 3.1934e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 417/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 3.2923e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 418/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 3.2262e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 419/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 3.1608e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 420/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 144ms/step - loss: 3.1335e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 421/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.2317e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 422/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - loss: 3.1659e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 423/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - loss: 3.2951e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 424/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 226ms/step - loss: 3.2065e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 425/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 3.1821e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 426/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 3.0950e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 427/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 3.1552e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 428/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - loss: 3.2094e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 429/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 3.1227e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 430/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 3.2541e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 431/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 3.1951e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 432/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - loss: 3.1305e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 433/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 3.1222e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 434/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - loss: 3.1174e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 435/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 3.2125e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 436/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 143ms/step - loss: 3.0917e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 437/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 3.1321e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 438/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - loss: 3.1935e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 439/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 3.1915e-04 - val_loss: 0.0141 - learning_rate: 3.0000e-05\n",
      "Epoch 440/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 3.2295e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 441/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 3.0660e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 442/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 3.0710e-04 - val_loss: 0.0141 - learning_rate: 3.0000e-05\n",
      "Epoch 443/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 3.1340e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 444/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 3.1250e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 445/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 3.1061e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 446/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 223ms/step - loss: 3.2583e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 447/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 3.1166e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 448/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 3.1429e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 449/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 3.1493e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 450/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - loss: 3.1629e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 451/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 3.1325e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 452/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 3.1546e-04 - val_loss: 0.0141 - learning_rate: 3.0000e-05\n",
      "Epoch 453/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 3.0830e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 454/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - loss: 3.0424e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 455/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 3.0808e-04 - val_loss: 0.0140 - learning_rate: 3.0000e-05\n",
      "Epoch 456/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 3.1471e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 457/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 3.1406e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 458/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 189ms/step - loss: 3.0085e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 459/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 214ms/step - loss: 3.1076e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 460/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - loss: 2.9856e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 461/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 3.0130e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 462/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 3.1683e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 463/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 3.1149e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 464/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - loss: 2.9106e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 465/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 3.0122e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 466/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 3.0575e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 467/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 3.0578e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 468/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 140ms/step - loss: 3.1083e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 469/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 3.0044e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 470/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 191ms/step - loss: 3.0602e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 471/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 3.0948e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 472/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 235ms/step - loss: 3.0309e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 473/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 3.0020e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 474/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 3.0478e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 475/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 3.0683e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 476/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - loss: 2.9938e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 477/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 3.0464e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 478/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 3.0347e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 479/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 3.0140e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 480/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 3.0238e-04 - val_loss: 0.0141 - learning_rate: 3.0000e-05\n",
      "Epoch 481/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.9489e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 482/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.8879e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 483/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 2.9517e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 484/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.9965e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 485/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - loss: 2.9449e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 486/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - loss: 2.9062e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 487/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.9176e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 488/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 3.0709e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 489/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 3.0731e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 490/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 3.0139e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 491/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 142ms/step - loss: 3.0667e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 492/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 146ms/step - loss: 2.9657e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 493/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 2.9852e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 494/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - loss: 3.0324e-04 - val_loss: 0.0141 - learning_rate: 3.0000e-05\n",
      "Epoch 495/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 2.8777e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 496/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.9568e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 497/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 2.9697e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 498/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.9029e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 499/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 225ms/step - loss: 2.9733e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 500/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 2.9553e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 501/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 3.0337e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 502/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 3.0597e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 503/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.8995e-04 - val_loss: 0.0141 - learning_rate: 3.0000e-05\n",
      "Epoch 504/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 2.9182e-04 - val_loss: 0.0141 - learning_rate: 3.0000e-05\n",
      "Epoch 505/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - loss: 2.8848e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 506/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 235ms/step - loss: 2.9014e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 507/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 2.9480e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 508/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.8918e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 509/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.9242e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 510/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 2.8950e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 511/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.8291e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 512/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 2.8146e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 513/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 2.9473e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 514/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 223ms/step - loss: 2.8436e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 515/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 2.8643e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 516/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 2.8201e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 517/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.8289e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 518/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - loss: 2.8447e-04 - val_loss: 0.0141 - learning_rate: 3.0000e-05\n",
      "Epoch 519/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.8975e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 520/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 3.0320e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 521/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.9419e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 522/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.8699e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 523/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.8122e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 524/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.8069e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 525/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.8586e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 526/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 2.9011e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 527/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 2.8064e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 528/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 194ms/step - loss: 2.8885e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 529/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.7875e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 530/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.7885e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 531/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 2.7639e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 532/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 2.8088e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 533/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 137ms/step - loss: 2.8403e-04 - val_loss: 0.0140 - learning_rate: 3.0000e-05\n",
      "Epoch 534/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 143ms/step - loss: 2.7833e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 535/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 2.7697e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 536/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - loss: 2.8173e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 537/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.8411e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 538/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - loss: 2.7672e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 539/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.8520e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 540/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.7113e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 541/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.7587e-04 - val_loss: 0.0141 - learning_rate: 3.0000e-05\n",
      "Epoch 542/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 2.6808e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 543/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 2.6870e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 544/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 194ms/step - loss: 2.8069e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 545/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 2.7930e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 546/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.8436e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 547/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.7883e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 548/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.7607e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 549/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.8001e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 550/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 2.7713e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 551/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - loss: 2.7063e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 552/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 2.6994e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 553/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 2.6895e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 554/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - loss: 2.7045e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 555/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 2.8297e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 556/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 130ms/step - loss: 2.6991e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 557/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 206ms/step - loss: 2.7470e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 558/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.7268e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 559/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 2.7304e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 560/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.6434e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 561/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - loss: 2.7197e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 562/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 2.6834e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 563/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 2.8434e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 564/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 183ms/step - loss: 2.8215e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 565/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.6877e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 566/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.7522e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 567/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 2.6174e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 568/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 2.6263e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 569/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 2.6105e-04 - val_loss: 0.0141 - learning_rate: 3.0000e-05\n",
      "Epoch 570/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 149ms/step - loss: 2.7305e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 571/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 2.7179e-04 - val_loss: 0.0141 - learning_rate: 3.0000e-05\n",
      "Epoch 572/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 2.6515e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 573/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.7255e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 574/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.6139e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 575/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 2.7028e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 576/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.7717e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 577/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 2.5291e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 578/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 2.6432e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 579/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 2.7056e-04 - val_loss: 0.0141 - learning_rate: 3.0000e-05\n",
      "Epoch 580/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - loss: 2.6444e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 581/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.5807e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 582/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 225ms/step - loss: 2.5748e-04 - val_loss: 0.0141 - learning_rate: 3.0000e-05\n",
      "Epoch 583/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 2.6210e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 584/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.6336e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 585/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.6663e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 586/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 2.6054e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 587/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 2.5708e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 588/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 2.5895e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 589/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 2.6859e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 590/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 2.5774e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 591/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - loss: 2.6071e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 592/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.5851e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 593/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 170ms/step - loss: 2.6101e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 594/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.6106e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 595/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - loss: 2.8088e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 596/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 235ms/step - loss: 2.7373e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 597/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - loss: 2.5657e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 598/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - loss: 2.6944e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 599/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.6500e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 600/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 2.6519e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 601/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.6209e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 602/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 2.6780e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 603/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.6292e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 604/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 2.5540e-04 - val_loss: 0.0141 - learning_rate: 3.0000e-05\n",
      "Epoch 605/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.6993e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 606/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - loss: 2.6941e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 607/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.6288e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 608/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.6592e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 609/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.6301e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 610/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - loss: 2.6161e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 611/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - loss: 2.6775e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 612/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 2.6413e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 613/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 2.5139e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 614/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 142ms/step - loss: 2.6337e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 615/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - loss: 2.6095e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 616/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - loss: 2.5158e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 617/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - loss: 2.5314e-04 - val_loss: 0.0152 - learning_rate: 3.0000e-05\n",
      "Epoch 618/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 2.5577e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 619/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 144ms/step - loss: 2.5629e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 620/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 2.5681e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 621/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - loss: 2.5019e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 622/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.6156e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 623/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 2.6010e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 624/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.5681e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 625/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 242ms/step - loss: 2.4936e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 626/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 223ms/step - loss: 2.5640e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 627/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.5002e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 628/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 235ms/step - loss: 2.5053e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 629/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.5789e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 630/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 2.5644e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 631/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - loss: 2.4390e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 632/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 144ms/step - loss: 2.5799e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 633/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 2.5069e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 634/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - loss: 2.5808e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 635/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.5489e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 636/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.5990e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 637/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.5135e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 638/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - loss: 2.4940e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 639/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.5245e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 640/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 129ms/step - loss: 2.5542e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 641/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 208ms/step - loss: 2.5020e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 642/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.4869e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 643/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.6130e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 644/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.4638e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 645/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.4947e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 646/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.4465e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 647/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 2.4535e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 648/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 2.4481e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 649/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - loss: 2.5074e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 650/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.4570e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 651/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.4526e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 652/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.4201e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 653/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.5116e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 654/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 2.4209e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 655/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.3933e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 656/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - loss: 2.4855e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 657/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.5145e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 658/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 226ms/step - loss: 2.4575e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 659/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.4290e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 660/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - loss: 2.5474e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 661/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 244ms/step - loss: 2.4652e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 662/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.4126e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 663/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.4685e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 664/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 223ms/step - loss: 2.4328e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 665/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.4112e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 666/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - loss: 2.5298e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 667/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - loss: 2.5214e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 668/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - loss: 2.4955e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 669/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 2.4168e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 670/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.3679e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 671/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 2.4255e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 672/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - loss: 2.3917e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 673/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.4188e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 674/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 2.3679e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 675/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.4487e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 676/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.3991e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 677/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 2.4014e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 678/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 2.4286e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 679/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.4251e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 680/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 2.4307e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 681/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 223ms/step - loss: 2.2542e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 682/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 2.3544e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 683/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 2.4389e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 684/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - loss: 2.3555e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 685/1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 16:36:15.260960: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.3319e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 686/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.3851e-04 - val_loss: 0.0153 - learning_rate: 3.0000e-05\n",
      "Epoch 687/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 2.4261e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 688/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - loss: 2.3370e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 689/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - loss: 2.2605e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 690/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.4374e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 691/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.3656e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 692/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.3283e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 693/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 2.4584e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 694/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 146ms/step - loss: 2.3985e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 695/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.3508e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 696/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - loss: 2.4135e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 697/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.4197e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 698/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.3135e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 699/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.2979e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 700/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.3835e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 701/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 2.3322e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 702/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.4049e-04 - val_loss: 0.0151 - learning_rate: 3.0000e-05\n",
      "Epoch 703/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - loss: 2.2869e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 704/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 2.3431e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 705/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.2818e-04 - val_loss: 0.0151 - learning_rate: 3.0000e-05\n",
      "Epoch 706/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.4405e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 707/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.3866e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 708/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 2.3364e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 709/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - loss: 2.3330e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 710/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 2.2911e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 711/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 2.3434e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 712/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.3090e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 713/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.3714e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 714/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - loss: 2.4279e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 715/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 226ms/step - loss: 2.2891e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 716/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.3327e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 717/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.3514e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 718/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 2.2563e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 719/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 2.3078e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 720/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - loss: 2.2751e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 721/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.2778e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 722/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.3537e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 723/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 2.2674e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 724/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 2.1646e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 725/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 190ms/step - loss: 2.2362e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 726/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 2.2618e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 727/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.2911e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 728/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - loss: 2.3368e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 729/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.2326e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 730/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 2.2164e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 731/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.3225e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 732/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 2.1238e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 733/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.2709e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 734/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - loss: 2.3274e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 735/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 2.2858e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 736/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.1641e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 737/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.3552e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 738/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.3389e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 739/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.2037e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 740/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 2.2185e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 741/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - loss: 2.3717e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 742/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 2.3147e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 743/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 2.2751e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 744/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 2.2017e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 745/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 227ms/step - loss: 2.1923e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 746/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 2.2476e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 747/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.2602e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 748/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 2.2198e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 749/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.2268e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 750/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.1883e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 751/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - loss: 2.1488e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 752/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.2816e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 753/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.2159e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 754/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - loss: 2.1790e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 755/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 2.2545e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 756/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 2.2509e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 757/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.2108e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 758/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 2.2260e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 759/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 179ms/step - loss: 2.1363e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 760/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 2.2312e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 761/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.1912e-04 - val_loss: 0.0151 - learning_rate: 3.0000e-05\n",
      "Epoch 762/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - loss: 2.1708e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 763/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 2.2333e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 764/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.1593e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 765/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.2136e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 766/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.2028e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 767/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.1681e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 768/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - loss: 2.1672e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 769/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 209ms/step - loss: 2.2197e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 770/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.1496e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 771/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 2.2312e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 772/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.1948e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 773/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 183ms/step - loss: 2.1900e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 774/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.2199e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 775/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.3217e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 776/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 2.2185e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 777/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.1434e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 778/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 2.2171e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 779/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 2.2111e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 780/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.1806e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 781/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - loss: 2.1095e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 782/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 2.1471e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 783/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 226ms/step - loss: 2.1638e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 784/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - loss: 2.1305e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 785/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 2.1407e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 786/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.1671e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 787/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.1151e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 788/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 2.1480e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 789/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 143ms/step - loss: 2.1596e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 790/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.1243e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 791/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - loss: 2.1215e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 792/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.1150e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 793/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.1560e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 794/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.0943e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 795/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 226ms/step - loss: 2.1080e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 796/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 2.0883e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 797/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.1497e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 798/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 183ms/step - loss: 2.1575e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 799/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.1591e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 800/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 2.1474e-04\n",
      "Epoch 800: Increasing exponent to 4\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.1467e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 801/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.1235e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 802/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 223ms/step - loss: 2.1341e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 803/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 2.0318e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 804/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 2.1156e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 805/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.0933e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 806/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 2.0966e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 807/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.0959e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 808/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 2.1564e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 809/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.1388e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 810/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 225ms/step - loss: 2.0137e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 811/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.0547e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 812/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.0993e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 813/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 2.0944e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 814/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - loss: 2.0979e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 815/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.1507e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 816/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - loss: 2.1491e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 817/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 2.0981e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 818/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.9970e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 819/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 183ms/step - loss: 2.1271e-04 - val_loss: 0.0151 - learning_rate: 3.0000e-05\n",
      "Epoch 820/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.1334e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 821/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.1246e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 822/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 2.1057e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 823/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 2.1083e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 824/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - loss: 2.0607e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 825/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 2.1160e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 826/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 130ms/step - loss: 2.0726e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 827/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 211ms/step - loss: 2.1070e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 828/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 226ms/step - loss: 2.0086e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 829/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.9827e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 830/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 211ms/step - loss: 2.1520e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 831/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 235ms/step - loss: 2.0430e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 832/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 2.0137e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 833/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.1068e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 834/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 179ms/step - loss: 2.0106e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 835/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 226ms/step - loss: 2.0229e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 836/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.9213e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 837/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.0335e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 838/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 2.0255e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 839/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.1162e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 840/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 2.0464e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 841/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - loss: 1.9965e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 842/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.0838e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 843/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - loss: 2.0788e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 844/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.0575e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 845/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 2.0834e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 846/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.9672e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 847/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - loss: 1.9244e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 848/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.0042e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 849/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.0615e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 850/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.0346e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 851/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 2.0642e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 852/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 2.0152e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 853/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 2.0116e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 854/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.0635e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 855/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.9581e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 856/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 2.0417e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 857/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - loss: 1.9764e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 858/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 1.9001e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 859/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 2.0815e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 860/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 225ms/step - loss: 1.9305e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 861/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 1.9830e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 862/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - loss: 1.9645e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 863/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 2.0000e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 864/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.9682e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 865/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.9603e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 866/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 2.0026e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 867/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 1.9309e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 868/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.9561e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 869/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - loss: 1.9644e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 870/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 1.9123e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 871/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.8933e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 872/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 227ms/step - loss: 1.9998e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 873/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.0750e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 874/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.9907e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 875/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 144ms/step - loss: 1.9336e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 876/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 1.9263e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 877/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 179ms/step - loss: 2.0248e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 878/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 2.0588e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 879/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 1.9492e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 880/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.9828e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 881/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 2.0091e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 882/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 1.9119e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 883/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.9665e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 884/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - loss: 2.0942e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 885/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.9412e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 886/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 212ms/step - loss: 1.9911e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 887/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 212ms/step - loss: 1.9092e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 888/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 227ms/step - loss: 1.8778e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 889/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 2.0022e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 890/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.8195e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 891/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - loss: 1.9224e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 892/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 1.9014e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 893/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.9473e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 894/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 2.0350e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 895/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 2.0161e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 896/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 222ms/step - loss: 2.0425e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 897/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 223ms/step - loss: 1.9953e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 898/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.8948e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 899/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.8784e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 900/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.9038e-04 - val_loss: 0.0151 - learning_rate: 3.0000e-05\n",
      "Epoch 901/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.8912e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 902/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 183ms/step - loss: 1.8588e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 903/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.9161e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 904/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.8383e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 905/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 1.9068e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 906/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 226ms/step - loss: 1.8734e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 907/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 1.8436e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 908/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.9898e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 909/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 1.8932e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 910/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 1.8974e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 911/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 1.9919e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 912/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.8910e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 913/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 226ms/step - loss: 1.9546e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 914/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.9243e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 915/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.8610e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 916/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - loss: 1.9070e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 917/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.9477e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 918/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.8229e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 919/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.8936e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 920/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 1.8554e-04 - val_loss: 0.0152 - learning_rate: 3.0000e-05\n",
      "Epoch 921/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.9210e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 922/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 243ms/step - loss: 1.8391e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 923/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.8756e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 924/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 224ms/step - loss: 1.9054e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 925/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 1.9413e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 926/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 1.8814e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 927/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 1.9740e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 928/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 1.9218e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 929/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 2.0035e-04 - val_loss: 0.0151 - learning_rate: 3.0000e-05\n",
      "Epoch 930/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.8778e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 931/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.8759e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 932/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.8824e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 933/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.9289e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 934/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.8438e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 935/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.8597e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 936/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.8326e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 937/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.8732e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 938/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.8425e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 939/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 207ms/step - loss: 1.8640e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 940/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 216ms/step - loss: 1.8695e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 941/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - loss: 1.7870e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 942/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 1.9879e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 943/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 128ms/step - loss: 1.9358e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 944/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 194ms/step - loss: 1.8244e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 945/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 218ms/step - loss: 1.8722e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 946/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 196ms/step - loss: 1.7410e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 947/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 219ms/step - loss: 1.7445e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 948/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.8658e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 949/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 1.8999e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 950/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 1.8722e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 951/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 218ms/step - loss: 1.8916e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 952/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 215ms/step - loss: 1.9009e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 953/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 1.8193e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 954/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 222ms/step - loss: 1.9100e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 955/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 1.8502e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 956/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 1.7430e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 957/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 215ms/step - loss: 1.7630e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 958/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.8328e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 959/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.9183e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 960/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 1.8473e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 961/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 1.7941e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 962/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 219ms/step - loss: 1.8295e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 963/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 1.7269e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 964/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 1.7894e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 965/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - loss: 1.7862e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 966/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 223ms/step - loss: 1.8629e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 967/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 218ms/step - loss: 1.8272e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 968/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - loss: 1.7758e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 969/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - loss: 1.7793e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 970/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.7833e-04 - val_loss: 0.0151 - learning_rate: 3.0000e-05\n",
      "Epoch 971/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.8565e-04 - val_loss: 0.0141 - learning_rate: 3.0000e-05\n",
      "Epoch 972/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 1.8333e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 973/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 216ms/step - loss: 1.7640e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 974/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 222ms/step - loss: 1.6868e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 975/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 1.7661e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 976/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - loss: 1.8021e-04 - val_loss: 0.0152 - learning_rate: 3.0000e-05\n",
      "Epoch 977/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 219ms/step - loss: 1.8097e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 978/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 1.7795e-04 - val_loss: 0.0142 - learning_rate: 3.0000e-05\n",
      "Epoch 979/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.7595e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 980/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.7969e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 981/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - loss: 1.7114e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 982/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 221ms/step - loss: 1.7547e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 983/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 222ms/step - loss: 1.7622e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 984/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 1.7908e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 985/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 219ms/step - loss: 1.7992e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 986/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 1.7143e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 987/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 218ms/step - loss: 1.8223e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 988/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 1.7937e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 989/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 1.8240e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 990/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 1.7030e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 991/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 219ms/step - loss: 1.7709e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 992/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 225ms/step - loss: 1.7065e-04 - val_loss: 0.0151 - learning_rate: 3.0000e-05\n",
      "Epoch 993/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 1.9211e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 994/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 207ms/step - loss: 1.8010e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 995/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 1.7447e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 996/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 207ms/step - loss: 1.8022e-04 - val_loss: 0.0152 - learning_rate: 3.0000e-05\n",
      "Epoch 997/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8353e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 998/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 1.8567e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 999/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 1.8101e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1000/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 226ms/step - loss: 1.7707e-04 - val_loss: 0.0151 - learning_rate: 3.0000e-05\n",
      "Epoch 1001/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 199ms/step - loss: 1.8374e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1002/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 225ms/step - loss: 1.6763e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1003/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 221ms/step - loss: 1.7279e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1004/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 219ms/step - loss: 1.6730e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1005/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 216ms/step - loss: 1.7325e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1006/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.6744e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 1007/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 1.7894e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1008/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - loss: 1.7705e-04 - val_loss: 0.0151 - learning_rate: 3.0000e-05\n",
      "Epoch 1009/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.7614e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 1010/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - loss: 1.6750e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1011/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 213ms/step - loss: 1.7827e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1012/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.6998e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1013/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.6593e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1014/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - loss: 1.6611e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 1015/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 1.8587e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1016/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - loss: 1.8254e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1017/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 1.8245e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1018/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 218ms/step - loss: 1.7491e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 1019/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.7091e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1020/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.7516e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1021/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - loss: 1.7362e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1022/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 1.6884e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1023/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 223ms/step - loss: 1.6857e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1024/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 221ms/step - loss: 1.7426e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1025/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 218ms/step - loss: 1.7328e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 1026/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.7583e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1027/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.6920e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1028/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - loss: 1.7130e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1029/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 225ms/step - loss: 1.7570e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1030/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 1.7769e-04 - val_loss: 0.0151 - learning_rate: 3.0000e-05\n",
      "Epoch 1031/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 213ms/step - loss: 1.7139e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1032/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 199ms/step - loss: 1.7035e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1033/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 1.7786e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1034/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 1.7122e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1035/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 219ms/step - loss: 1.7445e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1036/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 216ms/step - loss: 1.6421e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 1037/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - loss: 1.8128e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 1038/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 1.7924e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1039/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 218ms/step - loss: 1.6095e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1040/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.6725e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1041/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 1.6652e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1042/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - loss: 1.6719e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1043/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 223ms/step - loss: 1.6909e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1044/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - loss: 1.6917e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1045/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 1.6518e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 1046/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.6334e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1047/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 228ms/step - loss: 1.7628e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1048/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 221ms/step - loss: 1.6288e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1049/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.6468e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1050/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.8153e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1051/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 170ms/step - loss: 1.6775e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1052/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 216ms/step - loss: 1.6948e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 1053/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 222ms/step - loss: 1.7413e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1054/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 222ms/step - loss: 1.6572e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1055/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 1.7071e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 1056/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 1.6953e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1057/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 1.6050e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1058/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.6360e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1059/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6168e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1060/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 1.6449e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1061/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 205ms/step - loss: 1.7222e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1062/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 216ms/step - loss: 1.7300e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1063/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 218ms/step - loss: 1.6398e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1064/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 1.6321e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1065/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - loss: 1.6202e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1066/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.7093e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 1067/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 137ms/step - loss: 1.7095e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1068/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 1.6108e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1069/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 1.7008e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1070/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 221ms/step - loss: 1.6315e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1071/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.6210e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1072/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 235ms/step - loss: 1.6729e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1073/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 215ms/step - loss: 1.6900e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1074/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 216ms/step - loss: 1.5815e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1075/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 216ms/step - loss: 1.6083e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1076/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - loss: 1.7190e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1077/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 1.6701e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1078/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 218ms/step - loss: 1.6520e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1079/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 1.5960e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1080/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - loss: 1.5730e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1081/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 215ms/step - loss: 1.5601e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1082/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 216ms/step - loss: 1.6410e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1083/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 1.6957e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1084/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 216ms/step - loss: 1.6298e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 1085/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 1.6228e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1086/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 1.6377e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1087/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6163e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1088/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 167ms/step - loss: 1.7242e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1089/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 213ms/step - loss: 1.5610e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1090/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 223ms/step - loss: 1.6488e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1091/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 1.6590e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1092/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 219ms/step - loss: 1.7231e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1093/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.7014e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1094/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 1.6047e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 1095/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 1.6260e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1096/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 219ms/step - loss: 1.6082e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1097/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - loss: 1.5702e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 1098/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.5632e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1099/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.5917e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1100/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 1.5721e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1101/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 194ms/step - loss: 1.6949e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1102/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.7242e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1103/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 1.6812e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1104/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - loss: 1.6064e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1105/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.5082e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1106/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - loss: 1.5649e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1107/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.6507e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1108/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5730e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1109/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 1.6099e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1110/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - loss: 1.5685e-04 - val_loss: 0.0151 - learning_rate: 3.0000e-05\n",
      "Epoch 1111/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.5400e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1112/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 1.5516e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1113/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.5782e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1114/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.5849e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1115/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - loss: 1.6281e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1116/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 169ms/step - loss: 1.6668e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1117/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 1.6861e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1118/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.7368e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1119/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 172ms/step - loss: 1.5987e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1120/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 145ms/step - loss: 1.6227e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1121/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 1.5843e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1122/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 1.6342e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1123/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.5818e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1124/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.5823e-04 - val_loss: 0.0151 - learning_rate: 3.0000e-05\n",
      "Epoch 1125/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 1.6049e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1126/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.5211e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1127/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 1.5294e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 1128/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 144ms/step - loss: 1.5258e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 1129/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.5412e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1130/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 191ms/step - loss: 1.5196e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1131/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 222ms/step - loss: 1.6628e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1132/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 1.4925e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1133/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - loss: 1.5594e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1134/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - loss: 1.5197e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1135/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.5005e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1136/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.5265e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1137/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 1.6043e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1138/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.5676e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1139/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 189ms/step - loss: 1.6629e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1140/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.5756e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1141/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.5213e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1142/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.5040e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1143/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.5658e-04 - val_loss: 0.0153 - learning_rate: 3.0000e-05\n",
      "Epoch 1144/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.6155e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1145/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.5988e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1146/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - loss: 1.5958e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1147/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.6155e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1148/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 225ms/step - loss: 1.5724e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1149/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 1.4931e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1150/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 1.5125e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 1151/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - loss: 1.5403e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 1152/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 1.4779e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1153/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.5225e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1154/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.4946e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1155/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 1.5315e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1156/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.5273e-04 - val_loss: 0.0152 - learning_rate: 3.0000e-05\n",
      "Epoch 1157/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 1.5120e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1158/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.6072e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1159/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.5622e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1160/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - loss: 1.5124e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1161/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.5049e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1162/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.5240e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1163/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 1.5468e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1164/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - loss: 1.5391e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1165/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.4646e-04 - val_loss: 0.0151 - learning_rate: 3.0000e-05\n",
      "Epoch 1166/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - loss: 1.5198e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1167/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 141ms/step - loss: 1.5705e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1168/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - loss: 1.4701e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1169/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 1.5997e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 1170/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.5549e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 1171/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 1.4328e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 1172/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 236ms/step - loss: 1.4652e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1173/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.4872e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1174/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.4237e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1175/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.4687e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1176/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 223ms/step - loss: 1.5825e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1177/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - loss: 1.5607e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1178/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 1.5736e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 1179/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 144ms/step - loss: 1.5788e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1180/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 1.4256e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1181/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 1.5590e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1182/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.5864e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1183/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 1.5243e-04 - val_loss: 0.0152 - learning_rate: 3.0000e-05\n",
      "Epoch 1184/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 1.6296e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1185/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 1.4609e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1186/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - loss: 1.5258e-04 - val_loss: 0.0151 - learning_rate: 3.0000e-05\n",
      "Epoch 1187/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.4803e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1188/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 244ms/step - loss: 1.4927e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 1189/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.4092e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1190/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 1.4313e-04 - val_loss: 0.0151 - learning_rate: 3.0000e-05\n",
      "Epoch 1191/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 1.5266e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1192/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 200ms/step - loss: 1.5530e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1193/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 1.4757e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1194/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 242ms/step - loss: 1.4760e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1195/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 1.4645e-04 - val_loss: 0.0151 - learning_rate: 3.0000e-05\n",
      "Epoch 1196/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.5466e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 1197/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 224ms/step - loss: 1.4350e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1198/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 1.5185e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1199/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 1.5056e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1200/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 1.4894e-04\n",
      "Epoch 1200: Increasing exponent to 5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.4882e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1201/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.4671e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1202/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - loss: 1.4912e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1203/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 1.4799e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1204/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.4547e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 1205/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 1.5821e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1206/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.4698e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1207/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 1.5098e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1208/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 1.4232e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1209/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 1.4706e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1210/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.4286e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1211/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.4745e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 1212/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 235ms/step - loss: 1.4968e-04 - val_loss: 0.0154 - learning_rate: 3.0000e-05\n",
      "Epoch 1213/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 1.5605e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1214/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.5254e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1215/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 243ms/step - loss: 1.3529e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 1216/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.4411e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1217/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 1.5141e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1218/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - loss: 1.4620e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1219/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.5379e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 1220/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 1.4669e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1221/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 1.4283e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1222/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - loss: 1.4842e-04 - val_loss: 0.0151 - learning_rate: 3.0000e-05\n",
      "Epoch 1223/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 142ms/step - loss: 1.5476e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1224/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 1.5083e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1225/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - loss: 1.4402e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1226/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.4532e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1227/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 235ms/step - loss: 1.4653e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1228/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.4795e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 1229/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.4291e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1230/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.4797e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1231/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 141ms/step - loss: 1.4739e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1232/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 1.4589e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1233/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - loss: 1.4514e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1234/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.5195e-04 - val_loss: 0.0152 - learning_rate: 3.0000e-05\n",
      "Epoch 1235/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 223ms/step - loss: 1.5227e-04 - val_loss: 0.0152 - learning_rate: 3.0000e-05\n",
      "Epoch 1236/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.4084e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1237/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 226ms/step - loss: 1.4151e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 1238/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - loss: 1.5227e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1239/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.4544e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1240/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.4170e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1241/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - loss: 1.3692e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1242/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - loss: 1.4347e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 1243/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.4723e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1244/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 217ms/step - loss: 1.4034e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1245/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - loss: 1.3589e-04 - val_loss: 0.0152 - learning_rate: 3.0000e-05\n",
      "Epoch 1246/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 1.4051e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 1247/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - loss: 1.4497e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 1248/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.4605e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1249/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.3780e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 1250/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 141ms/step - loss: 1.3474e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1251/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.5138e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1252/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - loss: 1.3939e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1253/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 1.3699e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1254/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.3824e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1255/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 1.3539e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1256/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.3809e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 1257/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.3866e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1258/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - loss: 1.3671e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 1259/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - loss: 1.3462e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1260/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.4694e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 1261/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.3786e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 1262/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - loss: 1.3943e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1263/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.3801e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1264/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.3941e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1265/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.4002e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1266/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - loss: 1.4788e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1267/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - loss: 1.4332e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1268/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.3624e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1269/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.3925e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1270/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - loss: 1.4949e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1271/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - loss: 1.4184e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1272/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.3741e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1273/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.3804e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1274/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 225ms/step - loss: 1.4271e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1275/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 1.2733e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 1276/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.3173e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1277/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.4877e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1278/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - loss: 1.4384e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1279/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.4163e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 1280/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.4965e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1281/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 1.3210e-04 - val_loss: 0.0151 - learning_rate: 3.0000e-05\n",
      "Epoch 1282/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 1.3010e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1283/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 1.3688e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1284/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 225ms/step - loss: 1.4037e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 1285/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 1.3452e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1286/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - loss: 1.3644e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 1287/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 129ms/step - loss: 1.4072e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1288/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 244ms/step - loss: 1.3396e-04 - val_loss: 0.0152 - learning_rate: 3.0000e-05\n",
      "Epoch 1289/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 1.3539e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1290/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.4145e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1291/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 1.4573e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1292/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - loss: 1.4063e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1293/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.3062e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1294/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 1.3893e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1295/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.3233e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1296/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - loss: 1.4356e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1297/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - loss: 1.4062e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1298/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.4293e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 1299/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - loss: 1.3777e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 1300/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.3616e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1301/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - loss: 1.3763e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1302/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.3174e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1303/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 1.4215e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1304/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.3454e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1305/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - loss: 1.3677e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1306/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.3679e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1307/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.3613e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1308/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 1.3548e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1309/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.4129e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1310/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.3423e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1311/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 1.3160e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 1312/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - loss: 1.2401e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1313/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 1.4355e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1314/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.3315e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1315/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 1.3880e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1316/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 1.3557e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1317/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.3987e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1318/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 222ms/step - loss: 1.3888e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1319/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.3690e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1320/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 140ms/step - loss: 1.3422e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1321/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.3825e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1322/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 183ms/step - loss: 1.2980e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1323/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 1.2824e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1324/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.3630e-04 - val_loss: 0.0151 - learning_rate: 3.0000e-05\n",
      "Epoch 1325/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - loss: 1.3786e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1326/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.3079e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1327/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.3597e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1328/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 1.2774e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1329/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.3656e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1330/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.3640e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 1331/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.3050e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 1332/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.3153e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1333/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.3139e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1334/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - loss: 1.3117e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1335/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - loss: 1.3465e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1336/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 1.3235e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1337/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.3817e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1338/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 222ms/step - loss: 1.3121e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1339/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.3232e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1340/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.3296e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1341/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - loss: 1.3665e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 1342/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.3587e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 1343/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.2680e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1344/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 1.2621e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1345/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 225ms/step - loss: 1.2232e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1346/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 235ms/step - loss: 1.5021e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1347/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 1.3513e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 1348/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.3261e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1349/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 183ms/step - loss: 1.3386e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1350/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.2772e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1351/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.2913e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 1352/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.2934e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1353/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.3088e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 1354/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - loss: 1.2799e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1355/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.3000e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1356/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 1.2760e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1357/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 226ms/step - loss: 1.2688e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1358/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 1.1893e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1359/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.2857e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1360/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 143ms/step - loss: 1.3459e-04 - val_loss: 0.0153 - learning_rate: 3.0000e-05\n",
      "Epoch 1361/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.2673e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1362/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 189ms/step - loss: 1.3278e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1363/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.3312e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1364/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 219ms/step - loss: 1.2780e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1365/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.3180e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1366/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.2230e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1367/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.3365e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1368/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 1.2976e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 17:31:51.800697: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 1.2969e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1369/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.4084e-04 - val_loss: 0.0150 - learning_rate: 3.0000e-05\n",
      "Epoch 1370/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 232ms/step - loss: 1.2530e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1371/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 211ms/step - loss: 1.2945e-04 - val_loss: 0.0144 - learning_rate: 3.0000e-05\n",
      "Epoch 1372/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.3322e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1373/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 1.2933e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1374/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 1.2679e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1375/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 1.1962e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1376/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 189ms/step - loss: 1.2140e-04 - val_loss: 0.0143 - learning_rate: 3.0000e-05\n",
      "Epoch 1377/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 1.3013e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1378/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 1.2739e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1379/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.2416e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1380/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 1.2797e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1381/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.3044e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1382/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.2995e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1383/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.2871e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1384/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.2074e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1385/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - loss: 1.3274e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1386/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 227ms/step - loss: 1.3065e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1387/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - loss: 1.3081e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1388/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 226ms/step - loss: 1.2489e-04 - val_loss: 0.0151 - learning_rate: 3.0000e-05\n",
      "Epoch 1389/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.2620e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1390/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 245ms/step - loss: 1.2863e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1391/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - loss: 1.2381e-04 - val_loss: 0.0148 - learning_rate: 3.0000e-05\n",
      "Epoch 1392/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.2327e-04 - val_loss: 0.0146 - learning_rate: 3.0000e-05\n",
      "Epoch 1393/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 1.2830e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1394/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.1822e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1395/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.3304e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1396/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - loss: 1.3448e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1397/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.2738e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n",
      "Epoch 1398/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 229ms/step - loss: 1.2032e-04 - val_loss: 0.0147 - learning_rate: 3.0000e-05\n",
      "Epoch 1399/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 223ms/step - loss: 1.3283e-04 - val_loss: 0.0145 - learning_rate: 3.0000e-05\n",
      "Epoch 1400/1400\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 227ms/step - loss: 1.3387e-04 - val_loss: 0.0149 - learning_rate: 3.0000e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model with the custom callback\n",
    "history = model_builder.train_model(\n",
    "    train_dataset, \n",
    "    val_dataset, \n",
    "    epochs=1400,\n",
    "    callbacks_list=[lr_scheduler, dynamic_exponent_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Extract the losses from the history object\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "train_loss_x_midpoints = history.history.get('x_midpoints_reshape_loss', train_loss)\n",
    "val_loss_x_midpoints = history.history.get('val_x_midpoints_reshape_loss', val_loss)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2,1)\n",
    "plt.plot(train_loss_x_midpoints, label='Train Loss x_midpoints_reshape')\n",
    "plt.plot(val_loss_x_midpoints, label='Validation Loss x_midpoints_reshape')\n",
    "plt.xlabel('Epochs')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss ')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_builder.model.save(\"/home/da886/Analysis/30KNoFalsePositivesFixed-index84_13__overfit_customloss.keras\")\n",
    "# loaded_model = tf.keras.models.load_model(\n",
    "# \"/home/da886/Analysis/30KNoFalsePositivesFixed-index6_13__overfitNo.keras\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1, batch shape: (800, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728496296.028167 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.029142 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.029539 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.029837 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.029888 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.030383 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.030613 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.030915 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.031178 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.031262 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.031478 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.031873 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.031996 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.032178 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.032499 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.032772 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.032811 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.033085 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.033397 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.033476 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.033689 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.034109 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.034152 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.034345 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.034871 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.034916 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.035004 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.035379 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.035771 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.035825 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.035982 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.036434 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.036600 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.036781 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.037127 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.037295 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.037466 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.037692 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.038097 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.038210 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.038455 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.038752 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.038904 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.039029 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.039783 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.039822 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.039902 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.040367 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.040612 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.040638 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.041034 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.041210 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.041588 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.041612 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.042158 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.042615 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.042746 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.043105 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.043521 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.043915 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.059377 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.059780 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.060073 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.060367 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.060646 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.060932 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.061212 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.061259 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.061268 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.061835 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.062027 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.062151 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.062456 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.062533 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.062765 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.063111 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.063216 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.063490 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.063790 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.063811 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.064046 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.064394 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.064493 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.064728 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.065094 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.065171 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.065408 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.065763 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.065890 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.066067 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.066351 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.066467 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.066696 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.067054 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.067212 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.067396 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.067718 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.067805 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.068080 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.068436 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.068436 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.068636 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.069042 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.069206 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.069371 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.069577 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.069782 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.070018 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.070391 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.070470 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.070718 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.071104 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.071105 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.071259 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.071694 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.072032 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.072071 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.072238 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.072598 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.073015 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.073159 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.073358 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.073534 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.073969 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.074071 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.074188 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.074580 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.074831 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.074855 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.075257 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.076439 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.076770 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.077204 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.077768 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.077910 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.078358 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.078476 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.078811 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.090921 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.091328 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.091646 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.091952 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.092254 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.092563 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.092858 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.093139 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.093432 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.093715 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.093974 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.094068 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.094269 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.094501 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.094811 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.094938 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.095373 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.095383 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.095789 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.095876 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.096104 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.096312 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.096506 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.096940 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.096945 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.097274 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.097451 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.097656 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.098021 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.098084 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.098146 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.098597 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.098708 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.098894 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.099200 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.099507 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.099597 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.100007 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.100147 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.100325 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.100705 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.100903 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.101018 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.101289 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.101795 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.101812 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.102062 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.102342 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.102600 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.102935 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.103044 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.103661 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.103740 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.103756 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.103947 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.104197 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.104559 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.104655 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.104845 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.105247 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.105324 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.105536 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.105934 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.106012 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.106200 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.106595 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.106672 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.106877 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.107162 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.107430 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.107721 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.108000 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.108275 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.108578 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.108882 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.109241 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.109566 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.110037 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.110125 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.110310 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.110603 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.110679 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.110937 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.111285 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.111363 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.111635 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.111904 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.112302 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.112567 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.112956 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.113078 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.113370 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.113499 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.113915 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.113929 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.114425 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.114445 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.114959 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.114971 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.115469 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.115483 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.115982 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.115996 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.116513 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.116530 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.117031 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.117054 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.117442 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.117655 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.117766 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.117855 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.118272 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.118306 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.118383 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.118889 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.118900 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.118913 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.119338 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.119551 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.119586 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.119707 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.119928 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.120313 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.120414 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.120544 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.120676 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.120961 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.121076 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.121628 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.121698 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.122090 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.122109 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.122536 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.122613 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.122892 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.123100 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.123266 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.123634 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.123716 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.124067 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.124267 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.124431 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.124748 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.125215 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.125595 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.125962 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.126313 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.126742 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.126757 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.127078 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.127387 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.127568 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.127746 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.128050 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.128350 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.128663 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.128992 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.129074 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.129412 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.129605 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.129773 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.130074 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.130268 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.130435 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.130804 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.131061 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.131491 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.131494 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.131805 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.132337 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.132357 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.132666 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.132969 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.133287 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.133792 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.133808 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.134132 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.134623 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.134635 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.134927 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.135307 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.135415 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.136366 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.136384 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.137086 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.137193 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.138314 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.138899 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.139581 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.140302 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.141000 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.146547 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.146903 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.147215 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.147537 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.147842 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.148175 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.148483 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.148808 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.149116 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.149322 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.149506 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.149701 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.149890 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.150078 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.150264 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.150439 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.150726 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.151104 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.151185 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.151477 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.151792 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.151886 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.152117 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.152442 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.152799 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.152875 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.153325 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.153434 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.153800 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.153907 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.154469 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.154503 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.154575 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.155050 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.155064 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.155592 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.155607 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.156002 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.156178 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.156193 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.156718 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.156757 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.156890 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.157092 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.157395 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.157524 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.157756 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.158151 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.158165 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.158482 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.158896 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.159009 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.159223 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.159802 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.159820 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.160159 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.160494 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.160866 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.161433 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.161923 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.162468 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.163245 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.163850 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.166616 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.166991 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.167313 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.167623 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.167937 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.168275 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.168579 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.168903 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.169229 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.169537 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.169864 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.170215 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.170505 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.170996 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.171099 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.171344 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.171659 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.172226 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.172239 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.172583 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.172891 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.173462 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.173475 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.173799 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.174113 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.174648 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.174671 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.175026 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.175787 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.176125 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.176714 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.177062 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.177731 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.178806 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.179009 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.179047 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.179213 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.179538 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.179834 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.180146 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.180595 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.180674 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.180929 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.181283 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.181730 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.181808 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.182163 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.182505 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.182866 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.183287 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.183481 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.183706 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.184116 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.184540 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.184966 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.185690 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.186439 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.187673 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.188460 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.195665 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.196080 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.196453 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.196836 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.197189 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.197587 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.197958 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.198335 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.198714 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.199117 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.199534 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.199957 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.200380 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.200852 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.201369 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.201893 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.202240 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.202591 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.202603 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.202931 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.203296 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.203371 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.203693 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.203916 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.204088 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.204430 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.204770 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.205155 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.205364 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.205536 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.205893 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.206260 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.206678 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.206875 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.207246 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.207398 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.207696 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.207983 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.208001 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.208574 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.208587 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.209032 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.209181 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.209292 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.209485 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.209794 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.209903 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.210242 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.210770 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.210794 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.211168 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.211759 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.211773 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.212137 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.212501 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.213209 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.213216 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.213748 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.214418 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.214432 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.214875 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.215341 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.216070 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.216985 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.218225 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.218261 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.218746 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.219334 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.219403 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.219835 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.220357 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.220842 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.221382 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.221805 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.221903 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.222245 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.222416 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.222635 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.222910 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.223080 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.223482 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.223488 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.224026 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.224104 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.224426 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.224794 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.225164 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.225560 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.226008 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.226076 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.226488 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.226982 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.227413 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.228011 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.228048 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.228208 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.228458 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.228827 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.229264 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.229921 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.229936 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.230348 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.230539 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.230744 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.231152 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.231746 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.231761 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.232181 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.232818 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.233445 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.233558 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.235158 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.235175 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.235294 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.236890 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.237425 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.237800 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.238506 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.239313 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.240006 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.241856 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.242670 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.244176 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.285478 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.285895 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.286284 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.286672 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.287071 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.287468 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.287879 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.288292 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.288725 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.289169 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.289611 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.290051 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.290589 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.290798 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.291401 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.291423 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.291933 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.292039 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.292339 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.292747 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.292856 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.293379 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.293489 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.293809 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.294403 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.294423 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.294856 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.295295 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.295866 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.295987 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.296337 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.296817 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.297367 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.297956 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.298160 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.298551 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.299171 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.300077 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.300087 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.301540 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.303689 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.305372 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.309745 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.310299 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.310798 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.311286 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.311877 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.312367 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.312898 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.313445 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.313929 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.314472 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.315032 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.315071 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.315828 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.315854 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.316347 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.316836 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.317434 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.317924 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.318263 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.318489 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.319040 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.319526 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.320071 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.320640 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.320865 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.321204 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.323403 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.323654 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.324039 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.324503 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.324972 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.325438 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.325669 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.325930 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.326308 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.326485 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.326975 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.327480 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.328126 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.328200 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.328767 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.328936 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.329363 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.329961 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.330666 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.330741 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.331238 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.331481 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.332228 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.333039 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.333653 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.333945 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.334896 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.335680 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.336119 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.341132 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.342968 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.345186 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.355092 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.355500 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.355886 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.356309 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.356734 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.357211 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.357690 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.358979 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.360291 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.361594 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.363879 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.365545 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.367823 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.369717 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.409398 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.409789 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.410164 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.410560 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.410942 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.411323 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.411720 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.412119 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.412511 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.412896 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.413283 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.413689 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.414102 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.414510 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.414984 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.415474 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.416025 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.416527 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.417059 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.417714 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.418321 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.420011 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.421655 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.425746 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.426247 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.426737 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.427258 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.427797 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.428328 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.428863 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.429424 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.429994 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.430433 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.430633 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.430820 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.431161 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.431350 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.431525 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.432249 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.432247 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.432330 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.432792 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.433003 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.433096 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.433521 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.434210 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.434331 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.434345 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.434771 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.435072 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.435204 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.435298 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.435632 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.436203 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.436300 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.436406 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.437055 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.437233 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.437343 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.437873 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.437953 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.438528 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.438702 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.438716 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.439340 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.439887 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.440062 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.440872 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.440980 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.441369 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.441738 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.442613 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.443470 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.444452 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.444851 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.445524 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.447953 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.450644 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.450952 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.451251 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.451561 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.451956 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.451977 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.452274 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.452586 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.453074 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.453371 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.453736 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.454110 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.454510 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.454841 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.455211 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.455535 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.455859 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.456273 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.456679 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.457159 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.457650 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.458268 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.458707 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.459152 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.459317 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.459554 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.460124 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.460587 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.461064 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.461562 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.462862 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.464373 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.466040 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.466409 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.466454 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.466759 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.466975 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.467127 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.467590 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.467710 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.467780 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.468110 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.468202 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.468395 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.468761 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.468838 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.469152 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.469320 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.469623 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.469829 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.470143 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.470373 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.470652 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.471206 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.471311 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.471875 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.472245 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.472788 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.472947 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.473902 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.474198 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.474477 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.475864 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.476055 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.476218 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.476506 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.476788 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.477084 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.477344 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.477609 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.477882 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.478152 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.478559 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.478759 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.478915 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.479206 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.479505 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.479869 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.480211 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.480687 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.480770 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.481059 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.481776 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.482148 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.482494 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.482648 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.483094 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.484227 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.484723 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.491074 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.491369 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.491643 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.491915 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.492439 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.492983 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.493530 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.494247 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.494952 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.495537 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.496735 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.498303 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.499276 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.499515 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.499775 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.500049 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.500301 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.500571 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.500827 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.501107 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.501411 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.501733 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.502004 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.502372 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.502756 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.503140 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.503532 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.503981 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.504399 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.504895 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.505444 3196720 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.519522 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.519906 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.520290 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.520681 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.521072 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.521458 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.521856 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.522259 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.522657 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.523069 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.523492 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.523919 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.524368 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.524818 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.525286 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.525813 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.526379 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.526909 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.527470 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.528134 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.528436 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.529086 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.529100 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.529487 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.529880 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.530271 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.530779 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.530888 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.531194 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.531595 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.531990 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.532588 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.532665 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.533061 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.533503 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.533961 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.534415 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.534890 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.535509 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.536094 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.536632 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.537196 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.537868 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.538579 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.540400 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.541384 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.541731 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.542201 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.542624 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.542600 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.543067 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.543442 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.543912 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.544311 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.544786 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.545723 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.546432 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.547287 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.548122 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.549254 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.550731 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.552266 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.552619 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.552947 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.553282 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.553681 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.554052 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.554521 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.554924 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.555400 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.556086 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.556776 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.557635 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.558482 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.559611 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.561093 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.562877 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.563196 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.563492 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.563807 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.564133 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.564438 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.564754 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.565057 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.565360 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.565720 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.566090 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.566487 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.566824 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.567201 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.567523 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.567849 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.568269 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.568679 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.569166 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.569654 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.570280 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.571568 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.573475 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.573991 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.574488 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.574991 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.575460 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.575925 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.576424 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.576904 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.577385 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.577944 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.578518 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.578657 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.579319 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.579456 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.580131 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.580161 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.580771 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.580933 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.581270 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.581675 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.581839 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.582509 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.582533 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.583002 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.583283 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.583793 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.583965 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.584758 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.584785 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.585767 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.585791 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.586817 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.586841 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.587557 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.588089 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.588727 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.590020 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.591622 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.591909 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.592194 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.592482 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.592788 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.593060 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.593335 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.593603 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.593873 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.594241 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.594518 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.594803 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.595100 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.595142 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.595719 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.595722 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.596237 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.596244 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.596635 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.596828 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.596940 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.597436 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.597455 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.597739 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.598106 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.598210 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.598804 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.598816 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.599329 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.599439 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.599902 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.600012 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.600573 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.601149 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.601254 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.601663 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.602262 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.603545 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.605167 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.605441 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.605723 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.606010 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.606303 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.606559 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.606822 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.607089 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.607358 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.607734 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.608005 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.608036 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.608527 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.608550 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.609066 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.609081 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.609591 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.609605 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.609983 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.610154 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.610349 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.610926 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.610937 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.611588 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.611699 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.612074 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.612338 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.612521 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.613185 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.613200 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.613794 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.614337 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.614846 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.615025 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.616614 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.617577 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.617823 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.618087 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.618356 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.618616 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.618891 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.619145 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.619423 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.619723 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.620031 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.620309 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.620673 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.621057 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.621181 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.621665 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.621690 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.622054 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.622160 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.622341 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.622633 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.622896 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.623060 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.623541 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.623651 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.624198 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.624313 3196724 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.624913 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.625636 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.626219 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.627425 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.629008 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.629973 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.630220 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.630484 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.630758 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.631018 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.631296 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.631553 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.631842 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.632145 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728496296.632461 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.632733 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.633109 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.633486 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.633872 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.634277 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.634726 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.635142 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.635646 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728496296.636204 3196714 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 3, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 4, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 5, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 6, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "Processing batch 7, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 8, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 9, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 10, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 11, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 12, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 13, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 14, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "Processing batch 15, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 16, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 17, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 18, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 19, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 20, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 21, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 22, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "Processing batch 23, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 24, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 25, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 26, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 27, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 28, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 29, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 30, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the function for visualizing midpoints\n",
    "def visualize_midpoints(image, midpoints, title=\"Predicted Midpoint Visualization\"):\n",
    "    \"\"\"\n",
    "    Visualizes midpoints on an image without using a probability vector.\n",
    "\n",
    "    Parameters:\n",
    "    - image: A 3D tensor representing the image.\n",
    "    - midpoints: A 2D tensor representing the midpoint coordinates (x, y).\n",
    "    - title: The title of the plot.\n",
    "\n",
    "    Returns:\n",
    "    None (displays the image with midpoints).\n",
    "    \"\"\"\n",
    "    # Convert to NumPy arrays for easier handling\n",
    "    image_np = image\n",
    "    midpoints_np = midpoints\n",
    "\n",
    "    # Denormalize image if necessary (adjust based on your normalization method)\n",
    "    denormalized_image = image_np  # Modify if normalization was applied during training\n",
    "\n",
    "    # Visualize the image\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(denormalized_image, cmap='gray')\n",
    "    plt.title(title)\n",
    "\n",
    "    # Plot midpoints directly, only if they are not (0, 0)\n",
    "    for i, (x, y) in enumerate(midpoints_np):\n",
    "        if x >= 3 and y >= 3:  # Only plot if the point is not (0, 0)\n",
    "            plt.scatter(x, y, color='red', s=5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Create the validation dataset\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n",
    "# val_dataset = val_dataset.batch(800)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)\n",
    "# # Initialize lists to collect the data\n",
    "all_images = []\n",
    "all_true_midpoints = []\n",
    "all_pred_midpoints = []\n",
    "\n",
    "# # Loop through each batch in the validation dataset, predict, and collect results\n",
    "# for i, (data_batch, midpoints_batch) in enumerate(val_dataset):\n",
    "\n",
    "for i, (data_batch, midpoints_batch) in enumerate(train_dataset):\n",
    "    print(f\"Processing batch {i + 1}, batch shape: {data_batch.shape}\")\n",
    "    \n",
    "    # Get the model predictions\n",
    "    predictions = model_builder.model.predict(data_batch)\n",
    "\n",
    "    # Extend the lists to store data from each batch\n",
    "    all_images.extend(data_batch.numpy())  # Store all images\n",
    "    all_true_midpoints.extend(midpoints_batch.numpy())  # Store all true midpoints\n",
    "    all_pred_midpoints.extend(predictions)  # Store all predicted midpoints\n",
    "\n",
    "# Convert lists to arrays for easier indexing\n",
    "all_images = np.array(all_images)\n",
    "all_true_midpoints = np.array(all_true_midpoints)\n",
    "all_pred_midpoints = np.array(all_pred_midpoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "# train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24000, 64, 64), (24000, 1, 13, 2), (24000, 1, 13, 2))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images.shape,all_pred_midpoints.shape,all_true_midpoints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Select an index to visualize from the entire dataset\n",
    "index_to_visualize = np.random.randint(0, len(all_images))\n",
    "\n",
    "# index_to_visualize = 11548\n",
    "# Visualize the selected image with predicted and true midpoints\n",
    "visualize_midpoints(all_images[index_to_visualize], all_pred_midpoints[index_to_visualize, 0, :, :] * 64, title=\"Predicted Midpoints\")\n",
    "visualize_midpoints(all_images[index_to_visualize], all_true_midpoints[index_to_visualize, 0, :, :] * 64, title=\"Ground Truth Midpoints\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.085455336, 0.8973845)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(all_pred_midpoints),np.max(all_pred_midpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.140625, 0.84375)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(all_true_midpoints),np.max(all_true_midpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.65831906, 0.14478773],\n",
       "         [0.7904177 , 0.15355638],\n",
       "         [0.17361225, 0.20449938],\n",
       "         [0.66889393, 0.2731334 ],\n",
       "         [0.21128556, 0.29179233],\n",
       "         [0.5561055 , 0.2980113 ],\n",
       "         [0.18257172, 0.34556022],\n",
       "         [0.24933907, 0.37970328],\n",
       "         [0.81192124, 0.44601887],\n",
       "         [0.3674544 , 0.5157404 ],\n",
       "         [0.25184494, 0.56984687],\n",
       "         [0.33452287, 0.86085165],\n",
       "         [0.34384012, 0.8332963 ]]], dtype=float32),\n",
       " array([[[0.65625 , 0.140625],\n",
       "         [0.78125 , 0.15625 ],\n",
       "         [0.1875  , 0.1875  ],\n",
       "         [0.65625 , 0.28125 ],\n",
       "         [0.234375, 0.296875],\n",
       "         [0.546875, 0.296875],\n",
       "         [0.1875  , 0.359375],\n",
       "         [0.234375, 0.375   ],\n",
       "         [0.828125, 0.453125],\n",
       "         [0.359375, 0.515625],\n",
       "         [0.265625, 0.546875],\n",
       "         [0.328125, 0.84375 ],\n",
       "         [0.359375, 0.84375 ]]], dtype=float32))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pred_midpoints[2],all_true_midpoints[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., 31., 25.],\n",
       "       [ 1., 44., 15.],\n",
       "       [ 1., 13., 15.],\n",
       "       [ 1., 32., 22.],\n",
       "       [ 1., 19., 53.],\n",
       "       [ 1., 44., 17.],\n",
       "       [ 1., 37., 27.],\n",
       "       [ 1., 17., 32.],\n",
       "       [ 1., 28., 26.],\n",
       "       [ 1., 24., 36.],\n",
       "       [ 1., 31., 50.],\n",
       "       [ 1., 14., 46.],\n",
       "       [ 1., 48., 29.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[2],)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize variables to track the min and max MSE\n",
    "min_mse = float('inf')\n",
    "max_mse = float('-inf')\n",
    "min_mse_index = -1\n",
    "max_mse_index = -1\n",
    "\n",
    "# Loop through each prediction to calculate the MSE\n",
    "for i in range(len(all_pred_midpoints)):\n",
    "    mse = np.mean((all_pred_midpoints[i] - all_true_midpoints[i]) **2)\n",
    "    \n",
    "    if mse < min_mse:\n",
    "        min_mse = mse\n",
    "        min_mse_index = i\n",
    "    \n",
    "    if mse > max_mse:\n",
    "        max_mse = mse\n",
    "        max_mse_index = i\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot an image with its centers\n",
    "def plot_image_with_centers(image, true_center, predicted_center, title):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image.squeeze(), cmap='gray')  # Display the image\n",
    "\n",
    "    # Plot the actual center (Groundtruth)\n",
    "    plt.scatter(true_center[:, 0], true_center[:, 1], color='green', label='Groundtruth', s=10)\n",
    "\n",
    "    # Plot the predicted center\n",
    "    plt.scatter(predicted_center[:, 0], predicted_center[:, 1], color='red', label='Predictions', s=10)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the image with the least MSE\n",
    "plot_image_with_centers(all_images[min_mse_index],\n",
    "                        all_true_midpoints[min_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[min_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        f'Image with Least MSE. MSE: {min_mse:.4f}')\n",
    "\n",
    "# Plotting the image with the largest MSE\n",
    "plot_image_with_centers(all_images[max_mse_index],\n",
    "                        all_true_midpoints[max_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[max_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        f'Image with Largest MSE. MSE: {max_mse:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5266"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_mse_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "objectdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
