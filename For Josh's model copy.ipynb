{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Set CUDA device order and visible devices\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7,8,9\"\n",
    "\n",
    "# # Set the device\n",
    "# device = '/cpu:0'\n",
    "# if tf.config.experimental.list_physical_devices('GPU'):\n",
    "#     try:\n",
    "#         # Restrict TensorFlow to only use the second GPU\n",
    "#         gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#         if gpus:\n",
    "#             tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "#             device = '/gpu:0'\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)\n",
    "\n",
    "# print(\"device\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 20:02:19.882480: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-08 20:02:19.897984: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-08 20:02:19.911646: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-08 20:02:19.915775: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-08 20:02:19.928793: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-08 20:02:20.564132: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 20:02:22.267025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79196 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:45:00.0, compute capability: 8.0\n",
      "2024-10-08 20:02:22.269268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 79196 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:46:00.0, compute capability: 8.0\n",
      "2024-10-08 20:02:22.270637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 79194 MB memory:  -> device: 2, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:49:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"  # Only GPUs 0 and 1 will be visible to TensorFlow\n",
    "\n",
    "import tensorflow as tf\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\",\"/gpu:2\"])\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# DataLoader Class Definition\n",
    "# -----------------------------\n",
    "class DataLoader:\n",
    "    def __init__(self, h5_filename):\n",
    "        self.h5_filename = h5_filename\n",
    "        self.images, self.centers = self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        with h5py.File(self.h5_filename, 'r') as f:\n",
    "            images = np.array(f['images'])\n",
    "            centers = np.array(f['centers_training'])\n",
    "        return images, centers\n",
    "\n",
    "    def plot_image_with_centers(self, image_index=None):\n",
    "        if image_index is None:\n",
    "            image_index = np.random.randint(0, len(self.images))\n",
    "\n",
    "        image = self.images[image_index]\n",
    "        centers = self.centers[image_index]\n",
    "\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        valid_centers = centers[centers[:, 0] == 1]\n",
    "        for center in valid_centers:\n",
    "            plt.scatter(center[1], center[2], c='red', marker='x')  # center[1] is x and center[2] is y\n",
    "        plt.title('Image with Valid Centers Marked')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_centers(centers):\n",
    "        return centers[np.lexsort((centers[:, 0], centers[:, 1]))]\n",
    "\n",
    "    def normalize_data(self):\n",
    "        normalized_images = self.images / np.max(self.images)\n",
    "        sorted_centers = np.array([self.sort_centers(image_centers[:, 1:]) for image_centers in self.centers])\n",
    "        normalized_centers = sorted_centers / 64\n",
    "\n",
    "        normalized_midpoints = tf.expand_dims(normalized_centers, axis=1)\n",
    "        return normalized_images, normalized_midpoints.numpy()\n",
    "\n",
    "    def split_data(self, train_size=0.8, random_state=42):\n",
    "        normalized_images, normalized_midpoints_np = self.normalize_data()\n",
    "        return train_test_split(normalized_images, normalized_midpoints_np, train_size=train_size, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Utility Function Definition\n",
    "# -----------------------------\n",
    "def plot_transposed_images_with_midpoints(dataset, image_indices=[0, 1, 2, 3]):\n",
    "    \"\"\"\n",
    "    Extracts multiple images and their midpoints from the given dataset, transposes the images, \n",
    "    corrects the midpoints, and plots the transposed images with the corrected midpoints.\n",
    "\n",
    "    Args:\n",
    "    - dataset (tf.data.Dataset): The dataset from which to extract the images and midpoints.\n",
    "    - image_indices (list): The indices of the images in the batch to visualize. Default is [0, 1, 2, 3].\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract a sample image batch and its corresponding midpoints from the dataset\n",
    "    sample_image_batch, sample_midpoints_batch = next(iter(dataset))\n",
    "\n",
    "    # Create a figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(6, 6))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(image_indices):\n",
    "            # Select the specified image and corresponding midpoints from the batch\n",
    "            sample_image = np.array(sample_image_batch[image_indices[i]])\n",
    "            sample_midpoints = np.array(sample_midpoints_batch[image_indices[i]])\n",
    "\n",
    "            # Transpose the image\n",
    "            transposed_image = sample_image.T\n",
    "\n",
    "            # Correct the midpoints by swapping the x and y coordinates\n",
    "            transposed_midpoints_corrected = sample_midpoints[:, :, [1, 0]]\n",
    "\n",
    "            # Plot the transposed image with corrected midpoints\n",
    "            ax.imshow(transposed_image, cmap='gray')\n",
    "            ax.scatter(\n",
    "                transposed_midpoints_corrected[:, :, 0] * 64, \n",
    "                transposed_midpoints_corrected[:, :, 1] * 64, \n",
    "                c='red', marker='o', s=5\n",
    "            )\n",
    "            ax.set_title(f'Image {image_indices[i]} for this batch')\n",
    "        else:\n",
    "            ax.axis('off')  # If fewer than 4 images are requested, hide the unused subplots\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Custom Loss and Callback Definitions\n",
    "# -----------------------------\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def custom_loss(exponent):\n",
    "    def loss(y_true, y_pred):\n",
    "        diff = tf.abs(y_true - y_pred)\n",
    "        powered_diff = tf.pow(diff, exponent)\n",
    "        return tf.reduce_mean(powered_diff)\n",
    "    return loss\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class DynamicExponentCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, initial_exponent, increment, update_frequency):\n",
    "        super().__init__()\n",
    "        self.exponent = initial_exponent\n",
    "        self.increment = increment\n",
    "        self.update_frequency = update_frequency\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.update_frequency == 0:\n",
    "            self.exponent += self.increment\n",
    "            print(f\"\\nEpoch {epoch + 1}: Increasing exponent to {self.exponent}\")\n",
    "            self.model.loss = self.custom_loss(self.exponent)\n",
    "\n",
    "    def custom_loss(self, exponent):\n",
    "        def loss(y_true, y_pred):\n",
    "            diff = tf.abs(y_true - y_pred)\n",
    "            powered_diff = tf.pow(diff, exponent)\n",
    "            return tf.reduce_mean(powered_diff)\n",
    "        return loss\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'initial_exponent': self.exponent,\n",
    "            'increment': self.increment,\n",
    "            'update_frequency': self.update_frequency,\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my NEW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import layers, regularizers\n",
    "\n",
    "# class ModelBuilder:\n",
    "#     def __init__(self, input_shape=(64, 64, 1), num_classes=3, num_coordinates=2, learning_rate=3e-5, weights_path=None, l2_reg=0.001):\n",
    "#         self.input_shape = input_shape\n",
    "#         self.num_classes = num_classes\n",
    "#         self.num_coordinates = num_coordinates\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.l2_reg = l2_reg\n",
    "#         self.model = self.build_model()\n",
    "\n",
    "#         # Load weights if a path is provided\n",
    "#         if weights_path is not None:\n",
    "#             self.model.load_weights(weights_path)\n",
    "\n",
    "#         self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "#         # self.optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "#     def build_model(self):\n",
    "#         l2 = regularizers.l2(self.l2_reg)\n",
    "        \n",
    "#         x_input = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "#         # First branch\n",
    "#         x_1 = layers.Conv2D(64, kernel_size=6, strides=1, padding='same', activation='relu')(x_input)\n",
    "#         x_1 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(x_1)\n",
    "#         x_1 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu')(x_1)\n",
    "#         x_1 = layers.Conv2D(16, kernel_size=3, strides=3, padding='same', activation='relu', kernel_regularizer=l2)(x_1)\n",
    "#         # x_1 = layers.Dropout(0.1)(x_1)\n",
    "#         # x_1 = layers.BatchNormalization()(x_1)\n",
    "\n",
    "#         # Second branch\n",
    "#         x_2 = layers.Conv2D(32, kernel_size=8, strides=3, padding='same', activation='relu')(x_input)\n",
    "#         x_2 = layers.Conv2D(64, kernel_size=4, strides=1, padding='same', activation='relu')(x_2)\n",
    "#         x_2 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2)(x_2)\n",
    "#         # x_2 = layers.Dropout(0.1)(x_2)\n",
    "#         # x_2 = layers.BatchNormalization()(x_2)\n",
    "\n",
    "#         # Concatenate branches\n",
    "#         x_3 = layers.concatenate([x_1, x_2])\n",
    "#         x_3 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu')(x_3)\n",
    "#         x_3 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(x_3)\n",
    "#         x_3 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2)(x_3)\n",
    "#         # x_3 = layers.Dropout(0.1)(x_3)\n",
    "#         # x_3 = layers.BatchNormalization()(x_3)\n",
    "\n",
    "#         # Third branch\n",
    "#         x_4 = layers.Conv2D(64, kernel_size=19, strides=5, padding='same', activation='relu', kernel_regularizer=l2)(x_input)\n",
    "        \n",
    "#         # Flatten and concatenate\n",
    "#         x_3 = layers.Flatten()(x_3)\n",
    "#         x_4 = layers.Flatten()(x_4)\n",
    "#         x = layers.Concatenate()([x_3, x_4])\n",
    "\n",
    "#         # Dense layers with L2 regularization\n",
    "#         x = layers.Dense(256, activation='relu', kernel_regularizer=l2)(x)\n",
    "#         # x = layers.Dropout(0.1)(x)\n",
    "\n",
    "#         # Output layer for midpoints\n",
    "#         x_midpoints = layers.Dense(self.num_classes * self.num_coordinates, activation='sigmoid', name='x_midpoints')(x)\n",
    "#         x_midpoints_reshape = layers.Reshape((-1, self.num_classes, self.num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "        \n",
    "#         return tf.keras.models.Model(x_input, x_midpoints_reshape)\n",
    "\n",
    "#     def compile_model(self, loss_function):\n",
    "#         self.model.compile(optimizer=self.optimizer, loss=loss_function)\n",
    "\n",
    "#     def train_model(self, train_dataset, val_dataset, epochs, callbacks_list):\n",
    "#         history = self.model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks_list)\n",
    "#         return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "\n",
    "class ModelBuilder:\n",
    "    def __init__(self, input_shape=(64, 64, 1), num_classes=13, num_coordinates=2, learning_rate=1e-3, weights_path=None,l1_reg=0.001,l2_reg =0.01):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.num_coordinates = num_coordinates\n",
    "        self.learning_rate = learning_rate\n",
    "        self.l1_reg = l1_reg\n",
    "        self.l2_reg = l2_reg\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        # Load weights if a path is provided\n",
    "        if weights_path is not None:\n",
    "            self.model.load_weights(weights_path)\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "        # self.optimizer =tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "    def build_model(self):\n",
    "        \n",
    "        l1 = regularizers.l1(self.l1_reg)\n",
    "        l2 = regularizers.l2(self.l2_reg)\n",
    "\n",
    "    \n",
    "        x_input = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "        \n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x_input)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        \n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        \n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.3)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.3)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        # x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(128, kernel_size=5, padding='same', activation='relu')(x)\n",
    "        # x = layers.MaxPool2D()(x)\n",
    "        # x = layers.Dropout(0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Flatten()(x)\n",
    "        \n",
    "        x_midpoints = layers.Dense(self.num_classes * self.num_coordinates, activation='linear', name='x_midpoints')(x)\n",
    "        x_midpoints_reshape = layers.Reshape((-1, self.num_classes, self.num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "        \n",
    "        return tf.keras.models.Model(x_input, x_midpoints_reshape)\n",
    "\n",
    "    def compile_model(self, loss_function):\n",
    "        self.model.compile(optimizer=self.optimizer, loss=loss_function)\n",
    "\n",
    "    def train_model(self, train_dataset, val_dataset, epochs, callbacks_list):\n",
    "        history = self.model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks_list)\n",
    "        return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Main Script Execution\n",
    "# -----------------------------\n",
    "\n",
    "# Load data\n",
    "# h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KFixed_Mixed_13.h5'             \n",
    "h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KNoFalsePositivesFixed-index6_13.h5'\n",
    "data_loader = DataLoader(h5_filename)\n",
    "images, centers = data_loader.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f79387e5390>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l=np.random.randint(0,len(centers))\n",
    "data_loader.plot_image_with_centers(l)\n",
    "plt.imshow(images[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the data and split it into training and validation sets\n",
    "train_images, val_images, train_midpoints, val_midpoints = data_loader.split_data()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images: (24000, 64, 64), Train Midpoints: (24000, 1, 13, 2)\n",
      "Validation Images: (6000, 64, 64), Validation Midpoints: (6000, 1, 13, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 1000\n",
    "train_dataset = train_dataset.shuffle(buffer_size=8000, reshuffle_each_iteration=True).batch(batch_size)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=8000).batch(batch_size)\n",
    "\n",
    "# Check the shape of the datasets\n",
    "print(f'Train Images: {train_images.shape}, Train Midpoints: {train_midpoints.shape}')\n",
    "print(f'Validation Images: {val_images.shape}, Validation Midpoints: {val_midpoints.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_transposed_images_with_midpoints(train_dataset, image_indices=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set up learning rate scheduler\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.9, patience=13, verbose=1, mode='min', min_lr=3e-5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">819,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,338</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_44 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_20 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_45 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_46 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_47 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_48 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_49 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_50 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_21 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_51 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_22 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_52 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_23 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_53 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m1,179,904\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_24 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_54 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m819,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │        \u001b[38;5;34m13,338\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m2\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,059,162</span> (34.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,059,162\u001b[0m (34.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,057,882</span> (34.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,057,882\u001b[0m (34.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> (5.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,280\u001b[0m (5.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# dynamic_exponent_callback = DynamicExponentCallback(2, 1, 50)\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    # Instantiate the model builder\n",
    "    # model_builder = ModelBuilder(weights_path= \"/home/da886/Weights from Josh's model/Josh's5fixedMSE45overfit-1.keras\")\n",
    "    model_builder = ModelBuilder()\n",
    "\n",
    "    # Build the model\n",
    "    model_builder.build_model()\n",
    "\n",
    "    # Display the model architecture\n",
    "    model_builder.model.summary()\n",
    "\n",
    "    # Compile the model using the custom loss function\n",
    "    # model_builder.compile_model(loss_function=dynamic_exponent_callback.custom_loss(2))\n",
    "    model_builder.compile_model(loss_function=tf.keras.losses.MeanSquaredError()) \n",
    "    \n",
    "    # model_builder.compile_model(loss_function=custom_loss(3))e\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 20:04:09.083831: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-08 20:04:09.096101: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-08 20:04:09.123359: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1728417849.209619   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.211945   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.212596   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.272592   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.272592   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.272750   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.273508   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.273636   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.273759   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.279584   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.279584   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.280288   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.298372   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.298376   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.298798   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.300715   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.300819   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.301372   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.302147   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.302172   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.302609   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.303736   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.303816   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.303967   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.306629   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.306814   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.307221   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.324195   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.324196   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.325577   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.325584   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.326143   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.326748   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.326755   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.327537   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.328211   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.328217   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.328684   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.329615   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.329622   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.330139   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.331297   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.331304   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.331545   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.333230   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.334078   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.334154   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.335619   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.336415   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.336485   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.336855   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.340314   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.340319   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.340341   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.344983   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.345056   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.345070   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.350611   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.350935   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.351040   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.353418   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.353437   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.353748   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.355431   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.362267   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.362286   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.362294   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.365808   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.365934   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.365940   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.457674   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.458680   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.459572   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.460459   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.461475   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.462831   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.464512   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.466181   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.467918   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.469706   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.472702   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.475700   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.494421   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.495064   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.495776   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.496521   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.497298   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.498065   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.498857   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.499713   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.501858   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.502986   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.504131   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.505687   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.513085   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.514369   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.515539   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.519682   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.521706   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.523819   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.525205   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.527128   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.529348   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.531762   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.542844   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.543883   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.545000   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.546017   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.546997   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.548519   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.551553   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.554595   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.557588   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.560548   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.563515   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.566756   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.603943   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.604877   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.605834   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.606897   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.607988   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.609136   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.610332   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.611511   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.612928   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.614289   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.615776   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.619643   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.624853   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.626632   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.628247   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.630271   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.632213   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.633941   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.636269   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.639704   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.643882   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.656240   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.657727   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.659441   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.660918   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.662330   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.664726   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.670574   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.676345   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.682217   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.687931   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.693646   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.699881   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.727265   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.728225   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.729107   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.729989   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.730989   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.732331   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.733996   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.735636   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.737276   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.739026   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.741980   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.744942   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.761226   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.762187   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.763088   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.763621   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.763987   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.764275   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.765150   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.765237   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.765919   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.766685   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.766780   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.767549   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.768477   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.768578   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.769360   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.770283   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.770471   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.771440   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.771959   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.772426   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.773917   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.773913   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.774325   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.775301   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.776693   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.776920   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.777210   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.778498   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.778518   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.779508   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.779976   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.780175   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.781849   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.782802   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.783582   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.784094   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.785574   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.785597   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.787563   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.787735   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.789913   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.790015   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.792209   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.792376   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.798695   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.798906   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.799556   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.800274   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.801020   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.801801   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.802567   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.803357   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.803484   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.804223   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.804631   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.805212   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.805772   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.806177   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.806793   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.807128   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.807230   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.807787   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.808278   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.809315   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.809827   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.810624   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.811723   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.812347   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.812593   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.812765   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.815426   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.815596   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.816427   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.817730   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.818423   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.818993   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.819168   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.821105   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.821376   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.822023   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.823347   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.824329   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.825817   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.825896   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.827564   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.832247   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.837104   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.838164   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.839297   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.840318   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.841312   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.842858   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.845907   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.848959   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.850474   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.851974   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.852945   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.855092   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.855174   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.857643   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.858083   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.860612   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.861362   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.863058   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.864404   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.865218   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.865460   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.866132   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.867183   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.868324   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.868445   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.869616   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.870832   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.871789   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.872026   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.873451   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.874223   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.874830   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.876333   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.876947   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.880236   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.885426   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.887202   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.888475   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.888833   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.890858   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.892785   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.894491   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.897913   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.898562   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.899378   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.900037   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.900295   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.901351   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.902072   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.902457   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.903605   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.904799   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.905986   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.907426   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.908792   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.910263   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.911845   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.914112   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.914200   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.915609   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.917327   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.918798   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.919413   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.920220   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.921212   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.922603   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.922847   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.923160   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.924896   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.926846   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.928377   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.928585   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.932030   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.934063   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.934433   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.936247   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.939851   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.945458   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.946639   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.948374   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.949876   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.951080   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.951616   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.953097   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.954514   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.956898   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.957284   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.958628   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.962715   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.968452   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.974289   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.979939   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.985596   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417849.991784   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.030214   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.031490   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.032865   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.034420   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.036060   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.037746   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.039481   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.041231   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.043312   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.045429   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.047568   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.054051   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.062391   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.065131   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.065447   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.066728   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.067913   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.068134   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.069703   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.070926   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.071368   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.073055   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.074367   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.074814   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.076578   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.077463   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.078694   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.080835   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.083010   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.084038   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.089583   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.098088   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.100807   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.101884   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.103587   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.104430   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.104664   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.106494   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.106678   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.107034   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.108968   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.109719   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.110128   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.111975   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.112410   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.113243   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.114446   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.115414   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.116833   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.118253   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.119576   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.120103   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.121560   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.122430   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.124428   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.124872   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.127809   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.127826   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.132283   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.136120   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.138026   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.139337   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.140070   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.140508   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.142529   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.144000   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.145002   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.147996   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.150496   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.150676   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.151274   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.152886   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.155619   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.156431   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.158479   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.160911   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.162245   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.162347   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.163657   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.167450   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.171696   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.173326   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.175225   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.184403   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.186625   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.187078   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.193510   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.196474   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.198218   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.199556   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.206490   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.208416   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.209465   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.219341   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.220669   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.231473   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.232855   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.244905   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.258177   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.262264   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.265897   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.270028   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.274064   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.279238   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.283179   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.287904   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.292778   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.296935   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.301727   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.325990   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.349754   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.353669   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.355997   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.358655   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.361327   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.364354   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.367205   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.370578   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.372772   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.373397   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.376469   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.380136   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.383857   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.387713   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.391624   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.391776   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.393988   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.394837   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.396667   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.399003   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.399372   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.402405   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.404077   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.405291   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.408641   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.409706   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.411465   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.414563   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.415101   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.416779   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.418253   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.419332   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.422015   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.425905   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.429888   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.434605   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.437249   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.440674   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.441011   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.442458   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.446983   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.448174   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.453249   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.457472   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.459805   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.463837   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.472031   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.472777   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.479184   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.485179   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.498042   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.498328   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.502388   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.505981   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.510080   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.510427   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.514131   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.519315   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.523251   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.527858   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.532745   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.536931   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.537115   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.541211   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.541777   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.544830   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.548943   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.552994   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.558185   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.562128   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.565420   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.566771   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.571663   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.575844   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.580672   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.588774   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.604213   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.611602   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.627557   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.633585   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.650341   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.655427   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.672354   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.679189   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.694410   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.702304   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.718383   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.741422   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.751875   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.756007   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.760500   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.764846   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.769804   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.774715   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.780024   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.784950   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.790432   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.796186   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.802942   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.809788   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.817068   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.828104   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.837174   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.846750   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.856313   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.863874   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.891086   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.903001   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.914574   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.927394   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.956960   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.964498   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.972192   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.979000   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.989178   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.990765   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.994860   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.996980   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417850.999317   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.003635   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.006301   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.008477   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.013280   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.014407   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.018663   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.022310   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.023672   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.029080   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.031455   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.031610   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.034674   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.035578   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.040054   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.041303   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.041487   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.044395   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.048337   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.049286   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.054217   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.055529   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.059523   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.064481   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.066463   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.069874   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.075702   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.075807   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.082453   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.085257   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.088855   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.089308   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.094774   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.096562   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.102160   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.107614   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.116779   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.126395   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.129026   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.133094   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.136026   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.140917   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.143561   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.152316   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.170689   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.177370   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.181391   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.182548   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.188825   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.193979   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.196444   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.203180   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.213297   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.220225   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.220899   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.223417   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.230059   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.230916   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.237989   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.238612   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.245332   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.245774   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.254834   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.255515   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.263264   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.264547   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.264544   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.272532   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.280573   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.288434   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.297620   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.307143   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.310503   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.311233   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.353795   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.355525   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.357604   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.398356   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.398797   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.441580   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.442934   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.485840   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.486582   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.529660   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.531621   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.574955   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.578356   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.621644   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.933953   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.941953   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.949389   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.957765   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.968263   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.977883   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.988096   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417851.998989   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.008761   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.019439   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.032461   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.045647   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.059568   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.074184   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.091862   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.110176   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.127932   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.151186   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.153552   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.161641   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.169018   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.176601   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.177242   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.187085   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.196637   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.200177   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.200831   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.206577   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.208743   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.216127   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.217352   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.224631   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.226978   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.234799   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.237489   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.243536   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.244307   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.250352   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.254356   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.263492   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.265098   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.274746   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.277027   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.285315   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.291282   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.304816   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.309125   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.317861   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.327691   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.331180   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.345366   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.345477   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.362927   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.368472   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.381256   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.391641   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.398879   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.422211   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.434858   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.446003   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.495758   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.586493   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.590207   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.593592   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.597235   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.600931   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.605626   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.609155   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.613367   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.617000   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.621177   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.625506   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.649408   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.672631   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.695732   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.718466   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.740459   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.763753   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.768610   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.773732   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.777067   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.780657   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.784301   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.787916   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.787928   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.792598   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.796797   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.800395   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.804566   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.808676   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.829242   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.832062   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.832921   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.836271   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.839898   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.843561   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.847046   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.851747   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.854780   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.855979   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.859578   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.863712   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.867955   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.877700   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.891471   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.900227   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.914365   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.921975   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.937471   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.945048   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.960185   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.969119   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417852.982166   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.005458   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.029660   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.105494   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.109543   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.113380   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.117395   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.121676   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.125914   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.130382   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.135122   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.139774   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.144671   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.150827   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.157061   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.163939   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.171159   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.179923   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.188973   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.198605   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.210168   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.222496   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.234298   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.255881   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.284932   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.286107   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.286850   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.287303   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.288853   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.290060   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.290860   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.291232   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.292533   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.294021   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.294643   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.295407   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.296632   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.297919   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.298606   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.302850   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.304192   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.307061   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.310418   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.311263   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.315691   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.316753   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.320188   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.323227   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.325185   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.329639   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.331229   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.336404   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.337305   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.342969   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.344001   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.348355   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.351032   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.352382   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.356174   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.359562   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.360166   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.364439   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.368229   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.368653   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.373127   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.377745   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.377965   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.382642   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.387609   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.388990   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.393731   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.399935   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.400456   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.406797   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.413994   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.421892   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.422655   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.424867   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.426112   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.427322   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.428556   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.429813   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.431046   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.431546   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.432424   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.433776   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.435032   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.436345   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.437897   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.439445   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.441002   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.441264   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.443424   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.445592   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.447507   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.450151   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.450672   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.451857   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.452422   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.453057   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.454607   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.455808   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.456094   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.456986   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.458275   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.458960   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.459751   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.461101   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.462299   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.463552   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.464074   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.464629   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.467687   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.469690   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.475809   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.482034   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.485567   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.488376   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.494657   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.495233   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.495686   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.496192   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.496584   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.497712   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.498902   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.500119   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.501543   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.501570   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.502920   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.505291   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.507035   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.508072   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.514394   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.515568   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.516751   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.518304   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.518519   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.518942   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.519451   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.519661   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.519894   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.520324   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.520926   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.521006   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.521366   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.521770   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.522208   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.522385   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.522727   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.523212   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.523739   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.523919   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.524156   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.524554   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.525336   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.525419   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.525843   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.526434   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.526684   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.527983   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.528356   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.529821   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.531101   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.534321   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.534381   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.540514   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.546860   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.551554   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.551868   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.552164   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.552423   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.552711   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.552964   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.553367   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.553443   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.553640   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.553908   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.554207   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.554443   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.554696   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.554945   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.555226   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.555512   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.555864   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.556154   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.556453   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.556773   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.557208   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.557544   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.558464   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.558822   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.559895   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.559993   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.560516   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.561062   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.564095   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.566672   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.573224   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.589916   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.591153   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.592343   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.593573   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.594821   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.596046   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.597395   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.598735   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.599979   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.601284   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.602842   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.604378   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.606171   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.608227   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.610344   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.612250   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.614856   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.620667   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.623521   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.629204   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.655879   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.656970   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.657134   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.657416   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.657916   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.658464   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.658556   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.659598   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.659817   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.660801   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.661080   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.662018   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.662339   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.663212   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.663701   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.664573   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.665061   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.666124   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.666346   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.667694   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.667859   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.669280   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.670848   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.672654   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.674739   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.676879   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.678819   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.679334   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.679751   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.680200   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.680616   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.681039   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.681604   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.681918   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.682333   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.682726   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.683121   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.683627   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.684116   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.684614   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.685008   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.685539   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.686190   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.687077   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.687467   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.687685   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.689611   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.690303   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.691074   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.692354   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.695442   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.695884   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.712174   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.712478   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.712770   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.713019   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.713309   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.713556   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.713816   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.714070   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.714339   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.714637   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.714874   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.715124   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.715378   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.715667   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.716171   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.716529   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.716820   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.717116   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.717434   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.717773   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.718688   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.719038   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.720058   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.720576   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.721108   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.723012   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.723463   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.723965   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.724159   56645 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.724393   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.725579   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.728372   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.729585   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.730771   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.732121   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.733622   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.735252   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.746568   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.746999   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.747467   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.747889   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.748323   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.748791   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.749204   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.749606   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.750006   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.750514   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.750997   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.751500   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.751898   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.752301   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.752954   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.753452   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.754047   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.755952   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.757428   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.758761   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.761845   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.763441   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.763784   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.764040   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.764298   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.765710   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.767697   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.769854   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.770117   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.771937   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.772459   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.772758   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.773013   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.773342   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.773618   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.773899   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.774206   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.774488   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.774789   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.775043   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.776629   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.776906   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.778247   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.778908   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.779220   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.779516   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.779773   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.780064   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.780322   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.780663   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.780965   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.782437   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.782837   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.783212   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.783465   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.783826   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.783842   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.784132   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.784420   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.784777   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.785243   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.785593   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.785670   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.785988   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.786324   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.787239   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.787598   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.788619   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.789133   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.789671   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.792697   56657 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.807062   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.808011   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.809877   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.813087   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.828973   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.830334   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.830806   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.831429   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.832811   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.833088   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.834461   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.835046   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.836042   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.837030   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.837331   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.838471   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.838740   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.840351   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.841508   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.842454   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.844272   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.844558   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.846024   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.862162   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.862606   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.865347   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.865829   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.866495   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.866988   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.867501   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.871857   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.872289   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.872705   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.873115   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.873534   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.873915   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.874309   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.874751   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.876924   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.877385   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.877870   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.878455   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.878997   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.879603   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.880175   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.881448   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.882687   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.883840   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.884992   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.894655   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.895067   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.895514   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.895917   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.896331   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.896752   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.897190   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.897593   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.898016   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.898466   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.898874   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.899270   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.899765   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.900223   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.900695   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.901214   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.901792   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.903610   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.907187   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.910154   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.926919   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.927124   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.927294   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.927692   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.927709   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.928007   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.928355   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.928557   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.929160   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.929180   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.930281   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.930304   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.930583   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.931065   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.931221   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.931652   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.931770   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.932193   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.932290   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.932470   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.932902   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.932923   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.933243   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.933517   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.933629   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.934111   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.934214   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.934415   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.934922   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.934948   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.935214   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.935598   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.935818   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.936235   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.936260   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.936867   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.936890   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.938296   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.939002   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.939032   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.939642   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.939667   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.942759   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.943219   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.943515   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.943734   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.944442   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.944569   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.945132   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.945787   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.947539   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.949017   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.949699   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.952857   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.956013   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.957430   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.957899   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.958244   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.958632   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.959262   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.959285   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.959555   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.960012   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.960369   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.960710   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.961705   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.961991   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.962429   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.962609   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.962875   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.963947   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.964398   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.965358   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.965971   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.966259   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.966827   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.977646   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.978220   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.978620   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.978661   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.979261   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.979264   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.979815   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.979993   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.980366   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.980482   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.981059   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.981082   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.981602   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.981703   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.982027   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.982803   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.983063   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.983492   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.983607   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.984160   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.984264   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.984565   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.984975   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.985494   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.985596   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.985909   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.986353   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.986468   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.987157   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.987604   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.988078   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.988653   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.989192   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.989484   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.989827   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.990396   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.991660   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.992597   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.992896   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.994044   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417853.995184   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.003216   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.004417   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.004771   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.005177   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.005746   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.005767   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.006188   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.006591   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.006606   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.007182   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.007196   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.007308   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.007471   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.007870   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.007977   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.008582   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.008664   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.008682   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.009172   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.009281   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.010005   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.010149   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.010167   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.010544   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.011241   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.011520   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.011726   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.011857   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.012193   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.012420   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.012574   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.013203   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.013216   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.013234   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.013666   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.013785   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.013959   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.014545   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.014556   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.014649   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.014863   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.015283   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.015373   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.015684   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.016004   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.016087   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.016652   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.016950   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.017443   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.017565   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.017646   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.019042   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.019553   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.020031   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.023247   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.023272   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.023882   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.024729   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.024885   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.026230   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.026464   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.026476   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.027844   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.029784   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.029871   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.031702   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.038116   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.038180   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.038586   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.038943   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.039334   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.039830   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.040095   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.040566   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.041091   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.041507   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.042403   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.042507   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.042931   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.043161   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.043525   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.043732   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.043936   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.044447   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.044543   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.044932   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.045090   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.045609   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.045712   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.046099   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.046575   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.046730   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.047259   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.047411   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.047840   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.047942   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.048463   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.048648   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.049145   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.049620   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.050081   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.050882   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.050897   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.051615   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.052083   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.052550   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.053508   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.053970   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.054471   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.055079   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.055751   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.057930   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.060056   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.060639   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.061099   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.061729   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.062125   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.062535   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.063053   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.063083   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.063279   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.063524   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.064237   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.064653   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.065079   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.065476   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.065891   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.066315   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.066483   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.066733   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.067179   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.068184   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.068650   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.069139   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.069636   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.069814   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.070363   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.070980   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.071543   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.072884   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.072985   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.074234   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.075393   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.076555   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.085691   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.086239   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.086651   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.087108   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.087522   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.087988   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.088184   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.088431   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.088786   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.088963   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.089278   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.089465   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.089795   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.089973   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.090443   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.090548   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.090943   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.091044   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.091578   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.091677   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.092119   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.092222   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.092861   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.092872   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.093481   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.093582   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.094050   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.094224   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.094652   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.095358   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.095985   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.096497   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.099126   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.100095   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.102250   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.103071   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.111708   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.112904   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.114036   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.115171   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.116296   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.117573   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.118764   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.118818   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.119290   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.119719   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.120157   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.120267   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.120713   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.121170   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.121389   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.121680   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.122127   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.122690   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.122786   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.123163   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.123606   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.124174   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.124266   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.124659   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.125122   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.125428   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.125665   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.126156   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.126766   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.126863   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.127254   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.128329   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.128429   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.128805   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.129464   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.129955   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.130269   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.131123   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.131750   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.133522   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.133762   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.135887   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.136012   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.139356   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.142056   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.142623   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.145909   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.148114   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.149064   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.154569   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.160429   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.161586   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.162888   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.164100   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.164404   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.164966   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.165347   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.165508   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.165986   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.166800   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.166886   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.166900   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.167329   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.167824   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.168127   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.168303   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.168832   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.169513   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.169590   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.170128   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.170863   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.171268   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.171901   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.172276   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.173681   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.175031   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.175293   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.176869   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.178147   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.178587   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.180260   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.182079   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.184230   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.186620   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.187590   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.188782   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.189487   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.189916   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.191058   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.192196   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.192723   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.193480   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.194663   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.195940   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.197161   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.198469   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.198545   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.199831   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.200983   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.202272   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.203681   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.205041   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.205354   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.206664   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.208492   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.210400   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.216465   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.222518   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.229054   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.230310   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.231737   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.233091   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.234476   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.235822   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.237220   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.238660   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.240033   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.241206   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.241522   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.243009   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.244430   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.245911   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.247743   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.249153   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.250954   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.252683   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.254488   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.256190   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.258173   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.259985   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.263675   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.263735   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.264020   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.264855   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.265718   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.266174   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.267377   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.267605   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.268570   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.269776   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.271049   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.272313   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.273572   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.274547   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.274982   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.276377   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.277968   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.279541   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.281255   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.281501   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.282935   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.284722   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.286877   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.289263   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.290375   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.295343   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.299166   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.300901   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.307674   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.308035   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.316914   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.332111   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.333521   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.334867   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.336239   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.337579   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.338992   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.339058   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.340168   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.340491   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.341486   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.341876   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.342719   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.343345   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.343915   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.344827   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.345140   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.346355   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.346457   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.347802   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.347901   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.349077   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.349729   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.350496   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.351137   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.351912   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.352920   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.353524   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.354643   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.355117   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.356463   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.356905   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.358168   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.358599   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.360138   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.360406   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.361941   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.362586   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.364967   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.365515   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.367373   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.369317   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.371084   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.376147   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.376685   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.382995   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.383535   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.391784   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.400570   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.408123   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.409404   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.409589   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.410945   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.412326   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.413672   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.415067   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.416498   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.417870   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.418178   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.419357   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.420841   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.422257   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.423736   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.425566   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.426966   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.428738   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.430465   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.432269   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.433992   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.435967   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.436537   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.437835   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.437913   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.439103   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.440428   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.441482   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.441783   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.443401   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.443574   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.445493   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.445570   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.447542   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.449704   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.451970   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.452410   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.454589   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.456358   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.459318   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.463364   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.468184   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.474989   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.477059   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.478508   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.481986   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.485434   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.485933   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.489072   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.492691   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.494745   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.496277   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.500113   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.504025   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.507674   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.511729   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.515343   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.519893   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.524903   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.530201   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.535206   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.537859   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.539046   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.540306   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.541176   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.541660   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.543011   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.544720   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.546620   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.548098   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.548625   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.550794   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.553076   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.555721   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.557508   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.564532   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.569978   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.576121   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.579619   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.583072   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.586522   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.590154   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.593246   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.593829   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.597391   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.601129   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.604951   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.608522   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.612721   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.615855   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.616013   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.616468   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.617064   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.618333   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.619674   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.621161   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.621242   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.622965   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.624867   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.626098   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.626867   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.629042   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.631482   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.631587   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.634133   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.635923   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.636630   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.641227   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.642599   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.642990   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.649545   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.654295   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.657800   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.661251   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.664782   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.664887   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.668432   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.671184   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.672090   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.675650   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.679423   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.683348   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.687000   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.689193   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.691067   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.693947   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.694694   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.699099   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.704042   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.709304   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.714275   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.716263   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.720178   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.727040   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.741583   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.748527   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.765182   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.771372   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.789603   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.793840   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.819199   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.842750   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.867144   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.984815   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.988439   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.992192   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.995937   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417854.999930   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.003906   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.008231   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.012474   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.016821   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.021738   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.027067   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.032487   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.038659   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.045477   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.052230   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.058958   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.067785   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.077407   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.084909   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.088514   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.089528   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.092261   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.095984   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.099930   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.103786   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.108014   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.112134   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.114085   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.116684   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.121662   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.126778   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.131965   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.137970   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.144595   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.145952   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.150573   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.151192   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.155174   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.157720   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.159738   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.164068   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.164200   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.166246   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.167697   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.168655   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.171472   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.173645   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.175278   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.175505   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.178273   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.179262   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.183144   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.183468   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.186835   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.187599   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.188827   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.191966   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.194254   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.196460   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.199275   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.201407   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.205727   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.206597   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.210069   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.211932   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.212135   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.217023   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.218013   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.223386   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.224731   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.230265   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.231313   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.237983   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.238000   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.241425   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.244457   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.246050   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.246537   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.250627   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.255185   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.255818   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.258770   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.259577   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.263912   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.265410   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.267376   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.268796   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.272566   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.273303   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.278532   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.279331   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.283758   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.289061   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.290819   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.293977   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.300213   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.305378   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.306442   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.311267   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.317527   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.322319   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.324313   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.326983   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.331304   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.331643   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.331845   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.336244   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.338071   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.340651   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.345002   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.350056   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.353874   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.354728   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.358465   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.359989   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.360415   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.365232   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.367561   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.370538   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.374334   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.375461   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.381726   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.385619   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.388042   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.392858   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.399094   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.401613   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.405823   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.412923   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.413266   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.419567   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.428899   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.436891   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.440401   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.443522   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.450682   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.456177   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.457521   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.482152   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.485215   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.508120   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.512815   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.535389   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.540392   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.566398   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.592485   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.619806   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.914898   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.918600   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.922808   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.927201   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.931864   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.937934   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.944627   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.951990   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.960195   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.969001   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.979287   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417855.986011   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.007350   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.011041   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.015418   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.015425   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.019820   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.024379   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.030307   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.036844   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.044182   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.049513   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.052261   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.056754   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.060967   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.063961   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.071140   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.071373   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.077783   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.079399   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.086884   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.094762   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.095812   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.099536   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.103232   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.103793   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.106629   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.108230   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.111163   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.112883   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.118943   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.119932   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.125760   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.127653   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.133140   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.135463   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.140011   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.141322   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.145952   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.147151   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.150097   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.154250   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.156266   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.160357   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.161570   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.165594   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.167083   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.169557   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.176258   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.177017   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.184776   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.187957   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.193147   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.196185   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.200984   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.202146   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.209687   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.217326   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.225075   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.229393   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.235433   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.236633   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.243823   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.244952   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.245674   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.251192   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.254922   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.259310   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.265494   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.266852   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.274613   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.277079   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.283037   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.289642   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.290974   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.291166   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.299717   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.307369   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.315115   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.325383   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.333764   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.333788   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.335594   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.344886   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.355445   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.367022   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.377945   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.381075   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.382544   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.421795   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.423463   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.433161   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.467659   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.472436   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.482320   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.511543   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.521419   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.562448   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.568925   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.611769   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417856.659916   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.073545   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.080892   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.088318   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.095904   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.104362   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.113027   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.122386   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.131922   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.141605   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.152180   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.157158   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.163142   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.164480   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.171893   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.174005   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.179519   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.186514   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.187606   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.196104   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.200256   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.205288   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.213504   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.214588   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.224221   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.226933   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.234622   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.244077   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.245457   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.252951   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.256244   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.260308   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.262713   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.267761   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.268875   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.275398   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.282584   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.283577   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.285174   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.292073   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.295739   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.301241   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.309066   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.310691   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.320420   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.326105   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.330890   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.331071   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.342085   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.344634   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.352853   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.365320   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.366831   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.378750   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.390488   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.391973   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.402711   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.405403   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.412430   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.412460   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.422021   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.422480   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.431827   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.440856   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.441342   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.450700   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.460236   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.463052   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.470414   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.471584   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.481137   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.484178   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.490958   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.493438   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.501622   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.502879   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.508647   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.510371   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.512574   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.522113   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.523742   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.531535   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.533915   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.541180   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.542875   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.551503   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.553558   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.562288   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.565844   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.568243   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.572156   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.579403   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.580967   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.582865   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.590494   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.591612   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.593786   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.600154   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.602219   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.607347   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.610012   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.612302   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.619609   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.620772   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.621207   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.629020   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.631819   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.637893   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.638634   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.644218   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.648865   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.654827   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.657751   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.659643   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.668757   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.669465   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.671995   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.680069   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.683467   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.685474   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.688722   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.698798   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.699316   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.709305   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.715927   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.718060   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.728678   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.732988   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.733201   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.741222   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.746914   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.754710   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.761589   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.769003   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.782431   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.786036   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.795738   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.811262   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.812852   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.829869   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.839116   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.843962   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.858667   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.864322   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.894456   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.908749   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.917397   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.950495   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.962682   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417857.971570   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417858.016148   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417858.019069   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417858.026226   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417858.071257   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417858.095040   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417858.127273   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417858.197008   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417858.964189   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417858.971654   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417858.980441   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417858.989504   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417858.999172   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.012227   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.027404   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.037598   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.041634   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.045023   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.053591   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.056705   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.062479   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.072097   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.072879   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.084740   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.090643   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.099265   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.112435   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.112706   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.127362   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.136783   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.142807   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.149392   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.156864   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.160103   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.165523   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.174399   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.181753   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.184154   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.196783   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.205511   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.206146   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.211363   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.212396   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.216430   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.220675   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.225129   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.225238   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.229304   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.233480   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.237987   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.240163   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.242372   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.247245   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.251506   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.255847   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.256845   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.261175   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.266876   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.272106   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.273169   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.274019   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.278067   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.281133   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.284601   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.285232   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.289472   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.293793   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.294682   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.297839   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.301994   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.306590   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.308365   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.310996   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.315994   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.316221   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.319110   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.320294   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.325655   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.330025   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.335719   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.339439   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.340948   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.346882   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.353346   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.361994   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.377007   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.384657   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.386530   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.388332   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.394074   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.398161   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.402442   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.406806   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.407679   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.410913   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.414587   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.415132   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.419713   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.424117   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.429050   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.430029   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.433356   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.438705   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.440210   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.443102   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.448829   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.454085   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.456253   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.460067   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.466566   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.482263   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.490544   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.498250   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.507801   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.521379   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.543945   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.570526   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.596699   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.622210   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.736894   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.741179   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.745392   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.749772   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.754375   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.758830   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.763769   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.768938   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.774330   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.780081   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.786030   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.792028   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.799255   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.804708   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.807831   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.808968   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.813181   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.815360   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.817543   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.822110   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.823174   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.826546   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.831610   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.832928   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.836727   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.841998   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.845147   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.847641   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.853587   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.857007   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.859525   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.866721   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.875199   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.880786   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.882627   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.890318   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.900013   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.912057   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.917499   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.920317   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.922548   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.923763   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.924581   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.927558   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.928802   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.932277   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.933176   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.937906   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.937980   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.942362   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.944174   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.947153   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.947490   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.951298   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.952546   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.957794   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.958427   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.963380   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.966023   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.969250   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.974503   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.975116   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.983026   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.983028   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.983761   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.988781   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.989530   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.991485   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.993767   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.998590   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.998716   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417859.998930   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.004119   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.006601   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.007821   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.010269   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.016232   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.016813   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.017424   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.024584   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.026853   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.028242   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.032171   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.034305   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.039941   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.040648   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.040828   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.048409   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.048816   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.054791   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.055264   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.063285   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.064146   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.064765   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.073143   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.076315   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.082060   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.087874   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.092048   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.099430   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.099466   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.100314   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.104464   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.105829   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.109455   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.110522   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.113244   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.114147   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.119782   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.119881   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.126060   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.129755   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.133123   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.135630   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.140198   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.141161   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.147673   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.152526   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.156034   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.160755   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.164097   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.164798   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.170553   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.174954   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.179465   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.187764   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.188416   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.197305   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.199977   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.207277   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.214682   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.215070   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.221062   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.224867   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.228490   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.234899   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.244870   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.250238   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.251521   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.256345   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.267798   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.278442   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.280165   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.285401   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.290363   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.313130   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.315633   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.340901   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.347816   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.367894   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.395104   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.430128   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.465161   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.758426   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.762725   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.767384   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.772180   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.777482   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.784011   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.791057   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.798843   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.807248   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.819216   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.820937   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.825229   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.829897   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.830885   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.834654   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.839786   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.844826   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.846326   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.853413   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.861095   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.869280   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.874709   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.886391   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.897666   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.911050   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.922127   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.934853   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.941242   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.945564   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.950233   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.955046   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.957490   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.960248   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.966590   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.973625   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.981375   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.986982   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417860.989832   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.001908   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.006685   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.009183   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.011633   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.013627   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.014201   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.016686   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.019289   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.021505   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.021956   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.024415   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.026766   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.027425   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.029237   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.032235   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.036005   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.039159   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.042059   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.046061   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.049345   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.051730   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.057300   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.061692   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.069765   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.072412   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.074311   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.074779   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.077260   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.079734   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.082330   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.084969   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.086229   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.087430   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.089755   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.092205   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.095187   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.098064   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.098946   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.102047   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.104102   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.104934   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.108893   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.111656   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.112146   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.115715   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.120029   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.124953   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.132571   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.137940   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.138490   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.144447   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.156127   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.169615   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.182729   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.187089   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.189791   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.192145   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.194623   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.195552   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.197116   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.199707   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.202336   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.204797   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.207125   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.209570   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.212546   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.216442   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.219596   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.222510   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.226506   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.229782   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.233368   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.237734   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.250422   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.262458   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.274537   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.288034   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.288164   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.290575   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.293073   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.295661   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.298311   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.301072   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.301411   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.303891   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.306725   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.309685   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.312741   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.314353   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.315789   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.319765   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.323619   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.327781   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.332353   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.337575   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.343706   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.344533   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.347048   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.349551   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.352115   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.354747   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.356106   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.357487   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.360281   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.363119   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.366167   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.369296   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.372460   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.376322   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.377255   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.380055   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.380255   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.383666   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.384084   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.387085   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.388585   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.389993   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.392895   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.393788   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.395929   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.398946   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.399848   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.402195   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.406169   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.410605   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.411999   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.415074   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.419339   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.424262   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.429201   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.432670   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.432809   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.435786   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.437842   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.439225   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.442266   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.442658   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.445516   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.447685   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.448380   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.451373   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.453113   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.454369   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.457582   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.459297   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.461531   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.465303   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.465927   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.467988   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.468074   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.470424   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.470600   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.473183   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.474697   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.475830   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.478573   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.479599   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.480957   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.481394   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.484220   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.484496   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.487200   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.487952   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.490274   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.493119   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.493334   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.494608   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.497085   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.497559   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.500908   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.502978   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.505025   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.508446   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.508461   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.509528   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.514689   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.514805   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.520861   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.522102   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.523301   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.533093   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.535753   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.536100   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.549789   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.553196   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.553800   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.556796   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.560162   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.563719   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.563726   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.566605   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.569479   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.570730   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.572493   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.575478   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.577409   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.578718   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.582653   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.587077   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.591093   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.591511   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.595762   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.600652   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.605546   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.608657   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.609023   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.614204   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.618645   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.624042   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.626223   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.629450   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.635643   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.644230   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.657052   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.670794   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.684532   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.698267   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.711922   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.729429   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.746933   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.808434   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.811183   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.813980   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.817224   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.820699   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.824499   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.828519   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.832861   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.838364   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.844399   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.851931   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.863736   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.865129   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.866501   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.869303   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.872565   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.876042   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.879755   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.880041   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.883722   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.887976   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.893571   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.899689   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.900879   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.907364   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.920673   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.928172   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.935869   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.956879   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.959248   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.960770   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.962227   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.963742   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.965308   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.966944   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.968443   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.969870   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.971481   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.972979   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.974684   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.976835   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.978479   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.980242   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.982388   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.983987   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.984259   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.984633   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.986663   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.987399   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.988692   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.990226   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.993493   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.995271   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417861.997017   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.000753   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.001143   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.004793   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.007014   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.009141   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.014231   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.014452   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.014679   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.015988   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.017438   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.018948   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.020512   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.020741   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.021434   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.022184   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.023697   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.025137   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.026750   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.028422   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.028498   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.030204   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.032354   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.034008   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.035776   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.037922   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.039774   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.041609   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.042177   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.044184   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.050770   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.056618   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.056716   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.062512   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.069662   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.076867   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.077571   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.097472   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.099066   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.100641   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.102209   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.103848   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.104865   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.105549   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.107273   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.109029   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.110838   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.112658   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.114502   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.116741   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.118974   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.121343   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.123891   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.126926   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.130124   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.135956   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.136187   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.137494   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.138962   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.140498   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.142065   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.143450   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.143712   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.145208   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.146630   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.148247   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.149756   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.151472   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.151774   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.153393   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.153646   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.154980   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.155313   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.156553   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.157097   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.157654   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.158198   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.159335   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.159511   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.159903   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.161295   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.161377   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.161639   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.163418   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.163541   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.163782   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.165497   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.165516   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.165811   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.167390   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.167548   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.169262   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.169651   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.171513   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.171757   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.172398   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.173880   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.173896   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.175941   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.176306   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.178268   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.178351   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.178887   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.180723   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.181874   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.182927   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.184167   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.184949   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.185583   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.187853   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.190123   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.190888   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.191370   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.193042   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.195211   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.198206   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.198218   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.198569   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.200941   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.204068   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.207836   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.211935   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.212147   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.213934   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.215568   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.216886   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.217559   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.219402   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.221411   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.223507   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.223820   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.225618   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.227544   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.229579   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.230741   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.232001   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.234166   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.236317   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.237659   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.238954   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.241212   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.243471   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.244579   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.246376   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.248520   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.251281   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.253418   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.254001   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.257110   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.260884   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.262253   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.265024   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.269958   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.272841   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.274324   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.275925   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.276914   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.277516   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.279089   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.280724   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.282414   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.283868   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.284156   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.285940   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.287754   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.289582   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.290828   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.291442   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.293687   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.295936   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.297782   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.298342   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.300895   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.303879   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.306653   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.306977   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.312972   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.315485   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.320144   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.325932   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.334232   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.336015   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.337653   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.339636   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.341498   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.343519   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.345618   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.347720   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.349725   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.351767   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.354197   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.356382   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.358584   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.361258   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.363532   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.365816   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.368742   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.370922   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.373715   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.376443   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.379578   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.383384   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.387541   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.392553   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.392783   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.394727   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.396618   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.398710   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.399530   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.400976   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.403329   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.405716   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.406501   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.408326   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.413473   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.420434   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.424001   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.427952   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.429322   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.433134   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.438221   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.439130   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.444750   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.446673   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.446932   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.448578   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.448812   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.450679   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.452930   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.455275   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.457703   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.457889   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.460297   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.470966   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.475887   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.479945   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.485095   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.491018   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.498572   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.501346   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.502479   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.503779   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.505078   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.506436   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.507736   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.508883   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.509266   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.510288   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.511656   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.512787   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.514180   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.515642   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.517174   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.518909   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.520794   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.522149   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.522998   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.525035   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.528785   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.530825   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.533854   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.536878   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.540571   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.544285   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.551885   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.553004   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.554300   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.555593   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.556936   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.558229   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.559349   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.560720   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.562083   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.563207   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.564602   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.566059   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.567574   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.567932   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.569305   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.569875   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.571185   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.571777   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.573387   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.573889   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.575415   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.576148   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.578506   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.579224   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.580905   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.581276   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.582574   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.583512   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.583713   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.584298   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.584877   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.585978   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.587246   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.587364   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.588631   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.590026   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.591074   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.591389   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.592842   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.594329   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.594807   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.595791   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.597361   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.598829   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.599010   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.600576   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.602337   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.602950   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.604060   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.606473   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.608026   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.608187   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.611280   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.613788   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.615020   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.621290   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.624653   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.626297   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.627894   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.629527   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.631154   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.631897   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.632360   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.632799   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.633485   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.634395   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.634639   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.635859   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.635962   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.637017   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.637371   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.638381   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.639085   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.639798   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.640539   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.641215   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.642300   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.642676   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.644140   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.644254   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.644746   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.645718   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.645926   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.647358   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.647514   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.648802   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.649410   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.650539   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.651690   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.652317   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.654154   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.654175   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.656584   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.657140   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.658250   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.659637   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.661328   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.662138   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.664782   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.665058   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.668430   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.672060   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.674388   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.674603   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.675568   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.675719   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.676249   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.676879   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.677847   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.678461   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.679420   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.679543   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.679827   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.681256   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.681345   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.682402   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.682962   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.683791   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.684003   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.684542   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.685187   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.685936   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.686326   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.687327   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.687742   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.688599   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.689141   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.689244   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.690605   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.690800   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.692515   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.692599   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.694238   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.694574   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.694651   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.696018   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.696844   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.697547   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.698869   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.699418   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.699941   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.701688   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.702647   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.703953   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.704687   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.706958   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.707685   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.709437   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.710677   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.711916   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.714390   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.714561   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.718262   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.718383   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.721970   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.725535   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.729090   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.734880   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.739393   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.743898   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.749245   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.755465   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.756577   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.757720   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.758817   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.759967   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.760276   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.761369   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.761542   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.762846   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.762928   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.764376   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.764456   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.765714   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.765919   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.767147   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.767413   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.768808   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.768980   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.770234   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.770564   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.771990   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.773710   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.775466   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.777173   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.778994   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.779576   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.781217   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.782800   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.784265   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.787570   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.787972   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.793243   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.797378   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.797779   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.799005   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.800591   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.802211   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.803828   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.805459   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.807038   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.808418   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.809453   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.809823   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.809896   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.810779   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.810876   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.811547   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.811742   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.811973   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.812610   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.812984   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.813556   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.813578   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.814455   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.814847   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.814951   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.815323   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.816333   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.816477   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.816639   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.817094   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.818237   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.818364   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.818467   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.819090   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.819797   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.820002   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.820219   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.821461   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.821895   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.822704   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.824163   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.824934   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.826474   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.826649   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.828283   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.828606   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.829475   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.829970   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.831718   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.831958   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.832426   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.833399   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.834440   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.836391   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.837125   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.837269   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.839626   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.840724   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.842885   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.844310   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.846589   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.847451   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.847891   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.851463   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.857280   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.859105   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.859925   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.860773   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.861641   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.861818   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.862413   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.863297   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.864151   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.865039   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.865433   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.865808   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.866310   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.866469   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.866793   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.867096   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.867640   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.867892   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.868870   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.868891   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.869819   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.870150   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.870806   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.871400   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.871933   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.872007   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.872898   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.873651   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.873896   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.874885   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.875301   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.875895   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.877087   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.877189   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.878312   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.878762   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.879312   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.880628   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.880730   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.882308   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.883280   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.885288   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.885921   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.888504   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.893910   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.894882   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.895274   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.896474   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.897681   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.898961   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.900232   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.901459   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.902689   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.903961   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.905249   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.906184   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.907113   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.908050   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.909379   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.910489   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.911683   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.913713   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.914619   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.914727   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.915420   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.916197   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.916990   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.917557   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.917931   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.918911   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.920020   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.920114   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.920982   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.921964   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.922525   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.922971   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.924003   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.924163   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.925080   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.926200   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.927182   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.927708   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.928431   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.931010   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.931241   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.932391   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.933577   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.933739   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.934884   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.934960   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.936297   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.937621   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.938532   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.939058   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.940656   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.941615   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.942079   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.942980   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.944180   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.945378   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.946645   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.947914   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.949154   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.950383   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.950861   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.951660   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.952940   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.953868   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.954742   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.954904   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.955840   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.957169   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.958281   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.959507   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.959666   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.962369   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.964757   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.965303   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.967561   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.969203   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.970061   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.970255   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.970357   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.971231   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.971811   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.972295   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.973291   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.974320   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.975468   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.975606   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.976887   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.978171   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.978994   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.980386   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.981783   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.982663   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.982770   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.983624   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.984481   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.985283   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.986310   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.986399   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.987225   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.987296   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.988187   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.988940   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.989914   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.990681   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.990853   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.991969   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.993216   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.994217   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.994469   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.996719   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.997968   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.998369   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417862.999998   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.001652   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.002541   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.003397   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.005070   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.008239   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.011466   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.013978   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.014751   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.015945   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.017107   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.018016   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.018160   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.018233   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.019108   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.019435   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.020217   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.021022   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.021227   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.022394   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.022414   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.023523   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.023681   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.024799   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.025081   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.026096   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.026700   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.028317   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.028894   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.030521   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.035846   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.037231   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.037311   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.038118   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.038902   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.039233   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.039710   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.040104   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.040523   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.041465   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.042449   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.042763   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.043438   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.044392   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.045370   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.046404   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.046564   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.047420   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.047644   56659 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.048506   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.049664   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.050659   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.051151   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.051910   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.054479   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.057053   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.061736   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.062510   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.063707   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.065571   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.065596   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.067101   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.067117   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.068317   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.068706   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.069533   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.069909   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.070820   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.071161   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.072111   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.072557   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.073362   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.074181   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.074615   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.075900   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.076377   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.077204   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.078128   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.078224   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.083673   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.084737   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.084842   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.086085   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.087202   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.087608   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.088419   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.091268   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.093670   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.095248   56652 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.096498   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.098905   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.100443   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.103972   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.107498   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.111029   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.114572   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.145417   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.146339   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.147218   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.148264   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.149272   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.150302   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.151365   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.152631   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.153916   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.156136   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.161408   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.164791   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.168321   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.172063   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.176668   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.187164   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.187926   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.189129   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.191028   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.192441   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.194009   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.195202   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.196441   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.197823   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.199442   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.201631   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.203263   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.209808   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417863.212575   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - loss: 0.9331"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728417863.220141   56656 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.4005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 20:04:25.686255: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-10-08 20:04:25.686367: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-10-08 20:04:25.686507: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n",
      "W0000 00:00:1728417866.422550   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.423330   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.424222   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.425008   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.425181   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.426011   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.426083   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.426920   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.427090   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.427704   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.427776   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.428028   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.428862   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.428863   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.429105   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.429934   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.430079   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.430165   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.431053   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.431222   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.431309   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.432236   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.432367   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.433575   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.433705   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.434022   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.434757   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.435045   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.435139   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.435889   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.436012   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.436237   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.436843   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.436926   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.437269   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.437629   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.438058   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.438622   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.438621   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.439349   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.439731   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.440152   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.440776   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.441241   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.441384   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.442326   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.442445   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.442675   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.443363   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.443806   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.444017   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.444547   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.445333   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.445504   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.445887   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.447091   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.447215   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.447446   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.448856   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.449120   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.449253   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.450915   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.451043   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.452181   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.452749   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.452842   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.453590   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.454168   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.454601   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.454790   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.454870   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.455603   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.456353   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.456554   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.456668   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.458055   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.458385   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.459538   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.459933   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.460121   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.460525   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.460995   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.461439   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.461568   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.462648   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.462917   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.463008   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.463877   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.464521   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.464612   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.465583   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.465840   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.466621   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.467538   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.467837   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.469539   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.469540   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.471084   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.471358   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.472368   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.473064   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.474837   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.475089   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.476002   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.476847   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.477871   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.477943   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.479413   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.481638   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.485113   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.487267   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.489966   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.497828   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.497842   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.498695   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.498778   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.499873   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.499880   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.500676   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.500679   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.501515   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.501518   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.502297   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.502373   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.503144   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.503268   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.505645   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.505812   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.506576   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.507332   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.507996   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.508751   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.509550   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.510423   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.510604   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.510625   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.511364   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.513819   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.515022   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.515205   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.518597   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.518730   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.518752   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.522257   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.522430   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.523284   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.526836   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.526942   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.526957   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.530574   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.531162   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.531235   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.534890   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.539080   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.615919   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.616632   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.616736   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.617451   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.617516   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.618314   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.618396   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.619192   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.619277   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.620132   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.620201   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.621124   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.621198   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.622130   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.622206   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.623119   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.623196   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.624010   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.624169   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.624483   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.624937   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.625254   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.625358   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.625863   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.626121   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.626316   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.627018   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.627036   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.627396   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.627825   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.628102   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.628843   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.628856   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.629381   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.629769   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.629990   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.630539   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.630718   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.631226   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.631620   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.631797   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.632513   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.632604   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.633000   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.633536   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.634744   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.634766   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.635074   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.635828   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.636606   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.636930   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.637133   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.638245   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.639446   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.639939   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.640262   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.640659   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.642362   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.642834   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.642906   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.644505   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.646378   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.649712   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.651254   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.651333   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.652356   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.652434   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.652455   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.653283   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.653364   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.654324   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.654400   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.655364   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.655448   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.656248   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.656332   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.657096   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.657191   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.658068   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.658158   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.659071   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.659157   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.660416   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.660511   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.661416   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.661610   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.661701   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.662288   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.663108   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.663152   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.663278   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.664227   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.665165   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.665958   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.666783   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.667430   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.667508   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.667738   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.668653   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.669976   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.671146   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.671847   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.672017   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.672462   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.676090   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.676280   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.676649   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.681064   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.684892   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.685195   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.685372   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.693587   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.693961   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.694216   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.698966   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.699701   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.702945   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.704431   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.705304   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.708344   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.713825   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.873478   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.874389   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.875333   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.875930   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.876317   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.876872   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.877343   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.877839   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.878350   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.878820   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.879373   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.879841   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.880509   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.880857   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.881719   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.881914   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.883232   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.883281   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.883538   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.884647   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.884771   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.884852   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.885616   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.886056   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.886227   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.886609   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.887420   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.887823   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.887855   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.888883   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.888959   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.889523   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.890003   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.890341   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.891277   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.891398   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.892018   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.892473   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.893226   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.893856   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.893931   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.895314   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.895337   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.895786   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.896648   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.897379   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.897818   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.898110   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.899816   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.899926   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.900629   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.901586   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.903197   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.903432   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.905105   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.905444   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.907473   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.907777   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.909858   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.910388   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.912587   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.913654   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.918254   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.921423   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.922736   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.923035   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.924032   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.924151   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.925587   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.925696   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.926891   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.927256   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.928702   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.928939   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.930394   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.930483   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.931646   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.931886   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.933285   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.933369   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.934607   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.934984   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.935560   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.936113   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.936327   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.937576   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.937760   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.938401   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.939326   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.939825   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.940379   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.940890   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.942282   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.942637   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.943593   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.944827   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.946299   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.946739   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.948581   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.949575   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.950555   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.952793   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.955198   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.958126   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.959651   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.963386   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.966398   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.968149   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.976357   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.980625   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.983804   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.993655   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417866.997643   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.000970   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.007859   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.010761   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.011249   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.018234   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.021030   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.021704   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.031447   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.356910   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.358415   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.359853   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.361351   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.362609   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.362870   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.364088   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.364486   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.365515   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.366076   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.367009   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.367752   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.368533   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.369633   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.370132   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.370670   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.371650   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.371832   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.372172   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.373687   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.373820   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.373933   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.375470   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.375686   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.375863   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.377002   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.377669   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.378045   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.378610   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.379612   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.380192   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.380610   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.381603   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.381850   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.383413   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.383845   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.383925   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.385826   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.386498   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.387770   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.389329   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.389767   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.391931   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.392207   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.394500   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.395153   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.397272   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.398185   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.398385   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.401126   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.401839   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.404338   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.406080   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.407787   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.408125   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.409012   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.412227   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.414105   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.415709   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.419894   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.426218   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.426524   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.428602   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.430055   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.430657   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.432141   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.432993   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.434227   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.435661   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.436602   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.438470   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.439308   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.440489   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.441449   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.443107   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.443472   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.443984   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.445351   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.446202   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.446294   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.447391   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.448291   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.448572   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.449724   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.450787   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.450860   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.452159   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.453162   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.453440   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.455657   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.455739   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.457673   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.460289   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.462527   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.464595   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.464820   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.466947   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.468467   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.469391   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.477941   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.481572   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.482043   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.494679   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.495239   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.498409   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.510837   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.512169   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.514708   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.528311   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.528489   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.532333   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.546034   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.547265   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.550615   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.564543   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.583505   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.587505   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417867.600986   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.257135   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.259438   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.261873   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.264137   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.266605   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.269096   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.269280   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.271436   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.272015   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.273900   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.274688   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.276311   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.276489   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.277838   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.278945   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.279023   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.281417   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.281745   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.281844   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.283716   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.284610   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.285072   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.286202   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.287317   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.288490   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.288861   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.290521   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.291610   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.291919   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.294444   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.294527   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.296500   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.297607   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.297908   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.301495   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.301578   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.301686   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.304826   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.305058   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.307072   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.308237   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.309691   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.311652   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.314840   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.316220   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.320258   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.321341   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.322685   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.326771   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.328579   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.335054   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.335983   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.341902   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.342520   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.347210   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.348554   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.348632   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.356085   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.360696   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.362663   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.371213   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.375059   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.375171   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.379342   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.383197   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.386079   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.386919   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.389781   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.391604   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.394090   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.395335   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.397970   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.399303   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.400207   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.401722   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.403025   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.403822   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.406367   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.407381   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.407561   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.410062   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.411283   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.411971   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.414934   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.415105   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.416584   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.418624   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.419849   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.422402   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.423654   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.426816   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.428602   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.431409   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.432273   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.435996   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.439938   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.440472   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.445138   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.455293   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.465788   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.468703   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.481772   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.495275   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.498511   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.515047   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.528522   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.530205   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.547146   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.560450   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.564913   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.581783   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.595243   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.602475   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.619166   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.632697   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.681208   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.699014   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417868.712203   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.028208   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.032191   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.036222   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.040258   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.044636   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.049115   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.053399   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.054019   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.057434   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.058547   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.061153   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.061498   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.064281   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.065189   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.065595   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.069380   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.069403   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.070020   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.073488   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.074551   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.075507   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.077862   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.079495   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.081751   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.082408   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.084056   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.087296   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.088429   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.089601   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.092039   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.094699   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.097699   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.097878   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.100906   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.102881   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.106869   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.107203   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.108986   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.113897   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.115372   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.116235   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.122159   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.123012   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.131343   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.132291   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.140681   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.141640   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.143951   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.150169   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.155393   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.169583   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.173129   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.178298   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.179761   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.180983   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.186658   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.189853   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.195590   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.198736   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.202424   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.203237   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.205421   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.209467   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.212322   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.217458   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.221332   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.221449   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.224122   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.228137   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.228551   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.233605   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.235134   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.235866   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.240598   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.244328   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.244335   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.248849   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.251161   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.251578   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.257544   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.258641   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.260644   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.266859   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.267633   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.273770   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.275850   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.283459   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.284475   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.290567   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.298838   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.302545   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.307549   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.329924   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.353122   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.353527   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.381151   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.404222   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.419010   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.446537   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.469597   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.481405   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.509597   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.532124   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.546197   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.575115   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.597002   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.623903   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.654117   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.677092   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.773404   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.805934   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417870.826828   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.463800   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.470953   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.478219   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.485588   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.493606   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.501883   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.511535   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.513332   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.519936   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.520489   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.520666   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.527171   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.528012   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.531521   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.534522   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.535523   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.541039   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.541954   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.543705   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.549912   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.552126   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.552780   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.558649   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.561972   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.564757   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.568493   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.571053   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.577318   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.577667   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.582347   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.588966   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.592101   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.595020   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.598774   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.604089   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.610833   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.612097   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.616242   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.623086   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.629112   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.630136   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.636065   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.647180   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.654026   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.664427   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.671183   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.680933   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.682351   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.689171   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.702726   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.733411   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.734538   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.740723   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.741086   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.744628   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.748195   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.752909   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.755081   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.756482   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.760715   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.762633   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.764141   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.768991   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.772710   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.776979   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.781500   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.786740   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.788533   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.793359   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.796914   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.800479   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.805141   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.808656   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.809411   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.812844   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.816354   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.820383   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.821293   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.824981   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.826870   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.829268   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.830450   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.831309   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.833829   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.834039   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.838943   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.842649   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.847045   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.850580   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.855511   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.859275   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.861540   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.863653   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.864671   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.868255   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.883301   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.896734   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.896873   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.916648   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.918598   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.928888   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.948631   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.952297   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.964734   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.980885   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417873.984662   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417874.016911   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417874.017126   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417874.042189   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417874.053749   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417874.098808   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417874.132593   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.329924   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.333734   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.337294   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.341059   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.345077   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.349073   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.353327   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.357510   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.362276   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.366923   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.372580   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.378288   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.384791   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.393496   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.397621   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.401465   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.402928   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.405062   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.408839   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.411692   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.412883   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.416902   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.421186   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.421247   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.425092   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.425304   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.428729   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.430083   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.432581   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.434036   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.434929   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.436647   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.440869   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.440955   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.444930   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.445165   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.446869   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.449482   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.453566   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.454300   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.459040   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.462382   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.462396   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.463576   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.464831   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.464940   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.466094   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.467202   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.468356   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.469788   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.470997   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.471296   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.471992   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.472869   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.474098   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.475410   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.476741   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.477726   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.480768   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.484206   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.486557   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.492967   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.496235   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.501440   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.503474   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.505135   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.509690   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.514526   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.518069   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.528013   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.532133   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.533345   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.534611   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.534617   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.535884   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.537006   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.538175   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.539104   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.539636   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.541165   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.542739   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.543975   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.545311   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.546645   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.550770   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.551641   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.554153   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.563001   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.569634   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.570839   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.571576   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.571970   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.573240   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.574363   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.575533   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.576998   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.578517   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.579899   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.580111   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.581360   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.582697   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.584046   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.588370   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.591618   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.600548   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.604845   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.609202   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.617512   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.621121   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.625980   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.642826   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.659887   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.847183   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.848359   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.849497   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.850615   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.851805   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.853082   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.854344   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.855509   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.856806   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.858076   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.859576   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.861067   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.862806   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.864870   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.867429   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.869566   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.889716   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.895605   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.898357   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.909736   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.910165   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.910562   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.910981   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.911396   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.911875   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.912343   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.913629   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.915089   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.916712   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.918395   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.919599   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.920453   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.920789   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.921935   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.922897   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.923169   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.924374   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.924817   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.925683   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.926954   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.928138   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.929451   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.930738   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.932260   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.933768   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.935528   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.937631   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.940203   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.942343   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.943082   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.943478   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.943862   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.944256   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.944661   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.945070   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.945480   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.945901   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.946342   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.946706   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.947197   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.947585   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.948070   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.948451   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.948959   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.949367   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.949837   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.950472   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.951040   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.952888   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.954324   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.957144   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.957459   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.958350   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.959504   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.960632   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.961832   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.962664   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.963121   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.964383   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.965569   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.966876   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.968168   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.968616   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.969687   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.971209   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.971404   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.972971   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.972979   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.973296   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.973559   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.973856   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.974126   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.974362   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.974663   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.974946   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.975213   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.975330   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.975608   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.975852   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.976139   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.976386   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.976664   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.976952   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.977334   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.977668   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.977950   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.978057   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.978390   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.978729   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.979756   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.980101   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.982834   56634 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.982923   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.983365   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.983760   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.984401   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.984821   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.985422   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.985910   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.987213   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.988678   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.990272   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.991964   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.994035   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.996739   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417875.998653   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.000321   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.006225   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.008969   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.012107   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.017054   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.017449   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.018026   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.018430   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.018830   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.019242   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.019654   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.020080   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.020526   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.020896   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.021380   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.021756   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.022254   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.022639   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.023146   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.023548   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.023770   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.024083   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.024271   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.024804   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.024874   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.025242   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.025466   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.025706   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.026187   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.026664   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.027336   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.027974   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.028804   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.029459   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.031068   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.031927   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.032763   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.034850   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.037276   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.039196   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.047574   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.047887   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.048147   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.048447   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.048721   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.048959   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.049268   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.049503   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.049748   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.050021   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.050254   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.050545   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.050789   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.051067   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.051330   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.051624   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.051932   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.052217   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.052533   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.052875   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.053916   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.057000   56630 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.057546   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.057947   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.058444   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.058855   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.059260   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.059687   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.060098   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.060522   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.060963   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.061335   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.061807   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.062188   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.062667   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.063056   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.063556   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.063954   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.064430   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.065062   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.065638   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.067485   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.068923   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.072030   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.087639   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.087945   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.088203   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.088504   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.088778   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.089019   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.089321   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.089562   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.089803   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.090078   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.090315   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.090608   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.090852   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.091135   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.091397   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.091702   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.092002   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.092282   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.092601   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.092944   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.093984   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728417876.097021   56648 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 573ms/step - loss: 0.3914 - val_loss: 0.2212 - learning_rate: 0.0010\n",
      "Epoch 2/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 20:04:36.316480: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0255"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 20:04:39.349695: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 131ms/step - loss: 0.0255 - val_loss: 0.2257 - learning_rate: 0.0010\n",
      "Epoch 3/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 0.0244 - val_loss: 0.2275 - learning_rate: 0.0010\n",
      "Epoch 4/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 20:04:43.301043: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - loss: 0.0232 - val_loss: 0.2265 - learning_rate: 0.0010\n",
      "Epoch 5/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0217 - val_loss: 0.2228 - learning_rate: 0.0010\n",
      "Epoch 6/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 20:04:52.912497: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0204 - val_loss: 0.2248 - learning_rate: 0.0010\n",
      "Epoch 7/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - loss: 0.0190 - val_loss: 0.2329 - learning_rate: 0.0010\n",
      "Epoch 8/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.0181 - val_loss: 0.2367 - learning_rate: 0.0010\n",
      "Epoch 9/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0175 - val_loss: 0.2364 - learning_rate: 0.0010\n",
      "Epoch 10/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 0.0170 - val_loss: 0.2387 - learning_rate: 0.0010\n",
      "Epoch 11/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0168 - val_loss: 0.2356 - learning_rate: 0.0010\n",
      "Epoch 12/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 20:05:10.533194: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0164 - val_loss: 0.2336 - learning_rate: 0.0010\n",
      "Epoch 13/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.0162 - val_loss: 0.2281 - learning_rate: 0.0010\n",
      "Epoch 14/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0160\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0160 - val_loss: 0.2250 - learning_rate: 0.0010\n",
      "Epoch 15/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 131ms/step - loss: 0.0157 - val_loss: 0.2168 - learning_rate: 9.0000e-04\n",
      "Epoch 16/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0155 - val_loss: 0.2098 - learning_rate: 9.0000e-04\n",
      "Epoch 17/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0153 - val_loss: 0.2037 - learning_rate: 9.0000e-04\n",
      "Epoch 18/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0152 - val_loss: 0.1937 - learning_rate: 9.0000e-04\n",
      "Epoch 19/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0149 - val_loss: 0.1840 - learning_rate: 9.0000e-04\n",
      "Epoch 20/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0149 - val_loss: 0.1727 - learning_rate: 9.0000e-04\n",
      "Epoch 21/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0147 - val_loss: 0.1493 - learning_rate: 9.0000e-04\n",
      "Epoch 22/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0145"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 20:05:47.098536: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0145 - val_loss: 0.1373 - learning_rate: 9.0000e-04\n",
      "Epoch 23/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.0144 - val_loss: 0.1207 - learning_rate: 9.0000e-04\n",
      "Epoch 24/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0143 - val_loss: 0.1100 - learning_rate: 9.0000e-04\n",
      "Epoch 25/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0142 - val_loss: 0.0849 - learning_rate: 9.0000e-04\n",
      "Epoch 26/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0140 - val_loss: 0.0734 - learning_rate: 9.0000e-04\n",
      "Epoch 27/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 0.0139 - val_loss: 0.0578 - learning_rate: 9.0000e-04\n",
      "Epoch 28/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0137 - val_loss: 0.0482 - learning_rate: 9.0000e-04\n",
      "Epoch 29/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0137 - val_loss: 0.0394 - learning_rate: 9.0000e-04\n",
      "Epoch 30/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0135 - val_loss: 0.0366 - learning_rate: 9.0000e-04\n",
      "Epoch 31/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0134 - val_loss: 0.0252 - learning_rate: 9.0000e-04\n",
      "Epoch 32/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0133 - val_loss: 0.0223 - learning_rate: 9.0000e-04\n",
      "Epoch 33/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0131 - val_loss: 0.0222 - learning_rate: 9.0000e-04\n",
      "Epoch 34/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 0.0130 - val_loss: 0.0199 - learning_rate: 9.0000e-04\n",
      "Epoch 35/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0129 - val_loss: 0.0161 - learning_rate: 9.0000e-04\n",
      "Epoch 36/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0127 - val_loss: 0.0164 - learning_rate: 9.0000e-04\n",
      "Epoch 37/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0126 - val_loss: 0.0269 - learning_rate: 9.0000e-04\n",
      "Epoch 38/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0125 - val_loss: 0.0207 - learning_rate: 9.0000e-04\n",
      "Epoch 39/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 0.0124 - val_loss: 0.0143 - learning_rate: 9.0000e-04\n",
      "Epoch 40/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0123 - val_loss: 0.0161 - learning_rate: 9.0000e-04\n",
      "Epoch 41/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0122 - val_loss: 0.0149 - learning_rate: 9.0000e-04\n",
      "Epoch 42/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0121 - val_loss: 0.0147 - learning_rate: 9.0000e-04\n",
      "Epoch 43/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0120 - val_loss: 0.0325 - learning_rate: 9.0000e-04\n",
      "Epoch 44/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 20:06:58.691526: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 0.0119 - val_loss: 0.0636 - learning_rate: 9.0000e-04\n",
      "Epoch 45/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0117 - val_loss: 0.0141 - learning_rate: 9.0000e-04\n",
      "Epoch 46/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0117 - val_loss: 0.0152 - learning_rate: 9.0000e-04\n",
      "Epoch 47/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0116 - val_loss: 0.0191 - learning_rate: 9.0000e-04\n",
      "Epoch 48/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.0114 - val_loss: 0.0176 - learning_rate: 9.0000e-04\n",
      "Epoch 49/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0113 - val_loss: 0.0393 - learning_rate: 9.0000e-04\n",
      "Epoch 50/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0113 - val_loss: 0.0158 - learning_rate: 9.0000e-04\n",
      "Epoch 51/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 0.0112 - val_loss: 0.0154 - learning_rate: 9.0000e-04\n",
      "Epoch 52/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0111 - val_loss: 0.0135 - learning_rate: 9.0000e-04\n",
      "Epoch 53/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0111 - val_loss: 0.0129 - learning_rate: 9.0000e-04\n",
      "Epoch 54/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0109 - val_loss: 0.0137 - learning_rate: 9.0000e-04\n",
      "Epoch 55/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0108 - val_loss: 0.2175 - learning_rate: 9.0000e-04\n",
      "Epoch 56/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 0.0107 - val_loss: 0.0404 - learning_rate: 9.0000e-04\n",
      "Epoch 57/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 0.0106 - val_loss: 0.0347 - learning_rate: 9.0000e-04\n",
      "Epoch 58/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0106 - val_loss: 0.0171 - learning_rate: 9.0000e-04\n",
      "Epoch 59/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0105 - val_loss: 0.0233 - learning_rate: 9.0000e-04\n",
      "Epoch 60/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.0105 - val_loss: 0.0302 - learning_rate: 9.0000e-04\n",
      "Epoch 61/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 0.0103 - val_loss: 0.0148 - learning_rate: 9.0000e-04\n",
      "Epoch 62/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0103 - val_loss: 0.0152 - learning_rate: 9.0000e-04\n",
      "Epoch 63/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0102 - val_loss: 0.0165 - learning_rate: 9.0000e-04\n",
      "Epoch 64/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0102 - val_loss: 0.0127 - learning_rate: 9.0000e-04\n",
      "Epoch 65/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0101 - val_loss: 0.0135 - learning_rate: 9.0000e-04\n",
      "Epoch 66/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0100 - val_loss: 0.0167 - learning_rate: 9.0000e-04\n",
      "Epoch 67/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 132ms/step - loss: 0.0100 - val_loss: 0.0138 - learning_rate: 9.0000e-04\n",
      "Epoch 68/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0098 - val_loss: 0.0124 - learning_rate: 9.0000e-04\n",
      "Epoch 69/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0098 - val_loss: 0.0165 - learning_rate: 9.0000e-04\n",
      "Epoch 70/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0096 - val_loss: 0.0110 - learning_rate: 9.0000e-04\n",
      "Epoch 71/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 0.0096 - val_loss: 0.0116 - learning_rate: 9.0000e-04\n",
      "Epoch 72/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0095 - val_loss: 0.0138 - learning_rate: 9.0000e-04\n",
      "Epoch 73/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0095 - val_loss: 0.0144 - learning_rate: 9.0000e-04\n",
      "Epoch 74/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0094 - val_loss: 0.0130 - learning_rate: 9.0000e-04\n",
      "Epoch 75/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 0.0095 - val_loss: 0.0115 - learning_rate: 9.0000e-04\n",
      "Epoch 76/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0093 - val_loss: 0.0113 - learning_rate: 9.0000e-04\n",
      "Epoch 77/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0092 - val_loss: 0.0125 - learning_rate: 9.0000e-04\n",
      "Epoch 78/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 131ms/step - loss: 0.0092 - val_loss: 0.0121 - learning_rate: 9.0000e-04\n",
      "Epoch 79/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.0091 - val_loss: 0.0109 - learning_rate: 9.0000e-04\n",
      "Epoch 80/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0090 - val_loss: 0.0132 - learning_rate: 9.0000e-04\n",
      "Epoch 81/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.0089 - val_loss: 0.0118 - learning_rate: 9.0000e-04\n",
      "Epoch 82/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 0.0089 - val_loss: 0.0119 - learning_rate: 9.0000e-04\n",
      "Epoch 83/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0087\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0087 - val_loss: 0.0114 - learning_rate: 9.0000e-04\n",
      "Epoch 84/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0086 - val_loss: 0.0111 - learning_rate: 8.1000e-04\n",
      "Epoch 85/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0086 - val_loss: 0.0119 - learning_rate: 8.1000e-04\n",
      "Epoch 86/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0084 - val_loss: 0.0175 - learning_rate: 8.1000e-04\n",
      "Epoch 87/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 20:09:25.433143: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0084 - val_loss: 0.0745 - learning_rate: 8.1000e-04\n",
      "Epoch 88/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 0.0082 - val_loss: 0.0439 - learning_rate: 8.1000e-04\n",
      "Epoch 89/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0082 - val_loss: 0.0338 - learning_rate: 8.1000e-04\n",
      "Epoch 90/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0081 - val_loss: 0.0123 - learning_rate: 8.1000e-04\n",
      "Epoch 91/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0080 - val_loss: 0.0119 - learning_rate: 8.1000e-04\n",
      "Epoch 92/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0080 - val_loss: 0.0123 - learning_rate: 8.1000e-04\n",
      "Epoch 93/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0079 - val_loss: 0.0116 - learning_rate: 8.1000e-04\n",
      "Epoch 94/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0078 - val_loss: 0.0119 - learning_rate: 8.1000e-04\n",
      "Epoch 95/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0077 - val_loss: 0.0166 - learning_rate: 8.1000e-04\n",
      "Epoch 96/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0077\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 0.0077 - val_loss: 0.0128 - learning_rate: 8.1000e-04\n",
      "Epoch 97/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0074 - val_loss: 0.0118 - learning_rate: 7.2900e-04\n",
      "Epoch 98/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - loss: 0.0073 - val_loss: 0.0113 - learning_rate: 7.2900e-04\n",
      "Epoch 99/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0072 - val_loss: 0.0117 - learning_rate: 7.2900e-04\n",
      "Epoch 100/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0072 - val_loss: 0.0114 - learning_rate: 7.2900e-04\n",
      "Epoch 101/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 0.0070 - val_loss: 0.0114 - learning_rate: 7.2900e-04\n",
      "Epoch 102/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0070 - val_loss: 0.0127 - learning_rate: 7.2900e-04\n",
      "Epoch 103/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0068 - val_loss: 0.0127 - learning_rate: 7.2900e-04\n",
      "Epoch 104/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0067 - val_loss: 0.0119 - learning_rate: 7.2900e-04\n",
      "Epoch 105/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0066 - val_loss: 0.0113 - learning_rate: 7.2900e-04\n",
      "Epoch 106/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0066 - val_loss: 0.0122 - learning_rate: 7.2900e-04\n",
      "Epoch 107/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0065 - val_loss: 0.0145 - learning_rate: 7.2900e-04\n",
      "Epoch 108/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0063 - val_loss: 0.0131 - learning_rate: 7.2900e-04\n",
      "Epoch 109/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0062\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 0.0062 - val_loss: 0.0126 - learning_rate: 7.2900e-04\n",
      "Epoch 110/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0060 - val_loss: 0.0122 - learning_rate: 6.5610e-04\n",
      "Epoch 111/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0059 - val_loss: 0.0133 - learning_rate: 6.5610e-04\n",
      "Epoch 112/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0057 - val_loss: 0.0119 - learning_rate: 6.5610e-04\n",
      "Epoch 113/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0056 - val_loss: 0.0145 - learning_rate: 6.5610e-04\n",
      "Epoch 114/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0054 - val_loss: 0.0127 - learning_rate: 6.5610e-04\n",
      "Epoch 115/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0054 - val_loss: 0.0124 - learning_rate: 6.5610e-04\n",
      "Epoch 116/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0052 - val_loss: 0.0121 - learning_rate: 6.5610e-04\n",
      "Epoch 117/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 0.0051 - val_loss: 0.0125 - learning_rate: 6.5610e-04\n",
      "Epoch 118/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0050 - val_loss: 0.0131 - learning_rate: 6.5610e-04\n",
      "Epoch 119/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0049 - val_loss: 0.0124 - learning_rate: 6.5610e-04\n",
      "Epoch 120/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0047 - val_loss: 0.0132 - learning_rate: 6.5610e-04\n",
      "Epoch 121/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0047 - val_loss: 0.0131 - learning_rate: 6.5610e-04\n",
      "Epoch 122/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0045\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0045 - val_loss: 0.0133 - learning_rate: 6.5610e-04\n",
      "Epoch 123/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0043 - val_loss: 0.0143 - learning_rate: 5.9049e-04\n",
      "Epoch 124/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0041 - val_loss: 0.0137 - learning_rate: 5.9049e-04\n",
      "Epoch 125/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0040 - val_loss: 0.0127 - learning_rate: 5.9049e-04\n",
      "Epoch 126/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0038 - val_loss: 0.0133 - learning_rate: 5.9049e-04\n",
      "Epoch 127/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 0.0038 - val_loss: 0.0132 - learning_rate: 5.9049e-04\n",
      "Epoch 128/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0036 - val_loss: 0.0132 - learning_rate: 5.9049e-04\n",
      "Epoch 129/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0035 - val_loss: 0.0137 - learning_rate: 5.9049e-04\n",
      "Epoch 130/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0033 - val_loss: 0.0131 - learning_rate: 5.9049e-04\n",
      "Epoch 131/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0033 - val_loss: 0.0138 - learning_rate: 5.9049e-04\n",
      "Epoch 132/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0032 - val_loss: 0.0133 - learning_rate: 5.9049e-04\n",
      "Epoch 133/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0031 - val_loss: 0.0132 - learning_rate: 5.9049e-04\n",
      "Epoch 134/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0029 - val_loss: 0.0133 - learning_rate: 5.9049e-04\n",
      "Epoch 135/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0029\n",
      "Epoch 135: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0028 - val_loss: 0.0127 - learning_rate: 5.9049e-04\n",
      "Epoch 136/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 0.0027 - val_loss: 0.0127 - learning_rate: 5.3144e-04\n",
      "Epoch 137/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 0.0026 - val_loss: 0.0131 - learning_rate: 5.3144e-04\n",
      "Epoch 138/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0025 - val_loss: 0.0132 - learning_rate: 5.3144e-04\n",
      "Epoch 139/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 132ms/step - loss: 0.0023 - val_loss: 0.0130 - learning_rate: 5.3144e-04\n",
      "Epoch 140/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0023 - val_loss: 0.0145 - learning_rate: 5.3144e-04\n",
      "Epoch 141/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0022 - val_loss: 0.0129 - learning_rate: 5.3144e-04\n",
      "Epoch 142/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0021 - val_loss: 0.0141 - learning_rate: 5.3144e-04\n",
      "Epoch 143/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0021 - val_loss: 0.0130 - learning_rate: 5.3144e-04\n",
      "Epoch 144/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0020 - val_loss: 0.0133 - learning_rate: 5.3144e-04\n",
      "Epoch 145/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0020 - val_loss: 0.0134 - learning_rate: 5.3144e-04\n",
      "Epoch 146/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0019 - val_loss: 0.0129 - learning_rate: 5.3144e-04\n",
      "Epoch 147/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0018 - val_loss: 0.0130 - learning_rate: 5.3144e-04\n",
      "Epoch 148/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0018\n",
      "Epoch 148: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0018 - val_loss: 0.0130 - learning_rate: 5.3144e-04\n",
      "Epoch 149/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 0.0017 - val_loss: 0.0133 - learning_rate: 4.7830e-04\n",
      "Epoch 150/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0016 - val_loss: 0.0132 - learning_rate: 4.7830e-04\n",
      "Epoch 151/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0015 - val_loss: 0.0131 - learning_rate: 4.7830e-04\n",
      "Epoch 152/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0015 - val_loss: 0.0132 - learning_rate: 4.7830e-04\n",
      "Epoch 153/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0015 - val_loss: 0.0131 - learning_rate: 4.7830e-04\n",
      "Epoch 154/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0014 - val_loss: 0.0131 - learning_rate: 4.7830e-04\n",
      "Epoch 155/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0014 - val_loss: 0.0130 - learning_rate: 4.7830e-04\n",
      "Epoch 156/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0014 - val_loss: 0.0134 - learning_rate: 4.7830e-04\n",
      "Epoch 157/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0013 - val_loss: 0.0136 - learning_rate: 4.7830e-04\n",
      "Epoch 158/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 0.0013 - val_loss: 0.0135 - learning_rate: 4.7830e-04\n",
      "Epoch 159/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0013 - val_loss: 0.0134 - learning_rate: 4.7830e-04\n",
      "Epoch 160/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0013 - val_loss: 0.0142 - learning_rate: 4.7830e-04\n",
      "Epoch 161/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0013\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0013 - val_loss: 0.0136 - learning_rate: 4.7830e-04\n",
      "Epoch 162/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0012 - val_loss: 0.0131 - learning_rate: 4.3047e-04\n",
      "Epoch 163/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0012 - val_loss: 0.0136 - learning_rate: 4.3047e-04\n",
      "Epoch 164/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0011 - val_loss: 0.0129 - learning_rate: 4.3047e-04\n",
      "Epoch 165/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 0.0011 - val_loss: 0.0131 - learning_rate: 4.3047e-04\n",
      "Epoch 166/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 0.0011 - val_loss: 0.0132 - learning_rate: 4.3047e-04\n",
      "Epoch 167/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 9.9856e-04 - val_loss: 0.0130 - learning_rate: 4.3047e-04\n",
      "Epoch 168/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.0010 - val_loss: 0.0131 - learning_rate: 4.3047e-04\n",
      "Epoch 169/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.7678e-04 - val_loss: 0.0135 - learning_rate: 4.3047e-04\n",
      "Epoch 170/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 9.6686e-04 - val_loss: 0.0134 - learning_rate: 4.3047e-04\n",
      "Epoch 171/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 9.7483e-04 - val_loss: 0.0139 - learning_rate: 4.3047e-04\n",
      "Epoch 172/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 9.7238e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 20:14:16.321742: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.6954e-04 - val_loss: 0.0133 - learning_rate: 4.3047e-04\n",
      "Epoch 173/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.6367e-04 - val_loss: 0.0134 - learning_rate: 4.3047e-04\n",
      "Epoch 174/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 9.4260e-04\n",
      "Epoch 174: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.3996e-04 - val_loss: 0.0134 - learning_rate: 4.3047e-04\n",
      "Epoch 175/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.0825e-04 - val_loss: 0.0129 - learning_rate: 3.8742e-04\n",
      "Epoch 176/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.7319e-04 - val_loss: 0.0130 - learning_rate: 3.8742e-04\n",
      "Epoch 177/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 8.3653e-04 - val_loss: 0.0134 - learning_rate: 3.8742e-04\n",
      "Epoch 178/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.3469e-04 - val_loss: 0.0133 - learning_rate: 3.8742e-04\n",
      "Epoch 179/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.2628e-04 - val_loss: 0.0130 - learning_rate: 3.8742e-04\n",
      "Epoch 180/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 8.2832e-04 - val_loss: 0.0132 - learning_rate: 3.8742e-04\n",
      "Epoch 181/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 8.3300e-04 - val_loss: 0.0135 - learning_rate: 3.8742e-04\n",
      "Epoch 182/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.1147e-04 - val_loss: 0.0136 - learning_rate: 3.8742e-04\n",
      "Epoch 183/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.1107e-04 - val_loss: 0.0132 - learning_rate: 3.8742e-04\n",
      "Epoch 184/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 7.8201e-04 - val_loss: 0.0137 - learning_rate: 3.8742e-04\n",
      "Epoch 185/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 7.9060e-04 - val_loss: 0.0131 - learning_rate: 3.8742e-04\n",
      "Epoch 186/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 7.7749e-04 - val_loss: 0.0130 - learning_rate: 3.8742e-04\n",
      "Epoch 187/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 7.7908e-04\n",
      "Epoch 187: ReduceLROnPlateau reducing learning rate to 0.0003486784757114947.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 7.7706e-04 - val_loss: 0.0130 - learning_rate: 3.8742e-04\n",
      "Epoch 188/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 7.6395e-04 - val_loss: 0.0133 - learning_rate: 3.4868e-04\n",
      "Epoch 189/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 7.2644e-04 - val_loss: 0.0130 - learning_rate: 3.4868e-04\n",
      "Epoch 190/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 7.2625e-04 - val_loss: 0.0133 - learning_rate: 3.4868e-04\n",
      "Epoch 191/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 7.1403e-04 - val_loss: 0.0133 - learning_rate: 3.4868e-04\n",
      "Epoch 192/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 7.1073e-04 - val_loss: 0.0133 - learning_rate: 3.4868e-04\n",
      "Epoch 193/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 6.9222e-04 - val_loss: 0.0129 - learning_rate: 3.4868e-04\n",
      "Epoch 194/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 6.8000e-04 - val_loss: 0.0132 - learning_rate: 3.4868e-04\n",
      "Epoch 195/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 6.8033e-04 - val_loss: 0.0133 - learning_rate: 3.4868e-04\n",
      "Epoch 196/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 6.6675e-04 - val_loss: 0.0134 - learning_rate: 3.4868e-04\n",
      "Epoch 197/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 6.6236e-04 - val_loss: 0.0131 - learning_rate: 3.4868e-04\n",
      "Epoch 198/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 6.6533e-04 - val_loss: 0.0135 - learning_rate: 3.4868e-04\n",
      "Epoch 199/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 6.5065e-04 - val_loss: 0.0133 - learning_rate: 3.4868e-04\n",
      "Epoch 200/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 6.6663e-04\n",
      "Epoch 200: ReduceLROnPlateau reducing learning rate to 0.00031381062290165574.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 6.6473e-04 - val_loss: 0.0129 - learning_rate: 3.4868e-04\n",
      "Epoch 201/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 6.3807e-04 - val_loss: 0.0132 - learning_rate: 3.1381e-04\n",
      "Epoch 202/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 6.1366e-04 - val_loss: 0.0135 - learning_rate: 3.1381e-04\n",
      "Epoch 203/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 6.1772e-04 - val_loss: 0.0131 - learning_rate: 3.1381e-04\n",
      "Epoch 204/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 6.0358e-04 - val_loss: 0.0130 - learning_rate: 3.1381e-04\n",
      "Epoch 205/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 5.9715e-04 - val_loss: 0.0131 - learning_rate: 3.1381e-04\n",
      "Epoch 206/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 5.9451e-04 - val_loss: 0.0133 - learning_rate: 3.1381e-04\n",
      "Epoch 207/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 6.0988e-04 - val_loss: 0.0131 - learning_rate: 3.1381e-04\n",
      "Epoch 208/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 5.9256e-04 - val_loss: 0.0134 - learning_rate: 3.1381e-04\n",
      "Epoch 209/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 5.9597e-04 - val_loss: 0.0133 - learning_rate: 3.1381e-04\n",
      "Epoch 210/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 5.9881e-04 - val_loss: 0.0134 - learning_rate: 3.1381e-04\n",
      "Epoch 211/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 5.9645e-04 - val_loss: 0.0133 - learning_rate: 3.1381e-04\n",
      "Epoch 212/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 6.0257e-04 - val_loss: 0.0130 - learning_rate: 3.1381e-04\n",
      "Epoch 213/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 5.9099e-04\n",
      "Epoch 213: ReduceLROnPlateau reducing learning rate to 0.0002824295632308349.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 5.9101e-04 - val_loss: 0.0135 - learning_rate: 3.1381e-04\n",
      "Epoch 214/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 5.8241e-04 - val_loss: 0.0135 - learning_rate: 2.8243e-04\n",
      "Epoch 215/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 5.7176e-04 - val_loss: 0.0131 - learning_rate: 2.8243e-04\n",
      "Epoch 216/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 5.6666e-04 - val_loss: 0.0131 - learning_rate: 2.8243e-04\n",
      "Epoch 217/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 5.4861e-04 - val_loss: 0.0130 - learning_rate: 2.8243e-04\n",
      "Epoch 218/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 5.5344e-04 - val_loss: 0.0129 - learning_rate: 2.8243e-04\n",
      "Epoch 219/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 5.4516e-04 - val_loss: 0.0132 - learning_rate: 2.8243e-04\n",
      "Epoch 220/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 5.4460e-04 - val_loss: 0.0129 - learning_rate: 2.8243e-04\n",
      "Epoch 221/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 5.2749e-04 - val_loss: 0.0133 - learning_rate: 2.8243e-04\n",
      "Epoch 222/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 5.2385e-04 - val_loss: 0.0130 - learning_rate: 2.8243e-04\n",
      "Epoch 223/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 5.4320e-04 - val_loss: 0.0131 - learning_rate: 2.8243e-04\n",
      "Epoch 224/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 5.3697e-04 - val_loss: 0.0135 - learning_rate: 2.8243e-04\n",
      "Epoch 225/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 5.3193e-04 - val_loss: 0.0131 - learning_rate: 2.8243e-04\n",
      "Epoch 226/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 5.4929e-04\n",
      "Epoch 226: ReduceLROnPlateau reducing learning rate to 0.00025418660952709616.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 5.4770e-04 - val_loss: 0.0134 - learning_rate: 2.8243e-04\n",
      "Epoch 227/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 5.1384e-04 - val_loss: 0.0132 - learning_rate: 2.5419e-04\n",
      "Epoch 228/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 5.0697e-04 - val_loss: 0.0133 - learning_rate: 2.5419e-04\n",
      "Epoch 229/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 4.9226e-04 - val_loss: 0.0131 - learning_rate: 2.5419e-04\n",
      "Epoch 230/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 5.0158e-04 - val_loss: 0.0132 - learning_rate: 2.5419e-04\n",
      "Epoch 231/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 5.0086e-04 - val_loss: 0.0134 - learning_rate: 2.5419e-04\n",
      "Epoch 232/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 5.0265e-04 - val_loss: 0.0133 - learning_rate: 2.5419e-04\n",
      "Epoch 233/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 5.0514e-04 - val_loss: 0.0136 - learning_rate: 2.5419e-04\n",
      "Epoch 234/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 4.9913e-04 - val_loss: 0.0133 - learning_rate: 2.5419e-04\n",
      "Epoch 235/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 4.8656e-04 - val_loss: 0.0129 - learning_rate: 2.5419e-04\n",
      "Epoch 236/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 4.9604e-04 - val_loss: 0.0135 - learning_rate: 2.5419e-04\n",
      "Epoch 237/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 4.9164e-04 - val_loss: 0.0135 - learning_rate: 2.5419e-04\n",
      "Epoch 238/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 4.8636e-04 - val_loss: 0.0130 - learning_rate: 2.5419e-04\n",
      "Epoch 239/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 4.8261e-04\n",
      "Epoch 239: ReduceLROnPlateau reducing learning rate to 0.00022876793809700757.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 4.8166e-04 - val_loss: 0.0129 - learning_rate: 2.5419e-04\n",
      "Epoch 240/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 4.9028e-04 - val_loss: 0.0134 - learning_rate: 2.2877e-04\n",
      "Epoch 241/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 4.7452e-04 - val_loss: 0.0131 - learning_rate: 2.2877e-04\n",
      "Epoch 242/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 4.4949e-04 - val_loss: 0.0133 - learning_rate: 2.2877e-04\n",
      "Epoch 243/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 4.6594e-04 - val_loss: 0.0130 - learning_rate: 2.2877e-04\n",
      "Epoch 244/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 4.7192e-04 - val_loss: 0.0132 - learning_rate: 2.2877e-04\n",
      "Epoch 245/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 4.5622e-04 - val_loss: 0.0130 - learning_rate: 2.2877e-04\n",
      "Epoch 246/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 4.7512e-04 - val_loss: 0.0131 - learning_rate: 2.2877e-04\n",
      "Epoch 247/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 4.6035e-04 - val_loss: 0.0130 - learning_rate: 2.2877e-04\n",
      "Epoch 248/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 4.4503e-04 - val_loss: 0.0133 - learning_rate: 2.2877e-04\n",
      "Epoch 249/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 4.5188e-04 - val_loss: 0.0133 - learning_rate: 2.2877e-04\n",
      "Epoch 250/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 4.4608e-04 - val_loss: 0.0130 - learning_rate: 2.2877e-04\n",
      "Epoch 251/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 4.3849e-04 - val_loss: 0.0133 - learning_rate: 2.2877e-04\n",
      "Epoch 252/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 4.5194e-04\n",
      "Epoch 252: ReduceLROnPlateau reducing learning rate to 0.00020589114428730683.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 4.5163e-04 - val_loss: 0.0130 - learning_rate: 2.2877e-04\n",
      "Epoch 253/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 4.3926e-04 - val_loss: 0.0130 - learning_rate: 2.0589e-04\n",
      "Epoch 254/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 4.3348e-04 - val_loss: 0.0130 - learning_rate: 2.0589e-04\n",
      "Epoch 255/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 138ms/step - loss: 4.2422e-04 - val_loss: 0.0130 - learning_rate: 2.0589e-04\n",
      "Epoch 256/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 4.2118e-04 - val_loss: 0.0131 - learning_rate: 2.0589e-04\n",
      "Epoch 257/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 4.4350e-04 - val_loss: 0.0130 - learning_rate: 2.0589e-04\n",
      "Epoch 258/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 4.2091e-04 - val_loss: 0.0133 - learning_rate: 2.0589e-04\n",
      "Epoch 259/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 4.3046e-04 - val_loss: 0.0131 - learning_rate: 2.0589e-04\n",
      "Epoch 260/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 4.0730e-04 - val_loss: 0.0134 - learning_rate: 2.0589e-04\n",
      "Epoch 261/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 4.0138e-04 - val_loss: 0.0132 - learning_rate: 2.0589e-04\n",
      "Epoch 262/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 4.1523e-04 - val_loss: 0.0129 - learning_rate: 2.0589e-04\n",
      "Epoch 263/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 4.1351e-04 - val_loss: 0.0132 - learning_rate: 2.0589e-04\n",
      "Epoch 264/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 4.2140e-04 - val_loss: 0.0129 - learning_rate: 2.0589e-04\n",
      "Epoch 265/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 4.2972e-04\n",
      "Epoch 265: ReduceLROnPlateau reducing learning rate to 0.00018530203378759326.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 4.2953e-04 - val_loss: 0.0128 - learning_rate: 2.0589e-04\n",
      "Epoch 266/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 4.1481e-04 - val_loss: 0.0130 - learning_rate: 1.8530e-04\n",
      "Epoch 267/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 3.9501e-04 - val_loss: 0.0129 - learning_rate: 1.8530e-04\n",
      "Epoch 268/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 4.0022e-04 - val_loss: 0.0133 - learning_rate: 1.8530e-04\n",
      "Epoch 269/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 3.8993e-04 - val_loss: 0.0132 - learning_rate: 1.8530e-04\n",
      "Epoch 270/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.8640e-04 - val_loss: 0.0129 - learning_rate: 1.8530e-04\n",
      "Epoch 271/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.8781e-04 - val_loss: 0.0132 - learning_rate: 1.8530e-04\n",
      "Epoch 272/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 3.9054e-04 - val_loss: 0.0131 - learning_rate: 1.8530e-04\n",
      "Epoch 273/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.8601e-04 - val_loss: 0.0132 - learning_rate: 1.8530e-04\n",
      "Epoch 274/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.9400e-04 - val_loss: 0.0130 - learning_rate: 1.8530e-04\n",
      "Epoch 275/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.9218e-04 - val_loss: 0.0133 - learning_rate: 1.8530e-04\n",
      "Epoch 276/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 3.8782e-04 - val_loss: 0.0130 - learning_rate: 1.8530e-04\n",
      "Epoch 277/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.7718e-04 - val_loss: 0.0131 - learning_rate: 1.8530e-04\n",
      "Epoch 278/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 3.8403e-04\n",
      "Epoch 278: ReduceLROnPlateau reducing learning rate to 0.00016677183302817866.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.8422e-04 - val_loss: 0.0128 - learning_rate: 1.8530e-04\n",
      "Epoch 279/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 3.8286e-04 - val_loss: 0.0131 - learning_rate: 1.6677e-04\n",
      "Epoch 280/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 3.7501e-04 - val_loss: 0.0133 - learning_rate: 1.6677e-04\n",
      "Epoch 281/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 3.7417e-04 - val_loss: 0.0130 - learning_rate: 1.6677e-04\n",
      "Epoch 282/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 3.6182e-04 - val_loss: 0.0131 - learning_rate: 1.6677e-04\n",
      "Epoch 283/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 3.6097e-04 - val_loss: 0.0134 - learning_rate: 1.6677e-04\n",
      "Epoch 284/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 3.7170e-04 - val_loss: 0.0131 - learning_rate: 1.6677e-04\n",
      "Epoch 285/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 3.6088e-04 - val_loss: 0.0130 - learning_rate: 1.6677e-04\n",
      "Epoch 286/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.5675e-04 - val_loss: 0.0130 - learning_rate: 1.6677e-04\n",
      "Epoch 287/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.5424e-04 - val_loss: 0.0131 - learning_rate: 1.6677e-04\n",
      "Epoch 288/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 3.6001e-04 - val_loss: 0.0131 - learning_rate: 1.6677e-04\n",
      "Epoch 289/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.6140e-04 - val_loss: 0.0134 - learning_rate: 1.6677e-04\n",
      "Epoch 290/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 3.6166e-04 - val_loss: 0.0132 - learning_rate: 1.6677e-04\n",
      "Epoch 291/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 3.5985e-04\n",
      "Epoch 291: ReduceLROnPlateau reducing learning rate to 0.00015009464841568844.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.5972e-04 - val_loss: 0.0131 - learning_rate: 1.6677e-04\n",
      "Epoch 292/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.5766e-04 - val_loss: 0.0128 - learning_rate: 1.5009e-04\n",
      "Epoch 293/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.4634e-04 - val_loss: 0.0130 - learning_rate: 1.5009e-04\n",
      "Epoch 294/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.5713e-04 - val_loss: 0.0130 - learning_rate: 1.5009e-04\n",
      "Epoch 295/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.4940e-04 - val_loss: 0.0130 - learning_rate: 1.5009e-04\n",
      "Epoch 296/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.5574e-04 - val_loss: 0.0133 - learning_rate: 1.5009e-04\n",
      "Epoch 297/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.4695e-04 - val_loss: 0.0133 - learning_rate: 1.5009e-04\n",
      "Epoch 298/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.4279e-04 - val_loss: 0.0130 - learning_rate: 1.5009e-04\n",
      "Epoch 299/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 3.4078e-04 - val_loss: 0.0131 - learning_rate: 1.5009e-04\n",
      "Epoch 300/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 3.4809e-04 - val_loss: 0.0128 - learning_rate: 1.5009e-04\n",
      "Epoch 301/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 3.4233e-04 - val_loss: 0.0133 - learning_rate: 1.5009e-04\n",
      "Epoch 302/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.4214e-04 - val_loss: 0.0134 - learning_rate: 1.5009e-04\n",
      "Epoch 303/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 3.4115e-04 - val_loss: 0.0130 - learning_rate: 1.5009e-04\n",
      "Epoch 304/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 3.4821e-04\n",
      "Epoch 304: ReduceLROnPlateau reducing learning rate to 0.0001350851875031367.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.4801e-04 - val_loss: 0.0131 - learning_rate: 1.5009e-04\n",
      "Epoch 305/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.4836e-04 - val_loss: 0.0130 - learning_rate: 1.3509e-04\n",
      "Epoch 306/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.2592e-04 - val_loss: 0.0131 - learning_rate: 1.3509e-04\n",
      "Epoch 307/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.2022e-04 - val_loss: 0.0133 - learning_rate: 1.3509e-04\n",
      "Epoch 308/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 3.3084e-04 - val_loss: 0.0129 - learning_rate: 1.3509e-04\n",
      "Epoch 309/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 3.2098e-04 - val_loss: 0.0130 - learning_rate: 1.3509e-04\n",
      "Epoch 310/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 3.3340e-04 - val_loss: 0.0127 - learning_rate: 1.3509e-04\n",
      "Epoch 311/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 3.2360e-04 - val_loss: 0.0129 - learning_rate: 1.3509e-04\n",
      "Epoch 312/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 3.2408e-04 - val_loss: 0.0132 - learning_rate: 1.3509e-04\n",
      "Epoch 313/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.1945e-04 - val_loss: 0.0131 - learning_rate: 1.3509e-04\n",
      "Epoch 314/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 3.1638e-04 - val_loss: 0.0130 - learning_rate: 1.3509e-04\n",
      "Epoch 315/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 3.1523e-04 - val_loss: 0.0128 - learning_rate: 1.3509e-04\n",
      "Epoch 316/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.1309e-04 - val_loss: 0.0131 - learning_rate: 1.3509e-04\n",
      "Epoch 317/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3.1433e-04\n",
      "Epoch 317: ReduceLROnPlateau reducing learning rate to 0.00012157666351413355.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 3.1413e-04 - val_loss: 0.0133 - learning_rate: 1.3509e-04\n",
      "Epoch 318/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 3.1124e-04 - val_loss: 0.0131 - learning_rate: 1.2158e-04\n",
      "Epoch 319/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 3.0694e-04 - val_loss: 0.0131 - learning_rate: 1.2158e-04\n",
      "Epoch 320/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 3.0554e-04 - val_loss: 0.0129 - learning_rate: 1.2158e-04\n",
      "Epoch 321/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 3.1345e-04 - val_loss: 0.0130 - learning_rate: 1.2158e-04\n",
      "Epoch 322/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 3.0871e-04 - val_loss: 0.0132 - learning_rate: 1.2158e-04\n",
      "Epoch 323/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 3.0113e-04 - val_loss: 0.0132 - learning_rate: 1.2158e-04\n",
      "Epoch 324/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.9826e-04 - val_loss: 0.0133 - learning_rate: 1.2158e-04\n",
      "Epoch 325/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.8895e-04 - val_loss: 0.0130 - learning_rate: 1.2158e-04\n",
      "Epoch 326/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 2.9499e-04 - val_loss: 0.0132 - learning_rate: 1.2158e-04\n",
      "Epoch 327/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.9894e-04 - val_loss: 0.0131 - learning_rate: 1.2158e-04\n",
      "Epoch 328/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.9276e-04 - val_loss: 0.0132 - learning_rate: 1.2158e-04\n",
      "Epoch 329/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.9388e-04 - val_loss: 0.0130 - learning_rate: 1.2158e-04\n",
      "Epoch 330/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 3.1007e-04\n",
      "Epoch 330: ReduceLROnPlateau reducing learning rate to 0.00010941899454337544.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 3.0936e-04 - val_loss: 0.0128 - learning_rate: 1.2158e-04\n",
      "Epoch 331/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.9817e-04 - val_loss: 0.0130 - learning_rate: 1.0942e-04\n",
      "Epoch 332/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.9307e-04 - val_loss: 0.0129 - learning_rate: 1.0942e-04\n",
      "Epoch 333/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 2.8854e-04 - val_loss: 0.0131 - learning_rate: 1.0942e-04\n",
      "Epoch 334/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.8264e-04 - val_loss: 0.0129 - learning_rate: 1.0942e-04\n",
      "Epoch 335/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.8767e-04 - val_loss: 0.0132 - learning_rate: 1.0942e-04\n",
      "Epoch 336/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.8819e-04 - val_loss: 0.0129 - learning_rate: 1.0942e-04\n",
      "Epoch 337/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.9014e-04 - val_loss: 0.0133 - learning_rate: 1.0942e-04\n",
      "Epoch 338/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.8619e-04 - val_loss: 0.0129 - learning_rate: 1.0942e-04\n",
      "Epoch 339/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.8969e-04 - val_loss: 0.0134 - learning_rate: 1.0942e-04\n",
      "Epoch 340/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 2.8378e-04 - val_loss: 0.0130 - learning_rate: 1.0942e-04\n",
      "Epoch 341/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 2.9885e-04 - val_loss: 0.0130 - learning_rate: 1.0942e-04\n",
      "Epoch 342/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.8698e-04 - val_loss: 0.0130 - learning_rate: 1.0942e-04\n",
      "Epoch 343/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 2.8780e-04\n",
      "Epoch 343: ReduceLROnPlateau reducing learning rate to 9.847709443420172e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.8815e-04 - val_loss: 0.0130 - learning_rate: 1.0942e-04\n",
      "Epoch 344/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 20:23:57.311560: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.8399e-04 - val_loss: 0.0130 - learning_rate: 9.8477e-05\n",
      "Epoch 345/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.7852e-04 - val_loss: 0.0131 - learning_rate: 9.8477e-05\n",
      "Epoch 346/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.7486e-04 - val_loss: 0.0132 - learning_rate: 9.8477e-05\n",
      "Epoch 347/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.7898e-04 - val_loss: 0.0132 - learning_rate: 9.8477e-05\n",
      "Epoch 348/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.7111e-04 - val_loss: 0.0128 - learning_rate: 9.8477e-05\n",
      "Epoch 349/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.6688e-04 - val_loss: 0.0130 - learning_rate: 9.8477e-05\n",
      "Epoch 350/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.6654e-04 - val_loss: 0.0132 - learning_rate: 9.8477e-05\n",
      "Epoch 351/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.6825e-04 - val_loss: 0.0133 - learning_rate: 9.8477e-05\n",
      "Epoch 352/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.6923e-04 - val_loss: 0.0130 - learning_rate: 9.8477e-05\n",
      "Epoch 353/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.6525e-04 - val_loss: 0.0132 - learning_rate: 9.8477e-05\n",
      "Epoch 354/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.6630e-04 - val_loss: 0.0133 - learning_rate: 9.8477e-05\n",
      "Epoch 355/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.6621e-04 - val_loss: 0.0131 - learning_rate: 9.8477e-05\n",
      "Epoch 356/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 2.6993e-04\n",
      "Epoch 356: ReduceLROnPlateau reducing learning rate to 8.862938630045391e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.6966e-04 - val_loss: 0.0130 - learning_rate: 9.8477e-05\n",
      "Epoch 357/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.5748e-04 - val_loss: 0.0128 - learning_rate: 8.8629e-05\n",
      "Epoch 358/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.5930e-04 - val_loss: 0.0131 - learning_rate: 8.8629e-05\n",
      "Epoch 359/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.6070e-04 - val_loss: 0.0132 - learning_rate: 8.8629e-05\n",
      "Epoch 360/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 2.5778e-04 - val_loss: 0.0132 - learning_rate: 8.8629e-05\n",
      "Epoch 361/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 2.5668e-04 - val_loss: 0.0129 - learning_rate: 8.8629e-05\n",
      "Epoch 362/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.6395e-04 - val_loss: 0.0132 - learning_rate: 8.8629e-05\n",
      "Epoch 363/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.5748e-04 - val_loss: 0.0132 - learning_rate: 8.8629e-05\n",
      "Epoch 364/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.6136e-04 - val_loss: 0.0132 - learning_rate: 8.8629e-05\n",
      "Epoch 365/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.5725e-04 - val_loss: 0.0131 - learning_rate: 8.8629e-05\n",
      "Epoch 366/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.6396e-04 - val_loss: 0.0132 - learning_rate: 8.8629e-05\n",
      "Epoch 367/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.5528e-04 - val_loss: 0.0130 - learning_rate: 8.8629e-05\n",
      "Epoch 368/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.6084e-04 - val_loss: 0.0133 - learning_rate: 8.8629e-05\n",
      "Epoch 369/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 2.5311e-04\n",
      "Epoch 369: ReduceLROnPlateau reducing learning rate to 7.976644701557234e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.5310e-04 - val_loss: 0.0130 - learning_rate: 8.8629e-05\n",
      "Epoch 370/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 139ms/step - loss: 2.5165e-04 - val_loss: 0.0130 - learning_rate: 7.9766e-05\n",
      "Epoch 371/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.4144e-04 - val_loss: 0.0131 - learning_rate: 7.9766e-05\n",
      "Epoch 372/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.4404e-04 - val_loss: 0.0129 - learning_rate: 7.9766e-05\n",
      "Epoch 373/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.4132e-04 - val_loss: 0.0130 - learning_rate: 7.9766e-05\n",
      "Epoch 374/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 2.3828e-04 - val_loss: 0.0130 - learning_rate: 7.9766e-05\n",
      "Epoch 375/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.4340e-04 - val_loss: 0.0131 - learning_rate: 7.9766e-05\n",
      "Epoch 376/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.4934e-04 - val_loss: 0.0132 - learning_rate: 7.9766e-05\n",
      "Epoch 377/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.4712e-04 - val_loss: 0.0131 - learning_rate: 7.9766e-05\n",
      "Epoch 378/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.4730e-04 - val_loss: 0.0131 - learning_rate: 7.9766e-05\n",
      "Epoch 379/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.4513e-04 - val_loss: 0.0131 - learning_rate: 7.9766e-05\n",
      "Epoch 380/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.5770e-04 - val_loss: 0.0129 - learning_rate: 7.9766e-05\n",
      "Epoch 381/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.5379e-04 - val_loss: 0.0131 - learning_rate: 7.9766e-05\n",
      "Epoch 382/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 2.4431e-04\n",
      "Epoch 382: ReduceLROnPlateau reducing learning rate to 7.178980231401511e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.4434e-04 - val_loss: 0.0130 - learning_rate: 7.9766e-05\n",
      "Epoch 383/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.3637e-04 - val_loss: 0.0132 - learning_rate: 7.1790e-05\n",
      "Epoch 384/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.3740e-04 - val_loss: 0.0135 - learning_rate: 7.1790e-05\n",
      "Epoch 385/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.3692e-04 - val_loss: 0.0128 - learning_rate: 7.1790e-05\n",
      "Epoch 386/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.3215e-04 - val_loss: 0.0134 - learning_rate: 7.1790e-05\n",
      "Epoch 387/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 2.3346e-04 - val_loss: 0.0129 - learning_rate: 7.1790e-05\n",
      "Epoch 388/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.3274e-04 - val_loss: 0.0129 - learning_rate: 7.1790e-05\n",
      "Epoch 389/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.3249e-04 - val_loss: 0.0132 - learning_rate: 7.1790e-05\n",
      "Epoch 390/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.4066e-04 - val_loss: 0.0130 - learning_rate: 7.1790e-05\n",
      "Epoch 391/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.4161e-04 - val_loss: 0.0131 - learning_rate: 7.1790e-05\n",
      "Epoch 392/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.3553e-04 - val_loss: 0.0131 - learning_rate: 7.1790e-05\n",
      "Epoch 393/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.3821e-04 - val_loss: 0.0133 - learning_rate: 7.1790e-05\n",
      "Epoch 394/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.4144e-04 - val_loss: 0.0132 - learning_rate: 7.1790e-05\n",
      "Epoch 395/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 2.4243e-04\n",
      "Epoch 395: ReduceLROnPlateau reducing learning rate to 6.461082011810504e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.4218e-04 - val_loss: 0.0131 - learning_rate: 7.1790e-05\n",
      "Epoch 396/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.3648e-04 - val_loss: 0.0128 - learning_rate: 6.4611e-05\n",
      "Epoch 397/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.2711e-04 - val_loss: 0.0133 - learning_rate: 6.4611e-05\n",
      "Epoch 398/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.2034e-04 - val_loss: 0.0131 - learning_rate: 6.4611e-05\n",
      "Epoch 399/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 2.2910e-04 - val_loss: 0.0131 - learning_rate: 6.4611e-05\n",
      "Epoch 400/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.2585e-04 - val_loss: 0.0131 - learning_rate: 6.4611e-05\n",
      "Epoch 401/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.2754e-04 - val_loss: 0.0131 - learning_rate: 6.4611e-05\n",
      "Epoch 402/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.2871e-04 - val_loss: 0.0134 - learning_rate: 6.4611e-05\n",
      "Epoch 403/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.2742e-04 - val_loss: 0.0134 - learning_rate: 6.4611e-05\n",
      "Epoch 404/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.2382e-04 - val_loss: 0.0131 - learning_rate: 6.4611e-05\n",
      "Epoch 405/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.1714e-04 - val_loss: 0.0130 - learning_rate: 6.4611e-05\n",
      "Epoch 406/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.1772e-04 - val_loss: 0.0130 - learning_rate: 6.4611e-05\n",
      "Epoch 407/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.2298e-04 - val_loss: 0.0130 - learning_rate: 6.4611e-05\n",
      "Epoch 408/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 2.1930e-04\n",
      "Epoch 408: ReduceLROnPlateau reducing learning rate to 5.8149741380475466e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.1940e-04 - val_loss: 0.0134 - learning_rate: 6.4611e-05\n",
      "Epoch 409/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.1967e-04 - val_loss: 0.0131 - learning_rate: 5.8150e-05\n",
      "Epoch 410/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.1899e-04 - val_loss: 0.0131 - learning_rate: 5.8150e-05\n",
      "Epoch 411/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.1689e-04 - val_loss: 0.0131 - learning_rate: 5.8150e-05\n",
      "Epoch 412/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.2384e-04 - val_loss: 0.0132 - learning_rate: 5.8150e-05\n",
      "Epoch 413/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.2026e-04 - val_loss: 0.0131 - learning_rate: 5.8150e-05\n",
      "Epoch 414/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.1707e-04 - val_loss: 0.0130 - learning_rate: 5.8150e-05\n",
      "Epoch 415/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.1480e-04 - val_loss: 0.0132 - learning_rate: 5.8150e-05\n",
      "Epoch 416/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.1446e-04 - val_loss: 0.0129 - learning_rate: 5.8150e-05\n",
      "Epoch 417/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.1918e-04 - val_loss: 0.0132 - learning_rate: 5.8150e-05\n",
      "Epoch 418/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.1679e-04 - val_loss: 0.0128 - learning_rate: 5.8150e-05\n",
      "Epoch 419/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.2716e-04 - val_loss: 0.0129 - learning_rate: 5.8150e-05\n",
      "Epoch 420/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.1688e-04 - val_loss: 0.0132 - learning_rate: 5.8150e-05\n",
      "Epoch 421/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 2.1724e-04\n",
      "Epoch 421: ReduceLROnPlateau reducing learning rate to 5.233476658759173e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.1696e-04 - val_loss: 0.0131 - learning_rate: 5.8150e-05\n",
      "Epoch 422/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.1512e-04 - val_loss: 0.0130 - learning_rate: 5.2335e-05\n",
      "Epoch 423/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.0655e-04 - val_loss: 0.0131 - learning_rate: 5.2335e-05\n",
      "Epoch 424/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.1510e-04 - val_loss: 0.0132 - learning_rate: 5.2335e-05\n",
      "Epoch 425/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 2.1002e-04 - val_loss: 0.0132 - learning_rate: 5.2335e-05\n",
      "Epoch 426/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.1309e-04 - val_loss: 0.0131 - learning_rate: 5.2335e-05\n",
      "Epoch 427/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.2006e-04 - val_loss: 0.0131 - learning_rate: 5.2335e-05\n",
      "Epoch 428/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.1043e-04 - val_loss: 0.0130 - learning_rate: 5.2335e-05\n",
      "Epoch 429/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.0919e-04 - val_loss: 0.0132 - learning_rate: 5.2335e-05\n",
      "Epoch 430/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.0973e-04 - val_loss: 0.0132 - learning_rate: 5.2335e-05\n",
      "Epoch 431/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.0534e-04 - val_loss: 0.0132 - learning_rate: 5.2335e-05\n",
      "Epoch 432/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.1205e-04 - val_loss: 0.0132 - learning_rate: 5.2335e-05\n",
      "Epoch 433/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.1005e-04 - val_loss: 0.0132 - learning_rate: 5.2335e-05\n",
      "Epoch 434/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 2.0555e-04\n",
      "Epoch 434: ReduceLROnPlateau reducing learning rate to 4.7101289601414466e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.0533e-04 - val_loss: 0.0134 - learning_rate: 5.2335e-05\n",
      "Epoch 435/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.0971e-04 - val_loss: 0.0130 - learning_rate: 4.7101e-05\n",
      "Epoch 436/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.0195e-04 - val_loss: 0.0132 - learning_rate: 4.7101e-05\n",
      "Epoch 437/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.0242e-04 - val_loss: 0.0132 - learning_rate: 4.7101e-05\n",
      "Epoch 438/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 137ms/step - loss: 2.0178e-04 - val_loss: 0.0133 - learning_rate: 4.7101e-05\n",
      "Epoch 439/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.0189e-04 - val_loss: 0.0131 - learning_rate: 4.7101e-05\n",
      "Epoch 440/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.0129e-04 - val_loss: 0.0131 - learning_rate: 4.7101e-05\n",
      "Epoch 441/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.9986e-04 - val_loss: 0.0131 - learning_rate: 4.7101e-05\n",
      "Epoch 442/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.9454e-04 - val_loss: 0.0130 - learning_rate: 4.7101e-05\n",
      "Epoch 443/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 2.0017e-04 - val_loss: 0.0134 - learning_rate: 4.7101e-05\n",
      "Epoch 444/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.0079e-04 - val_loss: 0.0134 - learning_rate: 4.7101e-05\n",
      "Epoch 445/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 2.0690e-04 - val_loss: 0.0132 - learning_rate: 4.7101e-05\n",
      "Epoch 446/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 2.0006e-04 - val_loss: 0.0130 - learning_rate: 4.7101e-05\n",
      "Epoch 447/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 1.9988e-04\n",
      "Epoch 447: ReduceLROnPlateau reducing learning rate to 4.239116096869111e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.0007e-04 - val_loss: 0.0131 - learning_rate: 4.7101e-05\n",
      "Epoch 448/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 2.0107e-04 - val_loss: 0.0132 - learning_rate: 4.2391e-05\n",
      "Epoch 449/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 1.9933e-04 - val_loss: 0.0133 - learning_rate: 4.2391e-05\n",
      "Epoch 450/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.9390e-04 - val_loss: 0.0131 - learning_rate: 4.2391e-05\n",
      "Epoch 451/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.9655e-04 - val_loss: 0.0130 - learning_rate: 4.2391e-05\n",
      "Epoch 452/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.9398e-04 - val_loss: 0.0130 - learning_rate: 4.2391e-05\n",
      "Epoch 453/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.9301e-04 - val_loss: 0.0132 - learning_rate: 4.2391e-05\n",
      "Epoch 454/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.9453e-04 - val_loss: 0.0131 - learning_rate: 4.2391e-05\n",
      "Epoch 455/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.9548e-04 - val_loss: 0.0132 - learning_rate: 4.2391e-05\n",
      "Epoch 456/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.9365e-04 - val_loss: 0.0130 - learning_rate: 4.2391e-05\n",
      "Epoch 457/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.9217e-04 - val_loss: 0.0130 - learning_rate: 4.2391e-05\n",
      "Epoch 458/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.9285e-04 - val_loss: 0.0130 - learning_rate: 4.2391e-05\n",
      "Epoch 459/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 1.9616e-04 - val_loss: 0.0132 - learning_rate: 4.2391e-05\n",
      "Epoch 460/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 1.9340e-04\n",
      "Epoch 460: ReduceLROnPlateau reducing learning rate to 3.815204618149437e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.9339e-04 - val_loss: 0.0133 - learning_rate: 4.2391e-05\n",
      "Epoch 461/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.9267e-04 - val_loss: 0.0132 - learning_rate: 3.8152e-05\n",
      "Epoch 462/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.9177e-04 - val_loss: 0.0132 - learning_rate: 3.8152e-05\n",
      "Epoch 463/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.9254e-04 - val_loss: 0.0130 - learning_rate: 3.8152e-05\n",
      "Epoch 464/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.8908e-04 - val_loss: 0.0131 - learning_rate: 3.8152e-05\n",
      "Epoch 465/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.8896e-04 - val_loss: 0.0131 - learning_rate: 3.8152e-05\n",
      "Epoch 466/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.8587e-04 - val_loss: 0.0133 - learning_rate: 3.8152e-05\n",
      "Epoch 467/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.8622e-04 - val_loss: 0.0133 - learning_rate: 3.8152e-05\n",
      "Epoch 468/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 1.8950e-04 - val_loss: 0.0130 - learning_rate: 3.8152e-05\n",
      "Epoch 469/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 1.8724e-04 - val_loss: 0.0135 - learning_rate: 3.8152e-05\n",
      "Epoch 470/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8914e-04 - val_loss: 0.0129 - learning_rate: 3.8152e-05\n",
      "Epoch 471/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8379e-04 - val_loss: 0.0133 - learning_rate: 3.8152e-05\n",
      "Epoch 472/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.8873e-04 - val_loss: 0.0132 - learning_rate: 3.8152e-05\n",
      "Epoch 473/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 1.8987e-04\n",
      "Epoch 473: ReduceLROnPlateau reducing learning rate to 3.4336842873017304e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8961e-04 - val_loss: 0.0132 - learning_rate: 3.8152e-05\n",
      "Epoch 474/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8257e-04 - val_loss: 0.0131 - learning_rate: 3.4337e-05\n",
      "Epoch 475/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.7970e-04 - val_loss: 0.0129 - learning_rate: 3.4337e-05\n",
      "Epoch 476/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.8245e-04 - val_loss: 0.0132 - learning_rate: 3.4337e-05\n",
      "Epoch 477/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.8153e-04 - val_loss: 0.0131 - learning_rate: 3.4337e-05\n",
      "Epoch 478/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.8441e-04 - val_loss: 0.0133 - learning_rate: 3.4337e-05\n",
      "Epoch 479/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.8431e-04 - val_loss: 0.0132 - learning_rate: 3.4337e-05\n",
      "Epoch 480/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.7925e-04 - val_loss: 0.0129 - learning_rate: 3.4337e-05\n",
      "Epoch 481/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 1.7973e-04 - val_loss: 0.0134 - learning_rate: 3.4337e-05\n",
      "Epoch 482/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 1.8377e-04 - val_loss: 0.0132 - learning_rate: 3.4337e-05\n",
      "Epoch 483/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.8303e-04 - val_loss: 0.0131 - learning_rate: 3.4337e-05\n",
      "Epoch 484/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.8270e-04 - val_loss: 0.0136 - learning_rate: 3.4337e-05\n",
      "Epoch 485/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.7767e-04 - val_loss: 0.0130 - learning_rate: 3.4337e-05\n",
      "Epoch 486/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 1.7725e-04\n",
      "Epoch 486: ReduceLROnPlateau reducing learning rate to 3.0903160222806036e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.7721e-04 - val_loss: 0.0133 - learning_rate: 3.4337e-05\n",
      "Epoch 487/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.7959e-04 - val_loss: 0.0133 - learning_rate: 3.0903e-05\n",
      "Epoch 488/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.7855e-04 - val_loss: 0.0131 - learning_rate: 3.0903e-05\n",
      "Epoch 489/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.7873e-04 - val_loss: 0.0131 - learning_rate: 3.0903e-05\n",
      "Epoch 490/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.7721e-04 - val_loss: 0.0133 - learning_rate: 3.0903e-05\n",
      "Epoch 491/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.7971e-04 - val_loss: 0.0135 - learning_rate: 3.0903e-05\n",
      "Epoch 492/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.7641e-04 - val_loss: 0.0130 - learning_rate: 3.0903e-05\n",
      "Epoch 493/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.7804e-04 - val_loss: 0.0129 - learning_rate: 3.0903e-05\n",
      "Epoch 494/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.7402e-04 - val_loss: 0.0132 - learning_rate: 3.0903e-05\n",
      "Epoch 495/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.7578e-04 - val_loss: 0.0131 - learning_rate: 3.0903e-05\n",
      "Epoch 496/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.7689e-04 - val_loss: 0.0129 - learning_rate: 3.0903e-05\n",
      "Epoch 497/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.7851e-04 - val_loss: 0.0132 - learning_rate: 3.0903e-05\n",
      "Epoch 498/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.7563e-04 - val_loss: 0.0130 - learning_rate: 3.0903e-05\n",
      "Epoch 499/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.8072e-04\n",
      "Epoch 499: ReduceLROnPlateau reducing learning rate to 3e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.8082e-04 - val_loss: 0.0132 - learning_rate: 3.0903e-05\n",
      "Epoch 500/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.7772e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 501/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.7507e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 502/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.7662e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 503/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.7350e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 504/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.7193e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 505/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.7596e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 506/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.7887e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 507/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.7728e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 508/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.7216e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 509/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.6984e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 510/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.7559e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 511/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.7561e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 512/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 1.7139e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 513/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.7261e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 514/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.7472e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 515/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.7307e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 516/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.7247e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 517/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.7181e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 518/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.7211e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 519/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.7394e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 520/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.7183e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 521/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.7495e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 522/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.7663e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 523/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.7589e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 524/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 1.7276e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 525/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.6984e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 526/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.6986e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 527/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.7443e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 528/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 1.7034e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 529/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6885e-04 - val_loss: 0.0129 - learning_rate: 3.0000e-05\n",
      "Epoch 530/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6906e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 531/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.6979e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 532/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6832e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 533/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.6979e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 534/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.6659e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 535/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6612e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 536/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.6437e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 537/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6247e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 538/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6577e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 539/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6772e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 540/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 1.7087e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 541/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6843e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 542/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6610e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 543/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.6582e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 544/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6920e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 545/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.6985e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 546/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.6747e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 547/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.6723e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 548/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.7269e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 549/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6411e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 550/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.6491e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 551/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.6495e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 552/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6690e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 553/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6599e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 554/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.6679e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 555/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.6679e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 556/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.6340e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 557/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6295e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 558/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6468e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 559/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6046e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 560/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6154e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 561/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.6599e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 562/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.5891e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 563/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6272e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 564/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.6523e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 565/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6496e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 566/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6402e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 567/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.6652e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 568/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6212e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 569/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6138e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 570/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.6408e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 571/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.6509e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 572/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 1.6196e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 573/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.6335e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 574/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6511e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 575/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.6354e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 576/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6285e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 577/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.5805e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 578/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6029e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 579/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.5788e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 580/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.6030e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 581/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.5952e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 582/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5902e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 583/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5987e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 584/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.5962e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 585/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5994e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 586/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.5742e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 587/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6136e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 588/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5817e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 589/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.5810e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 590/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.5846e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 591/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.6153e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 592/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.6132e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 593/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5895e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 594/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.6058e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 595/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5512e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 596/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5698e-04 - val_loss: 0.0138 - learning_rate: 3.0000e-05\n",
      "Epoch 597/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.6217e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 598/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5906e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 599/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.5603e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 600/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.5397e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 601/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.5150e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 602/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5533e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 603/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5278e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 604/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5392e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 605/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5149e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 606/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.5174e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 607/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.5853e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 608/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.5370e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 609/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5398e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 610/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 1.5769e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 611/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5864e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 612/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5413e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 613/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5413e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 614/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5107e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 615/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5154e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 616/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4676e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 617/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5264e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 618/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.5169e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 619/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5400e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 620/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5300e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 621/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4987e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 622/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.4944e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 623/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5021e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 624/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5294e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 625/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4934e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 626/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.4783e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 627/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.5055e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 628/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.5220e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 629/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4966e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 630/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.5159e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 631/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5010e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 632/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.5034e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 633/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.4979e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 634/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.4892e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 635/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4867e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 636/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4624e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 637/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4693e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 638/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.4734e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 639/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4654e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 640/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4664e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 641/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.4862e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 642/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.4591e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 643/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4532e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 644/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4557e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 645/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4836e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 646/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.4937e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 647/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 1.4954e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 648/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.4533e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 649/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.4706e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 650/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.4361e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 651/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4193e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 652/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4407e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 653/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4796e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 654/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4494e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 655/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4629e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 656/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4750e-04 - val_loss: 0.0130 - learning_rate: 3.0000e-05\n",
      "Epoch 657/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.5203e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 658/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.5094e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 659/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4506e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 660/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 1.4583e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 661/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4213e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 662/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 1.4454e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 663/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.4092e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 664/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4399e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 665/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.4731e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 666/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.4858e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 667/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4754e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 668/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4817e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 669/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.4478e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 670/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.4536e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 671/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4195e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 672/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.4281e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 673/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4544e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 674/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4227e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 675/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4037e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 676/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4206e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 677/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.4167e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 678/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4107e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 679/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.3937e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 680/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4018e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 681/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 1.4184e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 682/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.4053e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 683/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3996e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 684/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3864e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 685/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3886e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 686/1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 20:43:20.094687: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.3660e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 687/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4158e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 688/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3933e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 689/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3806e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 690/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.4096e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 691/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3876e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 692/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.4341e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 693/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.4101e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 694/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.3840e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 695/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.3710e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 696/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3500e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 697/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3842e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 698/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.4137e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 699/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.4001e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 700/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3822e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 701/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3682e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 702/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.4120e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 703/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.3888e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 704/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.3390e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 705/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3422e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 706/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3498e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 707/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.3832e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 708/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3355e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 709/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.3310e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 710/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3794e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 711/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3334e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 712/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.3574e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 713/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3633e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 714/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.4009e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 715/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3486e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 716/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3568e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 717/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3954e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 718/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3533e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 719/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3601e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 720/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3327e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 721/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.3324e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 722/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3366e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 723/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3534e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 724/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.3123e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 725/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3211e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 726/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.3294e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 727/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3254e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 728/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2735e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 729/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3251e-04 - val_loss: 0.0138 - learning_rate: 3.0000e-05\n",
      "Epoch 730/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2996e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 731/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.2974e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 732/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2885e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 733/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2832e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 734/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2945e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 735/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3166e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 736/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2891e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 737/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2570e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 738/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2575e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 739/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2760e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 740/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2977e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 741/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2703e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 742/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 1.2835e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 743/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.3212e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 744/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.3133e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 745/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.3226e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 746/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.2737e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 747/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2729e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 748/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2935e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 749/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.2771e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 750/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2661e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 751/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2749e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 752/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2781e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 753/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.3273e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 754/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2914e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 755/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2795e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 756/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2939e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 757/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2830e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 758/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2342e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 759/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2588e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 760/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.2938e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 761/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.2902e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 762/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.2821e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 763/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2412e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 764/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2314e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 765/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.2427e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 766/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2564e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 767/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2500e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 768/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2593e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 769/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.2557e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 770/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2527e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 771/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2379e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 772/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2285e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 773/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2275e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 774/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2209e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 775/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2168e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 776/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2049e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 777/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2394e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 778/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 1.2208e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 779/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2335e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 780/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2257e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 781/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2622e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 782/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2564e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 783/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2406e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 784/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2265e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 785/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2229e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 786/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2452e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 787/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.2585e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 788/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2355e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 789/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2249e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 790/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.2203e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 791/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.1831e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 792/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2216e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 793/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2004e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 794/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2136e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 795/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.1784e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 796/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2263e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 797/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.2014e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 798/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 1.2361e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 799/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1889e-04 - val_loss: 0.0138 - learning_rate: 3.0000e-05\n",
      "Epoch 800/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2383e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 801/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1938e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 802/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.1965e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 803/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.1979e-04 - val_loss: 0.0139 - learning_rate: 3.0000e-05\n",
      "Epoch 804/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.1965e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 805/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1668e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 806/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1737e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 807/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.2068e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 808/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1835e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 809/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2021e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 810/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2236e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 811/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2188e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 812/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2007e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 813/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2071e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 814/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1792e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 815/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1682e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 816/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.2432e-04 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 817/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1704e-04 - val_loss: 0.0138 - learning_rate: 3.0000e-05\n",
      "Epoch 818/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.1905e-04 - val_loss: 0.0138 - learning_rate: 3.0000e-05\n",
      "Epoch 819/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.1881e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 820/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2024e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 821/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1941e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 822/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1924e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 823/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.2215e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 824/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.2234e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 825/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1714e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 826/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.1703e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 827/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.1475e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 828/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1573e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 829/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.1418e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 830/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1653e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 831/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1401e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 832/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1747e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 833/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.1405e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 834/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1403e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 835/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.1287e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 836/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.1329e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 837/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1244e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 838/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.1637e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 839/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.1550e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 840/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1293e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 841/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.1536e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 842/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.1413e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 843/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.1937e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 844/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.1764e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 845/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.1463e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 846/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.1452e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 847/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1431e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 848/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.1641e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 849/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 1.1093e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 850/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.1507e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 851/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.1494e-04 - val_loss: 0.0139 - learning_rate: 3.0000e-05\n",
      "Epoch 852/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.1470e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 853/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1107e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 854/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1431e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 855/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.1200e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 856/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0735e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 857/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1096e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 858/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 132ms/step - loss: 1.1301e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 859/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1191e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 860/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0957e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 861/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1432e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 862/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1688e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 863/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1448e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 864/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1171e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 865/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.0613e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 866/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.0726e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 867/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.0970e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 868/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.0846e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 869/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1138e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 870/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0850e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 871/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1020e-04 - val_loss: 0.0138 - learning_rate: 3.0000e-05\n",
      "Epoch 872/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.1529e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 873/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1254e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 874/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.1056e-04 - val_loss: 0.0139 - learning_rate: 3.0000e-05\n",
      "Epoch 875/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0738e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 876/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1166e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 877/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.0619e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 878/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.1112e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 879/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0921e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 880/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.1035e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 881/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.0821e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 882/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.0680e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 883/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0810e-04 - val_loss: 0.0138 - learning_rate: 3.0000e-05\n",
      "Epoch 884/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.0783e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 885/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0754e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 886/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1493e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 887/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.1093e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 888/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.0675e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 889/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.1047e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 890/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.0849e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 891/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.0345e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 892/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.0667e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 893/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.1067e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 894/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0874e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 895/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.0672e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 896/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0579e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 897/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.0579e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 898/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0413e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 899/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0710e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 900/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.0823e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 901/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.0801e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 902/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0899e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 903/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0790e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 904/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0603e-04 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 905/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.0947e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 906/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0723e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 907/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0708e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 908/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0930e-04 - val_loss: 0.0138 - learning_rate: 3.0000e-05\n",
      "Epoch 909/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0841e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 910/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0557e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 911/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 1.0879e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 912/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.0738e-04 - val_loss: 0.0138 - learning_rate: 3.0000e-05\n",
      "Epoch 913/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 1.0336e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 914/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 1.0772e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 915/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0099e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 916/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 1.0501e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 917/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.0091e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 918/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0631e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 919/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0596e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 920/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0235e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 921/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.0553e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 922/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.0397e-04 - val_loss: 0.0138 - learning_rate: 3.0000e-05\n",
      "Epoch 923/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.0241e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 924/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0174e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 925/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 9.9877e-05 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 926/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.0015e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 927/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0370e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 928/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0109e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 929/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 9.9486e-05 - val_loss: 0.0138 - learning_rate: 3.0000e-05\n",
      "Epoch 930/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 9.8755e-05 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 931/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0013e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 932/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 9.9808e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 933/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0432e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 934/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 9.9878e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 935/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 9.9617e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 936/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0112e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 937/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0169e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 938/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 1.0097e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 939/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 1.0114e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 940/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.9990e-05 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 941/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.8440e-05 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 942/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.8837e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 943/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.9544e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 944/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0245e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 945/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 1.0036e-04 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 946/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 1.0017e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 947/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.7342e-05 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 948/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.9032e-05 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 949/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0052e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 950/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0024e-04 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 951/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0142e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 952/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 132ms/step - loss: 9.9819e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 953/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.9766e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 954/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 1.0132e-04 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 955/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 1.0049e-04 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 956/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.9932e-05 - val_loss: 0.0139 - learning_rate: 3.0000e-05\n",
      "Epoch 957/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 9.9718e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 958/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 1.0083e-04 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 959/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 9.5743e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 960/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.5307e-05 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 961/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.6586e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 962/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.9054e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 963/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.8590e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 964/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.5598e-05 - val_loss: 0.0138 - learning_rate: 3.0000e-05\n",
      "Epoch 965/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 9.6598e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 966/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.7853e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 967/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 9.8944e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 968/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.7861e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 969/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.5560e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 970/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.8441e-05 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 971/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.5437e-05 - val_loss: 0.0139 - learning_rate: 3.0000e-05\n",
      "Epoch 972/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.8712e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 973/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 9.6853e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 974/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.8185e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 975/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.3350e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 976/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.7090e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 977/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.8617e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 978/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 9.9097e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 979/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.9141e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 980/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.6867e-05 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 981/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.4152e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 982/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.7811e-05 - val_loss: 0.0139 - learning_rate: 3.0000e-05\n",
      "Epoch 983/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.7722e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 984/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.8100e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 985/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.3714e-05 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 986/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.1894e-05 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 987/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.7601e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 988/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.6015e-05 - val_loss: 0.0138 - learning_rate: 3.0000e-05\n",
      "Epoch 989/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.3296e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 990/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 9.5927e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 991/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.4590e-05 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 992/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 9.5636e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 993/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.5309e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 994/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 9.5404e-05 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 995/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.4289e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 996/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.3460e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 997/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.6184e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 998/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.6697e-05 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 999/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.2940e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 1000/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 9.7384e-05 - val_loss: 0.0138 - learning_rate: 3.0000e-05\n",
      "Epoch 1001/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.5425e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 1002/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.3002e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1003/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 9.2552e-05 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 1004/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.5346e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1005/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.4068e-05 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 1006/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.4248e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1007/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.2920e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 1008/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.4467e-05 - val_loss: 0.0139 - learning_rate: 3.0000e-05\n",
      "Epoch 1009/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.0984e-05 - val_loss: 0.0131 - learning_rate: 3.0000e-05\n",
      "Epoch 1010/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.0916e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 1011/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - loss: 9.0368e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 1012/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.1603e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1013/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.8533e-05 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 1014/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.9462e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1015/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.2149e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1016/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.2508e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1017/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.8318e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 1018/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.0102e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 1019/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.1015e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 1020/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 9.2312e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1021/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.2815e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 1022/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.0094e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1023/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.8847e-05 - val_loss: 0.0140 - learning_rate: 3.0000e-05\n",
      "Epoch 1024/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.8150e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1025/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.0160e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 1026/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 9.0034e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1027/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 9.1977e-05 - val_loss: 0.0138 - learning_rate: 3.0000e-05\n",
      "Epoch 1028/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 8.6913e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 1029/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.1938e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 1030/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 9.0583e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1031/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.8611e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 1032/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.3738e-05 - val_loss: 0.0140 - learning_rate: 3.0000e-05\n",
      "Epoch 1033/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 132ms/step - loss: 8.8321e-05 - val_loss: 0.0139 - learning_rate: 3.0000e-05\n",
      "Epoch 1034/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.4705e-05 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 1035/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.2406e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1036/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 9.1684e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1037/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.5289e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 1038/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.0918e-05 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 1039/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.9622e-05 - val_loss: 0.0138 - learning_rate: 3.0000e-05\n",
      "Epoch 1040/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.3850e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 1041/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.0031e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 1042/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.8576e-05 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 1043/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.9329e-05 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 1044/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 9.3111e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 1045/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.0688e-05 - val_loss: 0.0138 - learning_rate: 3.0000e-05\n",
      "Epoch 1046/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.8199e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 1047/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.7629e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 1048/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 8.4794e-05 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 1049/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 8.8968e-05 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 1050/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.6666e-05 - val_loss: 0.0138 - learning_rate: 3.0000e-05\n",
      "Epoch 1051/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.1461e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1052/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 9.0830e-05 - val_loss: 0.0138 - learning_rate: 3.0000e-05\n",
      "Epoch 1053/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.3477e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1054/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.1341e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1055/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 8.9413e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 1056/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.0441e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 1057/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.9098e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1058/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.5631e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 1059/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.8019e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 1060/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 8.8031e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 1061/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.8773e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1062/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 9.1698e-05 - val_loss: 0.0138 - learning_rate: 3.0000e-05\n",
      "Epoch 1063/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.8775e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 1064/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 9.5376e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 1065/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.9754e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1066/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 9.2719e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1067/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.7772e-05 - val_loss: 0.0140 - learning_rate: 3.0000e-05\n",
      "Epoch 1068/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.8764e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 1069/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 9.0271e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 1070/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 8.8880e-05 - val_loss: 0.0132 - learning_rate: 3.0000e-05\n",
      "Epoch 1071/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.5141e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 1072/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.5637e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1073/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.4324e-05 - val_loss: 0.0138 - learning_rate: 3.0000e-05\n",
      "Epoch 1074/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.8136e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1075/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.6945e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1076/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.5473e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1077/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.2731e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 1078/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.3106e-05 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 1079/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.4669e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 1080/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.5280e-05 - val_loss: 0.0138 - learning_rate: 3.0000e-05\n",
      "Epoch 1081/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.5897e-05 - val_loss: 0.0134 - learning_rate: 3.0000e-05\n",
      "Epoch 1082/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.4026e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1083/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 9.0807e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1084/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 8.4228e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 1085/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.6344e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 1086/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.7741e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1087/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.8264e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1088/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 8.2979e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 1089/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.0792e-05 - val_loss: 0.0138 - learning_rate: 3.0000e-05\n",
      "Epoch 1090/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.4625e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1091/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.5957e-05 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n",
      "Epoch 1092/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.5957e-05 - val_loss: 0.0138 - learning_rate: 3.0000e-05\n",
      "Epoch 1093/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 8.5744e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 1094/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - loss: 8.4677e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 1095/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 8.2424e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 1096/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.4127e-05 - val_loss: 0.0137 - learning_rate: 3.0000e-05\n",
      "Epoch 1097/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.2716e-05 - val_loss: 0.0135 - learning_rate: 3.0000e-05\n",
      "Epoch 1098/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 8.7580e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1099/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 134ms/step - loss: 8.3122e-05 - val_loss: 0.0136 - learning_rate: 3.0000e-05\n",
      "Epoch 1100/1100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 8.2220e-05 - val_loss: 0.0133 - learning_rate: 3.0000e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model with the custom callback\n",
    "history = model_builder.train_model(\n",
    "    train_dataset, \n",
    "    val_dataset, \n",
    "    epochs=1100,\n",
    "    callbacks_list=[lr_scheduler]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Extract the losses from the history object\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "train_loss_x_midpoints = history.history.get('x_midpoints_reshape_loss', train_loss)\n",
    "val_loss_x_midpoints = history.history.get('val_x_midpoints_reshape_loss', val_loss)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2,1)\n",
    "plt.plot(train_loss_x_midpoints, label='Train Loss x_midpoints_reshape')\n",
    "plt.plot(val_loss_x_midpoints, label='Validation Loss x_midpoints_reshape')\n",
    "plt.xlabel('Epochs')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss ')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder.model.save(\"/home/da886/Analysis/30KNoFalsePositivesFixed-index6_13__overfitNoBatchNorm.keras\")\n",
    "# loaded_model = tf.keras.models.load_model(\n",
    "# \"/home/da886/Analysis/30KNoFalsePositivesFixed-index6_13__overfitNo.keras\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1, batch shape: (800, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728421767.867430   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.868180   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.868445   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.868691   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.868937   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.869202   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.869472   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.869731   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.870023   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.870311   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.870588   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.870852   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.871174   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.871535   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.871823   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.872225   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.872525   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.873080   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.873437   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.874034   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.876620   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.877250   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.877502   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.877591   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.878148   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.878231   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.878718   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.878730   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.879185   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.879321   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.879595   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.879836   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.880083   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.880298   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.880603   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.880717   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.880898   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.881314   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.881351   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.881410   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.881896   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.882005   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.882026   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.882342   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.882735   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.882748   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.882758   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.883413   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.883549   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.883570   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.883734   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.884148   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.884300   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.884309   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.884768   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.884866   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.884969   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.885365   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.885482   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.885714   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.885824   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.886087   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.886269   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.886308   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.886733   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.886736   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.887319   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.887429   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.887445   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.887617   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.888128   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.888152   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.888374   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.888473   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.888936   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.889092   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.889346   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.889402   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.889965   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.890128   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.890278   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.890684   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.891180   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.891752   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.892083   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.892423   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.901886   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.902181   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.902459   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.902726   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.902994   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.903268   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.903532   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.903779   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.904034   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.904300   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.904556   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.904806   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.905282   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.905748   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.906146   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.906266   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.906602   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.906690   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.906867   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.907194   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.907409   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.907522   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.907642   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.908039   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.908138   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.908261   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.908473   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.908844   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.908971   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.909315   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.909329   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.909769   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.909898   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.910147   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.910384   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.910606   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.910815   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.911020   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.911253   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.911480   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.911696   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.911917   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.912154   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.912375   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.912595   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.912807   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.913018   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.913296   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.913531   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.913770   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.913973   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.914331   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.914553   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.914568   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.914959   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.915051   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.915277   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.915453   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.915614   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.915829   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.915848   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.916252   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.916271   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.916416   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.916711   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.916921   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.917005   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.917099   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.917548   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.917672   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.917679   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.918870   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.919017   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.919318   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.919331   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.919737   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.919902   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.920200   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.920248   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.920486   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.920611   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.920958   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.921116   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.921175   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.921454   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.921546   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.921836   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.922140   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.922448   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.922812   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.923137   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.923533   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.923902   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.924588   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.930994   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.931315   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.931598   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.931873   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.932161   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.932461   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.932747   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.933039   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.933339   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.933627   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.933929   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.934223   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.934521   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.934824   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.935134   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.935459   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.935775   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.936110   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.936473   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.936832   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.937172   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.937602   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.937712   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.937983   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.938060   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.938556   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.938576   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.938585   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.938937   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.939160   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.939251   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.939660   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.939662   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.940164   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.940340   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.940372   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.940793   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.941024   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.941037   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.941138   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.941657   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.941665   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.941747   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.942136   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.942135   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.942579   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.942704   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.942710   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.943121   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.943210   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.943489   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.943683   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.943881   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.944106   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.944472   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.944827   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.945033   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.945398   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.945586   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.945896   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.946544   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.946544   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.947128   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.947655   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.948171   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.952767   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.953024   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.953455   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.953715   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.953980   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.954285   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.954469   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.954681   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.954871   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.955088   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.955282   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.955478   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.955745   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.955869   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.956060   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.956257   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.956538   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.956671   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.956878   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.957087   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.957275   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.957487   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.957675   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.957869   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.958128   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.958263   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.958275   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.958530   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.958827   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.958858   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.958956   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.959438   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.959453   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.959468   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.959971   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.960059   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.960075   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.960410   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.960547   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.960652   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.960971   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.961040   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.961200   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.961585   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.961657   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.961796   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.962063   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.962142   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.962539   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.962665   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.962803   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.962931   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.963261   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.963358   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.963812   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.963816   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.964205   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.964551   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.964763   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.965317   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.966120   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.967548   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.968811   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.969098   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.969470   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.969664   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.969844   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.970149   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.970581   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.970649   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.970754   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.970944   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.971245   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.971342   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.971701   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.971782   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.972183   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.972260   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.972656   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.972736   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.973134   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.973212   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.973621   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.973706   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.973917   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.974238   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.974773   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.974785   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.975075   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.975490   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.975571   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.976325   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.976834   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.976989   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.977431   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.978178   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.978281   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.979011   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.979101   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.979803   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.979911   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.980527   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.981215   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.991522   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.991846   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.992234   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.992307   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.992671   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.992745   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.993061   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.993200   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.993485   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.993735   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.993754   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.993892   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.994266   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.994483   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.994501   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.994809   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.994953   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.994956   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.995308   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.995423   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.995554   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.995880   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.995888   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.995995   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.996515   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.996541   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.996612   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.996963   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.997094   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.997110   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.997333   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.997706   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.997827   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.997927   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.998236   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.998379   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.998478   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.998779   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.999073   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.999074   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.999193   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.999524   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.999706   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.999716   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421767.999937   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.000314   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.000435   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.000631   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.000732   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.001107   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.001284   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.001317   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.001517   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.001959   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.002077   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.002170   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.002644   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.002739   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.003398   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.003569   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.003589   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.004504   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.004535   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.004614   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.005118   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.011254   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.011633   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.011727   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.011734   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.012071   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.012384   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.012395   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.012498   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.012895   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.013039   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.013056   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.013279   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.013655   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.013670   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.013766   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.014208   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.014330   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.014520   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.014662   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.014962   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.015102   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.015205   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.015505   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.015614   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.015742   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.016124   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.016153   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.016257   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.016684   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.016811   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.016987   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.017113   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.017311   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.017483   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.017860   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.017941   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.018355   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.018431   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.018961   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.018981   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.019278   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.019456   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.020104   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.020125   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.020319   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.020635   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.021192   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.021331   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.021338   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.021947   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.022585   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.022882   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.022965   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.023947   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.024080   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.024192   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.025701   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.025876   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.026340   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.027662   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.036639   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.037133   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.037598   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.038032   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.038556   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.039044   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.039577   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.040056   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.040542   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.041013   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.041550   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.042053   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.043850   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.046006   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.048231   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.048858   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.049331   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.049404   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.049810   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.049904   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.050319   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.050410   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.050742   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.050867   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.050952   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.051359   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.051439   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.051909   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.051923   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.052391   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.052488   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.052865   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.052993   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.053109   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.053322   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.053493   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.053744   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.053928   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.054149   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.054349   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.054573   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.054746   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.054948   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.055305   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.055474   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.055493   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.055865   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.055972   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.056405   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.056506   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.056884   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.057072   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.057474   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.057575   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.058441   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.058454   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.059499   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.059505   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.059899   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.060867   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.060964   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.061899   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.062000   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.069484   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.069755   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.069922   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.070318   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.070419   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.070792   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.070887   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.071363   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.071443   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.071770   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.071947   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.072239   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.072414   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.072769   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.072876   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.073228   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.073327   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.073634   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.073813   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.074065   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.074257   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.074610   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.074715   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.075044   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.075989   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.076332   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.077625   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.077993   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.079214   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.079596   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.080807   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.081206   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.082293   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.082700   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.084932   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.085379   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.086443   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.086900   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.132597   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.133114   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.133230   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.133640   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.133746   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.134085   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.134261   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.134610   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.134711   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.135269   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.135280   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.135820   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.135919   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.136360   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.136463   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.136952   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.137034   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.137574   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.137591   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.138164   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.138265   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.138839   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.138851   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.139426   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.139526   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.139949   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.140124   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.140621   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.140720   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.141228   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.141404   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.141867   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.142108   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.142114   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.142731   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.142754   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.142857   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.143263   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.143439   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.143756   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.144352   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.144438   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.144910   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.145025   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.145419   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.145929   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.146586   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.146663   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.147282   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.147302   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.147884   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.148340   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.148509   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.148992   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.149185   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.149977   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.150726   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.151542   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.152449   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.153481   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.158114   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.158665   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.158733   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.159214   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.159408   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.159724   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.159918   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.160458   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.160559   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.160960   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.161171   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.161684   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.161689   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.161794   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.162307   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.162407   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.162832   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.163012   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.163512   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.163613   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.164177   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.164285   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.164386   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.164952   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.165052   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.165597   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.167385   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.168166   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.169979   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.170783   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.172511   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.173341   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.174791   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.175641   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.177182   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.177818   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.178058   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.178352   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.178741   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.179168   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.179820   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.179844   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.180382   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.180556   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.180879   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.182164   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.183481   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.184977   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.185088   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.185564   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.187406   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.189079   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.191358   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.193258   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.232829   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.233227   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.233606   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.233999   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.234383   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.234769   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.235174   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.235572   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.235965   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.236346   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.236730   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.237138   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.237552   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.237958   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.238433   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.238931   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.239480   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.239992   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.240520   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.241174   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.241779   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.243475   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.245113   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.253863   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.254207   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.254526   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.254822   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.255273   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.255643   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.256739   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.257138   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.257612   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.258277   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.258983   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.259660   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.260364   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.261485   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.262956   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.272227   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.272543   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.272840   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.273157   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.273472   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.273779   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.274097   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.274393   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.274689   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.275054   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.275626   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.275666   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.276240   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.276403   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.276504   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.276672   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.277349   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.277352   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.277453   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.277954   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.278079   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.278187   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.278354   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.278750   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.278992   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.279075   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.279356   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.279674   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.279696   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.279905   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.280363   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.280441   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.280544   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.280996   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.281261   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.281273   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.281679   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.282004   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.282099   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.282910   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.282930   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.283015   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.283673   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.283773   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.284549   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.284632   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.285382   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.285463   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.286371   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.286474   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.287295   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.287399   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.288223   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.288323   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.289329   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.289432   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.290227   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.290636   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.290775   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.290859   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.291126   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.291393   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.291659   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.291933   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.292209   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.292482   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.292973   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.293362   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.293386   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.293556   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.294068   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.294637   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.295200   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.296176   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.297471   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.297579   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.297647   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.299258   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.299534   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.299817   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.300101   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.300398   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.300653   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.300921   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.301190   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.301462   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.301840   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.302122   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.302414   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.302716   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.303079   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.303414   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.303769   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.304115   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.304826   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.305201   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.305867   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.306327   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.307458   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.307955   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.311860   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.312010   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.312340   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.312531   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.312774   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.312976   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.313250   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.313454   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.313690   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.313900   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.314179   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.314402   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.314706   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.314713   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.315000   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.315113   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.315351   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.315593   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.315945   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.316095   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.316307   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.316448   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.316609   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.316853   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.317093   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.317336   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.317745   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.317767   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.318092   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.318174   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.318436   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.318720   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.318992   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.319382   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.319513   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.319729   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.319851   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.320022   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.320321   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.320608   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.321085   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.321105   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.321384   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.321525   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.321891   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.322463   56553 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.323710   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.324056   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.325586   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.325951   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.327251   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.327627   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.372908   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.373395   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.373519   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.373819   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.373995   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.374248   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.374422   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.374772   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.374882   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.375198   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.375383   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.375637   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.375816   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.376166   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.376266   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.376614   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.376798   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.377076   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.377243   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.377632   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.377734   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.378233   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.378320   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.378848   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.378937   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.379463   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.379543   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.380075   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.380176   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.380736   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.380837   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.381469   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.381555   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.382041   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.382215   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.382725   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.382831   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.383522   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.383620   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.384220   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.384387   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.384944   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.386088   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.386666   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.387741   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.388323   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.396534   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.396884   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.397150   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.397215   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.397672   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.397749   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.398131   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.398339   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.398514   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.398748   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.399014   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.399361   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.399470   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.399840   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.400020   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.400372   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.400551   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.401157   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.401257   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.401918   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.402014   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.402624   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.402870   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.403496   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.403708   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.404351   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.404832   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.405492   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.406325   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.406991   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.418492   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.418802   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.419231   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.419343   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.419588   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.419803   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.420001   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.420197   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.420483   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.420584   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.420942   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.421054   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.421369   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.421477   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.421705   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.421899   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.422202   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.422308   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.422739   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.422823   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.423277   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.423370   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.423745   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.423847   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.424157   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.424368   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.424646   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.424747   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.425018   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.425188   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.425608   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.425692   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.426158   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.426251   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.426624   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.426801   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.427044   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.427300   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.427537   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.428162   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.428173   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.428798   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.429316   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.429947   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.436276   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.436586   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.436863   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.436871   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.437298   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.437513   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.437629   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.437853   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.438127   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.438244   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.438637   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.438647   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.439040   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.439135   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.439338   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.439719   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.439817   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.440376   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.440461   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.441024   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.441126   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.441743   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.441829   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.442385   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.442492   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.443039   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.443375   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.444032   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.444651   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.445323   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.446269   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.446541   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.446909   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.447035   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.447318   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.447424   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.447652   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.447846   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.448026   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.448222   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.448402   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.448594   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.448845   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.448967   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.449180   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.449346   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.449710   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.449796   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.450105   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.450205   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.450524   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.450626   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.450981   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.451061   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.451475   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.451575   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.451969   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.452051   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.452364   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.452551   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.452841   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.452939   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.453293   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.453711   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.453794   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.454096   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.454634   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.454729   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.455210   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.455317   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.455722   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.456200   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.456363   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.456861   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.457354   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.457852   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.463660   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.463943   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.464175   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.464412   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.464595   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.464654   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.465025   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.465100   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.465352   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.465481   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.465657   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.465832   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.466009   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.466181   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.466352   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.466527   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.466705   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.466871   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.467055   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.467234   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.467405   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.467578   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.467752   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.467929   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.468104   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.468278   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.468461   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.468626   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.468805   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.468974   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.469159   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.469337   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.469506   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.469697   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.469868   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.470104   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.470206   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.470557   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.470638   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.471005   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.471105   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.471518   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.471603   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.471929   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.472134   56557 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.472307   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1728421768.472681   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728421768.473269   56561 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 3, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 4, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 5, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 6, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 7, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 8, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 9, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 10, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 11, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 12, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 13, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 14, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 15, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 16, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 17, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 18, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 19, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 20, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 21, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 22, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 23, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 24, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 25, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 26, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 27, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 28, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 29, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Processing batch 30, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the function for visualizing midpoints\n",
    "def visualize_midpoints(image, midpoints, title=\"Predicted Midpoint Visualization\"):\n",
    "    \"\"\"\n",
    "    Visualizes midpoints on an image without using a probability vector.\n",
    "\n",
    "    Parameters:\n",
    "    - image: A 3D tensor representing the image.\n",
    "    - midpoints: A 2D tensor representing the midpoint coordinates (x, y).\n",
    "    - title: The title of the plot.\n",
    "\n",
    "    Returns:\n",
    "    None (displays the image with midpoints).\n",
    "    \"\"\"\n",
    "    # Convert to NumPy arrays for easier handling\n",
    "    image_np = image\n",
    "    midpoints_np = midpoints\n",
    "\n",
    "    # Denormalize image if necessary (adjust based on your normalization method)\n",
    "    denormalized_image = image_np  # Modify if normalization was applied during training\n",
    "\n",
    "    # Visualize the image\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(denormalized_image, cmap='gray')\n",
    "    plt.title(title)\n",
    "\n",
    "    # Plot midpoints directly, only if they are not (0, 0)\n",
    "    for i, (x, y) in enumerate(midpoints_np):\n",
    "        if x >= 3 and y >= 3:  # Only plot if the point is not (0, 0)\n",
    "            plt.scatter(x, y, color='red', s=5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Create the validation dataset\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n",
    "# val_dataset = val_dataset.batch(800)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)\n",
    "# # Initialize lists to collect the data\n",
    "all_images = []\n",
    "all_true_midpoints = []\n",
    "all_pred_midpoints = []\n",
    "\n",
    "# # Loop through each batch in the validation dataset, predict, and collect results\n",
    "# for i, (data_batch, midpoints_batch) in enumerate(val_dataset):\n",
    "\n",
    "for i, (data_batch, midpoints_batch) in enumerate(train_dataset):\n",
    "    print(f\"Processing batch {i + 1}, batch shape: {data_batch.shape}\")\n",
    "    \n",
    "    # Get the model predictions\n",
    "    predictions = model_builder.model.predict(data_batch)\n",
    "\n",
    "    # Extend the lists to store data from each batch\n",
    "    all_images.extend(data_batch.numpy())  # Store all images\n",
    "    all_true_midpoints.extend(midpoints_batch.numpy())  # Store all true midpoints\n",
    "    all_pred_midpoints.extend(predictions)  # Store all predicted midpoints\n",
    "\n",
    "# Convert lists to arrays for easier indexing\n",
    "all_images = np.array(all_images)\n",
    "all_true_midpoints = np.array(all_true_midpoints)\n",
    "all_pred_midpoints = np.array(all_pred_midpoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "# train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24000, 64, 64), (24000, 1, 13, 2), (24000, 1, 13, 2))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images.shape,all_pred_midpoints.shape,all_true_midpoints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Select an index to visualize from the entire dataset\n",
    "index_to_visualize = np.random.randint(0, len(all_images))\n",
    "\n",
    "# index_to_visualize = 11548\n",
    "# Visualize the selected image with predicted and true midpoints\n",
    "visualize_midpoints(all_images[index_to_visualize], all_pred_midpoints[index_to_visualize, 0, :, :] * 64, title=\"Predicted Midpoints\")\n",
    "visualize_midpoints(all_images[index_to_visualize], all_true_midpoints[index_to_visualize, 0, :, :] * 64, title=\"Ground Truth Midpoints\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00016376097, 0.9970034)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(all_pred_midpoints),np.max(all_pred_midpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13964641, 0.84375)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(all_true_midpoints),np.max(all_true_midpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize variables to track the min and max MSE\n",
    "min_mse = float('inf')\n",
    "max_mse = float('-inf')\n",
    "min_mse_index = -1\n",
    "max_mse_index = -1\n",
    "\n",
    "# Loop through each prediction to calculate the MSE\n",
    "for i in range(len(all_pred_midpoints)):\n",
    "    mse = np.mean((all_pred_midpoints[i] - all_true_midpoints[i]) **2)\n",
    "    \n",
    "    if mse < min_mse:\n",
    "        min_mse = mse\n",
    "        min_mse_index = i\n",
    "    \n",
    "    if mse > max_mse:\n",
    "        max_mse = mse\n",
    "        max_mse_index = i\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot an image with its centers\n",
    "def plot_image_with_centers(image, true_center, predicted_center, title):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image.squeeze(), cmap='gray')  # Display the image\n",
    "\n",
    "    # Plot the actual center (Groundtruth)\n",
    "    plt.scatter(true_center[:, 0], true_center[:, 1], color='green', label='Groundtruth', s=10)\n",
    "\n",
    "    # Plot the predicted center\n",
    "    plt.scatter(predicted_center[:, 0], predicted_center[:, 1], color='red', label='Predictions', s=10)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the image with the least MSE\n",
    "plot_image_with_centers(all_images[min_mse_index],\n",
    "                        all_true_midpoints[min_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[min_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        f'Image with Least MSE. MSE: {min_mse:.4f}')\n",
    "\n",
    "# Plotting the image with the largest MSE\n",
    "plot_image_with_centers(all_images[max_mse_index],\n",
    "                        all_true_midpoints[max_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[max_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        f'Image with Largest MSE. MSE: {max_mse:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5266"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_mse_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "objectdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
