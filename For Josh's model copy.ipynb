{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Set CUDA device order and visible devices\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7,8,9\"\n",
    "\n",
    "# # Set the device\n",
    "# device = '/cpu:0'\n",
    "# if tf.config.experimental.list_physical_devices('GPU'):\n",
    "#     try:\n",
    "#         # Restrict TensorFlow to only use the second GPU\n",
    "#         gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#         if gpus:\n",
    "#             tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "#             device = '/gpu:0'\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)\n",
    "\n",
    "# print(\"device\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 21:11:08.920256: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-03 21:11:08.934378: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-03 21:11:08.947488: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-03 21:11:08.951477: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-03 21:11:08.963568: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-03 21:11:09.670390: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 21:11:11.322273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79194 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:45:00.0, compute capability: 8.0\n",
      "2024-10-03 21:11:11.323799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 79194 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:46:00.0, compute capability: 8.0\n",
      "2024-10-03 21:11:11.325167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 79194 MB memory:  -> device: 2, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:49:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"  # Only GPUs 0 and 1 will be visible to TensorFlow\n",
    "\n",
    "import tensorflow as tf\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\",\"/gpu:2\"])\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# DataLoader Class Definition\n",
    "# -----------------------------\n",
    "class DataLoader:\n",
    "    def __init__(self, h5_filename):\n",
    "        self.h5_filename = h5_filename\n",
    "        self.images, self.centers = self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        with h5py.File(self.h5_filename, 'r') as f:\n",
    "            images = np.array(f['images'])\n",
    "            centers = np.array(f['centers_training'])\n",
    "        return images, centers\n",
    "\n",
    "    def plot_image_with_centers(self, image_index=None):\n",
    "        if image_index is None:\n",
    "            image_index = np.random.randint(0, len(self.images))\n",
    "\n",
    "        image = self.images[image_index]\n",
    "        centers = self.centers[image_index]\n",
    "\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        valid_centers = centers[centers[:, 0] == 1]\n",
    "        for center in valid_centers:\n",
    "            plt.scatter(center[1], center[2], c='red', marker='x')  # center[1] is x and center[2] is y\n",
    "        plt.title('Image with Valid Centers Marked')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_centers(centers):\n",
    "        return centers[np.lexsort((centers[:, 0], centers[:, 1]))]\n",
    "\n",
    "    def normalize_data(self):\n",
    "        normalized_images = self.images / np.max(self.images)\n",
    "        sorted_centers = np.array([self.sort_centers(image_centers[:, 1:]) for image_centers in self.centers])\n",
    "        normalized_centers = sorted_centers / 64\n",
    "\n",
    "        normalized_midpoints = tf.expand_dims(normalized_centers, axis=1)\n",
    "        return normalized_images, normalized_midpoints.numpy()\n",
    "\n",
    "    def split_data(self, train_size=0.8, random_state=42):\n",
    "        normalized_images, normalized_midpoints_np = self.normalize_data()\n",
    "        return train_test_split(normalized_images, normalized_midpoints_np, train_size=train_size, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Utility Function Definition\n",
    "# -----------------------------\n",
    "def plot_transposed_images_with_midpoints(dataset, image_indices=[0, 1, 2, 3]):\n",
    "    \"\"\"\n",
    "    Extracts multiple images and their midpoints from the given dataset, transposes the images, \n",
    "    corrects the midpoints, and plots the transposed images with the corrected midpoints.\n",
    "\n",
    "    Args:\n",
    "    - dataset (tf.data.Dataset): The dataset from which to extract the images and midpoints.\n",
    "    - image_indices (list): The indices of the images in the batch to visualize. Default is [0, 1, 2, 3].\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract a sample image batch and its corresponding midpoints from the dataset\n",
    "    sample_image_batch, sample_midpoints_batch = next(iter(dataset))\n",
    "\n",
    "    # Create a figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(6, 6))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(image_indices):\n",
    "            # Select the specified image and corresponding midpoints from the batch\n",
    "            sample_image = np.array(sample_image_batch[image_indices[i]])\n",
    "            sample_midpoints = np.array(sample_midpoints_batch[image_indices[i]])\n",
    "\n",
    "            # Transpose the image\n",
    "            transposed_image = sample_image.T\n",
    "\n",
    "            # Correct the midpoints by swapping the x and y coordinates\n",
    "            transposed_midpoints_corrected = sample_midpoints[:, :, [1, 0]]\n",
    "\n",
    "            # Plot the transposed image with corrected midpoints\n",
    "            ax.imshow(transposed_image, cmap='gray')\n",
    "            ax.scatter(\n",
    "                transposed_midpoints_corrected[:, :, 0] * 64, \n",
    "                transposed_midpoints_corrected[:, :, 1] * 64, \n",
    "                c='red', marker='o', s=5\n",
    "            )\n",
    "            ax.set_title(f'Image {image_indices[i]} for this batch')\n",
    "        else:\n",
    "            ax.axis('off')  # If fewer than 4 images are requested, hide the unused subplots\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Custom Loss and Callback Definitions\n",
    "# -----------------------------\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def custom_loss(exponent):\n",
    "    def loss(y_true, y_pred):\n",
    "        diff = tf.abs(y_true - y_pred)\n",
    "        powered_diff = tf.pow(diff, exponent)\n",
    "        return tf.reduce_mean(powered_diff)\n",
    "    return loss\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class DynamicExponentCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, initial_exponent, increment, update_frequency):\n",
    "        super().__init__()\n",
    "        self.exponent = initial_exponent\n",
    "        self.increment = increment\n",
    "        self.update_frequency = update_frequency\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.update_frequency == 0:\n",
    "            self.exponent += self.increment\n",
    "            print(f\"\\nEpoch {epoch + 1}: Increasing exponent to {self.exponent}\")\n",
    "            self.model.loss = self.custom_loss(self.exponent)\n",
    "\n",
    "    def custom_loss(self, exponent):\n",
    "        def loss(y_true, y_pred):\n",
    "            diff = tf.abs(y_true - y_pred)\n",
    "            powered_diff = tf.pow(diff, exponent)\n",
    "            return tf.reduce_mean(powered_diff)\n",
    "        return loss\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'initial_exponent': self.exponent,\n",
    "            'increment': self.increment,\n",
    "            'update_frequency': self.update_frequency,\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my NEW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import layers, regularizers\n",
    "\n",
    "# class ModelBuilder:\n",
    "#     def __init__(self, input_shape=(64, 64, 1), num_classes=3, num_coordinates=2, learning_rate=3e-5, weights_path=None, l2_reg=0.001):\n",
    "#         self.input_shape = input_shape\n",
    "#         self.num_classes = num_classes\n",
    "#         self.num_coordinates = num_coordinates\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.l2_reg = l2_reg\n",
    "#         self.model = self.build_model()\n",
    "\n",
    "#         # Load weights if a path is provided\n",
    "#         if weights_path is not None:\n",
    "#             self.model.load_weights(weights_path)\n",
    "\n",
    "#         self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "#         # self.optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "#     def build_model(self):\n",
    "#         l2 = regularizers.l2(self.l2_reg)\n",
    "        \n",
    "#         x_input = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "#         # First branch\n",
    "#         x_1 = layers.Conv2D(64, kernel_size=6, strides=1, padding='same', activation='relu')(x_input)\n",
    "#         x_1 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(x_1)\n",
    "#         x_1 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu')(x_1)\n",
    "#         x_1 = layers.Conv2D(16, kernel_size=3, strides=3, padding='same', activation='relu', kernel_regularizer=l2)(x_1)\n",
    "#         # x_1 = layers.Dropout(0.1)(x_1)\n",
    "#         # x_1 = layers.BatchNormalization()(x_1)\n",
    "\n",
    "#         # Second branch\n",
    "#         x_2 = layers.Conv2D(32, kernel_size=8, strides=3, padding='same', activation='relu')(x_input)\n",
    "#         x_2 = layers.Conv2D(64, kernel_size=4, strides=1, padding='same', activation='relu')(x_2)\n",
    "#         x_2 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2)(x_2)\n",
    "#         # x_2 = layers.Dropout(0.1)(x_2)\n",
    "#         # x_2 = layers.BatchNormalization()(x_2)\n",
    "\n",
    "#         # Concatenate branches\n",
    "#         x_3 = layers.concatenate([x_1, x_2])\n",
    "#         x_3 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu')(x_3)\n",
    "#         x_3 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(x_3)\n",
    "#         x_3 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu', kernel_regularizer=l2)(x_3)\n",
    "#         # x_3 = layers.Dropout(0.1)(x_3)\n",
    "#         # x_3 = layers.BatchNormalization()(x_3)\n",
    "\n",
    "#         # Third branch\n",
    "#         x_4 = layers.Conv2D(64, kernel_size=19, strides=5, padding='same', activation='relu', kernel_regularizer=l2)(x_input)\n",
    "        \n",
    "#         # Flatten and concatenate\n",
    "#         x_3 = layers.Flatten()(x_3)\n",
    "#         x_4 = layers.Flatten()(x_4)\n",
    "#         x = layers.Concatenate()([x_3, x_4])\n",
    "\n",
    "#         # Dense layers with L2 regularization\n",
    "#         x = layers.Dense(256, activation='relu', kernel_regularizer=l2)(x)\n",
    "#         # x = layers.Dropout(0.1)(x)\n",
    "\n",
    "#         # Output layer for midpoints\n",
    "#         x_midpoints = layers.Dense(self.num_classes * self.num_coordinates, activation='sigmoid', name='x_midpoints')(x)\n",
    "#         x_midpoints_reshape = layers.Reshape((-1, self.num_classes, self.num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "        \n",
    "#         return tf.keras.models.Model(x_input, x_midpoints_reshape)\n",
    "\n",
    "#     def compile_model(self, loss_function):\n",
    "#         self.model.compile(optimizer=self.optimizer, loss=loss_function)\n",
    "\n",
    "#     def train_model(self, train_dataset, val_dataset, epochs, callbacks_list):\n",
    "#         history = self.model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks_list)\n",
    "#         return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "\n",
    "class ModelBuilder:\n",
    "    def __init__(self, input_shape=(64, 64, 1), num_classes=5, num_coordinates=2, learning_rate=1e-3, weights_path=None,l1_reg=0.001,l2_reg =0.005):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.num_coordinates = num_coordinates\n",
    "        self.learning_rate = learning_rate\n",
    "        self.l1_reg = l1_reg\n",
    "        self.l2_reg = l2_reg\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        # Load weights if a path is provided\n",
    "        if weights_path is not None:\n",
    "            self.model.load_weights(weights_path)\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "        # self.optimizer =tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "    def build_model(self):\n",
    "        \n",
    "        l1 = regularizers.l1(self.l1_reg)\n",
    "        l2 = regularizers.l2(self.l2_reg)\n",
    "\n",
    "    \n",
    "        x_input = layers.Input(shape=self.input_shape)\n",
    "        x = layers.Conv2D(64, kernel_size=3,strides =1, padding='same', activation='relu')(x_input)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        \n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Dropout(0.1)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        \n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        x = layers.Conv2D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu',kernel_regularizer=l2)(x)\n",
    "        x = layers.MaxPool2D()(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        \n",
    "        x = layers.Flatten()(x)\n",
    "        \n",
    "        x = layers.Dense(16, activation='relu')(x)\n",
    "        \n",
    "        \n",
    "        x_midpoints = layers.Dense(self.num_classes * self.num_coordinates, activation='sigmoid', name='x_midpoints')(x)\n",
    "        x_midpoints_reshape = layers.Reshape((-1, self.num_classes, self.num_coordinates), name='x_midpoints_reshape')(x_midpoints)\n",
    "        \n",
    "        return tf.keras.models.Model(x_input, x_midpoints_reshape)\n",
    "\n",
    "    def compile_model(self, loss_function):\n",
    "        self.model.compile(optimizer=self.optimizer, loss=loss_function)\n",
    "\n",
    "    def train_model(self, train_dataset, val_dataset, epochs, callbacks_list):\n",
    "        history = self.model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks_list)\n",
    "        return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Main Script Execution\n",
    "# -----------------------------\n",
    "\n",
    "# Load data\n",
    "# h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KFixed_Mixed_13.h5'             \n",
    "h5_filename = '/home/da886/Final Electron counting project/Images and Labels/30KFixed-index6_13.h5'\n",
    "data_loader = DataLoader(h5_filename)\n",
    "images, centers = data_loader.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAGzCAYAAAAPLj87AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAABg9UlEQVR4nO3deXzUZP4H8M/0Lj25eheoyIIoAhapBZHDrhWEBWEFgRWsiscWF6guigoIq9RjZeuB4IHgIojiT/HGo1JgBVQqrAcLchRpwRZQaUux18zz+6Pt2GmTMk8n6SQzn/frlZeSSZ48OWa+TfLNNxYhhAAREREZlo+7O0BEREQtY7AmIiIyOAZrIiIig2OwJiIiMjgGayIiIoNjsCYiIjI4BmsiIiKDY7AmIiIyOAZrIiIig2Owpjb34IMPwmKxSE176tQpnXvlnNWrV8NiseDIkSP2ccOGDcOwYcPOOW9eXh4sFgvy8vJ06x/po2HfvfHGG7oup1u3brjxxht1XQaZE4O1Thp+1Hft2uXurpjCkiVLsHHjRs3aq6mpQadOnXD55ZerTiOEQGJiIi655BLNlqulQ4cO4bbbbsN5552HoKAghIeHY/DgwXjyySfx22+/6bbc48eP48EHH8SePXt0W0ZrNPzh5uPjg8LCwmafl5WVITg4GBaLBTNnznRDD4n0w2BNbe6BBx5oFmy0Dtb+/v647rrrsH37dvz444+K02zduhVFRUX4y1/+4tKyPv74Y3z88ccutdHU+++/jz59+uD111/HmDFj8PTTTyM7OxtdunTB3//+d8yaNUvT5TV2/PhxLFq0yHDBukFgYCBeffXVZuPffPNNN/SGqG0wWFOb8/PzQ1BQkO7LmTp1KoQQij/sALBu3Tr4+Pjg+uuvd2k5AQEBCAgIcKmNxgoKCnD99deja9eu2Lt3L5588knMmDEDmZmZePXVV7F3715ceOGFmi2vrVRUVGjSzqhRoxT36bp163DNNddosowGtbW1qK6u1rRNotZgsG5DN954I0JDQ3H06FGMHj0aoaGhiI+Px7JlywAA3377LUaMGIGQkBB07doV69atc5j/l19+wd13340+ffogNDQU4eHhGDlyJP773/82W9aPP/6IP/3pTwgJCUFUVBTmzJmDjz76SPGe6RdffIGrr74aERERaNeuHYYOHYrPP/+8xXURQqBTp07Iysqyj7PZbIiMjISvry9Onz5tH//oo4/Cz88PZ86cAdD8nrXFYkFFRQVefvllWCwWWCyWZvftTp8+jRtvvBGRkZGIiIhARkYGzp4922IfBw8ejG7dujXbjkDdZfI33ngDw4cPR1xcHL755hvceOON9kvOMTExuOmmm/Dzzz+3uAxA+Z51UVERxo0b57D9q6qqztkWADz22GM4c+YMVq5cidjY2Gafn3/++c3OrF955RUkJycjODgYHTp0wPXXX9/sUvGwYcNw0UUXYe/evRg+fDjatWuH+Ph4PPbYY/Zp8vLycOmllwIAMjIy7Ptj9erV9mmcOV4a9vHevXsxZcoUtG/f3n5Lori4GBkZGUhISEBgYCBiY2MxduxYhzyAlkyZMgV79uzBvn377OOKi4vx2WefYcqUKc2mr66uxoIFC5CcnIyIiAiEhIRgyJAh2Lx5s8N0R44cgcViwT//+U/k5OSge/fuCAwMxN69exX7UVVVhdGjRyMiIgLbt28HUPcdyMnJwYUXXoigoCBER0fjtttuw6+//uowrxACDz30EBISEtCuXTsMHz4c33//vVPrT97Jz90d8DZWqxUjR47EFVdcgcceewxr167FzJkzERISgvvvvx9Tp07F+PHjsWLFCkybNg2pqalISkoCABw+fBgbN27Eddddh6SkJJSUlOC5557D0KFDsXfvXsTFxQGoO4MZMWIEfvrpJ8yaNQsxMTFYt25dsx8nAPjss88wcuRIJCcnY+HChfDx8cGqVaswYsQIbNu2DQMHDlRcD4vFgsGDB2Pr1q32cd988w1KS0vh4+ODzz//3H6Ws23bNvTv3x+hoaGKba1Zswa33HILBg4ciFtvvRUA0L17d4dpJk6ciKSkJGRnZ+Prr7/Giy++iKioKDz66KOq29pisWDKlClYsmQJvv/+e4ez0U2bNuGXX37B1KlTAQCffPIJDh8+jIyMDMTExOD777/H888/j++//x47d+50OiEOAH777TdceeWVOHr0KP72t78hLi4Oa9aswWeffebU/O+++y7OO+88DBo0yKnpH374YcyfPx8TJ07ELbfcgpMnT+Lpp5/GFVdcgd27dyMyMtI+7a+//oqrr74a48ePx8SJE/HGG2/gnnvuQZ8+fTBy5EhccMEFWLx4MRYsWIBbb70VQ4YMAQB7X2SPl+uuuw49evTAkiVL0PA23gkTJuD777/HnXfeiW7duuHEiRP45JNPcPToUXTr1u2c63vFFVcgISEB69atw+LFiwEAr732GkJDQxXPrMvKyvDiiy9i8uTJmDFjBsrLy7Fy5Uqkp6fjyy+/RL9+/RymX7VqFSorK3HrrbciMDAQHTp0cPjjE6jbx2PHjsWuXbvw6aef2v/Aue2227B69WpkZGTgb3/7GwoKCvDMM89g9+7d+Pzzz+Hv7w8AWLBgAR566CGMGjUKo0aNwtdff42rrrqKZ/GkTpAuVq1aJQCIr776yj5u+vTpAoBYsmSJfdyvv/4qgoODhcViEevXr7eP37dvnwAgFi5caB9XWVkprFarw3IKCgpEYGCgWLx4sX3cE088IQCIjRs32sf99ttvolevXgKA2Lx5sxBCCJvNJnr06CHS09OFzWazT3v27FmRlJQk/vjHP7a4jo8//rjw9fUVZWVlQgghnnrqKdG1a1cxcOBAcc899wghhLBarSIyMlLMmTPHPt/ChQtF00MvJCRETJ8+vdkyGqa96aabHMZfe+21omPHji32Twghvv/+ewFAzJs3z2H89ddfL4KCgkRpaal9nZt69dVXBQCxdetW+7iG/VpQUGAfN3ToUDF06FD7v3NycgQA8frrr9vHVVRUiPPPP99h+yspLS0VAMTYsWPPuW5CCHHkyBHh6+srHn74YYfx3377rfDz83MYP3ToUAFA/Pvf/7aPq6qqEjExMWLChAn2cV999ZUAIFatWuXQpszx0rDfJk+e7NDGr7/+KgCIxx9/3Kn1a6yhzZMnT4q7775bnH/++fbPLr30UpGRkSGEEAKAyMzMtH9WW1srqqqqmvUjOjra4bgqKCgQAER4eLg4ceKEw/SbN28WAMSGDRtEeXm5GDp0qOjUqZPYvXu3fZpt27YJAGLt2rUO827atMlh/IkTJ0RAQIC45pprHLbjfffdJwAofg+IeBncDW655Rb7/0dGRqJnz54ICQnBxIkT7eN79uyJyMhIHD582D4uMDAQPj51u8xqteLnn39GaGgoevbsia+//to+3aZNmxAfH48//elP9nFBQUGYMWOGQz/27NmDAwcOYMqUKfj5559x6tQpnDp1ChUVFbjyyiuxdetW2Gw21fUYMmQIrFar/RLgtm3bMGTIEAwZMgTbtm0DAHz33Xc4ffq0/QyttW6//fZmy/75559RVlbW4ny9e/dG//79sX79evu4iooKvPPOOxg9ejTCw8MBAMHBwfbPKysrcerUKVx22WUA4LBtnfHBBx8gNjYWf/7zn+3j2rVrZ79q0JKG9QkLC3NqWW+++SZsNhsmTpxo33+nTp1CTEwMevTo0exqSmhoqENCXUBAAAYOHOhwnKlpzfHSdL8FBwcjICAAeXl5zS4Ny5gyZQoOHjyIr776yv5fpUvgAODr62vPKbDZbPjll19QW1uLAQMGKO7bCRMmoHPnzoptlZaW4qqrrsK+ffuQl5fncFa+YcMGRERE4I9//KPDvkhOTkZoaKh9X3z66aeorq7GnXfe6XDFZvbs2a3cGuQNeBm8jQUFBTX7IYiIiEBCQkKzS60REREOP2g2mw1PPvkknn32WRQUFMBqtdo/69ixo/3/f/zxR3Tv3r1Ze+eff77Dvw8cOAAAmD59ump/S0tL0b59e8XPLrnkErRr1w7btm1Deno6tm3bhkWLFiEmJgZPP/00Kisr7UG7pUeonNGlSxeHfzf06ddff7UHXDVTp07F3Xffje3bt2PQoEHYuHEjzp49a78EDtTlAyxatAjr16/HiRMnHOYvLS2V6uuPP/6I888/v9n279mz5znnbViX8vJyp5Z14MABCCHQo0cPxc8bLrs2UDrO2rdvj2+++capZQFyx0vDLZwGgYGBePTRR3HXXXchOjoal112GUaPHo1p06YhJibmnH1o0L9/f/Tq1Qvr1q1DZGQkYmJiMGLECNXpX375ZTzxxBPYt28fampqVPunNq7B7NmzUVlZid27dzdL8jtw4ABKS0sRFRWlOG/DcdXwdELTfda5c2fV7xoRg3Ub8/X1lRov6u/zAXWPN82fPx833XQT/vGPf6BDhw7w8fHB7NmzWzwDVtMwz+OPP97svl0DtfvMQF0gSElJwdatW3Hw4EEUFxdjyJAhiI6ORk1NDb744gts27YNvXr1Uj1TcZYz20fN5MmTMXfuXKxbtw6DBg3CunXr0L59e4waNco+zcSJE7F9+3b8/e9/R79+/RAaGgqbzYarr766Vdu2tcLDwxEXF4fvvvvOqeltNhssFgs+/PBDxW3UdP+5sh1bc7w0vmLRYPbs2RgzZgw2btyIjz76CPPnz0d2djY+++wz9O/f/5z9aDBlyhQsX74cYWFhmDRpkv2qU1OvvPIKbrzxRowbNw5///vfERUVBV9fX2RnZ+PQoUPNplfqc4OxY8di/fr1eOSRR/Dvf//bYZk2mw1RUVFYu3at4ryufgfIuzFYm0hD9vLKlSsdxp8+fRqdOnWy/7vhkR8hhMNZ1MGDBx3ma0jiCg8PR1paWqv6NGTIEDz66KP49NNP0alTJ/Tq1QsWiwUXXnghtm3bhm3btmH06NHnbEcmgUtWXFwchg8fjg0bNmD+/Pn45JNPcOONN9ovjf7666/Izc3FokWLsGDBAvt8DWeSsrp27Yrvvvuu2fbfv3+/U/OPHj0azz//PHbs2IHU1NQWp+3evTuEEEhKSsIf/vCHVvW3KbV9ocXx0ritu+66C3fddRcOHDiAfv364YknnsArr7zidBtTpkzBggUL8NNPP2HNmjWq073xxhs477zz8Oabbzqs28KFC6X7PW7cOFx11VW48cYbERYWhuXLlzus06efforBgwe3GPC7du0KoO74Ou+88+zjT5486dKtAfJsvGdtIr6+vs3OgDZs2IBjx445jEtPT8exY8fwzjvv2MdVVlbihRdecJguOTkZ3bt3xz//+U/7Y1WNnTx58px9GjJkCKqqqpCTk4PLL7/c/mM4ZMgQrFmzBsePH3fqfnVISEizjFstTZ06FSdOnMBtt92Gmpoah0vgDWebTbdtTk5Oq5Y1atQoHD9+3KE05dmzZ/H88887Nf/cuXMREhKCW265BSUlJc0+P3ToEJ588kkAwPjx4+Hr64tFixY1678QwqlHz5oKCQkBgGb7Q4vj5ezZs6isrHQY1717d4SFhTn9aFvj+XJycpCdna361AKgvH+/+OIL7NixQ2p5DaZNm4annnoKK1aswD333GMfP3HiRFitVvzjH/9oNk9tba19e6alpcHf3x9PP/20Q59ae7yRd+CZtYmMHj0aixcvRkZGBgYNGoRvv/0Wa9eudfjrHKh7fOSZZ57B5MmTMWvWLMTGxmLt2rX2QiQNAdXHxwcvvvgiRo4ciQsvvBAZGRmIj4/HsWPHsHnzZoSHh+Pdd99tsU+pqanw8/PD/v37HRKorrjiCvtZhzPBOjk5GZ9++imWLl2KuLg4JCUlISUlRWr7tGTChAn461//irfffhuJiYm44oor7J+Fh4fbH6WrqalBfHw8Pv74YxQUFLRqWTNmzMAzzzyDadOmIT8/H7GxsVizZg3atWvn1Pzdu3fHunXrMGnSJFxwwQWYNm0aLrroIlRXV2P79u3YsGGD/Tn07t2746GHHsK8efNw5MgRjBs3DmFhYSgoKMBbb72FW2+9FXfffbdU/7t3747IyEisWLECYWFhCAkJQUpKCpKSklw+Xn744QdceeWVmDhxInr37g0/Pz+89dZbKCkpaVVxGmcquY0ePRpvvvkmrr32WlxzzTUoKCjAihUr0Lt3b8U/Opwxc+ZMlJWV4f7770dERATuu+8+DB06FLfddhuys7OxZ88eXHXVVfD398eBAwewYcMGPPnkk/jzn/+Mzp074+6770Z2djZGjx6NUaNGYffu3fjwww8drpAROXBLDroXUHt0KyQkpNm0Q4cOFRdeeGGz8V27dhXXXHON/d+VlZXirrvuErGxsSI4OFgMHjxY7Nixo9mjQ0IIcfjwYXHNNdeI4OBg0blzZ3HXXXeJ//u//xMAxM6dOx2m3b17txg/frzo2LGjCAwMFF27dhUTJ04Uubm5Tq3rpZdeKgCIL774wj6uqKhIABCJiYnNpld6dGvfvn3iiiuuEMHBwQ6PrzR+XKcxpUeozuW6664TAMTcuXObfVZUVCSuvfZaERkZKSIiIsR1110njh8/3uzxOWce3RJCiB9//FH86U9/Eu3atROdOnUSs2bNsj/C09KjW4398MMPYsaMGaJbt24iICBAhIWFicGDB4unn35aVFZWOkz7f//3f+Lyyy8XISEhIiQkRPTq1UtkZmaK/fv3O/RT6TibPn266Nq1q8O4t99+W/Tu3Vv4+fk1e4zLmeNFbb+dOnVKZGZmil69eomQkBAREREhUlJSHB5zU6PWZlNo8uiWzWYTS5YsEV27dhWBgYGif//+4r333mu23g2Pbik9Vtb40a3G5s6dKwCIZ555xj7u+eefF8nJySI4OFiEhYWJPn36iLlz54rjx4/bp7FarWLRokX27/KwYcPEd999J7p27cpHt0iRRQgnMkvII+Tk5GDOnDkoKipCfHy8u7tDREROYrD2UL/99luzZ4f79+8Pq9WKH374wY09IyIiWbxn7aHGjx+PLl26oF+/figtLcUrr7yCffv2qT5WQkRExsVg7aHS09Px4osvYu3atbBarejduzfWr1+PSZMmubtrREQkiY9ueajZs2fju+++w5kzZ/Dbb78hPz+fgZqISANbt27FmDFjEBcXB4vFgo0bN55znry8PFxyySUIDAzE+eef7/AmO2cwWBMREUmoqKhA37597a83PpeCggJcc801GD58OPbs2YPZs2fjlltuwUcffeT0MplgRkRE1EoWiwVvvfUWxo0bpzrNPffcg/fff9+hjPD111+P06dPY9OmTU4tR7d71suWLcPjjz+O4uJi9O3bF08//XSLVYYa2Gw2HD9+HGFhYbqWoCQiIn0IIVBeXo64uDjVmu1aqKys1OQd4KJJaWCg7qUzgYGBLrcNADt27GhWojc9PV3qTWu6BOvXXnsNWVlZWLFiBVJSUpCTk4P09HTs379f9Y00DY4fP47ExEQ9ukVERG2osLAQCQkJurRdWVmJpK6hKD5hPffE5xAaGtqsmt3ChQvx4IMPutw2ABQXFyM6OtphXHR0NMrKypo9ZqtGl2C9dOlSzJgxAxkZGQCAFStW4P3338dLL72Ee++9t8V5nX2Pb2upna3reTdA7S/Ltnybk1nIXk2R2W9qb5xq/KrRxrjf2pY7vptGInt8ynDXttXz97y6uhrFJ6woyO+K8LDWn72XlduQlPwjCgsLHV63q9VZtVY0D9bV1dXIz8/HvHnz7ON8fHyQlpamWDi/qqrKoYC/s+/xbS09g4HsMvX8Apn1h0/P/SPbtllvw3j7vldqR2ZavZepRs/jTfaY0GJ9WlqulsLDfFwK1vZ2wsMdgrWWYmJimr2Up6SkBOHh4U6dVQM6ZIOfOnUKVqtV8ZS/uLi42fTZ2dmIiIiwD7wETkREzrIKm8uD3lJTU5Gbm+sw7pNPPjnnK3Abc/ujW/PmzUNpaal9KCwsdHeXiIjIJGwQLg+yzpw5gz179mDPnj0A6h7N2rNnD44ePQqgLq5NmzbNPv3tt9+Ow4cPY+7cudi3bx+effZZvP7665gzZ47Ty9T8MninTp3g6+ureMofExPTbHotMu6U7vWoXbLR4n6j7L0ltfF+fsqbX6nvam1ocZ/LSPdytbofrHT5rba2VqoNmW2uxX3Flihtc7VtJbt/lLaV7H7Q4jKrVvtei8v9sm1osUzZ41NPSuuj5z11V9hggytHTmvm3rVrF4YPH27/d1ZWFgBg+vTpWL16NX766Sd74AaApKQkvP/++5gzZw6efPJJJCQk4MUXX0R6errTy9Q8WAcEBCA5ORm5ubn2585sNhtyc3Mxc+ZMrRdHRETUpoYNG9biH2hK1cmGDRuG3bt3t3qZumSDZ2VlYfr06RgwYAAGDhyInJwcVFRU2LPDiYiItGAVAlYXrmy4Mm9b0iVYT5o0CSdPnsSCBQtQXFyMfv36YdOmTc2SzoiIiFzR2vvOjec3A90qmM2cOZOXvYmIiDTAV2QSEZFp2SBg5Zm1sahlucpkI/r7+yuOr6mpaVWfGpPNwtUi+1OLTEzZNoxUwcsdhWWUtpfehUiUtrlM/1pi1ipwWrSt1f7RqoiIXrTY3jL7WAjRZuvvLZfB3f6cNREREbXMVGfWREREjTEbnIiIyOBs9YMr85sBL4MTEREZnKnOrGWSJNSSb9QSydRKfyolgckm8Ki1rdaOUmKGFiUk1dpW445XRMr2W4v10aJt2bc6ySbfyJQ41bMspFbLlHkbk56JSlptKy3e/qb3MeQqmd/ItmR1MRvclXnbkqmCNRERUWNWUTe4Mr8ZMFgTEZFp8Z41ERERGQLPrImIyLRssMAK53MglOY3AwZrIiIyLZuoG1yZ3ww8NlirZUrKZjQqZRCrlSytqqqSaluNUvanbAa2FpmiasvUM0tcz/KPalm1ema3a7U+MtnJWmR9q9Gi5K9WbetZQlNPaseEFk986Jkh7u6sb2/nscGaiIg8n9XFy+CuzNuWGKyJiMi0vCVYMxuciIjI4HhmTUREpmUTFtiEC9ngLszblhisiYjItLzlMrhHBGuZzF/ZjEalTEy1rG/Z2tN6ZifrWR/aHbXB1aitpxY13d1Rv1ptfZS2udoyZfe90nGrto9l971MXWt3ZGbL0vNJCD2f+DBKfXFqPY8I1kRE5J2s8IHVhfQr4/+JWIfBmoiITEu4eM9a8J41ERGRvrzlnjUf3SIiIjI4nlkTEZFpWYUPrMKFe9YmybHziGCtlNEom+UoWzNciVo2p56Z2bJ9kcn81ZNaffWamhqpdmT2j2xGrBaZsrLZ7VocE7JtKO1/rbKH9cw2dkeGs8x3XG0/eFpmttJvihCizdbHBgtsLlwktsEc252XwYmIiAzOI86siYjIO3lLghmDNRERmZbr96x5GZyIiIg0YOgz66aJGO5IHFEiW3LQSC+4VyK7PlokzMkmkqmRSdbR8/hR2yZqy1TbtmZNPtKi1K6e5Tb1pud33B0Jqkr7R+Z3oi33TV2CmQsv8uBlcCIiIn3ZXCw3ymxwIiIi0gTPrImIyLS8JcGMwZqIiEzLBh+vKIrCYE1ERKZlFRZYXXhzlivztiVDB+umGYVaZMpqUeZSq/KcMusjmxEqM71s5qZsFqpSKVeZMqGAvlnSstnwSmRLS6rRcz21yJxXa0PPTG7ZbajUtlobWq2PDNl96Y4Sp0rjtTrGqXUMHayJiIhaYnUxG9zKy+BERET6sgkf2FxIMLOZJMGMj24REREZHM+siYjItHgZnDxaOIAwAMcUPosHUA6grE17REQkzwbXMrr1SyXUlqGDtSu1wdUyfNWyvmWyp7XK8JWpD61VHeABAwYgpLYWTx04gA61tbi9Z0/83K6d/fOoqios27sXv/r74/IzZzQJ2Er7TSlDHFDPEtczS1rPOt1qx5XaemqRheyOzHk961TL9lvm+ym7vd1Ru12tbaVtrva9MtL+odbhPWsvFGKzoUNtLRKqqrBi/35EVVUB+D1QJ1RVoX1NDcLc3E8ionNpKIriymAG5uglaepEQABu79kTRYGBSKgP0H3Ky+2BuigwEJm9eyteIiciMpKGcqOuDGZgjl6S5kqaBOznv//eIVCfCAx0dxeJiKgeg7UXKwkIwMKkJIdxi88/n4GaiEyj4X3WrgxmIB2st27dijFjxiAuLg4WiwUbN250+FwIgQULFiA2NhbBwcFIS0vDgQMHtOovaSi6uhqLCgocxi04eNB+D5uIyOi85TK4dDZ4RUUF+vbti5tuugnjx49v9vljjz2Gp556Ci+//DKSkpIwf/58pKenY+/evQgKCpJalitZhmpZnmq1wdWyc5WyX/WsGwxoUzdZrY9ff/01ACBBCKwXAgkADgG4AcAaAN2rqrB0924Mk+pxy5T6oraOWtRuB5S3i+zxpDa90jGhth9ks9vVsnmV1t9INZm1yJKWrd+tRqbWuSyZmunuyJKWrbmvBaXvgxCizdbf9eesPTRYjxw5EiNHjlT8TAiBnJwcPPDAAxg7diwA4N///jeio6OxceNGXH/99a71ljQRLwQ+EwLdUReohwEoqv9vHoDu9f8dCuXnsImIqG1p+idFQUEBiouLkZaWZh8XERGBlJQU7NixQ3GeqqoqlJWVOQykr3IAJ1AXqEdYLCiqH98QsA/Vf17ult4RETnPJiwuD2agaVGU4uJiAEB0dLTD+OjoaPtnTWVnZ2PRokVadoPOocxiwSjUVzCzWIBGl6uKUHdGzQpmRGQGNhcvg/M5ayfNmzcPpaWl9qGwsNDdXfIKZRZLXaBWcAwM1ERERqLpmXVMTAwAoKSkBLGxsfbxJSUl6Nevn+I8gYGBCOSjQkRE1AquvyLT7eesTtE0WCclJSEmJga5ubn24FxWVoYvvvgCd9xxh1RbFovF6drgMlmHsm1okdGoRRtqNabVsr5l1kc2k1e2LzLZ02pZ37K1xLXY5rKZ9lq0LZOBLlvTXIZaG7I1ptWOFZn9I3NcybatVa1vLd5boEWdcq0ysJXa1vP74AorLLC68Ky0K/O2JelgfebMGRw8eND+74KCAuzZswcdOnRAly5dMHv2bDz00EPo0aOH/dGtuLg4jBs3Tst+ExEReQ3pYL1r1y4MHz7c/u+srCwAwPTp07F69WrMnTsXFRUVuPXWW3H69Glcfvnl2LRpk/Qz1kREROfCy+Aqhg0b1uKlFovFgsWLF2Px4sUudYyIiOhcrHDtUrZ+Lw/Vljn+pCAiIvJimiaYaUmmXF1bJ1rItq2WZKNGKYlHNrFHJnFGLeFFbZmyfVGaXm2ZavRMYpFNMtIzgcsd5SL1JHusyJA5JrRK6tKCFolkenNHqdTW4mVwIiIig3P1ZRxmeZGHOXpJRESkQLj4ekzRyvvdy5YtQ7du3RAUFISUlBR8+eWXLU6fk5ODnj17Ijg4GImJiZgzZw4qKyudXh6DNRERkYTXXnsNWVlZWLhwIb7++mv07dsX6enpOHHihOL069atw7333ouFCxfif//7H1auXInXXnsN9913n9PLZLAmIiLTcsf7rJcuXYoZM2YgIyMDvXv3xooVK9CuXTu89NJLitNv374dgwcPxpQpU9CtWzdcddVVmDx58jnPxhtjsCYiItPS6q1bTd/+WFVVpbi86upq5OfnO7xd0sfHB2lpaapvlxw0aBDy8/Ptwfnw4cP44IMPMGrUKKfX0+sSzGQzMfUsN6pnNqtMhrOeGbuAcja82jKNWtKwMS1KS6qtvxYlNLWgRTnUlqZXGq/21IQWx6c7Mqq1KmUqewxp0Rc9n7AxqsTERId/L1y4EA8++GCz6U6dOgWr1ar4dsl9+/Yptj1lyhScOnUKl19+OYQQqK2txe233y51GdzrgjUREXkOq4uvyGyYt7CwEOHh4fbxWr5gKi8vD0uWLMGzzz6LlJQUHDx4ELNmzcI//vEPzJ8/36k2GKyJiMi0Gl/Kbu38ABAeHu4QrNV06tQJvr6+KCkpcRhfUlJif/NkU/Pnz8cNN9yAW265BQDQp08fe1nu+++/36m6E7xnTURE5KSAgAAkJycjNzfXPs5msyE3NxepqamK85w9e7ZZQG647ePs7QWeWRMRkWnZ4AObC+edrZk3KysL06dPx4ABAzBw4EDk5OSgoqICGRkZAIBp06YhPj4e2dnZAIAxY8Zg6dKl6N+/v/0y+Pz58zFmzBinK1wyWBMRkWlZhQVWFy6Dt2beSZMm4eTJk1iwYAGKi4vRr18/bNq0yZ50dvToUYcz6QceeAAWiwUPPPAAjh07hs6dO2PMmDF4+OGHnV6mRRgsxa+srAwRERGKn+mZLWpWalmeMuNlM7PVaJElLdu2FoevVlm7bb1MtTa0yB52B9ljWY0WTw7oWUtc9nfMSHXNlbSUOV5aWurUfeDWaIgVd2wbj8BQ/1a3U3WmBsuHvKlrX7XAM2siIjItrRLMjI7BmoiITEu4+NYtYZIXeTBYExGRaVlhgbWVL+NomN8MzPEnBRERkRfjmTUREZmWTbh239lmqBRrdaYK1m1dC1e2bdmsVZksbNlsaD1rmmtRv1otk1W2bS0yZd3xQITscag0vZ5Z32oZy2rbVXZ9ZL4r7tg/emZay+4foz/x4O4Himwu3rN2Zd62ZI5eEhEReTFTnVkTERE1ZoMFNheSxFyZty0xWBMRkWm5o4KZO/AyOBERkcF57Jm1bGKLTEKJWhtalXPUomynWht+fs13eU1NjdPLA+STw2S2rZ5tq5Et/yiTACjbb5l29CwfqvexrGdSkkwpW636p3QM6b0NtUhE9QTekmDmscGaiIg8nw0ulhs1yT1rc/xJQURE5MV4Zk1ERKYlXMwGFyY5s2awJiIi0+Jbt4iIiAyOCWYGJJO1K5uxLZO1q1UpQn9/5RemK2VuymYPq42vra11snfytNguemZ9q9Ezq1qt37LlH7VYf5ll6vk0hVb07Ita22q/QTLfK7XvvVq/9Swfq0Zpme74btLvTBWsiYiIGuNlcCIiIoPzlnKj5rhYT0RE5MV4Zk1ERKbFy+BEREQGx2DtZhaLpVlGpkxWpNq0snWglTIgtcp+lKnJrdXL42WmV6ojDqhnvsr0UTY7VU+y21aLOt0ytdsBbZ5KkNn3ahnLembOy9Iiu90dT1OotaFn/W7ZpwzUthe5j2GDNRER0bnwzJqIiMjgvCVYMxuciIjI4HhmTUREpiXg2rPSZnnTN4M1ERGZlrdcBjdssBZCOJ0dKZOxLZtxqUXmt54Z6GpZu2qZ5gEBAc3GVVdXK04rm/kqs221yipWq1esNF6rLFylfSGbbaw2vVoftciel6ntrHZMqJFdf6X1kc3MNlJNaj1/g7Sg55MD7uYtwZr3rImIiAzOsGfWRERE5+ItZ9YM1kREZFreEqx5GZyIiMjgpIJ1dnY2Lr30UoSFhSEqKgrjxo3D/v37HaaprKxEZmYmOnbsiNDQUEyYMAElJSWadpqIiAgAhLC4PJiB1GXwLVu2IDMzE5deeilqa2tx33334aqrrsLevXsREhICAJgzZw7ef/99bNiwAREREZg5cybGjx+Pzz//XJcVAJQzHdUyX2WzHGVq5GqVtSozvVqWsFo2uNJ4mSxho1Hro559lzmGZJ8EUKNF9rxRtgmg3BetMpCVjme9s5vd8V3Roka9TNtG/T3wlvdZSwXrTZs2Ofx79erViIqKQn5+Pq644gqUlpZi5cqVWLduHUaMGAEAWLVqFS644ALs3LkTl112mXY9JyIi8hIu3bMuLS0FAHTo0AEAkJ+fj5qaGqSlpdmn6dWrF7p06YIdO3YotlFVVYWysjKHgYiIyBkNCWauDGbQ6mBts9kwe/ZsDB48GBdddBEAoLi4GAEBAYiMjHSYNjo6GsXFxYrtZGdnIyIiwj4kJia2tktERORlvOWedauDdWZmJr777jusX7/epQ7MmzcPpaWl9qGwsNCl9oiIGgsXAvEq96zjAYS3bXeIWqVVz1nPnDkT7733HrZu3YqEhAT7+JiYGFRXV+P06dMOZ9clJSWIiYlRbCswMBCBgYFOLVcm2Uv2pepavMhejZ7JLWqJZGqU+mKm0oJNyZZbVSJ7TMgk2miV8KPUF9nEQHfsZy2SF135zoYLgQ8ARAG40mJBUaN5EoRArhA4AWAkgLJGn7ljW8mWbNUz4UuLkrpthc9ZKxBCYObMmXjrrbfw2WefISkpyeHz5ORk+Pv7Izc31z5u//79OHr0KFJTU7XpMRGRk8JQF6i7A8i12ZBQH1gShECuzYbu9Z+Hua+L5CJvuQwudWadmZmJdevW4e2330ZYWJj9PnRERASCg4MRERGBm2++GVlZWejQoQPCw8Nx5513IjU1lZngRNTmjlksGC4ENuP3gH2jjw9W1wfqQwCG109H5iRcPLP2yGC9fPlyAMCwYcMcxq9atQo33ngjAOBf//oXfHx8MGHCBFRVVSE9PR3PPvusJp0lIpJVZLHgSovFfia9rf4Sb0OgLmKgJhOQCtbO3JsICgrCsmXLsGzZslZ3iohIS0UWC2708bEHagC40ccHRSbO16A6AoAru9EsRwBrgxORx0sQAqubJE2tbnQPm8yroYKZK4MZmOqtW1pkHWqRnarWD61KSyplXaotU7ZtP7/mu7y2tlaqDXdQ229qWd9K21A2u1vmeJM9rmQza5XGy+57LY592WNcbX20KOPr7PQJAHKFsN+jvgHAGtTdw94MYLgQhrgU7up6tobMcSjzuyeEMGx5UrPimTUReax4AHmAPVAPA7Cj/r+H8HvAVnsOm4yP2eBERCZXDuBE/f8PA1BU//9F9f/Oq/+8vI37RdqxCQssXvCcNYM1EXmsMgBXo+456mNNPmsI2OVwLIhCZEQM1kTk0crqByV8vtr8hHAxG9wkd0AYrImIyLRcve/Me9ZtSOZF6Wrj1bJcZTKltcj6lp1WNiNUi5rMssvUM/NXi3rxWpA9rrSqGa5Ez3rcsv3Ws260WttKTzzI/h7IknnKwh3HhBot9o/SNnR3vXBP5BHBmoiIvBPPrImIiAyO2eBEREQG5y0JZiyKQkREZHA8syYiItOqO7N25Z61hp3RkamCtUxtZ7Vp1cbLZG7qXZNZKbNUpmZ0S21rUQM9ICBAcXx1dbXLbatxR51hLbLhtaoNLsMdbciuj8wTHLKU2tH7+NHzqRE1ar8rSvQ8Dt2d+e0tCWa8DE5ERGRwpjqzJiIiakzAtXdSm+QqOIM1ERGZFy+DExERkSHwzJqIiMzLS66DmypYa5GhKJu5KJO5qUVNZkA5s1QpQ7yltrXI8pTNnJdpx90ZpM7QIpNZpo2Wplciu4/Vpv/LX/7SbNwrr7wi1bYspe2l1fdH5ukQMxyHMk/ByLZhhvU/Jxcvg6OV8y5btgyPP/44iouL0bdvXzz99NMYOHCg6vSnT5/G/fffjzfffBO//PILunbtipycHIwaNcqp5ZkqWBMRETXmjgpmr732GrKysrBixQqkpKQgJycH6enp2L9/P6KioppNX11djT/+8Y+IiorCG2+8gfj4ePz444+IjIx0epkM1kRERBKWLl2KGTNmICMjAwCwYsUKvP/++3jppZdw7733Npv+pZdewi+//ILt27fD398fANCtWzepZTLBjIiITKshG9yVAQDKysochqqqKsXlVVdXIz8/H2lpafZxPj4+SEtLw44dOxTneeedd5CamorMzExER0fjoosuwpIlS+Rus0psEyIiImMRFtcHAImJiYiIiLAP2dnZios7deoUrFYroqOjHcZHR0ejuLhYcZ7Dhw/jjTfegNVqxQcffID58+fjiSeewEMPPeT0avIyeD0tXgivZ7KGbFKXGi2So2S5o1SoUkKeVttQi+0iu020SNLr2bOn4vjRo0c3G7dmzRrFabVKAtOrDUA9mUqJ7PfeHYla7igfq2c5WKMqLCxEeHi4/d+BgYGatW2z2RAVFYXnn38evr6+SE5OxrFjx/D4449j4cKFTrXBYE1ERKalVYJZeHi4Q7BW06lTJ/j6+qKkpMRhfElJCWJiYhTniY2Nhb+/v8MfhxdccAGKi4tRXV2t+r6FxngZnIiIzEtoMEgICAhAcnIycnNz7eNsNhtyc3ORmpqqOM/gwYNx8OBBh6sTP/zwA2JjY50K1ACDNRERkZSsrCy88MILePnll/G///0Pd9xxByoqKuzZ4dOmTcO8efPs099xxx345ZdfMGvWLPzwww94//33sWTJEmRmZjq9TF4GJ/ISoVYrQmw2lNQ/OtJY8M8/ozY4GDXt2rmhZ0St547a4JMmTcLJkyexYMECFBcXo1+/fti0aZM96ezo0aMO9/0TExPx0UcfYc6cObj44osRHx+PWbNm4Z577nF6mQzWRF4gHMALhYXoYLViepcuKG4UsINPncLwxYtRGR6Obffdx4BN5uOGQmwzZ87EzJkzFT/Ly8trNi41NRU7d+5s9fI8NlirZa2qZXPKZH3rnUGqZ3lOLTI6b731VsXxzz33nNNtyGYVy25Dmf0pS8/MX7X1dPWYCAPQu1MnBBQV4aOqKhSsWIGamBj4FxfjvJtvhn9JCQIDAzHwggtgjY1VbUfPjG3ZfSwzXq1cr+xxYqTynHr+Tih9P2Wy7IUQHp893tZ4z5qkhAOIPHNG8bP4+s/JeI4BKFi1CtVxcQgoKkJSRgaC9+xBUkYG/I8eRU2XLvj56adhCwlxd1eJpGhVFMXoGKzJaeEANgG469130b5JwG5/5gy21H/OgG1M1pAQWMPDIXx9EVBUhO433ICAoqK6QP3UU+h4552ImjYNlrIyd3eVyHltnA3uLgzW5LQwAFEAOpeVIatRwG5/5gyy3n0X3es/D3NjH0mdT0UFfM+cgaXJpd/T99+Pjn/7G/yPHoXPzz/Dp6LCTT0kag2LBoPxMViT044BGAbgZHi4PWCfV1yMrHffReeyMhyq//yYOztJqmpjYlD46KMQTXIuOmVm2i+Fn3jttRbvWRORezBYk5QiAEvHjLEH7Llvv43OZWU4GR6OYfWfkzH5Fxcj8Z57YLFaHQK2pbYWws8PPz/1FKxxcW7sIVEreMllcFNlg8tki+qZiah3BqlMNqtW9a6VqGW9f19Whsf79MFjn39uH/d4nz4oavTvc1HbP1rUaAe0yYrVog60VhnOMpm4SuIB9LztNqCoCDjvPFj++U9g/Pjf26+tRcW4cRiKuisjatn6amS/b0rrqWcms1bfE3fUBncHqbdBSR4rmnM14Jpk15kqWJMxdPrtN8zZvdth3Jzdu/EqeGZtVOUAEBVV949164ApUxw+rwFwumE6IjIcXgYnKQlC4OHt2xF79ix+atcOcwcPxk/t2iH27FnkAUhwdwdJURkAbNoEvPpqXaA+fBg47zzg889xCIA/gA5gJj+ZkEavyDQ6BmtyWrwQyLXZ7IH6/kGDsK9DB9w/aBB+atcO3QHkoe6SKxlQeTkwefLvgTovDxg0CMMAHAKQBO4/Mp+Gt265MpgBgzU5rRzAScAeqE8FBwMATgUH4/5Bg3AIwAnwUqphhYXVXQpvCNSJiQDqbl0MAwy5/8Kh/scDi/CQN+E9a3JamcWCUT4+GDtoEH6uD9QNTgUHYyjqfuhZUsOgIiLqLoWXlwMJjjcsigCH/WeEv+IbivBEAc2eNEhA3VWAEwCuBo85r8YEM/drmnmplnHpr/AWoZqaGpeWda5l6kktI1qJbM1jmfVRyvA9DWD1p5863YYa2axv2VriWtAi61ut37LZ7UrrKZshfq7pGz8fL1ujXQtN2w4XAlGA/fbKMNQF7IZA3b1+ugiLBWcazau032T7baTsbj1/m2TaVjuW9czsd4qr9515z5qIqPWOWSwYjrrL8w0BOxW/B+pDAEZYLDim4x8QREZh6DNrIvJuRRYLhglhD9Db68c3BOoiBmqvZxF1gyvzmwHPrInI0IoA3NBk3A0AAzXV8ZIKZgzWRGRoCQDWNBm3BnXP/BPxOWsFy5cvx8UXX4zw8HCEh4cjNTUVH374of3zyspKZGZmomPHjggNDcWECRNQUlLS6s4JIRwGNTU1Nc0GWRaLRXFo6zaAuuSjpkPTbdEwKE3b0vQyZNuQWX+1fqux2WyKg57U1kdpkN0/WlBbphb7XpaPj4/iIEOpz/GNLoEfAjAYv9/D/kwIxYAt0w+ttpWr6w6oH28yfZT9DVJrW6YfSt9LIyXoeQqpIyohIQGPPPII8vPzsWvXLowYMQJjx47F999/DwCYM2cO3n33XWzYsAFbtmzB8ePHMb5R/WEiImfFwzGZbDiAHU2Szj6rD+jkxbzkMrhUgtmYMWMc/v3www9j+fLl2LlzJxISErBy5UqsW7cOI0aMAACsWrUKF1xwAXbu3InLLrtMu14TkccrR91z1EBdoG64R11ksWC4ENgM4xVxITfgc9Yts1qt2LBhAyoqKpCamor8/HzU1NQgLS3NPk2vXr3QpUsX7NixQzVYV1VVoaqqyv7vsjKWNyDPEA4gDMrv944HC8icSxnqCp6EA80ezyqqP8MuR12xHiJPJ31j5dtvv0VoaCgCAwNx++2346233kLv3r1RXFyMgIAAREZGOkwfHR2N4uJi1fays7MRERFhHxLrSyASmVlD9a0taP5yk4T68ZvAcpnnUobmgbrBMYuFgZq85jK4dLDu2bMn9uzZgy+++AJ33HEHpk+fjr1797a6A/PmzUNpaal9KCwsbHVbREYRBjhU32oI2I2rb0XVT0dELvCSbHDpy+ABAQE4//zzAQDJycn46quv8OSTT2LSpEmorq7G6dOnHc6uS0pKEBMTo9peYGAgAgMDm4339fVtlsWoRQlNtSxNmXKWsqUvZcr0AcolANXWXS3TU4sShbJtyKyPWttabUNXp21pemcy/I+hrjxmHn4P2Deg7pGjhoSpYWh+iVyLko6tyURuSm0/yO57GQEBAYrjq6urXV6mVmV5ZZYpW1JXi22oVRa2q+VGSXsuf6ttNhuqqqqQnJwMf39/5Obm2j/bv38/jh49itTUVFcXQ2Q6jd9m1VB9q3GgLlKbkYic1lDBzJXBDKTOrOfNm4eRI0eiS5cuKC8vx7p165CXl4ePPvoIERERuPnmm5GVlYUOHTogPDwcd955J1JTU5kJTl6rofrW9kbjbgADNZFmmA3e3IkTJzBt2jT89NNPiIiIwMUXX4yPPvoIf/zjHwEA//rXv+Dj44MJEyagqqoK6enpePbZZ3XpOJEZqFXfGgYGbCJynlSwXrlyZYufBwUFYdmyZVi2bJlLnSLyBI2TyQ7B8Z51Hhiwich5rA1OpIOm1beGAdgBx3vYefXTEVHrWeDiPWt3r4CTDPuKTKWMSS1efK+W5SpTZ1q2H7I1rGXal83ElMkU1qptLbat3nXAZTiTKVshBE7UTzccdc8EW1CX/d1S9S0t1tMd20o2U1hpvFrWt9oxoZZtXVtb69S41lDLKteqfVfJ/jbJPFEg86RGW9Sj/31hLj5+5amPbhHRuZVZLBgFIFQIxepbQ4VgBTMichqDNZFOyiwWlKp8plSClIhagdngREREBuclwZoJZm4SDvXkonghEM6qQEREVI/B2g3O9ZKHzULgAwZsIqJzYgUzN/Px8XG6NrielLIrXc22bfqShzRfXxRZLEgQAp9areheP12IEDitccB2R6aw0jbUO1NULUNViWyNbaVtqPd21SKLX60NLb5XauuvxRMcauvjjgxsmWW64/dKq++VzPHs9ic1eBmc9NLwkoeG520/tVqR2ihQq73kgYiIvJNhz6w9XRHqzqgbAvTW+r/C+ZIHIiIJPLMmvRVZLMhoUtghw9eXgZqIyEnecs+awdqNEoTAqib3tVZZrc2SzoiIyLsxWLtJAuBwj/oKX1+HmtEM2ERETmgoN+rKYAKGvWetlGGollmqlAEpM21rpneF0kseiqxWDGs0Pg/AULQ+yUyLOt1q1Goyy2S/ymQ3A/L99oYa27LHslGepgCU+67FcWUken4HZRmpL5rzknvWhg3WnqwcdS9xAByTyYrq/50H5Zc8EBGRI1fvO5vlnjWDtRuUAbgadc9bNz1zLkLdGTVf8kBERA0YrN2kDOrBmM9XExE5iZfBiYiIDM7Vx68YrLUnk1CjNq2nJbGoUUscUVp/tXVXSw7Ss7SkVgkvWpQ41TPpUHbbakGLY192m8isj1bJnDLHuCyZ9Zf9nuhZgle2bS3K9ZK2TBWsiYiIHPAyOBERkcF5SbBmURQiIiKD45k1ERGZlrc8Z80zayIiIoPzujNr2TKXnpYlLrM+almesqULtchA1yKbVXaZatnTtbW1TrfhjkxZ2cxsmSx+2WNCjVJfZDPhtSirqmfZW62ePJE5trQqKypT7pnahtcFayIi8iBekmDGYE1ERKblLfesGayJiMjcTBJwXcEEMyIiIoPjmTUREZkX71mbhxZ1oLXI+tYq+1OpHdkMXz8/5V2rlMksS22ZapmoSusvmz0tu22Vxsu2IbOtZI83mTr3su37+/srjldbTy3qkWuRma0n2e2qRRa/Vusu0xet6pErfZdl6tm35VMQ3nLPmpfBiYiIDM4jzqyJiMhL8TI4ERGRsfEyOBERERkCgzUREZmX0GBohWXLlqFbt24ICgpCSkoKvvzyS6fmW79+PSwWC8aNGye1PFNdBpet46ukpqZGg54ok609LdOOWht6Zn3LkslElc2G1iKzVrYNmeNNNqNaqycHlKgd43rWdtai3rVsBrFMhrNsTXN31HTXk+z6yBzPbq8Z7oZ71q+99hqysrKwYsUKpKSkICcnB+np6di/fz+ioqJU5zty5AjuvvtuDBkyRHqZPLMmIiKvV1ZW5jBUVVWpTrt06VLMmDEDGRkZ6N27N1asWIF27drhpZdeUp3HarVi6tSpWLRoEc477zzp/jFYExGRaTUkmLkyAEBiYiIiIiLsQ3Z2tuLyqqurkZ+fj7S0NPs4Hx8fpKWlYceOHar9XLx4MaKionDzzTe3aj1NdRmciIjIgUaXwQsLCxEeHm4fHRgYqDj5qVOnYLVaER0d7TA+Ojoa+/btU5znP//5D1auXIk9e/a0upsM1gYXDiAMwHGFz+KFwFkhUObue0ZERO6iUbAODw93CNZaKS8vxw033IAXXngBnTp1anU7pgrWWiQ9yCZaKCWgyCYTyfblgQceAAAEVlZi2quvIrSiAn7/+Q9EQsLvbRYVIWT0aHx55AiuBlAm1aO2pbSeaok9sttWq3b0akONOxKy9Eyackc5TzUy31mtktqUlqlVuVEtkhG1+D3U6jfV7Dp16gRfX1+UlJQ4jC8pKUFMTEyz6Q8dOoQjR45gzJgx9nENx6Ofnx/279+P7t27n3O5vGdtYIHV1QitqECH06cRMno0LEVFAH4P1L5HjiAKdWfeRETeSKt71s4KCAhAcnIycnNz7eNsNhtyc3ORmprabPpevXrh22+/xZ49e+zDn/70JwwfPhx79uxBYmKiU8s11Zm1tykLD8fKG27AzWvWoMORIwgZPRq/Pfccgm+7Db5HjsDarRuGHTmCY+7uKBGRu7jh0a2srCxMnz4dAwYMwMCBA5GTk4OKigpkZGQAAKZNm4b4+HhkZ2cjKCgIF110kcP8kZGRANBsfEsYrA2uLCICK2+4AVnvvgvfI0cQmp4OALB264aK995DkcTOJiIi102aNAknT57EggULUFxcjH79+mHTpk32pLOjR49qUhekMQZrEyiLiMBvzz1nD9QA8NtzzzncwyYi8kbuqg0+c+ZMzJw5U/GzvLy8FuddvXq19PJ4z9oEwktLEXzbbQ7jgm+7zX4Pm4jIa7mp3Ghbc+nM+pFHHsG8efMwa9Ys5OTkAAAqKytx1113Yf369aiqqkJ6ejqeffbZZs+k6U2rzEV3ZBU/9NBD9v9PAJAHwBfAIQA3AFgDoPuRIzh50UXoYrGgSOLRLT0znLWgtt88LRNVdj3b+kkI2RKSam3rWVZVi9K0Wh0/SvtHq2NWi22lxXrKZMILIQz/W2M2rT6z/uqrr/Dcc8/h4osvdhg/Z84cvPvuu9iwYQO2bNmC48ePY/z48S531BvFoy5Qd0ddoB4GYEf9fw/Vj/9MCMSbNGAREbnMS86sWxWsz5w5g6lTp+KFF15A+/bt7eNLS0uxcuVKLF26FCNGjEBycjJWrVqF7du3Y+fOnZp12luUAziB3wN1w0XvIvwesE/UT0dE5I0sGgxm0KpgnZmZiWuuucahNioA5Ofno6amxmF8r1690KVLF9WaqVVVVc0KqFOdMgBXAxiK3wN1g6L68aMsFlYwIyLycNL3rNevX4+vv/4aX331VbPPiouLERAQYH+GrEF0dDSKi4sV28vOzsaiRYtku+E1yqBenewYAB8GaiLyZm54ztodpM6sCwsLMWvWLKxduxZBQUGadGDevHkoLS21D4WFhZq0S0REnq+tK5i5i9SZdX5+Pk6cOIFLLrnEPs5qtWLr1q145pln8NFHH6G6uhqnT592OLtWq5kK1L3ZRO3tJk3JZFeqZSLKZqcqLVPtYXct6j2rcUcWu1YZwUpk+6dFDee2rkcNyK+nnhm0Mn1U21ayx4RW9bGV6FnX2tOePlDb9zLrb9jsbi85s5YK1ldeeSW+/fZbh3EZGRno1asX7rnnHiQmJsLf3x+5ubmYMGECAGD//v04evSoYs1UIiIiOjepYB0WFtaslmlISAg6duxoH3/zzTcjKysLHTp0QHh4OO68806kpqbisssu067XREREDUxyduwKzcuN/utf/4KPjw8mTJjgUBSFiIhIa+4qN9rWXA7WTWugBgUFYdmyZVi2bJmrTRMRERH4Ig8iIjIzJpgZj0wmpmzGtkz2pxZtaEXPLGmt+q20L9QyS7XKQJfpu9oTAmptKPVd7+x2LdrWsz60O7KkZY4htf5plcWvJy3qq8uuj8xTMO7eVt5yGZxv3SIiIjI4U51ZExEROeBlcCIiImPjZXAikwhH3etElcTXf05EZGYM1mRq4QA2AdgCIKHJZwn14zeBAZvIY3nJ+6w99jK4WoZiQECA4vja2lrF8e6oP6zUd60yMfXM2pXJWtUqqzgMQBSA7gDy8Pt7vxPq/9290XTlKstUy6pV2+YyZNtwR21wpW2uVW1w2b4o0aLOv1q/tVofLaj1RYv66rLfN6VtbqRt5cBL7lnzzJpM7RjqAvQh/B6wU/F7oD5U//kxd3SOiHTHt24RmUQR6gJyHuoC9Pb68Q2BusgdnSIi0hDPrMkjFAG4ocm4G8BATeTxvOSeNYM1eYQEAGuajFuD5klnRORZLEK4PJiB110Gr66ulppeplSmbHKUTDKRURKPWhovU4ZVy7KVjZPJDqHujHoNmiedySZNyUwvk6ijNy3KU6rRKslIi+2iRfKnFttEK0YqS6x0DLm7rKi345k1mVo8mieT7UDzpDO157CJyOS85DK4151Zk2cpB3Ci/v+H4fd71I2Tzk7UT0dEnsdbKpgxWJOplQG4GnXPUTd9PKsIwFDUBeqyNu4XEZGWGKzdJBzKAQaou2TLAOO8MqhvKz5fTeThWBSF9MISmURE2mBRFAPy81PurlqpUJk21DIdtSj92TQTNVwIp0tklqm00UCLDFJn+93A1fVvaVqtyGRsa7ENtSoH645lKn0n1L5TauNlj0+ZZaqR2W+emMks86SKLKV29MxWp3PjmbUbHLNYMBwskUlE5DJmg5OeiiwWDBOCJTKJiFzgLdngPLN2I5bIJCJykZecWTNYuxFLZBIRkTMYrN0kodEl8EMABsHxHjYDNhGRczw9Exww2T1r2UxUmTZkyGZPN82ijAewGY7JZE1f85iHuoIex1TaONcy1cZrkS0q24bMi+zdUb9blp7Z7TJPPGi1TC2+E7L7TYtlGp1ajXZ3vFtAlqkyv4WoG1yZ3wRMFaw9BUtkEhGRDAZrN2CJTCIibXhLNjiDtZuwRCYRkQZYbpSIiIiMgGfWRERkWhZb3eDK/GZgqmAtk/XtjixptQxKtRrOan2xWq3NxsnWRdcim1OrjFCl9ZdZ99b0ReZYUaNnvW8tsqRla7erbVs9yWSJy343jZ6x7I7trRWZpyn0fPLCKbwMTkREREZgqjNrIiKixpgNTkREZHQsikJERGRsPLM2IJmkBdnyhzLJRLKlL2XLkyqN16o8oxYvrNdq/ZXIJnXJ9kWGnuUctei32rRaJDZptV1l2tEiKVBvaomeSttcbVvJJovK0CrpUOZ3wuiJfp7CVMGaiIjIgZdkgzNYExGRaXnLZXA+ukVERGRwPLMmIiLzYjY4ERGRsXnLZXCvC9ayWeIybahRewm9WiamTClG2fXRM8NZjRalJdUYJRNVdh/rSc9Mcz2XqeexqdX+0SJjW6snO5Ro9X2Q2S5KmeNCCMN8Nz2F1wVrIiLyIMwGJyIiMjZvuQzObHAiIiKD45k1ERGZl03UDa7MbwJSZ9YPPvggLBaLw9CrVy/755WVlcjMzETHjh0RGhqKCRMmoKSkRPNOExERAfj9nrUrgwlIn1lfeOGF+PTTT39voFGd2zlz5uD999/Hhg0bEBERgZkzZ2L8+PH4/PPPtemtSelZ19rf319xfE1NjdNtyPZDNstTKVtUJhO+pWXqWdNdhmxWsZ51sLWoSa3VMaHnNg8ICFAcr3TsuyMr30hk11+mNrg7njBpzAIX71lr1hN9SQdrPz8/xMTENBtfWlqKlStXYt26dRgxYgQAYNWqVbjggguwc+dOXHbZZa73loiIyAtJJ5gdOHAAcXFxOO+88zB16lQcPXoUAJCfn4+amhqkpaXZp+3Vqxe6dOmCHTt2qLZXVVWFsrIyh4GIiMgpDRXMXBlMQCpYp6SkYPXq1di0aROWL1+OgoICDBkyBOXl5SguLkZAQAAiIyMd5omOjkZxcbFqm9nZ2YiIiLAPiYmJrVoRIiLyPg2PbrkymIFUsB45ciSuu+46XHzxxUhPT8cHH3yA06dP4/XXX291B+bNm4fS0lL7UFhY2Oq2iLxdOIB4lc/ihUC4Sc4iiIxu2bJl6NatG4KCgpCSkoIvv/xSddoXXngBQ4YMQfv27dG+fXukpaW1OL0Sl56zjoyMxB/+8AccPHgQMTExqK6uxunTpx2mKSkpUbzH3SAwMBDh4eEOAxHJCwewCcAWAAlNPksAkGu14n2rlQGbPIsbssFfe+01ZGVlYeHChfj666/Rt29fpKen48SJE4rT5+XlYfLkydi8eTN27NiBxMREXHXVVTh27JjTy3QpWJ85cwaHDh1CbGwskpOT4e/vj9zcXPvn+/fvx9GjR5GamurKYs7J19e32dD0EbOGQU1DLdumgxLZtrVYppqamhrFQYbs+vj4+CgOaqxWa7NBllofbTab4qBEi+2tFbW+KB3LasdzU2EAogB0B3AwPh7/fe897Nq1C/997z0cjI9HdwDRFgs6BwUhODjYPii1rdW20nOb19bWKg5G2cda0eL3xt/fX3FQ4+x3yggsQrg8AGiWO1VVVaW6zKVLl2LGjBnIyMhA7969sWLFCrRr1w4vvfSS4vRr167FX//6V/Tr1w+9evXCiy++CJvN5hAvz0UqWN99993YsmULjhw5gu3bt+Paa6+Fr68vJk+ejIiICNx8883IysrC5s2bkZ+fj4yMDKSmpjITnKgNHAMwDEBVfDwCjx1Dz9tuQ8h//4uet92GwGPHUGCxYFS7djjewh9WRN4qMTHRIX8qOztbcbrq6mrk5+c7JFP7+PggLS2txWTqxs6ePYuamhp06NDB6f5JPbpVVFSEyZMn4+eff0bnzp1x+eWXY+fOnejcuTMA4F//+hd8fHwwYcIEVFVVIT09Hc8++6zMIojIBUUA9j/3nD1A97r5ZgB1AXzU6dM4xkBNnsZWP7gyP4DCwkKH27CBgYGKk586dQpWqxXR0dEO46Ojo7Fv3z6nFnnPPfcgLi7OIeCfi1SwXr9+fYufBwUFYdmyZVi2bJlMs0SkoZqYGBQsXmwP1ABQsHgxjs2e7b5OEemk8aXs1s4PoM1yph555BGsX78eeXl5CAoKcno+/plNXq3F7On6z83Gv7gYSQsWOIxLWrAA8Qa+70hkFp06dYKvr2+zUtrnSqYGgH/+85945JFH8PHHH+Piiy+WWi6DNXmtc2VPb6n/3EwBOwGwXwKvio/HvpUr7fewPzh7lgGbPE8bZ4MHBAQgOTnZITmsIVmspWTqxx57DP/4xz+wadMmDBgwQG6hMNlbt9QyILWo+6tFjWk1emajalF7WTbTU216X19fxfEy+6ctM3cbZ08fSkxE0Zo1qI2Nhd9PPyHhhhsQUP/MfxiAxnX1lI4V2ZrZetSLjweQByDw2DEcAjDs2DEU3XwzEurHdxcC71VUYLjFgmONlqPUtp41vQHlY0V2W6lR6rs7MsJlflMAbb4/ajy6NrqrVchaMW9WVhamT5+OAQMGYODAgcjJyUFFRQUyMjIAANOmTUN8fLw9Se3RRx/FggULsG7dOnTr1s1eKCw0NBShoaFOLdNUwZpISw3Z04cSExFQWIiEG25A8WOPIWbuXAQUFtYFvPrpzKAcQMNTnsNQl2yG+v8OQ13APlE/HZGncLUKWWvmnTRpEk6ePIkFCxaguLgY/fr1w6ZNm+xJZ0ePHnX4Y2358uWorq7Gn//8Z4d2Fi5ciAcffNDJfhrsIcSysjJEREQofqbnX/tqf9Vq8fYmo59Za0XPMwM9HcrLcziTBoDqxER0Lyy0B7zGtDizVuPq/gxH3ZUApT8wEi0WlAMoa7KMtn5DGaDNmbXamatSO95+Zi3bF62UlpbqlrTVECuGDpoPPz/nE7Waqq2txJbt/9C1r1rgPWvyerWxsSh+7DGHccWPPaYYqI2uDOpXAo5ZLM0CNZHpecmLPHgZnLye308/IWbuXIdxMXPnIgEwZcAm8iYWW93gyvxmYNhg7ePj0+xSnNrlIKXLR7KXjrS41KR2qU3mcl1L412dVm9GLkmoJgGAGDYMAQAOAZhuseBlIdC9sBB5cLz320CL9VS7zKzF5We1NmSS2tSWp9WlWqW+yB7L7rjtJEOrxE0tLmHrecwqMco+8CS8DE5eqyF7ujvqAvUIiwU7LBaMsFhwqH58HtSfwyYiA+BlcCLP1jh7eoTFgqL6M4ciiwUjAHwmBLOniYyulW/OcpjfBBisyWuVAbgaQEST546BuoA9VIi67Gl3dI6IqBEGa/JqZQDOqNyLM8vz1UTeTKva4EbHYE1EROblhgpm7mDYYC2TvSiTiar2wvWamhqn29A7a1Umu13P0qfuKP6itky1LOTa2lqXl+mOLHY9t6FWx6cSrbaVO9bT6PT8ndAio9zTtrfZGDZYExERnZOAa++zNsnfIAzWRERkWrxnTUREZHQCLt6z1qwnumJRFCIiIoPjmTUREZkXs8Hdr2lmsBbZiDJZ37K0qpssM72eGdht/XrHlqbVIuvbDIz+mlHZ+vcy2cayT2rILFO2f3q+UlKr75vMMSFTF15tvGFr/9sAuPIyOYOuVlO8DE5ERGRwhj6zJiIiagmzwYmIiIzOS+5Z8zI4ERGRwfHMmoiIzMtLzqwNHazbshatFtmfshmXauunlBWrZxa7TO1hQD4zWWn9Zfetntm5smTqsautp1obemZ9a5GFrNaGFvtB9hjX4rup1fQy3FFjW/b7Y6o64F4SrHkZnIiIyOAMfWZNRETUIi95zprBmoiITIuPbhERERkd71kTERGREZjqzNoo2axqmZVqZDMrlepgy667n5/yrtWixrYWWeKydaC1yLTXKqNci0xZPbNt9fyeaHVcabH+asehErVjU60Ntf7JHCta1QDX4rjVos6/nk8CuMQmAIsLx5PNHGfWpgrWREREDngZnIiIiIyAZ9ZERGRiLp5Zwxxn1gzWRERkXl5yGdxUwVot0UKLEo0ySRxqyRpaJQ1pkQgkk/Cj53YFlPsoW1pSi6Q2tUQYtbbNWopRzwQ4LRKVZNvRszSrnuVdZcv4qh1v7khqU5re6Me9pzNVsCYiInJgE3DpUjazwYmIiHQmbHWDK/ObALPBiYiIDI5n1kREZF5MMCMiIjI43rM2Hi0yN91RKlI2Q1MpW1SrrFWlzG+tygVqVc5TiZ5Zu2qMlP2qdEzIlmB1x37QYplalOeUzShXm16m1LBa27LbUIsnVTyal5xZ8541ERGRwZnqzJqIiMiBgItn1pr1RFcM1kREZF68DE5ERERGIB2sjx07hr/85S/o2LEjgoOD0adPH+zatcv+uRACCxYsQGxsLIKDg5GWloYDBw5o2mkiIiIAgM3m+mACUpfBf/31VwwePBjDhw/Hhx9+iM6dO+PAgQNo3769fZrHHnsMTz31FF5++WUkJSVh/vz5SE9Px969exEUFORSZ/XMNlbLolTLCtWTTLaobP1hLWoyy2YbK02vVdaqFrWQzZBBq0U2vMy20mrfu4OevwdtvR8AfX/3ZH7f1H5TZN5DoAsvuQwuFawfffRRJCYmYtWqVfZxSUlJ9v8XQiAnJwcPPPAAxo4dCwD497//jejoaGzcuBHXX3+9Rt0mIiLyHlKXwd955x0MGDAA1113HaKiotC/f3+88MIL9s8LCgpQXFyMtLQ0+7iIiAikpKRgx44dim1WVVWhrKzMYSAiInJKw5m1K4MJSAXrw4cPY/ny5ejRowc++ugj3HHHHfjb3/6Gl19+GQBQXFwMAIiOjnaYLzo62v5ZU9nZ2YiIiLAPiYmJrVkPIiLyRjbh+mACUsHaZrPhkksuwZIlS9C/f3/ceuutmDFjBlasWNHqDsybNw+lpaX2obCwsNVtEREReSKpYB0bG4vevXs7jLvgggtw9OhRAEBMTAwAoKSkxGGakpIS+2dNBQYGIjw83GEgIiJyhhA2lwczkEowGzx4MPbv3+8w7ocffkDXrl0B1CWbxcTEIDc3F/369QMAlJWV4YsvvsAdd9zhcmfVsh9lamnLZmIqjdczO1OWbNa3FlnSstnTWmRby2YnGz0bXPYpA5k+qh2fWjxloOfTEVrsS0+kxVMWar8TMseE27O+1QgXL2Wb5PiSCtZz5szBoEGDsGTJEkycOBFffvklnn/+eTz//PMA6g6e2bNn46GHHkKPHj3sj27FxcVh3LhxevSfiIi8mXDxrVueGKwvvfRSvPXWW5g3bx4WL16MpKQk5OTkYOrUqfZp5s6di4qKCtx66604ffo0Lr/8cmzatMnlZ6yJiIi8lUUY7BpTWVkZIiIipObR8zK4Ek+7DG6wQ0CRnkU63HH5Vc/L4Fpc8lTjjgIdZjg+ZWhVFEXmu6znMdGS0tJS3fKQGmLFlWFT4WcJaHU7taIaueVrde2rFvgiDyIiMi9eBjcPLRJn1Pj7+zcbV1NTozitO8641drWs6yo2nqqJaDIXPlQo1WyW1uTPSa0SODS4qqSVseyzPq448xaq/VUa0eLtrX4/XBHmVTSlkcEayIi8k7CZoOwtP4PGo98dIuIiMhQvOQyON9nTUREZHA8syYiIvOyCcDi+WfWDNZERGReQgBw4b4zg7X2ZLKWtcrmVMv8VqJVpqye5Tllns1UGy+7nu54Xllpf6plxGpRWlN2W+lZtlONO0qwyjwHL7tMLTK5tdoPSstUe7bZHdS2lcyTHcz6di9TBWsiIqLGhE1AuHAZ3Cx/hDDBjIiIzEvYXB9aYdmyZejWrRuCgoKQkpKCL7/8ssXpN2zYgF69eiEoKAh9+vTBBx98ILU8BmsiIjItYRMuD7Jee+01ZGVlYeHChfj666/Rt29fpKen48SJE4rTb9++HZMnT8bNN9+M3bt3Y9y4cRg3bhy+++47p5dpqtrg7rhnrWf1MS3uWetZY1orSttWq+2qxT1r2baVyG5Xo+83rfIp9PxeadG2njWz3VWPW4kW96xboy1qgw+zXAs/S/NKk86qFTXIE29J9TUlJQWXXnopnnnmGQB1x1xiYiLuvPNO3Hvvvc2mnzRpEioqKvDee+/Zx1122WXo168fVqxY4dQyDXfPuqUfAz1/sNwRxLRYpsH+1lLkjv1m9G1r9P2mVf+Mvg2N3j+tuKtcb1tsg1pR1epL2QBQi7ok4rKyMofxgYGBCAwMbDZ9dXU18vPzMW/ePPs4Hx8fpKWlYceOHYrL2LFjB7KyshzGpaenY+PGjU7303DBury8XHoeo39pvZ07tq073oBGzRk9GLqjbr87qG0rvc/yy8vLpd+i6KyAgADExMTgP8Vy936VhIaGIjEx0WHcwoUL8eCDDzab9tSpU7BarYiOjnYYHx0djX379im2X1xcrDh9cXGx0300XLCOi4tDYWEhwsLCUF5ejsTERBQWFhr61WWuKisr43p6CG9YR4Dr6Wm0Xk8hBMrLyxEXF6dB75QFBQWhoKAA1dXVLrclhGh260fprNqdDBesfXx8kJCQAOD3+2bh4eEe/UVpwPX0HN6wjgDX09NouZ56nVE3FhQUhKCgIN2X01inTp3g6+uLkpISh/ElJSWIiYlRnCcmJkZqeiXMBiciInJSQEAAkpOTkZubax9ns9mQm5uL1NRUxXlSU1MdpgeATz75RHV6JYY7syYiIjKyrKwsTJ8+HQMGDMDAgQORk5ODiooKZGRkAACmTZuG+Ph4ZGdnAwBmzZqFoUOH4oknnsA111yD9evXY9euXXj++eedXqahg3VgYCAWLlxouHsHWuN6eg5vWEeA6+lpvGU9tTJp0iScPHkSCxYsQHFxMfr164dNmzbZk8iOHj3q8FjcoEGDsG7dOjzwwAO477770KNHD2zcuBEXXXSR08s03HPWRERE5Ij3rImIiAyOwZqIiMjgGKyJiIgMjsGaiIjI4BisiYiIDM7QwVr2faFGt3XrVowZMwZxcXGwWCzNirgLIbBgwQLExsYiODgYaWlpOHDggHs620rZ2dm49NJLERYWhqioKIwbNw779+93mKayshKZmZno2LEjQkNDMWHChGbVfYxu+fLluPjii+0Vn1JTU/Hhhx/aP/eEdWzqkUcegcViwezZs+3jPGE9H3zwQVgsFoehV69e9s89YR0bHDt2DH/5y1/QsWNHBAcHo0+fPti1a5f9c0/4DfJUhg3Wsu8LNYOKigr07dsXy5YtU/z8sccew1NPPYUVK1bgiy++QEhICNLT01FZWdnGPW29LVu2IDMzEzt37sQnn3yCmpoaXHXVVaioqLBPM2fOHLz77rvYsGEDtmzZguPHj2P8+PFu7LW8hIQEPPLII8jPz8euXbswYsQIjB07Ft9//z0Az1jHxr766is899xzuPjiix3Ge8p6Xnjhhfjpp5/sw3/+8x/7Z56yjr/++isGDx4Mf39/fPjhh9i7dy+eeOIJtG/f3j6NJ/wGeSxhUAMHDhSZmZn2f1utVhEXFyeys7Pd2CvtABBvvfWW/d82m03ExMSIxx9/3D7u9OnTIjAwULz66qtu6KE2Tpw4IQCILVu2CCHq1snf319s2LDBPs3//vc/AUDs2LHDXd3URPv27cWLL77ocetYXl4uevToIT755BMxdOhQMWvWLCGE5+zLhQsXir59+yp+5inrKIQQ99xzj7j88stVP/fU3yBPYcgz64b3haalpdnHnet9oWZXUFCA4uJih3WOiIhASkqKqde5tLQUANChQwcAQH5+PmpqahzWs1evXujSpYtp19NqtWL9+vWoqKhAamqqx61jZmYmrrnmGof1ATxrXx44cABxcXE477zzMHXqVBw9ehSAZ63jO++8gwEDBuC6665DVFQU+vfvjxdeeMH+uaf+BnkKQwbrlt4XKvP+TzNpWC9PWmebzYbZs2dj8ODB9rJ6xcXFCAgIQGRkpMO0ZlzPb7/9FqGhoQgMDMTtt9+Ot956C7179/aodVy/fj2+/vpre43jxjxlPVNSUrB69Wps2rQJy5cvR0FBAYYMGYLy8nKPWUcAOHz4MJYvX44ePXrgo48+wh133IG//e1vePnllwF45m+QJzF0bXAyt8zMTHz33XcO9/88Sc+ePbFnzx6UlpbijTfewPTp07FlyxZ3d0szhYWFmDVrFj755JM2fw1hWxo5cqT9/y+++GKkpKSga9eueP311xEcHOzGnmnLZrNhwIABWLJkCQCgf//++O6777BixQpMnz7dzb2jczHkmXVr3hdqdg3r5SnrPHPmTLz33nvYvHmz/f3kQN16VldX4/Tp0w7Tm3E9AwICcP755yM5ORnZ2dno27cvnnzySY9Zx/z8fJw4cQKXXHIJ/Pz84Ofnhy1btuCpp56Cn58foqOjPWI9m4qMjMQf/vAHHDx40GP2JQDExsaid+/eDuMuuOAC+yV/T/sN8jSGDNateV+o2SUlJSEmJsZhncvKyvDFF1+Yap2FEJg5cybeeustfPbZZ0hKSnL4PDk5Gf7+/g7ruX//fhw9etRU66nEZrOhqqrKY9bxyiuvxLfffos9e/bYhwEDBmDq1Kn2//eE9WzqzJkzOHToEGJjYz1mXwLA4MGDmz1G+cMPP6Br164APOc3yGO5O8NNzfr160VgYKBYvXq12Lt3r7j11ltFZGSkKC4udnfXWq28vFzs3r1b7N69WwAQS5cuFbt37xY//vijEEKIRx55RERGRoq3335bfPPNN2Ls2LEiKSlJ/Pbbb27uufPuuOMOERERIfLy8sRPP/1kH86ePWuf5vbbbxddunQRn332mdi1a5dITU0Vqampbuy1vHvvvVds2bJFFBQUiG+++Ubce++9wmKxiI8//lgI4RnrqKRxNrgQnrGed911l8jLyxMFBQXi888/F2lpaaJTp07ixIkTQgjPWEchhPjyyy+Fn5+fePjhh8WBAwfE2rVrRbt27cQrr7xin8YTfoM8lWGDtRBCPP3006JLly4iICBADBw4UOzcudPdXXLJ5s2bBYBmw/Tp04UQdY9OzJ8/X0RHR4vAwEBx5ZVXiv3797u305KU1g+AWLVqlX2a3377Tfz1r38V7du3F+3atRPXXnut+Omnn9zX6Va46aabRNeuXUVAQIDo3LmzuPLKK+2BWgjPWEclTYO1J6znpEmTRGxsrAgICBDx8fFi0qRJ4uDBg/bPPWEdG7z77rvioosuEoGBgaJXr17i+eefd/jcE36DPBXfZ01ERGRwhrxnTURERL9jsCYiIjI4BmsiIiKDY7AmIiIyOAZrIiIig2OwJiIiMjgGayIiIoNjsCYiIjI4BmsiIiKDY7AmIiIyOAZrIiIig/t/cGWd1SdcGG0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8afc29e290>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l=np.random.randint(0,len(centers))\n",
    "data_loader.plot_image_with_centers(l)\n",
    "plt.imshow(images[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the data and split it into training and validation sets\n",
    "train_images, val_images, train_midpoints, val_midpoints = data_loader.split_data()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images: (160000, 64, 64), Train Midpoints: (160000, 1, 13, 2)\n",
      "Validation Images: (40000, 64, 64), Validation Midpoints: (40000, 1, 13, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 1000\n",
    "train_dataset = train_dataset.shuffle(buffer_size=8000, reshuffle_each_iteration=True).batch(batch_size)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=8000).batch(batch_size)\n",
    "\n",
    "# Check the shape of the datasets\n",
    "print(f'Train Images: {train_images.shape}, Train Midpoints: {train_midpoints.shape}')\n",
    "print(f'Validation Images: {val_images.shape}, Validation Midpoints: {val_midpoints.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_transposed_images_with_midpoints(train_dataset, image_indices=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set up learning rate scheduler\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.9, patience=10, verbose=1, mode='min', min_lr=3e-5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,552</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m1,179,904\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_11 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │        \u001b[38;5;34m65,552\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m170\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ x_midpoints_reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m2\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,292,474</span> (31.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,292,474\u001b[0m (31.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,291,066</span> (31.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,291,066\u001b[0m (31.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> (5.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,408\u001b[0m (5.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# dynamic_exponent_callback = DynamicExponentCallback(2, 1, 50)\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    # Instantiate the model builder\n",
    "    # model_builder = ModelBuilder(weights_path= \"/home/da886/Weights from Josh's model/Josh's5fixedMSE45overfit-1.keras\")\n",
    "    model_builder = ModelBuilder()\n",
    "\n",
    "    # Build the model\n",
    "    model_builder.build_model()\n",
    "\n",
    "    # Display the model architecture\n",
    "    model_builder.model.summary()\n",
    "\n",
    "    # Compile the model using the custom loss function\n",
    "    # model_builder.compile_model(loss_function=dynamic_exponent_callback.custom_loss(2))\n",
    "    model_builder.compile_model(loss_function=tf.keras.losses.MeanSquaredError()) \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 18:29:49.863562: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/cond/else/_393/cond/StatefulPartitionedCall/functional_2_1/dropout_8_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-10-03 18:29:53.708418: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-03 18:29:53.718405: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-10-03 18:29:53.763067: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1727980193.783645 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.788217 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.792738 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.835801 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.835943 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.836042 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.836836 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.837112 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.837253 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.837643 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.837927 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.838171 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.840410 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.840554 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.840787 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.841404 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.841578 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.841817 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.843966 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.843981 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.844468 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.845146 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.845161 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.845621 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.846315 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.846331 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.846647 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.847606 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.847648 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.847860 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.850932 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.851041 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.851534 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.851994 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.852093 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.852514 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.852752 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.852926 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.853382 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.853600 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.853762 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.854295 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.854770 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.854939 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.855526 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.856088 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.856271 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.856869 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.867213 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.867228 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.867643 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.868805 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.868818 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.869164 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.870356 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.870372 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.870694 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.871941 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.871957 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.872249 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.873714 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.873826 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.874052 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.875360 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.875569 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.875786 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.892989 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.893002 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.894861 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.894963 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.895684 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.895830 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.896071 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.897220 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.897220 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.897367 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.898218 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.899254 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.924925 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.924978 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.925090 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.932374 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.932378 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.932843 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.935626 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.935736 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.935815 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.938515 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.938824 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.938895 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.941519 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.941649 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.941665 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.942984 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.943075 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.943171 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.945964 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.946060 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.946812 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.948679 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.949934 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.950049 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.952427 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.953595 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.953691 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.955922 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.956848 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.956949 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.958070 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.966579 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.966583 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980193.966604 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.336615 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.340414 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.341089 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.341846 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.342637 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.343347 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.344094 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.351261 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.355809 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.360353 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.364432 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.368049 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.372343 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.376526 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.461227 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.461895 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.462621 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.463381 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.464153 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.466157 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.467067 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.467948 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.468830 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.469717 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.471246 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.473374 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.475211 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.477446 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.479435 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.480663 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.481861 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.483932 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.485764 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.489094 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.491523 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.501720 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.502559 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.503367 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.504304 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.505229 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.506016 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.506833 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.507775 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.508675 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.509987 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.511149 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.512442 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.516619 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.521005 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.525236 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.534041 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.542747 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.548126 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.553569 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.614282 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.615874 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.616559 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.617326 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.618123 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.618827 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.619578 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.622671 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.627230 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.631791 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.635224 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.638837 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.643150 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.647349 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.654668 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.656215 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.656911 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.657675 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.658475 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.659178 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.659933 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.662482 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.667079 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.671641 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.675057 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.678695 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.683021 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.687235 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.722583 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.723498 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.724450 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.725426 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.726442 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.727432 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.728442 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.729568 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.730738 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.731977 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.732476 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.733159 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.733368 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.733894 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.734741 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.734758 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.735533 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.736205 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.736595 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.737496 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.737867 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.738398 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.739280 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.739620 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.740186 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.741193 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.741703 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.742392 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.743850 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.743864 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.745271 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.745909 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.746519 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.747742 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.748966 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.749168 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.751054 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.752658 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.753644 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.754514 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.757842 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.758384 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.760270 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.770031 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.770175 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.770903 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.771492 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.771740 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.773010 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.773093 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.773144 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.773861 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.774034 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.774746 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.774951 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.775052 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.775533 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.775895 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.776441 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.776807 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.777000 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.777514 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.777929 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.778215 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.778443 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.779509 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.779612 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.779740 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.780568 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.780737 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.781012 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.781477 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.782055 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.782729 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.782746 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.783923 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.785048 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.785229 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.786248 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.786651 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.787092 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.787887 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.789124 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.789344 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.790340 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.790673 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.792439 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.794280 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.794935 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.796258 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.797628 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.800058 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.803746 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.804713 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.809803 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.810676 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.811498 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.812579 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.812587 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.812904 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.813542 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.814340 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.815169 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.816118 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.817022 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.817984 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.818362 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.819529 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.820837 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.823457 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.825071 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.829497 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.830150 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.833768 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.842642 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.847148 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.851448 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.856861 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.857360 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.862388 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.867704 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.993053 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.994004 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.994975 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.995954 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.996977 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.997975 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980194.998991 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.000122 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.001298 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.002536 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.003893 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.005200 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.006637 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.008282 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.010039 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.011883 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.013882 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.015925 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.018612 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.021865 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.026345 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.031112 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.033263 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.034201 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.035165 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.036140 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.037173 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.038181 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.039198 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.040326 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.041507 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.042750 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.043369 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.044111 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.044710 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.045421 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.046022 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.046875 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.047590 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.048546 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.049160 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.050316 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.050578 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.051882 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.052191 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.053152 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.054199 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.054652 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.056265 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.056933 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.058902 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.059538 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.061164 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.064039 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.068038 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.068837 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.076618 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.080996 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.082322 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.083613 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.085086 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.085244 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.086799 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.088192 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.089493 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.090730 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.092203 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.094481 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.096439 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.098684 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.102695 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.105613 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.114156 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.119946 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.122419 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.130304 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.139833 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.140859 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.157048 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.167363 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.177839 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.208021 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.209490 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.210915 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.212400 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.213910 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.215499 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.217071 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.218703 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.220538 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.222491 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.224411 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.226402 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.228557 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.231107 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.233877 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.242648 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.245557 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.248745 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.252164 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.258453 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.479761 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.481208 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.482639 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.484130 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.485638 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.487228 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.488790 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.490431 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.492272 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.494229 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.496147 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.498113 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.500261 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.502812 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.505584 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.514368 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.517280 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.518438 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.519871 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.520533 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.521302 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.522781 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.524033 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.524286 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.525874 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.527438 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.528235 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.529096 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.530936 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.532898 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.534637 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.534838 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.536824 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.538989 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.541548 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.544291 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.553084 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.555979 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.559180 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.562684 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.569079 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.719853 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.722003 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.724093 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.726418 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.728937 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.730988 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.732987 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.735569 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.737844 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.739864 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.742183 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.744602 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.757134 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.770523 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.787506 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.803811 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.821318 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.839764 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.877092 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.994887 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.997070 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980195.999189 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.001521 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.004064 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.006114 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.008137 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.010743 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.013029 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.015084 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.017436 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.019886 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.026381 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.028548 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.030654 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.032806 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.033010 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.035547 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.037612 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.039620 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.042227 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.044512 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.046312 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.046555 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.048895 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.051322 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.063587 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.064106 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.077609 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.079990 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.094823 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.097469 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.111376 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.116393 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.129111 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.147260 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.155049 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.183880 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.552125 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.554468 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.556940 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.559256 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.561707 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.564335 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.567087 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.569783 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.572917 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.576667 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.579957 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.583362 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.586876 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.591578 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.596819 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.602317 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.618282 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.624331 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.630946 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.643356 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.667529 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.671241 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.675508 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.679395 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.683146 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.687883 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.691660 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.696618 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.700289 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.704009 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.708392 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.713067 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.736950 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.763646 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.796911 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.828690 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.831994 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.834349 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.836855 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.839211 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.841674 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.844313 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.847093 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.849811 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.852947 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.856686 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.860005 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.863251 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.863641 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.863670 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.865616 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.867176 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.868118 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.870441 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.871950 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.872924 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.875561 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.877255 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.878340 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.881042 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.882831 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.884245 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.888123 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.891540 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.895030 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.898547 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.898975 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.902496 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.903250 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.905107 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.908500 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.912857 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.914083 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.919662 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.930336 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.932367 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.936495 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.943260 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.955924 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.957017 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.960793 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.965178 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.969107 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.972914 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.977641 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.979574 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.980617 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.981390 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.984390 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.986294 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.988759 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.990065 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.992685 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.993905 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.996493 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980196.998374 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980197.001236 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980197.003067 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980197.004994 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980197.010040 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980197.013798 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980197.017604 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980197.022051 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980197.026690 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980197.027520 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980197.050988 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980197.055839 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980197.077685 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980197.092362 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980197.111265 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980197.125040 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980197.143366 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980197.159916 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980197.178046 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980197.198042 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980197.214985 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980197.276344 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980197.295347 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.322905 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.326932 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.331002 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.335099 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.339463 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.343996 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.348894 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.353370 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.359069 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.364132 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.370341 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.376668 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.383409 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.392751 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.402021 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.411468 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.439450 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.450982 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.469497 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.479748 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.486575 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.495377 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.502399 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.509713 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.518060 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.525067 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.534978 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.542261 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.550749 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.559690 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.606333 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.623601 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.627671 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.631791 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.635938 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.640329 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.644927 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.648932 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.649934 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.652986 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.654530 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.657086 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.657717 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.660155 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.661219 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.665297 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.665631 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.670190 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.671588 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.675125 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.677956 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.679690 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.684780 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.685629 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.690746 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.694154 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.697020 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.703409 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.703720 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.710245 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.713245 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.719680 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.722824 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.729060 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.738688 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.741633 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.753304 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.766953 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.767166 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.778919 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.785474 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.785864 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.796555 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.797592 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.803632 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.808239 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.813012 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.815192 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.820455 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.824295 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.827832 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.831554 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.836547 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.838994 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.843697 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.847765 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.851206 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.853689 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.855098 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.861072 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.865282 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.869774 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.872667 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.878930 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.881404 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.890510 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.926058 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.929383 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.937690 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.978339 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980198.989226 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980199.043735 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980199.054793 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980199.074859 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980199.107052 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980199.118065 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980199.174029 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980199.180055 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980199.249727 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980199.251782 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980199.396818 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980199.414747 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980201.757932 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980201.765208 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980201.772619 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980201.780240 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980201.788709 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980201.797331 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980201.807476 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980201.816861 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980201.828352 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980201.838276 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980201.850589 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980201.863125 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980201.876251 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980201.895121 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980201.912681 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980201.931368 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980201.983184 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.005563 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.036134 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.053020 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.066635 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.080594 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.089360 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.096745 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.099380 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.104284 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.111922 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.113537 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.119991 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.121196 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.128505 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.128824 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.130182 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.135969 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.139034 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.143539 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.143810 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.148566 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.152320 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.160431 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.161250 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.162949 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.170713 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.171544 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.176477 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.181238 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.183370 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.192553 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.193053 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.196105 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.203246 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.209596 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.209991 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.215713 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.228437 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.228532 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.241556 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.246374 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.260030 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.265143 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.277628 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.296162 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.297201 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.317299 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.339803 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.348868 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.366603 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.371447 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.397414 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.399718 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.402238 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.414582 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.419544 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.428215 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.433400 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.442589 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.447731 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.461546 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.466528 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.475983 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.480631 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.492547 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.497187 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.506231 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.510705 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.525456 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.528439 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.529706 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.539192 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.543318 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.555594 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.559588 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.573391 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.577128 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.653893 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.659594 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.662338 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.759828 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.762589 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.797902 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.890298 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.893067 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980202.947194 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980203.017164 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980203.019497 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980203.160037 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980203.162161 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980203.229318 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980203.310232 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980203.313125 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980203.592619 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980203.596536 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980208.618596 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980208.632040 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980208.645326 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980208.660709 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980208.678398 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980208.695417 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980208.714010 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980208.731461 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980208.750779 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980208.769535 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980208.792605 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980208.815735 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980208.840408 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980208.873394 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980208.907839 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980208.941082 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980208.983396 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980208.985150 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980208.996980 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.008113 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.010444 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.021607 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.025882 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.035153 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.040925 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.043599 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.049915 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.054636 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.058293 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.060691 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.062000 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.066851 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.067346 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.070509 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.074906 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.078421 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.079466 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.083420 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.084411 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.087147 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.091389 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.095882 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.097106 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.103372 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.116767 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.121184 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.123206 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.136058 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.140934 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.144787 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.159487 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.159993 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.178158 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.182638 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.183200 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.206345 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.207136 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.210029 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.230935 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.239945 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.242624 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.264119 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.274260 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.278144 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.298237 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.307596 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.331355 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.352451 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.354821 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.375723 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.403906 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.431020 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.444508 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.448046 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.451832 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.456811 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.459895 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.460546 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.464992 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.468581 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.473595 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.473859 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.477332 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.477681 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.481558 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.481741 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.486279 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.486601 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.490390 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.494846 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.498431 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.503420 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.507147 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.511466 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.514095 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.516032 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.535868 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.543595 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.565199 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.569125 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.598595 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.601218 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.630694 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.633258 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.663355 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.669933 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.699073 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.750462 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980209.776664 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.642896 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.646684 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.650209 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.653941 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.657918 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.661888 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.666132 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.670138 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.674606 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.679010 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.684517 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.690287 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.696645 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.705114 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.714424 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.723035 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.745260 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.756210 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.774176 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.774973 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.775759 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.776642 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.777414 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.778217 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.779226 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.780012 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.780920 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.781850 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.782610 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.783482 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.788419 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.793243 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.798048 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.802462 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.807307 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.815979 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.824783 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.975062 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.975849 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.976634 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.977384 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.978156 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.979020 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.979817 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.980594 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.981414 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.982223 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.983136 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.984041 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.985147 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.986341 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.987921 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.989133 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980210.999736 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.003106 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.004682 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.007669 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.047378 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.051177 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.054727 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.058491 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.062505 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.066694 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.066674 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.070505 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.070967 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.074107 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.075018 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.077910 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.079494 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.081947 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.084132 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.086005 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.089871 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.090251 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.094256 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.095635 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.098724 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.102012 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.103274 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.109096 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.110534 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.114943 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.119943 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.121425 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.128603 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.130025 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.139506 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.148173 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.150917 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.161931 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.170709 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.179766 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.180718 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.181815 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.181937 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.182703 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.183781 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.184578 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.185645 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.186415 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.187317 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.188253 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.189022 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.189903 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.194487 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.194907 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.199790 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.204632 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.208995 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.212765 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.213702 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.213975 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.214608 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.215513 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.216300 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.216428 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.217261 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.217342 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.218302 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.219106 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.219429 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.220033 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.221317 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.221786 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.222115 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.222659 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.223029 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.224025 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.224778 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.225537 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.226232 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.226963 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.227652 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.228082 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.230233 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.231050 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.231653 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.231980 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.232806 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.232995 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.233853 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.238079 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.238094 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.242532 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.242806 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.246632 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.247361 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.253024 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.255992 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.263692 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.264780 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.382811 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.383610 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.384400 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.385162 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.385949 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.386825 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.387628 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.388400 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.389236 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.390048 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.390979 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.391894 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.393008 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.394217 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.395804 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.397055 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.407738 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.411041 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.412617 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.415236 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.415640 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.416041 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.416842 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.417605 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.418385 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.419255 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.420181 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.420959 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.421799 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.423966 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.424303 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.424941 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.425116 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.426069 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.426082 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.426817 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.427317 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.428754 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.429210 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.429954 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.430348 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.431563 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.432687 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.433453 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.436018 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.437903 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.440419 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.441262 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.442357 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.442360 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.443328 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.444430 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.445763 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.446483 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.447363 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.447562 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.448864 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.449153 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.450406 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.452177 2950984 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.453451 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.476316 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.478379 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.479210 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.480105 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.481161 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.482329 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.483477 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.484634 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.485687 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.486746 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.487795 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.489100 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.490407 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.491473 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.492568 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.495889 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.498002 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.499267 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.500894 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.502795 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.504758 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.510346 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.514523 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.519644 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.524089 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.528508 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.532907 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.903143 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.904790 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.907456 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.909917 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.911058 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.912497 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.914051 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.916887 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.919685 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.921691 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.922189 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.922636 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.923156 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.923169 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.923561 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.924502 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.924976 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.925548 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.926207 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.926586 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.926788 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.927199 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.927608 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.927968 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.928376 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.928734 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.929076 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.929437 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.929817 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.930186 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.930515 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.931480 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.931869 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.932072 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.932570 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.932902 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.933387 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.933842 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.934328 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.934689 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.934857 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.935128 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.935740 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.936170 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.939382 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.940026 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.943564 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.944230 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.946701 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.947427 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.948411 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.950007 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.953275 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.953831 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.954855 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.956727 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.960004 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.963452 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.964501 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.967872 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.967880 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.971500 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.974947 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.978807 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.982191 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.986754 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.991745 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980211.997384 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.002129 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.028316 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.054679 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.079040 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.100012 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.115230 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.116001 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.116778 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.117516 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.118634 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.119278 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.119427 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.120047 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.120487 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.120834 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.121282 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.121843 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.122549 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.123004 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.123489 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.124075 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.124643 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.125136 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.125483 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.125918 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.126477 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.126985 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.127449 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.127933 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.128557 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.129190 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.129280 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.129726 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.130120 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.130784 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.131080 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.132169 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.132241 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.133282 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.133793 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.134434 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.135474 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.136935 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.137008 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.138491 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.141563 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.148275 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.149290 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.150202 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.151398 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.152468 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.153179 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.153636 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.154179 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.154472 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.154807 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.155029 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.156063 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.156139 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.157269 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.157371 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.158549 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.158622 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.159810 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.159881 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.161118 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.161222 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.162188 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.162569 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.163262 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.163657 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.164330 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.164773 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.165660 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.166976 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.168169 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.168251 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.169290 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.170381 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.171659 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.172605 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.173317 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.174731 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.175232 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.176014 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.176625 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.177672 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.179592 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.181120 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.181421 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.185689 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.185704 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.189898 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.190333 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.194526 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.194813 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.199025 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.199261 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.203489 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.203708 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.207954 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.571197 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.572185 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.573162 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.573983 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.574872 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.576065 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.577320 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.578032 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.578610 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.579079 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.580186 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.580253 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.581028 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.581929 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.582259 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.583121 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.583566 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.584386 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.585506 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.585867 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.587340 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.588910 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.589617 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.590202 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.592134 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.592574 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.596218 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.599204 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.604093 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.607427 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.610743 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.611051 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.614276 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.614449 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.617643 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.617815 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.621169 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.621334 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.624720 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.624802 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.628398 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.628469 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.631933 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.631951 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.635588 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.635892 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.639067 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.639441 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.642969 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.644174 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.646403 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.649201 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.650984 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.654868 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.655985 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.659661 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.661688 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.666466 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.686062 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.692867 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.712802 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.719494 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.737311 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.744052 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.758354 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.765100 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.787850 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.794385 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.813245 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980212.819778 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.433521 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.436968 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.440514 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.444060 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.447841 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.451576 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.455258 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.459419 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.463500 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.467711 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.472356 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.477177 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.482197 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.487959 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.494300 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.500642 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.506945 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.515282 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.524269 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.536153 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.568320 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.573019 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.577666 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.582799 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.587923 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.593132 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.599859 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.606028 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.612158 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.620257 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.626989 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.633714 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.640859 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.647998 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.654634 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.661887 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.668042 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.674615 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.689918 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.697430 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.705913 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.735061 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.764162 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.791219 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.818346 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.845477 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980213.876294 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.095190 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.098659 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.102251 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.105819 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.107818 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.109657 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.111281 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.113426 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.114876 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.117143 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.118455 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.121302 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.122268 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.125425 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.126031 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.129782 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.129854 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.133928 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.134483 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.137904 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.139326 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.142263 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.144299 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.147089 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.150074 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.152063 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.156460 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.157108 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.162888 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.163099 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.169260 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.169654 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.176133 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.177600 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.182541 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.186652 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.190950 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.198822 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.200231 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.212264 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.231426 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.236183 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.240897 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.244636 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.246095 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.249392 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.251293 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.254089 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.256565 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.259274 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.263058 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.264445 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.269259 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.269692 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.275481 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.276169 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.282333 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.283663 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.288510 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.290488 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.296604 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.297322 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.303304 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.304493 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.309980 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.311660 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.317059 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.318296 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.324181 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.325560 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.330800 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.331728 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.338078 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.338333 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.344263 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.350853 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.351893 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.359444 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.365812 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.367994 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.373416 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.382013 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.397243 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.411710 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.426317 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.441053 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.453271 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.468235 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.480207 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.495410 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.507443 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.522572 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.538856 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980214.553485 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.213076 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.216975 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.221361 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.225959 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.230713 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.236881 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.243748 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.251201 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.259346 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.268101 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.278310 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.284930 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.313920 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.339475 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.362244 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.375001 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.387771 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.400666 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.414078 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.428215 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.442234 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.457313 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.473495 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.487403 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.506386 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.525766 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.546978 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.565020 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.648616 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.747640 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.842893 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.843595 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.847514 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.851987 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.856635 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.861464 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.867819 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.874849 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.882417 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.890612 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.899427 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.909588 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.914116 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.916274 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.918139 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.922705 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.927404 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.932250 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.938531 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.945187 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.945608 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.945842 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.953312 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.961737 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.970747 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.970795 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.981195 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.987994 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980219.993909 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.006868 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.017645 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.019510 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.032598 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.043471 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.045952 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.059996 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.062918 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.066431 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.073704 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.079311 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.088577 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.092064 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.104513 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.104940 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.118444 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.118667 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.132812 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.137510 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.146817 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.157232 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.160726 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.161943 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.178129 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.178443 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.192180 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.196653 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.211528 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.231297 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.252718 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.270931 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.280095 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.354261 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.379327 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.454414 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.476225 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.551448 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.580318 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.654433 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.698518 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.773340 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.796538 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980220.870700 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980225.436779 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980225.449561 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980225.462789 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980225.476942 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980225.492404 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980225.508119 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980225.523991 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980225.541126 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980225.558255 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980225.575715 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980225.594713 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980225.614381 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980225.633710 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980225.656345 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980225.680983 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980225.705139 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980225.729830 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980225.762114 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980225.796617 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980225.841733 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980225.957388 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980225.984717 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.003411 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.024155 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.044697 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.065379 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.089025 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.114495 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.114898 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.127763 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.138871 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.141037 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.151682 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.155399 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.164545 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.171007 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.171360 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.177656 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.186959 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.192294 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.197113 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.203120 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.207997 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.220543 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.222861 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.223956 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.237917 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.240208 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.248351 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.255484 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.257892 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.274331 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.274852 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.275341 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.292976 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.294774 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.300514 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.312271 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.314265 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.324478 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.332279 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.336894 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.351937 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.352279 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.361627 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.375010 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.377902 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.385988 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.400064 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.410852 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.424347 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.443026 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.449179 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.466051 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.477519 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.481604 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.495240 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.516460 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.522866 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.528895 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.562084 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.640784 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.643992 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.666934 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.678879 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.685611 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.705685 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.706186 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.724378 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.726768 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.745277 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.747546 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.747712 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.766126 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.771811 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.787141 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.797156 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.811447 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.821153 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.837006 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.853219 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.855571 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.861196 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.879075 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.893760 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.904768 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.919669 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.930636 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.945455 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.957042 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.959597 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.971639 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.983426 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980226.998105 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.007556 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.024421 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.035380 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.048489 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.060904 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.075735 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.076160 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.101694 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.144806 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.173870 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.177972 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.196577 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.207010 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.207500 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.240359 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.323682 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.356343 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.428561 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.470675 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.536814 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.576280 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.643464 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.682758 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.761360 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.789901 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.882713 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980227.912471 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.410923 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.425000 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.442179 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.460373 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.479479 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.504646 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.532089 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.565088 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.598365 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.633618 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.673739 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.700955 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.834467 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.858291 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.865553 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.872980 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.880539 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.888394 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.896263 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.904523 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.913336 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.921048 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.931588 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.939394 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.949765 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.960555 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980287.972420 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.018478 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.070528 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.075729 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.090161 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.107404 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.124217 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.126816 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.147809 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.175100 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.175575 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.204703 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.234351 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.239044 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.275674 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.285295 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.312584 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.353697 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.378576 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.380343 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.392759 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.409980 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.428903 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.449146 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.475408 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.503780 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.515008 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.538711 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.540380 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.548161 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.555910 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.563497 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.571396 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.573108 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.579508 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.588011 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.597072 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.604958 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.608849 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.615686 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.623690 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.634358 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.645467 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.649138 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.657599 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.675500 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.704323 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.757980 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.808601 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.809625 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.833850 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.841489 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.849277 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.856920 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.864492 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.864743 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.872548 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.880839 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.889685 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.897436 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.907965 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.915871 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.925811 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.926429 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.937355 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.949364 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.977818 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980288.995756 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980289.048981 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980289.103690 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980289.154588 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980289.213377 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980289.265006 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980290.925831 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980290.933141 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980290.940362 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980290.947863 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980290.956006 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980290.964479 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980290.972930 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980290.982517 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980290.992057 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.002019 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.012781 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.023922 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.034964 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.047820 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.061849 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.075356 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.088869 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.106340 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.125298 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.149643 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.217621 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.227280 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.236873 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.246860 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.256902 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.266454 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.276524 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.288414 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.300229 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.309989 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.322082 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.335468 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.349995 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.363092 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.378026 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.390886 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.404287 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.422371 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.437147 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.451974 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.501936 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.542218 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.558276 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.581103 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.608045 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.624564 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.631962 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.639314 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.646928 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.655458 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.659857 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.664002 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.672975 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.682790 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.692662 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.702833 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.712129 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.713913 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.725374 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.736745 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.750039 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.764428 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.771130 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.778289 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.792307 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.810259 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.824469 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.829727 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.854801 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.878549 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.922978 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.924095 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.930370 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.933199 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.934166 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.937677 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.944224 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.945265 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.953693 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.954391 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.962341 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.964731 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.971143 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.974492 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.980944 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.984860 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.990625 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980291.996719 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.000642 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.008717 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.011567 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.018711 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.022844 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.031073 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.033984 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.044700 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.046911 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.059557 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.061077 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.072990 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.074871 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.088356 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.088690 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.101558 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.106444 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.115266 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.125601 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.133677 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.148659 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.150209 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.163699 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.218194 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.219229 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.229153 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.239112 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.249161 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.258270 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.259523 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.269265 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.274240 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.279742 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.291648 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.297301 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.306616 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.316425 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.324301 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.328210 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.341251 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.355517 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.368695 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.377102 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.383874 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.396908 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.410441 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.428601 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.430540 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.443171 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.458045 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.490712 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.507593 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.545780 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.547945 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.563904 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.586835 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.601067 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.613773 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.656061 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.665770 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.718330 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.778320 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.832205 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.886473 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980292.942305 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980321.959939 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980321.967956 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980321.977223 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980321.986861 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980321.997079 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.011061 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.026521 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.042999 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.060566 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.079912 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.103479 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.129458 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.193484 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.237026 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.245459 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.255181 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.257266 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.265270 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.269278 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.272986 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.275933 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.276662 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.280636 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.284702 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.288709 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.290296 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.292880 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.297425 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.301439 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.306232 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.306577 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.310641 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.316017 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.321663 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.323055 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.327838 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.341009 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.352698 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.360694 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.381081 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.384850 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.408262 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.411440 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.436291 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.467098 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.476377 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.493675 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.542120 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.554751 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.558592 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.562427 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.566397 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.570426 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.574403 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.578699 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.583469 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.587585 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.592816 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.596959 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.602504 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.608340 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.614730 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.640117 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.669257 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.696869 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.708409 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.716576 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.725731 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.725985 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.736338 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.747043 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.757443 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.761268 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.776679 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.784845 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.793172 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.811057 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.830565 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.854308 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.880379 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980322.943770 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.008897 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.021727 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.025506 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.029289 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.033183 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.037168 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.041075 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.045134 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.049549 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.053344 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.058168 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.062006 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.067079 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.072390 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.078180 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.101870 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.130864 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.158577 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.186861 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.217854 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.244798 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.828826 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.832788 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.836649 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.840700 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.844980 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.849255 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.853457 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.858102 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.862652 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.867373 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.872857 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.878537 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.884190 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.891130 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.899400 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.906599 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.913969 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.923462 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.935304 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.948023 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.985166 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.990645 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980323.995864 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.001079 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.005999 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.011515 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.017153 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.023848 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.031805 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.039681 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.047474 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.055275 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.062610 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.071069 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.079474 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.086712 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.093426 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.101684 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.112026 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.121228 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.121809 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.125859 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.129821 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.130558 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.133968 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.138059 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.138339 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.142645 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.146859 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.149801 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.151872 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.156792 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.160658 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.161878 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.167352 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.173193 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.174201 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.179034 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.186126 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.188088 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.194628 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.202072 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.209815 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.214613 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.219524 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.231727 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.241179 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.244829 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.268186 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.283723 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.289376 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.294766 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.295165 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.300175 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.305322 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.310945 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.316757 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.323587 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.326529 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.331748 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.339781 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.347720 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.355678 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.358318 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.363162 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.371833 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.380449 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.387872 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.394759 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.402670 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.413311 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.422782 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.432337 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.439962 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.451862 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.462826 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.476524 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.490543 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.517017 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.544260 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.572019 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.599114 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.599906 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.603128 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.607040 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.611134 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.615451 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.619700 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.623873 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.628823 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.632164 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.633703 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.638746 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.644150 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.649941 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.655732 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.662800 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.664390 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.671174 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.678497 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.686114 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.695864 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.708051 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.721081 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.759194 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.764782 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.770140 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.775499 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.780560 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.786140 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.791874 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.798634 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.806751 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.814781 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.822706 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.830639 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.838098 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.846725 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.855310 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.862649 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.869464 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.877175 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.887544 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.896956 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.906449 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.914005 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.925834 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.936741 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.950415 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.964443 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980324.991129 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980325.018158 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980325.045542 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980325.072952 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980325.104588 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980325.136521 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.059963 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.064514 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.069380 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.074377 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.079726 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.086269 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.093617 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.101832 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.110722 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.123379 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.135494 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.160714 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.215008 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.246145 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.250983 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.251192 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.256111 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.261398 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.267153 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.274147 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.281813 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.290163 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.295816 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.298143 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.299216 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.300425 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.302815 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.305191 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.307747 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.310103 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.312073 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.312346 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.314751 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.318546 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.321510 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.324450 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.324654 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.328094 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.331087 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.334915 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.348120 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.350175 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.362548 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.376546 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.391031 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.405597 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.417620 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.443326 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.487846 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.490413 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.492739 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.495175 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.497616 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.500249 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.502666 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.505040 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.507552 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.511495 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.514563 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.517794 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.521350 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.524449 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.528428 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.541963 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.557010 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.572264 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.586807 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.613992 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.822416 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.827079 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.832100 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.837241 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.842758 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.849498 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.857062 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.865341 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.874397 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.887200 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.899570 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.924840 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980339.977233 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.010563 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.054622 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.057064 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.059356 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.061764 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.064169 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.066751 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.069120 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.071373 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.073733 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.077438 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.080491 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.083707 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.087407 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.087590 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.090036 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.090520 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.092418 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.094488 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.094895 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.097443 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.099950 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.102584 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.105291 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.108059 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.108264 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.110917 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.113872 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.116769 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.120448 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.123227 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.124144 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.128135 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.132515 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.137640 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.137895 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.144350 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.152739 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.166496 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.169625 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.172877 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.176050 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.179606 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.179859 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.183490 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.187865 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.191441 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.195017 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.199054 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.203513 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.207653 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.212266 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.217102 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.220795 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.225926 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.231032 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.236150 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.241821 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.247486 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.253957 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.263003 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.276215 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.283377 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.285901 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.288321 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.289930 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.290841 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.293425 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.295991 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.298671 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.301412 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.303591 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.304184 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.307071 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.310201 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.313423 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.317296 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.317482 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.321290 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.325387 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.329918 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.331058 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.335252 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.342305 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.346993 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.363025 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.365021 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.368279 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.371605 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.374869 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.378424 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.382399 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.386894 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.390580 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.394220 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.398329 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.402962 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.407231 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.411986 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.416987 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.420777 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.425995 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.431250 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.436476 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.442264 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.448048 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.454628 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.463796 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.477333 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.491299 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.505262 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.519307 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.533464 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.549961 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.566668 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.857940 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.860393 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.862791 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.865292 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.867854 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.870391 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.873061 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.875787 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.878542 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.881432 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.884559 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.887744 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.891691 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.895433 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.899512 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.904003 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.909237 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.916152 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.938574 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.941796 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.945100 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.948308 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.951818 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.955743 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.960197 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.963847 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.967457 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.971523 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.976049 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.980245 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.984933 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.989830 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.993603 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980340.998786 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980341.003969 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980341.009170 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980341.014872 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980341.020576 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980341.027092 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980341.036208 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980341.049701 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980341.063622 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980341.077560 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980341.091543 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980341.105619 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980341.121945 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980341.138456 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.298244 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.301386 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.304587 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.307794 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.311461 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.315355 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.319480 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.323848 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.328558 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.334994 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.341505 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.349604 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.363380 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.379098 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.396997 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.425392 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.459735 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.461098 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.462401 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.463757 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.465167 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.466673 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.468014 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.469292 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.470642 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.472663 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.474210 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.475903 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.477752 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.479755 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.481373 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.488434 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.496125 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.503985 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.510629 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.511759 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.514034 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.517528 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.520935 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.524710 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.525445 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.528803 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.533170 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.537751 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.542719 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.549440 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.556346 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.564710 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.579041 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.594556 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.612601 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.641210 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.677103 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.678826 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.680181 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.681593 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.683029 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.684558 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.685914 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.687212 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.688574 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.690599 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.692171 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.693894 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.695935 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.697814 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.699451 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.706568 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.714499 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.722475 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.730694 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.744846 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.864122 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.865587 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.866985 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.868390 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.869869 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.871349 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.872872 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.874445 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.876054 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.877698 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.879370 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.881026 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.883081 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.885153 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.887351 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.889713 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.892529 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.895946 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.910454 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.912320 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.914342 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.916792 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.919060 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.921558 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.924172 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.926908 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.929198 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.931544 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.933594 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.936387 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.939838 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.942633 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.946894 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.950103 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.953306 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.957972 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.962615 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.967814 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.973008 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.979827 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.986631 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980346.993428 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.000262 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.008156 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.016032 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.025121 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.033748 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.084803 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.086279 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.087694 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.089125 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.090623 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.092114 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.093668 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.095261 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.096874 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.098532 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.100228 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.101900 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.103971 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.106038 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.108233 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.110746 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.113711 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.114550 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.117372 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.117791 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.121087 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.124374 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.128163 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.132139 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.132226 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.134084 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.136170 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.136450 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.138722 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.141113 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.141203 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.143817 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.145956 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.146570 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.149396 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.151785 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.152501 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.154232 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.156330 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.159289 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.159358 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.162942 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.165849 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.167606 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.170325 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.173656 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.176981 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.181574 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.181837 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.186666 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.191960 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.197013 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.197273 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.204248 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.211202 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.215000 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.218115 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.225006 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.233121 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.241295 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.243957 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.250631 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.259531 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.277042 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.279134 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.280441 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.281822 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.283250 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.284757 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.286118 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.287406 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.288768 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.290802 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.292370 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.294101 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.295982 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.298018 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.299659 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.306808 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.314649 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.322633 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.330538 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.344374 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.687170 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.688633 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.690037 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.691462 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.692949 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.694437 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.695979 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.697566 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.699173 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.700832 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.702520 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.704186 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.706250 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.708316 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.710530 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.712904 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.715661 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.719259 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.733903 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.735979 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.738229 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.740834 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.743352 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.746109 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.748973 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.751836 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.754212 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.756630 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.758713 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.761571 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.765095 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.767954 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.772253 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.775537 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.778788 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.783518 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.788268 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.793594 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.798912 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.805878 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.812830 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.819787 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.826740 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.834711 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.842871 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.852187 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980347.860985 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.711861 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.713795 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.715867 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.717936 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.720230 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.722625 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.725138 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.727668 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.730416 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.746803 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.751016 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.756690 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.762771 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.770487 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.779904 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.792969 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.823640 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.824692 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.825697 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.826845 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.828074 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.829303 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.830593 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.831821 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.832888 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.833946 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.835254 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.836751 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.838162 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.839339 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.840764 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.842111 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.846220 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.850259 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.854324 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.858379 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.863795 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.912473 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.914542 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.916782 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.919014 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.921523 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.924136 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.926925 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.929744 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.932803 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.950442 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.955011 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.961133 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.967832 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.976139 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.985964 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980349.999735 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.030344 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.031417 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.032449 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.033611 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.034866 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.035210 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.036258 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.036375 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.037498 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.037674 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.038555 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.038944 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.039653 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.040039 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.040988 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.041146 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.042383 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.042559 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.043701 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.044095 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.045084 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.045537 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.046503 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.046749 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.047890 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.048219 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.049422 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.049624 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.050804 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.052454 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.053744 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.054178 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.055849 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.057824 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.058205 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.060308 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.062082 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.066335 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.070237 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.071983 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.072448 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.074230 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.076161 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.077587 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.079388 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.081002 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.082841 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.084452 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.085879 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.087545 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.089606 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.091730 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.093499 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.095221 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.096948 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.099244 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.101542 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.104271 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.106786 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.109297 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.112268 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.115245 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.118744 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.122235 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.125742 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.129247 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.135101 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.139118 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.143109 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.147615 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.244000 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.245087 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.246190 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.247234 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.248328 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.249625 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.250976 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.252298 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.253674 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.255108 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.256499 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.258003 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.259361 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.261016 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.262739 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.264418 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.266754 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.268710 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.278375 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.280547 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.282199 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.284021 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.285458 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.287326 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.288991 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.290916 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.292584 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.294058 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.295766 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.297893 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.300097 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.301922 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.303710 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.305501 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.307876 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.310251 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.313077 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.315654 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.318228 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.321305 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.324386 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.328013 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.331641 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.335278 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.338897 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.344851 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.348946 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.353029 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.357633 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.543271 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.545316 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.547496 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.549694 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.552149 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.554730 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.557437 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.560125 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.563045 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.580236 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.584671 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.590636 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.597090 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.605065 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.614846 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.628475 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.659144 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.660200 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.661212 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.662350 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.663579 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.664815 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.666111 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.667351 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.668420 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.669486 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.670802 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.672287 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.673708 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.674899 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.676337 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.677688 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.681801 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.685844 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.689919 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.693989 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.699443 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.872953 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.874033 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.875120 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.876167 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.877249 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.878533 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.879884 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.881174 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.882548 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.883969 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.885352 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.886850 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.888219 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.889874 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.891540 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.893202 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.895528 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.897483 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.907125 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.909282 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.910925 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.912710 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.914119 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.915950 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.917590 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.919467 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.921112 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.922567 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.924251 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.926354 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.928509 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.930315 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.932064 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.933823 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.936157 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.938497 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.941262 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.943807 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.946349 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.949330 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.952305 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.955876 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.959431 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.962980 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.966543 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.972479 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.976545 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.980592 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980350.985161 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.411304 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.412590 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.413868 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.415366 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.416761 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.418282 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.419983 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.421494 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.430817 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.434843 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.440160 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.446094 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.450969 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.461693 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.462415 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.463096 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.463876 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.464653 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.465439 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.466114 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.466935 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.467771 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.468455 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.469274 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.470047 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.470994 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.472068 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.472998 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.473888 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.476395 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.480068 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.482907 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.485819 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.488810 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.574591 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.575335 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.576034 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.576744 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.577460 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.578301 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.579195 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.580083 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.580950 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.581841 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.582747 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.583665 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.584644 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.585680 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.586875 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.588047 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.595888 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.597017 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.598086 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.599181 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.600427 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.601681 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.602979 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.604305 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.605666 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.607034 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.608046 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.609308 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.610535 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.611773 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.613083 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.614393 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.615648 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.616908 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.618200 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.620335 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.622469 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.622814 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.624165 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.624853 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.625535 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.627134 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.628205 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.628627 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.630221 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.631565 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.632013 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.633597 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.634926 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.638281 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.643538 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.647787 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.653297 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.659480 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.664581 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.675247 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.675988 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.676675 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.677479 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.678266 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.679065 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.679750 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.680587 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.681440 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.682127 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.682965 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.683745 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.684693 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.685769 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.686713 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.687605 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.690103 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.693811 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.696663 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.699584 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.702589 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.789730 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.790474 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.791175 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.791894 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.792616 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.793459 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.794370 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.795269 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.796141 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.797060 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.797975 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.798902 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.799887 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.800937 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.802141 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.803340 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.811174 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.812300 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.813379 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.814470 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.815726 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.816989 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.818316 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.819649 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.821033 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.822421 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.823434 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.824698 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.825928 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.827167 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.828478 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.829786 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.831052 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.832310 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.833604 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.835754 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.837908 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.840299 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.843697 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.847088 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.850486 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980351.853938 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.238333 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.239373 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.240357 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.241532 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.242632 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.243756 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.244927 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.246323 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.247729 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.250226 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.250382 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.251721 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.253077 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.254624 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.256248 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.256347 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.257850 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.259737 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.259834 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.261309 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.263835 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.268861 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.270968 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.275190 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.280713 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.282345 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.283288 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.284531 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.285778 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.287138 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.287149 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.288440 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.289728 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.291024 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.292443 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.292452 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.294152 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.295847 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.297670 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.299377 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.300666 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.301939 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.303228 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.303258 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.304007 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.304639 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.304745 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.305540 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.305937 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.306344 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.307352 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.307367 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.308047 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.308640 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.308887 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.309757 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.309938 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.310455 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.311283 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.312069 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.313022 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.314092 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.315017 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.315908 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.318397 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.319435 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.320724 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.322107 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.322731 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.324221 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.325077 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.326065 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.327355 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.328014 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.328689 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.330155 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.331014 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.331869 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.334150 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.341202 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.344093 2950990 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.417913 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.418661 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.419348 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.420057 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.420773 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.421616 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.422517 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.423410 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.424282 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.425186 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.426099 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.427029 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.428016 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.429063 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.430270 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.431423 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.438833 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.439204 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.439945 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.440328 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.441010 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.441408 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.442283 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.442521 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.443486 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.443794 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.444736 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.445072 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.446033 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.446388 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.447611 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.447764 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.449262 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.449273 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.450661 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.451676 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.451992 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.452961 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.454203 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.455442 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.456758 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.458074 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.458574 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.459342 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.460595 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.462020 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.462099 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.464172 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.466404 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.466429 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.468798 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.471842 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.472172 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.475530 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.478980 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.482423 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.485086 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.486061 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.487351 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.488644 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.489776 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.491091 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.492399 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.493713 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.494979 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.496690 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.498396 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.500104 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.501829 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.503136 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.504397 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.505670 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.506937 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.508203 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.509476 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.510753 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.512013 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.521493 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.522772 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.524763 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.526271 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.527925 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.529225 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.530551 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.532029 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.533733 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.536016 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.542967 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980352.545802 2950982 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51:22\u001b[0m 171s/step - loss: 1.7941"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1727980353.090474 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.091555 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.092572 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.093778 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.094928 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.096106 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.097328 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.098784 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.100258 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.102697 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.108586 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.111762 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.115800 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.120981 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.133790 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.134788 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.136072 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.137346 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.138464 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.139750 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.141030 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.142314 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.143578 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.145296 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.146998 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.148695 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.150403 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.151694 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.152948 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.154219 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.155484 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.156750 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.158025 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.159284 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.160542 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.169972 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.171248 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.173236 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.174729 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.176393 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.177673 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.178997 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.180459 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.182161 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.184440 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.191467 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727980353.194349 2950977 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 1.0010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 18:32:40.509650: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-10-03 18:32:40.509777: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-10-03 18:32:40.509932: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 240ms/step - loss: 0.9897 - val_loss: 0.0689 - learning_rate: 0.0010\n",
      "Epoch 2/820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 18:32:42.450537: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0501"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 18:32:50.628111: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0500 - val_loss: 0.0519 - learning_rate: 0.0010\n",
      "Epoch 3/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0335 - val_loss: 0.0801 - learning_rate: 0.0010\n",
      "Epoch 4/820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 18:33:00.959345: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0312 - val_loss: 0.0846 - learning_rate: 0.0010\n",
      "Epoch 5/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0271 - val_loss: 0.0810 - learning_rate: 0.0010\n",
      "Epoch 6/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 18:33:27.313240: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0250 - val_loss: 0.0513 - learning_rate: 0.0010\n",
      "Epoch 7/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0245 - val_loss: 0.0451 - learning_rate: 0.0010\n",
      "Epoch 8/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0231 - val_loss: 0.0415 - learning_rate: 0.0010\n",
      "Epoch 9/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0234 - val_loss: 0.0402 - learning_rate: 0.0010\n",
      "Epoch 10/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0222 - val_loss: 0.0281 - learning_rate: 0.0010\n",
      "Epoch 11/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0201 - val_loss: 0.0278 - learning_rate: 0.0010\n",
      "Epoch 12/820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 18:34:13.779945: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0196 - val_loss: 0.0231 - learning_rate: 0.0010\n",
      "Epoch 13/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0188 - val_loss: 0.0214 - learning_rate: 0.0010\n",
      "Epoch 14/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0181 - val_loss: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 15/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0183 - val_loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 16/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0205 - val_loss: 0.0188 - learning_rate: 0.0010\n",
      "Epoch 17/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0181 - val_loss: 0.0305 - learning_rate: 0.0010\n",
      "Epoch 18/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0171 - val_loss: 0.0203 - learning_rate: 0.0010\n",
      "Epoch 19/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0165 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 20/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0175 - val_loss: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 21/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0171 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 22/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0160"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 18:35:51.606985: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0160 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 23/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0154 - val_loss: 0.0188 - learning_rate: 0.0010\n",
      "Epoch 24/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0155 - val_loss: 0.0188 - learning_rate: 0.0010\n",
      "Epoch 25/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0162 - val_loss: 0.0188 - learning_rate: 0.0010\n",
      "Epoch 26/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0161 - val_loss: 0.0413 - learning_rate: 0.0010\n",
      "Epoch 27/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0160 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 28/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0150 - val_loss: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 29/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0148 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 30/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0151 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 31/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0149 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 32/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0149 - val_loss: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 33/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0146 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 34/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0146 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 35/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0146 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 36/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0142 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 37/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0145 - val_loss: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 38/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0144 - val_loss: 0.0191 - learning_rate: 0.0010\n",
      "Epoch 39/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0154 - val_loss: 0.0379 - learning_rate: 0.0010\n",
      "Epoch 40/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0144 - val_loss: 0.0202 - learning_rate: 0.0010\n",
      "Epoch 41/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0142 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 42/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0139\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0139 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 43/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0138 - val_loss: 0.0155 - learning_rate: 9.0000e-04\n",
      "Epoch 44/820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 18:38:58.175625: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0139 - val_loss: 0.0173 - learning_rate: 9.0000e-04\n",
      "Epoch 45/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0138 - val_loss: 0.0150 - learning_rate: 9.0000e-04\n",
      "Epoch 46/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0136 - val_loss: 0.0138 - learning_rate: 9.0000e-04\n",
      "Epoch 47/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0135 - val_loss: 0.0141 - learning_rate: 9.0000e-04\n",
      "Epoch 48/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0133 - val_loss: 0.0144 - learning_rate: 9.0000e-04\n",
      "Epoch 49/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0133 - val_loss: 0.0144 - learning_rate: 9.0000e-04\n",
      "Epoch 50/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0132 - val_loss: 0.0140 - learning_rate: 9.0000e-04\n",
      "Epoch 51/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0132 - val_loss: 0.0134 - learning_rate: 9.0000e-04\n",
      "Epoch 52/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0130 - val_loss: 0.0139 - learning_rate: 9.0000e-04\n",
      "Epoch 53/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0131 - val_loss: 0.0129 - learning_rate: 9.0000e-04\n",
      "Epoch 54/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0130 - val_loss: 0.0141 - learning_rate: 9.0000e-04\n",
      "Epoch 55/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0129 - val_loss: 0.0131 - learning_rate: 9.0000e-04\n",
      "Epoch 56/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0129 - val_loss: 0.0134 - learning_rate: 9.0000e-04\n",
      "Epoch 57/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0129 - val_loss: 0.0132 - learning_rate: 9.0000e-04\n",
      "Epoch 58/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0133 - val_loss: 0.1160 - learning_rate: 9.0000e-04\n",
      "Epoch 59/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0130 - val_loss: 0.0465 - learning_rate: 9.0000e-04\n",
      "Epoch 60/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0130 - val_loss: 0.0280 - learning_rate: 9.0000e-04\n",
      "Epoch 61/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0128 - val_loss: 0.0149 - learning_rate: 9.0000e-04\n",
      "Epoch 62/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0129 - val_loss: 0.0144 - learning_rate: 9.0000e-04\n",
      "Epoch 63/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0129\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0130 - val_loss: 0.0171 - learning_rate: 9.0000e-04\n",
      "Epoch 64/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0130 - val_loss: 0.0233 - learning_rate: 8.1000e-04\n",
      "Epoch 65/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: 0.0128 - val_loss: 0.0177 - learning_rate: 8.1000e-04\n",
      "Epoch 66/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0129 - val_loss: 0.0145 - learning_rate: 8.1000e-04\n",
      "Epoch 67/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0126 - val_loss: 0.0132 - learning_rate: 8.1000e-04\n",
      "Epoch 68/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0126 - val_loss: 0.0129 - learning_rate: 8.1000e-04\n",
      "Epoch 69/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0126 - val_loss: 0.0127 - learning_rate: 8.1000e-04\n",
      "Epoch 70/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0125 - val_loss: 0.0128 - learning_rate: 8.1000e-04\n",
      "Epoch 71/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0126 - val_loss: 0.0132 - learning_rate: 8.1000e-04\n",
      "Epoch 72/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0127 - val_loss: 0.0124 - learning_rate: 8.1000e-04\n",
      "Epoch 73/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0125 - val_loss: 0.0129 - learning_rate: 8.1000e-04\n",
      "Epoch 74/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0125 - val_loss: 0.0129 - learning_rate: 8.1000e-04\n",
      "Epoch 75/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0124 - val_loss: 0.0130 - learning_rate: 8.1000e-04\n",
      "Epoch 76/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0123 - val_loss: 0.0131 - learning_rate: 8.1000e-04\n",
      "Epoch 77/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0124 - val_loss: 0.0131 - learning_rate: 8.1000e-04\n",
      "Epoch 78/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0126 - val_loss: 0.0132 - learning_rate: 8.1000e-04\n",
      "Epoch 79/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0124 - val_loss: 0.0127 - learning_rate: 8.1000e-04\n",
      "Epoch 80/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0124 - val_loss: 0.0122 - learning_rate: 8.1000e-04\n",
      "Epoch 81/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0125 - val_loss: 0.0152 - learning_rate: 8.1000e-04\n",
      "Epoch 82/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0124 - val_loss: 0.0135 - learning_rate: 8.1000e-04\n",
      "Epoch 83/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0123 - val_loss: 0.0137 - learning_rate: 8.1000e-04\n",
      "Epoch 84/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0123 - val_loss: 0.0139 - learning_rate: 8.1000e-04\n",
      "Epoch 85/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0121 - val_loss: 0.0133 - learning_rate: 8.1000e-04\n",
      "Epoch 86/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0122"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 18:45:15.806962: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0122 - val_loss: 0.0163 - learning_rate: 8.1000e-04\n",
      "Epoch 87/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0123 - val_loss: 0.0130 - learning_rate: 8.1000e-04\n",
      "Epoch 88/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0123 - val_loss: 0.0127 - learning_rate: 8.1000e-04\n",
      "Epoch 89/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0122 - val_loss: 0.0129 - learning_rate: 8.1000e-04\n",
      "Epoch 90/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0121\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0121 - val_loss: 0.0125 - learning_rate: 8.1000e-04\n",
      "Epoch 91/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0122 - val_loss: 0.0133 - learning_rate: 7.2900e-04\n",
      "Epoch 92/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0121 - val_loss: 0.0156 - learning_rate: 7.2900e-04\n",
      "Epoch 93/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0122 - val_loss: 0.0121 - learning_rate: 7.2900e-04\n",
      "Epoch 94/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0121 - val_loss: 0.0122 - learning_rate: 7.2900e-04\n",
      "Epoch 95/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0121 - val_loss: 0.0128 - learning_rate: 7.2900e-04\n",
      "Epoch 96/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0121 - val_loss: 0.0136 - learning_rate: 7.2900e-04\n",
      "Epoch 97/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0120 - val_loss: 0.0122 - learning_rate: 7.2900e-04\n",
      "Epoch 98/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0125 - val_loss: 0.0136 - learning_rate: 7.2900e-04\n",
      "Epoch 99/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0120 - val_loss: 0.0125 - learning_rate: 7.2900e-04\n",
      "Epoch 100/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0120 - val_loss: 0.0131 - learning_rate: 7.2900e-04\n",
      "Epoch 101/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0120 - val_loss: 0.0133 - learning_rate: 7.2900e-04\n",
      "Epoch 102/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0121 - val_loss: 0.0123 - learning_rate: 7.2900e-04\n",
      "Epoch 103/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0119\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0119 - val_loss: 0.0130 - learning_rate: 7.2900e-04\n",
      "Epoch 104/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0119 - val_loss: 0.0127 - learning_rate: 6.5610e-04\n",
      "Epoch 105/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0118 - val_loss: 0.0124 - learning_rate: 6.5610e-04\n",
      "Epoch 106/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0118 - val_loss: 0.0121 - learning_rate: 6.5610e-04\n",
      "Epoch 107/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0119 - val_loss: 0.0152 - learning_rate: 6.5610e-04\n",
      "Epoch 108/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0124 - val_loss: 0.0140 - learning_rate: 6.5610e-04\n",
      "Epoch 109/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0119 - val_loss: 0.0147 - learning_rate: 6.5610e-04\n",
      "Epoch 110/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0121 - val_loss: 0.0206 - learning_rate: 6.5610e-04\n",
      "Epoch 111/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0119 - val_loss: 0.0131 - learning_rate: 6.5610e-04\n",
      "Epoch 112/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0118 - val_loss: 0.0129 - learning_rate: 6.5610e-04\n",
      "Epoch 113/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0119\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0119 - val_loss: 0.0123 - learning_rate: 6.5610e-04\n",
      "Epoch 114/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: 0.0119 - val_loss: 0.0122 - learning_rate: 5.9049e-04\n",
      "Epoch 115/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0118 - val_loss: 0.0136 - learning_rate: 5.9049e-04\n",
      "Epoch 116/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0118 - val_loss: 0.0148 - learning_rate: 5.9049e-04\n",
      "Epoch 117/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0117 - val_loss: 0.0126 - learning_rate: 5.9049e-04\n",
      "Epoch 118/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0117 - val_loss: 0.0142 - learning_rate: 5.9049e-04\n",
      "Epoch 119/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0117 - val_loss: 0.0129 - learning_rate: 5.9049e-04\n",
      "Epoch 120/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0117 - val_loss: 0.0122 - learning_rate: 5.9049e-04\n",
      "Epoch 121/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0117 - val_loss: 0.0121 - learning_rate: 5.9049e-04\n",
      "Epoch 122/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0116 - val_loss: 0.0123 - learning_rate: 5.9049e-04\n",
      "Epoch 123/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0117\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0117 - val_loss: 0.0437 - learning_rate: 5.9049e-04\n",
      "Epoch 124/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 218ms/step - loss: 0.0117 - val_loss: 0.0230 - learning_rate: 5.3144e-04\n",
      "Epoch 125/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0116 - val_loss: 0.0196 - learning_rate: 5.3144e-04\n",
      "Epoch 126/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0115 - val_loss: 0.0194 - learning_rate: 5.3144e-04\n",
      "Epoch 127/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0115 - val_loss: 0.0152 - learning_rate: 5.3144e-04\n",
      "Epoch 128/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0115 - val_loss: 0.0151 - learning_rate: 5.3144e-04\n",
      "Epoch 129/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0114 - val_loss: 0.0139 - learning_rate: 5.3144e-04\n",
      "Epoch 130/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0114 - val_loss: 0.0163 - learning_rate: 5.3144e-04\n",
      "Epoch 131/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0114 - val_loss: 0.0216 - learning_rate: 5.3144e-04\n",
      "Epoch 132/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0115 - val_loss: 0.0176 - learning_rate: 5.3144e-04\n",
      "Epoch 133/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0114\n",
      "Epoch 133: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0115 - val_loss: 0.0120 - learning_rate: 5.3144e-04\n",
      "Epoch 134/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0114 - val_loss: 0.0117 - learning_rate: 4.7830e-04\n",
      "Epoch 135/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0113 - val_loss: 0.0119 - learning_rate: 4.7830e-04\n",
      "Epoch 136/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0112 - val_loss: 0.0119 - learning_rate: 4.7830e-04\n",
      "Epoch 137/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0113 - val_loss: 0.0120 - learning_rate: 4.7830e-04\n",
      "Epoch 138/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0112 - val_loss: 0.0119 - learning_rate: 4.7830e-04\n",
      "Epoch 139/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0112 - val_loss: 0.0121 - learning_rate: 4.7830e-04\n",
      "Epoch 140/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0112 - val_loss: 0.0120 - learning_rate: 4.7830e-04\n",
      "Epoch 141/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0112 - val_loss: 0.0118 - learning_rate: 4.7830e-04\n",
      "Epoch 142/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0111 - val_loss: 0.0116 - learning_rate: 4.7830e-04\n",
      "Epoch 143/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0111 - val_loss: 0.0118 - learning_rate: 4.7830e-04\n",
      "Epoch 144/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0111\n",
      "Epoch 144: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0111 - val_loss: 0.0135 - learning_rate: 4.7830e-04\n",
      "Epoch 145/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0110 - val_loss: 0.0124 - learning_rate: 4.3047e-04\n",
      "Epoch 146/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0114 - val_loss: 0.0118 - learning_rate: 4.3047e-04\n",
      "Epoch 147/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0110 - val_loss: 0.0121 - learning_rate: 4.3047e-04\n",
      "Epoch 148/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0110 - val_loss: 0.0123 - learning_rate: 4.3047e-04\n",
      "Epoch 149/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0110 - val_loss: 0.0118 - learning_rate: 4.3047e-04\n",
      "Epoch 150/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0109 - val_loss: 0.0118 - learning_rate: 4.3047e-04\n",
      "Epoch 151/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0109 - val_loss: 0.0160 - learning_rate: 4.3047e-04\n",
      "Epoch 152/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0109 - val_loss: 0.0210 - learning_rate: 4.3047e-04\n",
      "Epoch 153/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0109 - val_loss: 0.0169 - learning_rate: 4.3047e-04\n",
      "Epoch 154/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0109\n",
      "Epoch 154: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0109 - val_loss: 0.0116 - learning_rate: 4.3047e-04\n",
      "Epoch 155/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0108 - val_loss: 0.0116 - learning_rate: 3.8742e-04\n",
      "Epoch 156/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0108 - val_loss: 0.0117 - learning_rate: 3.8742e-04\n",
      "Epoch 157/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0107 - val_loss: 0.0116 - learning_rate: 3.8742e-04\n",
      "Epoch 158/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0107 - val_loss: 0.0116 - learning_rate: 3.8742e-04\n",
      "Epoch 159/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0106 - val_loss: 0.0116 - learning_rate: 3.8742e-04\n",
      "Epoch 160/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0107 - val_loss: 0.0114 - learning_rate: 3.8742e-04\n",
      "Epoch 161/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0106 - val_loss: 0.0116 - learning_rate: 3.8742e-04\n",
      "Epoch 162/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0106 - val_loss: 0.0114 - learning_rate: 3.8742e-04\n",
      "Epoch 163/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0106 - val_loss: 0.0114 - learning_rate: 3.8742e-04\n",
      "Epoch 164/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0106 - val_loss: 0.0116 - learning_rate: 3.8742e-04\n",
      "Epoch 165/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0105 - val_loss: 0.0416 - learning_rate: 3.8742e-04\n",
      "Epoch 166/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0105 - val_loss: 0.0329 - learning_rate: 3.8742e-04\n",
      "Epoch 167/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0107 - val_loss: 0.0196 - learning_rate: 3.8742e-04\n",
      "Epoch 168/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0104 - val_loss: 0.0576 - learning_rate: 3.8742e-04\n",
      "Epoch 169/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0105 - val_loss: 0.0341 - learning_rate: 3.8742e-04\n",
      "Epoch 170/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0104\n",
      "Epoch 170: ReduceLROnPlateau reducing learning rate to 0.0003486784757114947.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0105 - val_loss: 0.0247 - learning_rate: 3.8742e-04\n",
      "Epoch 171/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0104 - val_loss: 0.0156 - learning_rate: 3.4868e-04\n",
      "Epoch 172/820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 18:57:45.262696: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0104 - val_loss: 0.0118 - learning_rate: 3.4868e-04\n",
      "Epoch 173/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0103 - val_loss: 0.0116 - learning_rate: 3.4868e-04\n",
      "Epoch 174/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0103 - val_loss: 0.0114 - learning_rate: 3.4868e-04\n",
      "Epoch 175/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0102 - val_loss: 0.0115 - learning_rate: 3.4868e-04\n",
      "Epoch 176/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0103 - val_loss: 0.0115 - learning_rate: 3.4868e-04\n",
      "Epoch 177/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0103 - val_loss: 0.0115 - learning_rate: 3.4868e-04\n",
      "Epoch 178/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0103 - val_loss: 0.0110 - learning_rate: 3.4868e-04\n",
      "Epoch 179/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0102 - val_loss: 0.0111 - learning_rate: 3.4868e-04\n",
      "Epoch 180/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0103 - val_loss: 0.0132 - learning_rate: 3.4868e-04\n",
      "Epoch 181/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0102 - val_loss: 0.0116 - learning_rate: 3.4868e-04\n",
      "Epoch 182/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - loss: 0.0102 - val_loss: 0.0118 - learning_rate: 3.4868e-04\n",
      "Epoch 183/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: 0.0102 - val_loss: 0.0170 - learning_rate: 3.4868e-04\n",
      "Epoch 184/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0101 - val_loss: 0.0171 - learning_rate: 3.4868e-04\n",
      "Epoch 185/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0100 - val_loss: 0.0116 - learning_rate: 3.4868e-04\n",
      "Epoch 186/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0101 - val_loss: 0.0255 - learning_rate: 3.4868e-04\n",
      "Epoch 187/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0101 - val_loss: 0.0116 - learning_rate: 3.4868e-04\n",
      "Epoch 188/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0100\n",
      "Epoch 188: ReduceLROnPlateau reducing learning rate to 0.00031381062290165574.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0101 - val_loss: 0.0113 - learning_rate: 3.4868e-04\n",
      "Epoch 189/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0100 - val_loss: 0.0118 - learning_rate: 3.1381e-04\n",
      "Epoch 190/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0100 - val_loss: 0.0135 - learning_rate: 3.1381e-04\n",
      "Epoch 191/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0100 - val_loss: 0.0118 - learning_rate: 3.1381e-04\n",
      "Epoch 192/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0099 - val_loss: 0.0166 - learning_rate: 3.1381e-04\n",
      "Epoch 193/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0099 - val_loss: 0.0112 - learning_rate: 3.1381e-04\n",
      "Epoch 194/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0098 - val_loss: 0.0116 - learning_rate: 3.1381e-04\n",
      "Epoch 195/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0098 - val_loss: 0.0115 - learning_rate: 3.1381e-04\n",
      "Epoch 196/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0098 - val_loss: 0.0248 - learning_rate: 3.1381e-04\n",
      "Epoch 197/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0098 - val_loss: 0.0187 - learning_rate: 3.1381e-04\n",
      "Epoch 198/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0097\n",
      "Epoch 198: ReduceLROnPlateau reducing learning rate to 0.0002824295632308349.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0097 - val_loss: 0.0260 - learning_rate: 3.1381e-04\n",
      "Epoch 199/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0097 - val_loss: 0.0223 - learning_rate: 2.8243e-04\n",
      "Epoch 200/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0097 - val_loss: 0.0113 - learning_rate: 2.8243e-04\n",
      "Epoch 201/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0097 - val_loss: 0.0115 - learning_rate: 2.8243e-04\n",
      "Epoch 202/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0096 - val_loss: 0.0115 - learning_rate: 2.8243e-04\n",
      "Epoch 203/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0096 - val_loss: 0.0114 - learning_rate: 2.8243e-04\n",
      "Epoch 204/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0097 - val_loss: 0.0116 - learning_rate: 2.8243e-04\n",
      "Epoch 205/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0096 - val_loss: 0.0113 - learning_rate: 2.8243e-04\n",
      "Epoch 206/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0096 - val_loss: 0.0212 - learning_rate: 2.8243e-04\n",
      "Epoch 207/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0096 - val_loss: 0.0149 - learning_rate: 2.8243e-04\n",
      "Epoch 208/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0096\n",
      "Epoch 208: ReduceLROnPlateau reducing learning rate to 0.00025418660952709616.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0097 - val_loss: 0.0113 - learning_rate: 2.8243e-04\n",
      "Epoch 209/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0096 - val_loss: 0.0112 - learning_rate: 2.5419e-04\n",
      "Epoch 210/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0096 - val_loss: 0.0113 - learning_rate: 2.5419e-04\n",
      "Epoch 211/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0095 - val_loss: 0.0113 - learning_rate: 2.5419e-04\n",
      "Epoch 212/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0095 - val_loss: 0.0113 - learning_rate: 2.5419e-04\n",
      "Epoch 213/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0095 - val_loss: 0.0114 - learning_rate: 2.5419e-04\n",
      "Epoch 214/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0094 - val_loss: 0.0110 - learning_rate: 2.5419e-04\n",
      "Epoch 215/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0094 - val_loss: 0.0113 - learning_rate: 2.5419e-04\n",
      "Epoch 216/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0094 - val_loss: 0.0112 - learning_rate: 2.5419e-04\n",
      "Epoch 217/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0094 - val_loss: 0.0113 - learning_rate: 2.5419e-04\n",
      "Epoch 218/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0093\n",
      "Epoch 218: ReduceLROnPlateau reducing learning rate to 0.00022876793809700757.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0093 - val_loss: 0.0111 - learning_rate: 2.5419e-04\n",
      "Epoch 219/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0094 - val_loss: 0.0115 - learning_rate: 2.2877e-04\n",
      "Epoch 220/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0094 - val_loss: 0.0115 - learning_rate: 2.2877e-04\n",
      "Epoch 221/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0094 - val_loss: 0.0196 - learning_rate: 2.2877e-04\n",
      "Epoch 222/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0092 - val_loss: 0.0248 - learning_rate: 2.2877e-04\n",
      "Epoch 223/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0093 - val_loss: 0.0172 - learning_rate: 2.2877e-04\n",
      "Epoch 224/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0093 - val_loss: 0.0119 - learning_rate: 2.2877e-04\n",
      "Epoch 225/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0092 - val_loss: 0.0136 - learning_rate: 2.2877e-04\n",
      "Epoch 226/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0093 - val_loss: 0.0158 - learning_rate: 2.2877e-04\n",
      "Epoch 227/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0092 - val_loss: 0.0201 - learning_rate: 2.2877e-04\n",
      "Epoch 228/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0092\n",
      "Epoch 228: ReduceLROnPlateau reducing learning rate to 0.00020589114428730683.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0092 - val_loss: 0.0170 - learning_rate: 2.2877e-04\n",
      "Epoch 229/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0092 - val_loss: 0.0179 - learning_rate: 2.0589e-04\n",
      "Epoch 230/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0092 - val_loss: 0.0110 - learning_rate: 2.0589e-04\n",
      "Epoch 231/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0092 - val_loss: 0.0260 - learning_rate: 2.0589e-04\n",
      "Epoch 232/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0092 - val_loss: 0.0202 - learning_rate: 2.0589e-04\n",
      "Epoch 233/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0091 - val_loss: 0.0224 - learning_rate: 2.0589e-04\n",
      "Epoch 234/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0091 - val_loss: 0.0170 - learning_rate: 2.0589e-04\n",
      "Epoch 235/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0092 - val_loss: 0.0111 - learning_rate: 2.0589e-04\n",
      "Epoch 236/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0091 - val_loss: 0.0112 - learning_rate: 2.0589e-04\n",
      "Epoch 237/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0091 - val_loss: 0.0111 - learning_rate: 2.0589e-04\n",
      "Epoch 238/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0090\n",
      "Epoch 238: ReduceLROnPlateau reducing learning rate to 0.00018530203378759326.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0091 - val_loss: 0.0111 - learning_rate: 2.0589e-04\n",
      "Epoch 239/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0091 - val_loss: 0.0112 - learning_rate: 1.8530e-04\n",
      "Epoch 240/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0090 - val_loss: 0.0113 - learning_rate: 1.8530e-04\n",
      "Epoch 241/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0091 - val_loss: 0.0109 - learning_rate: 1.8530e-04\n",
      "Epoch 242/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0091 - val_loss: 0.0108 - learning_rate: 1.8530e-04\n",
      "Epoch 243/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0090 - val_loss: 0.0112 - learning_rate: 1.8530e-04\n",
      "Epoch 244/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0090 - val_loss: 0.0111 - learning_rate: 1.8530e-04\n",
      "Epoch 245/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0090 - val_loss: 0.0110 - learning_rate: 1.8530e-04\n",
      "Epoch 246/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0089 - val_loss: 0.0117 - learning_rate: 1.8530e-04\n",
      "Epoch 247/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0090 - val_loss: 0.0109 - learning_rate: 1.8530e-04\n",
      "Epoch 248/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0089 - val_loss: 0.0111 - learning_rate: 1.8530e-04\n",
      "Epoch 249/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0089 - val_loss: 0.0110 - learning_rate: 1.8530e-04\n",
      "Epoch 250/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0089 - val_loss: 0.0111 - learning_rate: 1.8530e-04\n",
      "Epoch 251/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0088\n",
      "Epoch 251: ReduceLROnPlateau reducing learning rate to 0.00016677183302817866.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0089 - val_loss: 0.0108 - learning_rate: 1.8530e-04\n",
      "Epoch 252/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0089 - val_loss: 0.0112 - learning_rate: 1.6677e-04\n",
      "Epoch 253/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0088 - val_loss: 0.0112 - learning_rate: 1.6677e-04\n",
      "Epoch 254/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0089 - val_loss: 0.0108 - learning_rate: 1.6677e-04\n",
      "Epoch 255/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0088 - val_loss: 0.0115 - learning_rate: 1.6677e-04\n",
      "Epoch 256/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0089 - val_loss: 0.0110 - learning_rate: 1.6677e-04\n",
      "Epoch 257/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0088 - val_loss: 0.0107 - learning_rate: 1.6677e-04\n",
      "Epoch 258/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: 0.0088 - val_loss: 0.0110 - learning_rate: 1.6677e-04\n",
      "Epoch 259/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0088 - val_loss: 0.0110 - learning_rate: 1.6677e-04\n",
      "Epoch 260/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0089 - val_loss: 0.0110 - learning_rate: 1.6677e-04\n",
      "Epoch 261/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0088 - val_loss: 0.0109 - learning_rate: 1.6677e-04\n",
      "Epoch 262/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0088 - val_loss: 0.0112 - learning_rate: 1.6677e-04\n",
      "Epoch 263/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0087 - val_loss: 0.0108 - learning_rate: 1.6677e-04\n",
      "Epoch 264/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0088 - val_loss: 0.0111 - learning_rate: 1.6677e-04\n",
      "Epoch 265/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: 0.0088 - val_loss: 0.0111 - learning_rate: 1.6677e-04\n",
      "Epoch 266/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0088 - val_loss: 0.0109 - learning_rate: 1.6677e-04\n",
      "Epoch 267/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0087\n",
      "Epoch 267: ReduceLROnPlateau reducing learning rate to 0.00015009464841568844.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0087 - val_loss: 0.0109 - learning_rate: 1.6677e-04\n",
      "Epoch 268/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0087 - val_loss: 0.0109 - learning_rate: 1.5009e-04\n",
      "Epoch 269/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0087 - val_loss: 0.0111 - learning_rate: 1.5009e-04\n",
      "Epoch 270/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0087 - val_loss: 0.0109 - learning_rate: 1.5009e-04\n",
      "Epoch 271/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0086 - val_loss: 0.0109 - learning_rate: 1.5009e-04\n",
      "Epoch 272/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0087 - val_loss: 0.0110 - learning_rate: 1.5009e-04\n",
      "Epoch 273/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0087 - val_loss: 0.0109 - learning_rate: 1.5009e-04\n",
      "Epoch 274/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0087 - val_loss: 0.0109 - learning_rate: 1.5009e-04\n",
      "Epoch 275/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0087 - val_loss: 0.0109 - learning_rate: 1.5009e-04\n",
      "Epoch 276/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0086 - val_loss: 0.0108 - learning_rate: 1.5009e-04\n",
      "Epoch 277/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0086\n",
      "Epoch 277: ReduceLROnPlateau reducing learning rate to 0.0001350851875031367.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0087 - val_loss: 0.0111 - learning_rate: 1.5009e-04\n",
      "Epoch 278/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0085 - val_loss: 0.0109 - learning_rate: 1.3509e-04\n",
      "Epoch 279/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0085 - val_loss: 0.0149 - learning_rate: 1.3509e-04\n",
      "Epoch 280/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0085 - val_loss: 0.0110 - learning_rate: 1.3509e-04\n",
      "Epoch 281/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0086 - val_loss: 0.0108 - learning_rate: 1.3509e-04\n",
      "Epoch 282/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0086 - val_loss: 0.0110 - learning_rate: 1.3509e-04\n",
      "Epoch 283/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0086 - val_loss: 0.0108 - learning_rate: 1.3509e-04\n",
      "Epoch 284/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0085 - val_loss: 0.0109 - learning_rate: 1.3509e-04\n",
      "Epoch 285/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0086 - val_loss: 0.0108 - learning_rate: 1.3509e-04\n",
      "Epoch 286/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0087 - val_loss: 0.0108 - learning_rate: 1.3509e-04\n",
      "Epoch 287/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0085\n",
      "Epoch 287: ReduceLROnPlateau reducing learning rate to 0.00012157666351413355.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0085 - val_loss: 0.0111 - learning_rate: 1.3509e-04\n",
      "Epoch 288/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0085 - val_loss: 0.0111 - learning_rate: 1.2158e-04\n",
      "Epoch 289/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0085 - val_loss: 0.0108 - learning_rate: 1.2158e-04\n",
      "Epoch 290/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0086 - val_loss: 0.0110 - learning_rate: 1.2158e-04\n",
      "Epoch 291/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0085 - val_loss: 0.0110 - learning_rate: 1.2158e-04\n",
      "Epoch 292/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0085 - val_loss: 0.0111 - learning_rate: 1.2158e-04\n",
      "Epoch 293/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0084 - val_loss: 0.0136 - learning_rate: 1.2158e-04\n",
      "Epoch 294/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0086 - val_loss: 0.0110 - learning_rate: 1.2158e-04\n",
      "Epoch 295/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0085 - val_loss: 0.0110 - learning_rate: 1.2158e-04\n",
      "Epoch 296/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0085 - val_loss: 0.0108 - learning_rate: 1.2158e-04\n",
      "Epoch 297/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0084\n",
      "Epoch 297: ReduceLROnPlateau reducing learning rate to 0.00010941899454337544.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0084 - val_loss: 0.0111 - learning_rate: 1.2158e-04\n",
      "Epoch 298/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0085 - val_loss: 0.0107 - learning_rate: 1.0942e-04\n",
      "Epoch 299/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0084 - val_loss: 0.0108 - learning_rate: 1.0942e-04\n",
      "Epoch 300/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0084 - val_loss: 0.0108 - learning_rate: 1.0942e-04\n",
      "Epoch 301/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0084 - val_loss: 0.0109 - learning_rate: 1.0942e-04\n",
      "Epoch 302/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0084 - val_loss: 0.0110 - learning_rate: 1.0942e-04\n",
      "Epoch 303/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0084 - val_loss: 0.0110 - learning_rate: 1.0942e-04\n",
      "Epoch 304/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 226ms/step - loss: 0.0083 - val_loss: 0.0112 - learning_rate: 1.0942e-04\n",
      "Epoch 305/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 214ms/step - loss: 0.0083 - val_loss: 0.0107 - learning_rate: 1.0942e-04\n",
      "Epoch 306/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0084 - val_loss: 0.0110 - learning_rate: 1.0942e-04\n",
      "Epoch 307/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0083\n",
      "Epoch 307: ReduceLROnPlateau reducing learning rate to 9.847709443420172e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0083 - val_loss: 0.0110 - learning_rate: 1.0942e-04\n",
      "Epoch 308/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0084 - val_loss: 0.0113 - learning_rate: 9.8477e-05\n",
      "Epoch 309/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0083 - val_loss: 0.0110 - learning_rate: 9.8477e-05\n",
      "Epoch 310/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: 0.0083 - val_loss: 0.0109 - learning_rate: 9.8477e-05\n",
      "Epoch 311/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0083 - val_loss: 0.0109 - learning_rate: 9.8477e-05\n",
      "Epoch 312/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0083 - val_loss: 0.0111 - learning_rate: 9.8477e-05\n",
      "Epoch 313/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0082 - val_loss: 0.0111 - learning_rate: 9.8477e-05\n",
      "Epoch 314/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0083 - val_loss: 0.0110 - learning_rate: 9.8477e-05\n",
      "Epoch 315/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0082 - val_loss: 0.0110 - learning_rate: 9.8477e-05\n",
      "Epoch 316/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0083 - val_loss: 0.0108 - learning_rate: 9.8477e-05\n",
      "Epoch 317/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0082\n",
      "Epoch 317: ReduceLROnPlateau reducing learning rate to 8.862938630045391e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0083 - val_loss: 0.0109 - learning_rate: 9.8477e-05\n",
      "Epoch 318/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0083 - val_loss: 0.0109 - learning_rate: 8.8629e-05\n",
      "Epoch 319/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 227ms/step - loss: 0.0082 - val_loss: 0.0110 - learning_rate: 8.8629e-05\n",
      "Epoch 320/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0082 - val_loss: 0.0109 - learning_rate: 8.8629e-05\n",
      "Epoch 321/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0082 - val_loss: 0.0110 - learning_rate: 8.8629e-05\n",
      "Epoch 322/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0083 - val_loss: 0.0109 - learning_rate: 8.8629e-05\n",
      "Epoch 323/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0082 - val_loss: 0.0107 - learning_rate: 8.8629e-05\n",
      "Epoch 324/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0083 - val_loss: 0.0109 - learning_rate: 8.8629e-05\n",
      "Epoch 325/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0082 - val_loss: 0.0109 - learning_rate: 8.8629e-05\n",
      "Epoch 326/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0082 - val_loss: 0.0108 - learning_rate: 8.8629e-05\n",
      "Epoch 327/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0082\n",
      "Epoch 327: ReduceLROnPlateau reducing learning rate to 7.976644701557234e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0083 - val_loss: 0.0108 - learning_rate: 8.8629e-05\n",
      "Epoch 328/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0082 - val_loss: 0.0108 - learning_rate: 7.9766e-05\n",
      "Epoch 329/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0082 - val_loss: 0.0108 - learning_rate: 7.9766e-05\n",
      "Epoch 330/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: 0.0082 - val_loss: 0.0107 - learning_rate: 7.9766e-05\n",
      "Epoch 331/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0082 - val_loss: 0.0109 - learning_rate: 7.9766e-05\n",
      "Epoch 332/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0082 - val_loss: 0.0109 - learning_rate: 7.9766e-05\n",
      "Epoch 333/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0082 - val_loss: 0.0107 - learning_rate: 7.9766e-05\n",
      "Epoch 334/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0081 - val_loss: 0.0109 - learning_rate: 7.9766e-05\n",
      "Epoch 335/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0081 - val_loss: 0.0108 - learning_rate: 7.9766e-05\n",
      "Epoch 336/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0082 - val_loss: 0.0107 - learning_rate: 7.9766e-05\n",
      "Epoch 337/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0081\n",
      "Epoch 337: ReduceLROnPlateau reducing learning rate to 7.178980231401511e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0082 - val_loss: 0.0107 - learning_rate: 7.9766e-05\n",
      "Epoch 338/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0081 - val_loss: 0.0109 - learning_rate: 7.1790e-05\n",
      "Epoch 339/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0081 - val_loss: 0.0108 - learning_rate: 7.1790e-05\n",
      "Epoch 340/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0081 - val_loss: 0.0109 - learning_rate: 7.1790e-05\n",
      "Epoch 341/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0081 - val_loss: 0.0109 - learning_rate: 7.1790e-05\n",
      "Epoch 342/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0081 - val_loss: 0.0108 - learning_rate: 7.1790e-05\n",
      "Epoch 343/820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 19:22:53.601745: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0080 - val_loss: 0.0108 - learning_rate: 7.1790e-05\n",
      "Epoch 344/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0081 - val_loss: 0.0107 - learning_rate: 7.1790e-05\n",
      "Epoch 345/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0081 - val_loss: 0.0109 - learning_rate: 7.1790e-05\n",
      "Epoch 346/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0081 - val_loss: 0.0120 - learning_rate: 7.1790e-05\n",
      "Epoch 347/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0081\n",
      "Epoch 347: ReduceLROnPlateau reducing learning rate to 6.461082011810504e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0082 - val_loss: 0.0112 - learning_rate: 7.1790e-05\n",
      "Epoch 348/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0081 - val_loss: 0.0107 - learning_rate: 6.4611e-05\n",
      "Epoch 349/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0080 - val_loss: 0.0108 - learning_rate: 6.4611e-05\n",
      "Epoch 350/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0081 - val_loss: 0.0109 - learning_rate: 6.4611e-05\n",
      "Epoch 351/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0080 - val_loss: 0.0106 - learning_rate: 6.4611e-05\n",
      "Epoch 352/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0080 - val_loss: 0.0107 - learning_rate: 6.4611e-05\n",
      "Epoch 353/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0080 - val_loss: 0.0107 - learning_rate: 6.4611e-05\n",
      "Epoch 354/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0080 - val_loss: 0.0110 - learning_rate: 6.4611e-05\n",
      "Epoch 355/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0080 - val_loss: 0.0110 - learning_rate: 6.4611e-05\n",
      "Epoch 356/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0080 - val_loss: 0.0111 - learning_rate: 6.4611e-05\n",
      "Epoch 357/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0080 - val_loss: 0.0104 - learning_rate: 6.4611e-05\n",
      "Epoch 358/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0080 - val_loss: 0.0107 - learning_rate: 6.4611e-05\n",
      "Epoch 359/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: 0.0080 - val_loss: 0.0106 - learning_rate: 6.4611e-05\n",
      "Epoch 360/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0080 - val_loss: 0.0109 - learning_rate: 6.4611e-05\n",
      "Epoch 361/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0080 - val_loss: 0.0110 - learning_rate: 6.4611e-05\n",
      "Epoch 362/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0080 - val_loss: 0.0108 - learning_rate: 6.4611e-05\n",
      "Epoch 363/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0080 - val_loss: 0.0109 - learning_rate: 6.4611e-05\n",
      "Epoch 364/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0080 - val_loss: 0.0109 - learning_rate: 6.4611e-05\n",
      "Epoch 365/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0080 - val_loss: 0.0111 - learning_rate: 6.4611e-05\n",
      "Epoch 366/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0080 - val_loss: 0.0110 - learning_rate: 6.4611e-05\n",
      "Epoch 367/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0079\n",
      "Epoch 367: ReduceLROnPlateau reducing learning rate to 5.8149741380475466e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0080 - val_loss: 0.0108 - learning_rate: 6.4611e-05\n",
      "Epoch 368/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0079 - val_loss: 0.0107 - learning_rate: 5.8150e-05\n",
      "Epoch 369/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0079 - val_loss: 0.0109 - learning_rate: 5.8150e-05\n",
      "Epoch 370/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0080 - val_loss: 0.0107 - learning_rate: 5.8150e-05\n",
      "Epoch 371/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0079 - val_loss: 0.0108 - learning_rate: 5.8150e-05\n",
      "Epoch 372/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0079 - val_loss: 0.0106 - learning_rate: 5.8150e-05\n",
      "Epoch 373/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0080 - val_loss: 0.0108 - learning_rate: 5.8150e-05\n",
      "Epoch 374/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0080 - val_loss: 0.0109 - learning_rate: 5.8150e-05\n",
      "Epoch 375/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0080 - val_loss: 0.0109 - learning_rate: 5.8150e-05\n",
      "Epoch 376/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0079 - val_loss: 0.0107 - learning_rate: 5.8150e-05\n",
      "Epoch 377/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0078\n",
      "Epoch 377: ReduceLROnPlateau reducing learning rate to 5.233476658759173e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0078 - val_loss: 0.0109 - learning_rate: 5.8150e-05\n",
      "Epoch 378/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0079 - val_loss: 0.0107 - learning_rate: 5.2335e-05\n",
      "Epoch 379/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0079 - val_loss: 0.0108 - learning_rate: 5.2335e-05\n",
      "Epoch 380/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0079 - val_loss: 0.0108 - learning_rate: 5.2335e-05\n",
      "Epoch 381/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0079 - val_loss: 0.0109 - learning_rate: 5.2335e-05\n",
      "Epoch 382/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0079 - val_loss: 0.0109 - learning_rate: 5.2335e-05\n",
      "Epoch 383/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0079 - val_loss: 0.0111 - learning_rate: 5.2335e-05\n",
      "Epoch 384/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0078 - val_loss: 0.0108 - learning_rate: 5.2335e-05\n",
      "Epoch 385/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0080 - val_loss: 0.0110 - learning_rate: 5.2335e-05\n",
      "Epoch 386/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0079 - val_loss: 0.0108 - learning_rate: 5.2335e-05\n",
      "Epoch 387/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0078\n",
      "Epoch 387: ReduceLROnPlateau reducing learning rate to 4.7101289601414466e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0079 - val_loss: 0.0107 - learning_rate: 5.2335e-05\n",
      "Epoch 388/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - loss: 0.0079 - val_loss: 0.0108 - learning_rate: 4.7101e-05\n",
      "Epoch 389/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: 0.0078 - val_loss: 0.0106 - learning_rate: 4.7101e-05\n",
      "Epoch 390/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0078 - val_loss: 0.0109 - learning_rate: 4.7101e-05\n",
      "Epoch 391/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0079 - val_loss: 0.0106 - learning_rate: 4.7101e-05\n",
      "Epoch 392/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0078 - val_loss: 0.0110 - learning_rate: 4.7101e-05\n",
      "Epoch 393/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0078 - val_loss: 0.0106 - learning_rate: 4.7101e-05\n",
      "Epoch 394/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0078 - val_loss: 0.0107 - learning_rate: 4.7101e-05\n",
      "Epoch 395/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0078 - val_loss: 0.0110 - learning_rate: 4.7101e-05\n",
      "Epoch 396/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0079 - val_loss: 0.0108 - learning_rate: 4.7101e-05\n",
      "Epoch 397/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0077\n",
      "Epoch 397: ReduceLROnPlateau reducing learning rate to 4.239116096869111e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0078 - val_loss: 0.0108 - learning_rate: 4.7101e-05\n",
      "Epoch 398/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0078 - val_loss: 0.0105 - learning_rate: 4.2391e-05\n",
      "Epoch 399/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0078 - val_loss: 0.0108 - learning_rate: 4.2391e-05\n",
      "Epoch 400/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0078 - val_loss: 0.0106 - learning_rate: 4.2391e-05\n",
      "Epoch 401/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0078 - val_loss: 0.0110 - learning_rate: 4.2391e-05\n",
      "Epoch 402/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0078 - val_loss: 0.0107 - learning_rate: 4.2391e-05\n",
      "Epoch 403/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0078 - val_loss: 0.0109 - learning_rate: 4.2391e-05\n",
      "Epoch 404/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0078 - val_loss: 0.0110 - learning_rate: 4.2391e-05\n",
      "Epoch 405/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0078 - val_loss: 0.0107 - learning_rate: 4.2391e-05\n",
      "Epoch 406/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0078 - val_loss: 0.0110 - learning_rate: 4.2391e-05\n",
      "Epoch 407/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0077\n",
      "Epoch 407: ReduceLROnPlateau reducing learning rate to 3.815204618149437e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0078 - val_loss: 0.0111 - learning_rate: 4.2391e-05\n",
      "Epoch 408/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0078 - val_loss: 0.0108 - learning_rate: 3.8152e-05\n",
      "Epoch 409/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0078 - val_loss: 0.0109 - learning_rate: 3.8152e-05\n",
      "Epoch 410/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0078 - val_loss: 0.0108 - learning_rate: 3.8152e-05\n",
      "Epoch 411/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0077 - val_loss: 0.0110 - learning_rate: 3.8152e-05\n",
      "Epoch 412/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0077 - val_loss: 0.0109 - learning_rate: 3.8152e-05\n",
      "Epoch 413/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0077 - val_loss: 0.0107 - learning_rate: 3.8152e-05\n",
      "Epoch 414/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0077 - val_loss: 0.0106 - learning_rate: 3.8152e-05\n",
      "Epoch 415/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0077 - val_loss: 0.0109 - learning_rate: 3.8152e-05\n",
      "Epoch 416/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0077 - val_loss: 0.0109 - learning_rate: 3.8152e-05\n",
      "Epoch 417/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0076\n",
      "Epoch 417: ReduceLROnPlateau reducing learning rate to 3.4336842873017304e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0077 - val_loss: 0.0108 - learning_rate: 3.8152e-05\n",
      "Epoch 418/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0077 - val_loss: 0.0107 - learning_rate: 3.4337e-05\n",
      "Epoch 419/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0078 - val_loss: 0.0108 - learning_rate: 3.4337e-05\n",
      "Epoch 420/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0077 - val_loss: 0.0110 - learning_rate: 3.4337e-05\n",
      "Epoch 421/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0077 - val_loss: 0.0105 - learning_rate: 3.4337e-05\n",
      "Epoch 422/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0077 - val_loss: 0.0108 - learning_rate: 3.4337e-05\n",
      "Epoch 423/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0077 - val_loss: 0.0108 - learning_rate: 3.4337e-05\n",
      "Epoch 424/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: 0.0077 - val_loss: 0.0109 - learning_rate: 3.4337e-05\n",
      "Epoch 425/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0077 - val_loss: 0.0109 - learning_rate: 3.4337e-05\n",
      "Epoch 426/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - loss: 0.0077 - val_loss: 0.0108 - learning_rate: 3.4337e-05\n",
      "Epoch 427/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0077\n",
      "Epoch 427: ReduceLROnPlateau reducing learning rate to 3.0903160222806036e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0077 - val_loss: 0.0107 - learning_rate: 3.4337e-05\n",
      "Epoch 428/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0076 - val_loss: 0.0108 - learning_rate: 3.0903e-05\n",
      "Epoch 429/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0077 - val_loss: 0.0108 - learning_rate: 3.0903e-05\n",
      "Epoch 430/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0077 - val_loss: 0.0109 - learning_rate: 3.0903e-05\n",
      "Epoch 431/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0077 - val_loss: 0.0109 - learning_rate: 3.0903e-05\n",
      "Epoch 432/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0076 - val_loss: 0.0107 - learning_rate: 3.0903e-05\n",
      "Epoch 433/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0076 - val_loss: 0.0107 - learning_rate: 3.0903e-05\n",
      "Epoch 434/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0076 - val_loss: 0.0109 - learning_rate: 3.0903e-05\n",
      "Epoch 435/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0077 - val_loss: 0.0109 - learning_rate: 3.0903e-05\n",
      "Epoch 436/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: 0.0077 - val_loss: 0.0108 - learning_rate: 3.0903e-05\n",
      "Epoch 437/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0076\n",
      "Epoch 437: ReduceLROnPlateau reducing learning rate to 3e-05.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0076 - val_loss: 0.0109 - learning_rate: 3.0903e-05\n",
      "Epoch 438/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0076 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 439/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0077 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 440/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0077 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 441/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0077 - val_loss: 0.0105 - learning_rate: 3.0000e-05\n",
      "Epoch 442/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0076 - val_loss: 0.0108 - learning_rate: 3.0000e-05\n",
      "Epoch 443/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0076 - val_loss: 0.0107 - learning_rate: 3.0000e-05\n",
      "Epoch 444/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0077 - val_loss: 0.0107 - learning_rate: 3.0000e-05\n",
      "Epoch 445/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0076 - val_loss: 0.0107 - learning_rate: 3.0000e-05\n",
      "Epoch 446/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0076 - val_loss: 0.0108 - learning_rate: 3.0000e-05\n",
      "Epoch 447/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0076 - val_loss: 0.0107 - learning_rate: 3.0000e-05\n",
      "Epoch 448/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0076 - val_loss: 0.0106 - learning_rate: 3.0000e-05\n",
      "Epoch 449/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0076 - val_loss: 0.0108 - learning_rate: 3.0000e-05\n",
      "Epoch 450/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0076 - val_loss: 0.0107 - learning_rate: 3.0000e-05\n",
      "Epoch 451/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0076 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 452/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0076 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 453/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0076 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 454/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0076 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 455/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0076 - val_loss: 0.0107 - learning_rate: 3.0000e-05\n",
      "Epoch 456/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0076 - val_loss: 0.0108 - learning_rate: 3.0000e-05\n",
      "Epoch 457/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0076 - val_loss: 0.0106 - learning_rate: 3.0000e-05\n",
      "Epoch 458/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0076 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 459/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0076 - val_loss: 0.0105 - learning_rate: 3.0000e-05\n",
      "Epoch 460/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0075 - val_loss: 0.0106 - learning_rate: 3.0000e-05\n",
      "Epoch 461/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0076 - val_loss: 0.0107 - learning_rate: 3.0000e-05\n",
      "Epoch 462/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0076 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 463/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0076 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 464/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0075 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 465/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0076 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 466/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0076 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 467/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0076 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 468/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0075 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 469/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: 0.0076 - val_loss: 0.0106 - learning_rate: 3.0000e-05\n",
      "Epoch 470/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0076 - val_loss: 0.0107 - learning_rate: 3.0000e-05\n",
      "Epoch 471/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0076 - val_loss: 0.0106 - learning_rate: 3.0000e-05\n",
      "Epoch 472/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0076 - val_loss: 0.0106 - learning_rate: 3.0000e-05\n",
      "Epoch 473/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0076 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 474/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 223ms/step - loss: 0.0075 - val_loss: 0.0108 - learning_rate: 3.0000e-05\n",
      "Epoch 475/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0075 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 476/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0076 - val_loss: 0.0107 - learning_rate: 3.0000e-05\n",
      "Epoch 477/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0075 - val_loss: 0.0107 - learning_rate: 3.0000e-05\n",
      "Epoch 478/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0075 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 479/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: 0.0076 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 480/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0076 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 481/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0075 - val_loss: 0.0107 - learning_rate: 3.0000e-05\n",
      "Epoch 482/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0076 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 483/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0076 - val_loss: 0.0108 - learning_rate: 3.0000e-05\n",
      "Epoch 484/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0075 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 485/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0075 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 486/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0075 - val_loss: 0.0107 - learning_rate: 3.0000e-05\n",
      "Epoch 487/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0076 - val_loss: 0.0107 - learning_rate: 3.0000e-05\n",
      "Epoch 488/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0076 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 489/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0075 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 490/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0075 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 491/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0075 - val_loss: 0.0107 - learning_rate: 3.0000e-05\n",
      "Epoch 492/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0075 - val_loss: 0.0113 - learning_rate: 3.0000e-05\n",
      "Epoch 493/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0075 - val_loss: 0.0108 - learning_rate: 3.0000e-05\n",
      "Epoch 494/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0075 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 495/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0075 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 496/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0075 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 497/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0075 - val_loss: 0.0107 - learning_rate: 3.0000e-05\n",
      "Epoch 498/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0074 - val_loss: 0.0107 - learning_rate: 3.0000e-05\n",
      "Epoch 499/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0075 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 500/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0075 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 501/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0075 - val_loss: 0.0107 - learning_rate: 3.0000e-05\n",
      "Epoch 502/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0075 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 503/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0075 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 504/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0075 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 505/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0075 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 506/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0074 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 507/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0075 - val_loss: 0.0108 - learning_rate: 3.0000e-05\n",
      "Epoch 508/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0074 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 509/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0075 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 510/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0075 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 511/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0075 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 512/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0075 - val_loss: 0.0108 - learning_rate: 3.0000e-05\n",
      "Epoch 513/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0075 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 514/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0075 - val_loss: 0.0106 - learning_rate: 3.0000e-05\n",
      "Epoch 515/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0075 - val_loss: 0.0108 - learning_rate: 3.0000e-05\n",
      "Epoch 516/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0074 - val_loss: 0.0108 - learning_rate: 3.0000e-05\n",
      "Epoch 517/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0075 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 518/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0075 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 519/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0075 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 520/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0074 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 521/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0074 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 522/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0075 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 523/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0074 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 524/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0075 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 525/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0074 - val_loss: 0.0107 - learning_rate: 3.0000e-05\n",
      "Epoch 526/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0074 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 527/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0074 - val_loss: 0.0108 - learning_rate: 3.0000e-05\n",
      "Epoch 528/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - loss: 0.0074 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 529/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0074 - val_loss: 0.0108 - learning_rate: 3.0000e-05\n",
      "Epoch 530/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0074 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 531/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0074 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 532/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0074 - val_loss: 0.0108 - learning_rate: 3.0000e-05\n",
      "Epoch 533/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0074 - val_loss: 0.0108 - learning_rate: 3.0000e-05\n",
      "Epoch 534/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0074 - val_loss: 0.0108 - learning_rate: 3.0000e-05\n",
      "Epoch 535/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0074 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 536/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0074 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 537/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0074 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 538/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0074 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 539/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0074 - val_loss: 0.0108 - learning_rate: 3.0000e-05\n",
      "Epoch 540/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0073 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 541/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0074 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 542/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0074 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 543/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0073 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 544/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0074 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 545/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0074 - val_loss: 0.0107 - learning_rate: 3.0000e-05\n",
      "Epoch 546/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: 0.0074 - val_loss: 0.0114 - learning_rate: 3.0000e-05\n",
      "Epoch 547/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0074 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 548/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0074 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 549/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0073 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 550/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0074 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 551/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0074 - val_loss: 0.0105 - learning_rate: 3.0000e-05\n",
      "Epoch 552/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0074 - val_loss: 0.0108 - learning_rate: 3.0000e-05\n",
      "Epoch 553/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0074 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 554/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0073 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 555/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0074 - val_loss: 0.0113 - learning_rate: 3.0000e-05\n",
      "Epoch 556/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0074 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 557/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0074 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 558/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0073 - val_loss: 0.0107 - learning_rate: 3.0000e-05\n",
      "Epoch 559/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0073 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 560/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0074 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 561/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0074 - val_loss: 0.0113 - learning_rate: 3.0000e-05\n",
      "Epoch 562/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0073 - val_loss: 0.0113 - learning_rate: 3.0000e-05\n",
      "Epoch 563/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0074 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 564/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0074 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 565/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0074 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 566/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0073 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 567/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0073 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 568/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0074 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 569/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0073 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 570/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0073 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 571/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0073 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 572/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0073 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 573/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0073 - val_loss: 0.0108 - learning_rate: 3.0000e-05\n",
      "Epoch 574/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0073 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 575/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0073 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 576/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0073 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 577/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0073 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 578/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0073 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 579/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - loss: 0.0073 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 580/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0074 - val_loss: 0.0108 - learning_rate: 3.0000e-05\n",
      "Epoch 581/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0073 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 582/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0073 - val_loss: 0.0107 - learning_rate: 3.0000e-05\n",
      "Epoch 583/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0073 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 584/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - loss: 0.0073 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 585/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0073 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 586/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0074 - val_loss: 0.0108 - learning_rate: 3.0000e-05\n",
      "Epoch 587/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: 0.0073 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 588/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0072 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 589/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0073 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 590/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0072 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 591/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0072 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 592/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - loss: 0.0073 - val_loss: 0.0108 - learning_rate: 3.0000e-05\n",
      "Epoch 593/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0072 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 594/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0072 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 595/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0073 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 596/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0072 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 597/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0072 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 598/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0073 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 599/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0073 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 600/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0072 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 601/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0073 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 602/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0073 - val_loss: 0.0113 - learning_rate: 3.0000e-05\n",
      "Epoch 603/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0072 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 604/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0072 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 605/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0072 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 606/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0072 - val_loss: 0.0108 - learning_rate: 3.0000e-05\n",
      "Epoch 607/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0072 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 608/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0072 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 609/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0072 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 610/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0071 - val_loss: 0.0114 - learning_rate: 3.0000e-05\n",
      "Epoch 611/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0071 - val_loss: 0.0116 - learning_rate: 3.0000e-05\n",
      "Epoch 612/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0072 - val_loss: 0.0113 - learning_rate: 3.0000e-05\n",
      "Epoch 613/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0072 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 614/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0072 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 615/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0073 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 616/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0071 - val_loss: 0.0113 - learning_rate: 3.0000e-05\n",
      "Epoch 617/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0072 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 618/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0072 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 619/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0071 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 620/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0072 - val_loss: 0.0113 - learning_rate: 3.0000e-05\n",
      "Epoch 621/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0072 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 622/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0072 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 623/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0072 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 624/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0072 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 625/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0072 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 626/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0071 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 627/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0071 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 628/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0071 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 629/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - loss: 0.0071 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 630/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0072 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 631/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0071 - val_loss: 0.0113 - learning_rate: 3.0000e-05\n",
      "Epoch 632/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0071 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 633/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0071 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 634/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0072 - val_loss: 0.0114 - learning_rate: 3.0000e-05\n",
      "Epoch 635/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0071 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 636/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - loss: 0.0071 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 637/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0071 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 638/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - loss: 0.0072 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 639/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0071 - val_loss: 0.0113 - learning_rate: 3.0000e-05\n",
      "Epoch 640/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0070 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 641/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0071 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 642/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - loss: 0.0071 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 643/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - loss: 0.0071 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 644/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 286ms/step - loss: 0.0071 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 645/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 281ms/step - loss: 0.0071 - val_loss: 0.0113 - learning_rate: 3.0000e-05\n",
      "Epoch 646/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 280ms/step - loss: 0.0071 - val_loss: 0.0113 - learning_rate: 3.0000e-05\n",
      "Epoch 647/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 278ms/step - loss: 0.0071 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 648/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 283ms/step - loss: 0.0071 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 649/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 278ms/step - loss: 0.0071 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 650/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 238ms/step - loss: 0.0071 - val_loss: 0.0115 - learning_rate: 3.0000e-05\n",
      "Epoch 651/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - loss: 0.0071 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 652/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 212ms/step - loss: 0.0070 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 653/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 212ms/step - loss: 0.0070 - val_loss: 0.0114 - learning_rate: 3.0000e-05\n",
      "Epoch 654/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 293ms/step - loss: 0.0071 - val_loss: 0.0116 - learning_rate: 3.0000e-05\n",
      "Epoch 655/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 281ms/step - loss: 0.0071 - val_loss: 0.0114 - learning_rate: 3.0000e-05\n",
      "Epoch 656/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 277ms/step - loss: 0.0071 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 657/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 282ms/step - loss: 0.0070 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 658/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 276ms/step - loss: 0.0071 - val_loss: 0.0113 - learning_rate: 3.0000e-05\n",
      "Epoch 659/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 280ms/step - loss: 0.0071 - val_loss: 0.0115 - learning_rate: 3.0000e-05\n",
      "Epoch 660/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 280ms/step - loss: 0.0071 - val_loss: 0.0113 - learning_rate: 3.0000e-05\n",
      "Epoch 661/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0070 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 662/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 212ms/step - loss: 0.0070 - val_loss: 0.0113 - learning_rate: 3.0000e-05\n",
      "Epoch 663/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 212ms/step - loss: 0.0071 - val_loss: 0.0115 - learning_rate: 3.0000e-05\n",
      "Epoch 664/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 213ms/step - loss: 0.0071 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 665/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 213ms/step - loss: 0.0071 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 666/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 271ms/step - loss: 0.0071 - val_loss: 0.0114 - learning_rate: 3.0000e-05\n",
      "Epoch 667/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 209ms/step - loss: 0.0070 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 668/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 212ms/step - loss: 0.0070 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 669/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 211ms/step - loss: 0.0070 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 670/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 210ms/step - loss: 0.0070 - val_loss: 0.0114 - learning_rate: 3.0000e-05\n",
      "Epoch 671/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 209ms/step - loss: 0.0070 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 672/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 211ms/step - loss: 0.0070 - val_loss: 0.0113 - learning_rate: 3.0000e-05\n",
      "Epoch 673/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 212ms/step - loss: 0.0070 - val_loss: 0.0114 - learning_rate: 3.0000e-05\n",
      "Epoch 674/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 211ms/step - loss: 0.0070 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 675/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 210ms/step - loss: 0.0070 - val_loss: 0.0109 - learning_rate: 3.0000e-05\n",
      "Epoch 676/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 210ms/step - loss: 0.0070 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 677/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 212ms/step - loss: 0.0070 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 678/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 210ms/step - loss: 0.0070 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 679/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 214ms/step - loss: 0.0071 - val_loss: 0.0113 - learning_rate: 3.0000e-05\n",
      "Epoch 680/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 210ms/step - loss: 0.0069 - val_loss: 0.0114 - learning_rate: 3.0000e-05\n",
      "Epoch 681/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 210ms/step - loss: 0.0069 - val_loss: 0.0113 - learning_rate: 3.0000e-05\n",
      "Epoch 682/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 212ms/step - loss: 0.0070 - val_loss: 0.0116 - learning_rate: 3.0000e-05\n",
      "Epoch 683/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 210ms/step - loss: 0.0070 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 684/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 209ms/step - loss: 0.0070 - val_loss: 0.0110 - learning_rate: 3.0000e-05\n",
      "Epoch 685/820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 20:14:51.371075: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 212ms/step - loss: 0.0070 - val_loss: 0.0113 - learning_rate: 3.0000e-05\n",
      "Epoch 686/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 213ms/step - loss: 0.0070 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 687/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 297ms/step - loss: 0.0070 - val_loss: 0.0113 - learning_rate: 3.0000e-05\n",
      "Epoch 688/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 271ms/step - loss: 0.0070 - val_loss: 0.0113 - learning_rate: 3.0000e-05\n",
      "Epoch 689/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 278ms/step - loss: 0.0070 - val_loss: 0.0114 - learning_rate: 3.0000e-05\n",
      "Epoch 690/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - loss: 0.0070 - val_loss: 0.0113 - learning_rate: 3.0000e-05\n",
      "Epoch 691/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 212ms/step - loss: 0.0069 - val_loss: 0.0114 - learning_rate: 3.0000e-05\n",
      "Epoch 692/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 212ms/step - loss: 0.0070 - val_loss: 0.0114 - learning_rate: 3.0000e-05\n",
      "Epoch 693/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 211ms/step - loss: 0.0070 - val_loss: 0.0115 - learning_rate: 3.0000e-05\n",
      "Epoch 694/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 213ms/step - loss: 0.0069 - val_loss: 0.0114 - learning_rate: 3.0000e-05\n",
      "Epoch 695/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 212ms/step - loss: 0.0069 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 696/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 211ms/step - loss: 0.0070 - val_loss: 0.0114 - learning_rate: 3.0000e-05\n",
      "Epoch 697/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 296ms/step - loss: 0.0069 - val_loss: 0.0117 - learning_rate: 3.0000e-05\n",
      "Epoch 698/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 276ms/step - loss: 0.0069 - val_loss: 0.0113 - learning_rate: 3.0000e-05\n",
      "Epoch 699/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 277ms/step - loss: 0.0069 - val_loss: 0.0115 - learning_rate: 3.0000e-05\n",
      "Epoch 700/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 273ms/step - loss: 0.0069 - val_loss: 0.0115 - learning_rate: 3.0000e-05\n",
      "Epoch 701/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 276ms/step - loss: 0.0069 - val_loss: 0.0111 - learning_rate: 3.0000e-05\n",
      "Epoch 702/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 280ms/step - loss: 0.0070 - val_loss: 0.0112 - learning_rate: 3.0000e-05\n",
      "Epoch 703/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 279ms/step - loss: 0.0069 - val_loss: 0.0115 - learning_rate: 3.0000e-05\n",
      "Epoch 704/820\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0069"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model with the custom callback\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m820\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 71\u001b[0m, in \u001b[0;36mModelBuilder.train_model\u001b[0;34m(self, train_dataset, val_dataset, epochs, callbacks_list)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_dataset, val_dataset, epochs, callbacks_list):\n\u001b[0;32m---> 71\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:343\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_epoch_iterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[1;32m    334\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m    335\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    341\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    342\u001b[0m     )\n\u001b[0;32m--> 343\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    355\u001b[0m }\n\u001b[1;32m    356\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:429\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    428\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m--> 429\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    431\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_end(step, logs)\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/objectdetection/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model with the custom callback\n",
    "history = model_builder.train_model(\n",
    "    train_dataset, \n",
    "    val_dataset, \n",
    "    epochs=820,\n",
    "    callbacks_list=[lr_scheduler]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Extract the losses from the history object\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "train_loss_x_midpoints = history.history.get('x_midpoints_reshape_loss', train_loss)\n",
    "val_loss_x_midpoints = history.history.get('val_x_midpoints_reshape_loss', val_loss)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2,1)\n",
    "plt.plot(train_loss_x_midpoints, label='Train Loss x_midpoints_reshape')\n",
    "plt.plot(val_loss_x_midpoints, label='Validation Loss x_midpoints_reshape')\n",
    "plt.xlabel('Epochs')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss ')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_builder.model.save(\"/home/da886/Analysis/5originalmodelgeneralized.keras\")\n",
    "loaded_model = tf.keras.models.load_model(\n",
    "\"/home/da886/Final Electron counting project/Trained weights/Fixed weights/13overfitoriginalmodelgeneralized.keras\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1, batch shape: (800, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 20:34:40.491502: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1727987680.543897 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.560826 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.561144 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.563252 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.563542 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.563819 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.564112 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.572916 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.574160 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.575549 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.576890 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.578383 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.579746 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.581136 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.586441 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.661005 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.664710 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.664955 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.665189 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.665431 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.665671 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.666729 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.667905 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.668800 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.669949 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.670198 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.671321 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.671572 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.671819 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.672078 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.672331 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.672580 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.672867 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.673169 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.674385 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.694100 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.695413 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.695739 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.696075 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.696355 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.696687 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.705160 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.705597 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.716316 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.717013 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.717284 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.717529 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.717782 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.718037 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.718306 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.718566 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.718817 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.719056 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.719302 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.719539 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.719988 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.720410 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.721680 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.722139 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.722546 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.722959 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.723458 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.727764 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.728009 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.728251 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.728496 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.728740 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.729009 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.729267 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.729533 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.729786 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.730032 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.730282 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.730543 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.730817 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.731078 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.731342 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.731622 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.731911 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.732208 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.732502 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.732836 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.733161 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.733544 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.733914 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.734283 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.740761 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.741079 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.741372 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.741654 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.741960 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.742241 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.742551 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.742839 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.743104 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.743399 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.743695 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.743962 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.744597 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.745238 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.745792 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.746349 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.746911 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.747473 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.748129 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.756497 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.756774 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.757055 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.757341 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.757630 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.757909 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.758192 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.758476 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.758760 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.759047 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.759335 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.759639 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.759946 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.760246 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.760562 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.760876 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.761182 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.761517 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.761852 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.762192 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.762617 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.763074 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.763549 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.764045 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.769752 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.770087 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.770411 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.770721 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.771020 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.771320 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.771620 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.771944 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.772277 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.772591 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.772904 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.773224 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.774520 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.775726 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.776441 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.777152 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.777894 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.778673 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.779377 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.795101 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.795418 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.795717 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.796016 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.796323 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.796638 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.796959 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.797286 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.797613 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.797937 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.798274 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.798604 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.798950 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.799325 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.799699 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.800095 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.800494 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.800907 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.801284 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.801946 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.802635 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.803399 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.804021 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.809880 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.810279 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.810664 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.811031 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.811399 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.811766 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.812131 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.812492 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.812892 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.813315 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.813700 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.814071 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.815244 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.817481 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.818711 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.819902 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.821206 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.823411 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.824682 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.855855 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.856231 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.856580 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.856936 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.857297 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.857668 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.858048 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.858416 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.858800 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.859192 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.859579 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.859957 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.860400 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.860855 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.861323 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.861863 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.862406 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.862955 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.863454 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.864705 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.865988 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.867092 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.873862 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.874490 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.875102 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.875689 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.876392 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.877069 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.877783 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.878429 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.879094 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.879731 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.880348 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.880976 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.883027 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.884932 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.886852 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.888713 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.890604 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.892428 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.896091 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.958163 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.958621 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.959079 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.959499 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.959979 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.960432 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.960877 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.961329 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.961809 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.962326 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.962833 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.963354 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.963931 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.964608 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.965298 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.965977 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.966721 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.967585 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.968411 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.970068 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.971994 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.973963 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.981240 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.981902 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.982495 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.983209 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.983919 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.984665 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.985412 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.988798 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.993003 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987680.996409 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.000024 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.003475 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.006735 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.013690 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 1s/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1727987681.137337 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.137961 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.138556 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.139145 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.139771 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.140399 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.141025 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.141689 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.142351 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.143039 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.143718 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.144407 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.145171 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.145942 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.146802 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.147816 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.148846 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.150061 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.151307 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.152728 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.154097 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.157698 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.160464 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.169528 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.169957 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.170391 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.170762 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.171240 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.171766 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.172336 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.173566 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.174225 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.175441 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.176681 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.178481 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.180253 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.181541 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.183106 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.213147 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.213563 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.213944 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.214322 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.214701 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.215085 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.215477 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.215874 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.216236 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.216611 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.216990 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.217364 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.217751 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.218187 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.218632 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.219101 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.219596 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.220065 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.220612 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.221209 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.222609 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.223422 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.224959 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.231893 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.232244 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.232569 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.232900 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.233234 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.233576 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.233912 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.234296 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.234673 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.235911 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.237154 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.238468 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.241081 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.244759 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.246321 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.249461 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.255510 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.255829 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.256147 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.256503 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.256851 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.257185 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.257522 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.257873 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.258233 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.258852 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.259230 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.259653 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.260071 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.260625 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.261194 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.261779 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.262525 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.263258 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.263966 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987681.264924 3432080 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Processing batch 2, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 3, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Processing batch 4, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 5, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 6, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 7, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 8, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 9, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 10, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 11, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 12, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 13, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 14, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 15, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 16, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 17, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 18, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 19, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 20, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 21, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 22, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Processing batch 23, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 24, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 25, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 26, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 27, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 28, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 29, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 30, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 31, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 32, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 33, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 34, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 35, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 36, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 37, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 38, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 39, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 40, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 41, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Processing batch 42, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 43, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 44, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 45, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 46, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 47, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 48, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 49, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 50, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 51, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 52, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 53, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 54, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 55, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 56, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 57, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 58, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 59, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 60, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step \n",
      "Processing batch 61, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 62, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 63, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 64, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 65, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 66, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 67, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 68, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 69, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 70, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 71, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 72, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 73, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 74, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 75, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 76, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 77, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 78, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 79, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Processing batch 80, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 81, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 82, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 83, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 84, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 85, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 86, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 87, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 88, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 89, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 90, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 91, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 92, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 93, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 94, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 95, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 96, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 97, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 98, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step \n",
      "Processing batch 99, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 100, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 101, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 102, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 103, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 104, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 105, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 106, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 107, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 108, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 109, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 110, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 111, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 112, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 113, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 114, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 115, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 116, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Processing batch 117, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 118, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 119, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 120, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 121, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 122, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 123, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 124, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 125, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 126, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 127, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 128, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 129, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 130, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 131, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 132, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 133, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 134, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Processing batch 135, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Processing batch 136, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 137, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 138, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 139, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 140, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 141, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 142, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 143, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 144, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 145, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 146, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 147, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 148, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 149, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 150, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 151, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 152, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 153, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Processing batch 154, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 155, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 156, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 157, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 158, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 159, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 160, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 161, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 162, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 163, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 164, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 165, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 166, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 167, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 168, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 169, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 170, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Processing batch 171, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step \n",
      "Processing batch 172, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 173, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 174, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 175, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 176, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 177, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 178, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 179, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 180, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 181, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 182, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 183, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 184, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 185, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 186, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 187, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 188, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 189, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Processing batch 190, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 191, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 192, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 193, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 194, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 195, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 196, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 197, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 198, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 199, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Processing batch 200, batch shape: (800, 64, 64)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 20:35:38.387676: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the function for visualizing midpoints\n",
    "def visualize_midpoints(image, midpoints, title=\"Predicted Midpoint Visualization\"):\n",
    "    \"\"\"\n",
    "    Visualizes midpoints on an image without using a probability vector.\n",
    "\n",
    "    Parameters:\n",
    "    - image: A 3D tensor representing the image.\n",
    "    - midpoints: A 2D tensor representing the midpoint coordinates (x, y).\n",
    "    - title: The title of the plot.\n",
    "\n",
    "    Returns:\n",
    "    None (displays the image with midpoints).\n",
    "    \"\"\"\n",
    "    # Convert to NumPy arrays for easier handling\n",
    "    image_np = image\n",
    "    midpoints_np = midpoints\n",
    "\n",
    "    # Denormalize image if necessary (adjust based on your normalization method)\n",
    "    denormalized_image = image_np  # Modify if normalization was applied during training\n",
    "\n",
    "    # Visualize the image\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(denormalized_image, cmap='gray')\n",
    "    plt.title(title)\n",
    "\n",
    "    # Plot midpoints directly, only if they are not (0, 0)\n",
    "    for i, (x, y) in enumerate(midpoints_np):\n",
    "        if x >= 3 and y >= 3:  # Only plot if the point is not (0, 0)\n",
    "            plt.scatter(x, y, color='red', s=5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Create the validation dataset\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_midpoints))\n",
    "# val_dataset = val_dataset.batch(800)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)\n",
    "# # Initialize lists to collect the data\n",
    "all_images = []\n",
    "all_true_midpoints = []\n",
    "all_pred_midpoints = []\n",
    "\n",
    "# # Loop through each batch in the validation dataset, predict, and collect results\n",
    "# for i, (data_batch, midpoints_batch) in enumerate(val_dataset):\n",
    "\n",
    "for i, (data_batch, midpoints_batch) in enumerate(train_dataset):\n",
    "    print(f\"Processing batch {i + 1}, batch shape: {data_batch.shape}\")\n",
    "    \n",
    "    # Get the model predictions\n",
    "    predictions = loaded_model.predict(data_batch)\n",
    "\n",
    "    # Extend the lists to store data from each batch\n",
    "    all_images.extend(data_batch.numpy())  # Store all images\n",
    "    all_true_midpoints.extend(midpoints_batch.numpy())  # Store all true midpoints\n",
    "    all_pred_midpoints.extend(predictions)  # Store all predicted midpoints\n",
    "\n",
    "# Convert lists to arrays for easier indexing\n",
    "all_images = np.array(all_images)\n",
    "all_true_midpoints = np.array(all_true_midpoints)\n",
    "all_pred_midpoints = np.array(all_pred_midpoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    }
   ],
   "source": [
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_midpoints))\n",
    "# train_dataset = train_dataset.batch(800)\n",
    "# inputs,targets = next(iter(train_dataset))\n",
    "# outputs = model_builder.model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24000, 64, 64), (24000, 1, 13, 2), (24000, 1, 13, 2))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images.shape,all_pred_midpoints.shape,all_true_midpoints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWMAAAF2CAYAAAC72fnJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8+0lEQVR4nO3de3RU1b0H8O/kNQl5TCBCHgIxKgiIoIYSU/BRiUagFGq0tkUbuXpVbog89F5FLw8tGha2BR88qnaBq4LY2IsUFRBTwEIBBXEpPmLEKKmQgF4zCVxJQrLvH5CRObOT7DmPzJ7k+1nrLMmZc/b5nTMn25P9O3tvlxBCgIiIQioi1AEQERErYyIiLbAyJiLSACtjIiINsDImItIAK2MiIg2wMiYi0gArYyIiDbAyJiLSACtjMu28887D7bff7vt527ZtcLlc2LZtW8hiMjLGaLfbb78d5513Xofbffnll3C5XFi1apVjsQDOny85h5VxmFq1ahVcLpdviY2NxcCBAzFt2jTU1NSEOrygvPHGG5g/f35IY2i9jnfeeaf084cffti3zTfffNPJ0XWOZcuWOf4/C2pbVKgDIGseffRRZGVl4eTJk9ixYweWL1+ON954AwcOHECPHj06NZarrroK33//PWJiYoLa74033sDSpUtDXiHHxsbir3/9K5YtWxZwDi+99BJiY2Nx8uRJv/XPPfccWlpaOjPMdpWXlyMiwtwz1rJly3DOOefwyTpE+GQc5saOHYtbb70Vd955J1atWoUZM2agsrIS69evb3OfEydOOBJLREQEYmNjTVcGoXbDDTegrq4OGzdu9Fv/z3/+E5WVlRg/fnzAPtHR0XC73Z0VYofcbjeio6NDHQaZEJ6/NdSma6+9FgBQWVkJ4HSbZkJCAg4ePIhx48YhMTERkydPBgC0tLRgyZIluPjiixEbG4vU1FTcfffd+O677/zKFEJgwYIF6Nu3L3r06IGf/OQn+OijjwKO3Vab8Z49ezBu3Dj07NkT8fHxGDZsGJ588klffEuXLgUAv2aXVnbH2J5zzz0XV111FdasWeO3fvXq1bjkkkswdOjQgH1kbca1tbW4/fbb4fF4kJycjMLCQtTW1kr3TUhIwBdffIH8/HzEx8cjIyMDjz76KIyDKZ44cQL33Xcf+vXrB7fbjYsuugi/+93vArYzthm3Nmft3LkTs2bNQu/evREfH4+f//znOHbsmN9+H330EbZv3+77Dq655hoAQFNTEx555BEMGDAAsbGxSElJwejRo7FlyxaFq0qq2EzRxRw8eBAAkJKS4lt36tQp5OfnY/To0fjd737na764++67sWrVKkyZMgX33nsvKisr8cwzz2D//v3YuXOn7wlr7ty5WLBgAcaNG4dx48bhvffew/XXX4/GxsYO49myZQt++tOfIj09HdOnT0daWho++eQTvPbaa5g+fTruvvtuHD58GFu2bMGf//zngP07I8az/frXv8b06dNx/PhxJCQk4NSpUygtLcWsWbMCmihkhBCYOHEiduzYgXvuuQeDBw/GunXrUFhYKN2+ubkZN9xwA6644gosWrQImzZtwrx583Dq1Ck8+uijvjJ/9rOfYevWrbjjjjtw6aWXYvPmzfjP//xPfP3111i8eHGHcRUXF6Nnz56YN28evvzySyxZsgTTpk3Dyy+/DABYsmQJiouLkZCQgIcffhgAkJqaCgCYP38+SkpKcOedd2LkyJGoq6vD3r178d577+G6665Tuq6kQFBYWrlypQAg3nrrLXHs2DFRVVUl1q5dK1JSUkRcXJz417/+JYQQorCwUAAQDz74oN/+//jHPwQAsXr1ar/1mzZt8lt/9OhRERMTI8aPHy9aWlp82z300EMCgCgsLPSt27p1qwAgtm7dKoQQ4tSpUyIrK0tkZmaK7777zu84Z5dVVFQkZLeiEzG2BYAoKioS//u//ytiYmLEn//8ZyGEEK+//rpwuVziyy+/FPPmzRMAxLFjx3z7FRYWiszMTN/Pr776qgAgFi1a5Ft36tQpceWVVwoAYuXKlX77AhDFxcV+12X8+PEiJibGd5zWMhcsWOAX80033SRcLpf4/PPPfesyMzP9zrf1PsnLy/O7NjNnzhSRkZGitrbWt+7iiy8WV199dcC1GT58uBg/fnwHV5CsYjNFmMvLy0Pv3r3Rr18//PKXv0RCQgLWrVuHc88912+7qVOn+v1cWloKj8eD6667Dt98841vyc7ORkJCArZu3QoAeOutt9DY2Iji4mK/5oMZM2Z0GNv+/ftRWVmJGTNmIDk52e+zs8tqS2fEaNSzZ0/ccMMNeOmllwAAa9aswY9//GNkZmYq7f/GG28gKirK73pHRkaiuLi4zX2mTZvm+7fL5cK0adPQ2NiIt956y1dmZGQk7r33Xr/97rvvPgghAtq4Ze666y6/a3PllVeiubkZX331VYf7Jicn46OPPkJFRUWH25J5bKYIc0uXLsXAgQMRFRWF1NRUXHTRRQEJtKioKPTt29dvXUVFBbxeL/r06SMt9+jRowDg+2UdMGCA3+e9e/dGz549242ttclE1taqojNilPn1r3+N2267DYcOHcKrr76KRYsWKe/71VdfIT09HQkJCX7rL7roIun2EREROP/88/3WDRw4EMDpd5Nby8zIyEBiYqLfdoMHD/Z93pH+/fv7/dx6XYxt7zKPPvooJk6ciIEDB2Lo0KG44YYbcNttt2HYsGEd7kvqWBmHuZEjR2LEiBHtbuN2uwMq6JaWFvTp0werV6+W7tO7d2/bYjQrVDH+7Gc/g9vtRmFhIRoaGvCLX/zCkeN0psjISOl6oTDr2lVXXYWDBw9i/fr1ePPNN/H8889j8eLFWLFiRZvvZVPwWBl3UxdccAHeeustjBo1CnFxcW1u1/rneUVFhd8T3LFjxzp8qrrgggsAAAcOHEBeXl6b27XVZNEZMcrExcVh0qRJePHFFzF27Ficc845yvtmZmairKzMlwBsVV5eLt2+paUFX3zxhe9pGAA+++wzAPC9pZGZmYm33noL9fX1fk/Hn376qe9zO7TXdNSrVy9MmTIFU6ZMwfHjx3HVVVdh/vz5rIxtxDbjbuoXv/gFmpub8dvf/jbgs1OnTvlexcrLy0N0dDSefvppv6eoJUuWdHiMyy+/HFlZWViyZEnAq11nlxUfHw8AAdt0Roxtuf/++zFv3jzMmTMnqP3GjRuHU6dOYfny5b51zc3NePrpp9vc55lnnvH9WwiBZ555BtHR0RgzZoyvzObmZr/tAGDx4sVwuVwYO3ZsUDG2JT4+XvoK3rfffuv3c0JCAi688EI0NDTYclw6jU/G3dTVV1+Nu+++GyUlJXj//fdx/fXXIzo6GhUVFSgtLcWTTz6Jm266Cb1798b999+PkpIS/PSnP8W4ceOwf/9+bNy4scMnxoiICCxfvhwTJkzApZdeiilTpiA9PR2ffvopPvroI2zevBkAkJ2dDQC49957kZ+fj8jISPzyl7/slBjbMnz4cAwfPjzo/SZMmIBRo0bhwQcfxJdffokhQ4bgf/7nf+D1eqXbx8bGYtOmTSgsLEROTg42btyI119/HQ899JCvGWbChAn4yU9+gocffhhffvklhg8fjjfffBPr16/HjBkzfH+BWJWdnY3ly5djwYIFuPDCC9GnTx9ce+21GDJkCK655hpkZ2ejV69e2Lt3L1555RW/xCPZIJSvcpB5ra8svfvuu+1uV1hYKOLj49v8/NlnnxXZ2dkiLi5OJCYmiksuuUT813/9lzh8+LBvm+bmZvHII4+I9PR0ERcXJ6655hpx4MCBgNeojK+2tdqxY4e47rrrRGJiooiPjxfDhg0TTz/9tO/zU6dOieLiYtG7d2/hcrkCXnOzM8a24Myrbe1RebVNCCG+/fZbcdttt4mkpCTh8XjEbbfdJvbv3y99tS0+Pl4cPHhQXH/99aJHjx4iNTVVzJs3TzQ3N/uVWV9fL2bOnCkyMjJEdHS0GDBggHjiiSf8XlcTou1X24z3iey7qq6uFuPHjxeJiYkCgO81twULFoiRI0eK5ORkERcXJwYNGiQee+wx0djY2O71ouC4hFBowSci291+++145ZVXcPz48VCHQhpgmzERkQZYGRMRaYCVMRGRBthmTESkAT4ZExFpwLHKeOnSpTjvvPMQGxuLnJwcvPPOO04diogo7DnSTPHyyy/jN7/5DVasWIGcnBwsWbIEpaWlKC8vb3PQl1YtLS04fPgwEhMTlUb2IiLSlRAC9fX1yMjI6HgGHCdeXh45cqTfC/TNzc0iIyNDlJSUdLhvVVWVAMCFCxcuXWapqqrqsO6zvTt0Y2Mj9u3bh9mzZ/vWRUREIC8vD7t27epwf+MwgU6QPXELk38gqJYl2y4qKvDyNzU1+f0sG21L9n9Y2aSYzc3NAeuM86MZjxcM2TkZY5PF4DQr36/qtbXzmGaF4phmr08oqMbaGddRpV6zvTL+5ptv0Nzc7JuypVVqaqpvlKmzNTQ0+A04Ul9f7/v32RfJzouj2vyhckwrlbFKHKr7qZ6T2WM6fU5Of7+q5ZttGrPznrJyzFA8VJiNw+n4rfxO2B2/Siwhf5uipKQEHo/Ht/Tr1y/UIRERdTrbK+NzzjkHkZGRqKmp8VtfU1ODtLS0gO1nz54Nr9frW6qqquwOiYhIe7Y3U8TExCA7OxtlZWWYNGkSgNPtNGVlZdIh99xuN9xut7SsYP9kUW0jUm03UvnTQrW9TLadSnvtqVOnAtapnqdsO5Vjql531WvrNOP3pHotVNvZVciumdNNBnZSLV92fWR5DZXraOWcjMeUHU/1uzR7z9r9nTgynvGsWbNQWFiIESNGYOTIkViyZAlOnDiBKVOmOHE4IqKw50hlfMstt+DYsWOYO3cuqqurcemll2LTpk0BST0iIjpNu7Ep6urq4PF4TO1r5bUbs1l0K5fP7J+jVpopjOWH4uu3+89wY3myspx+JSsUbzbo8pqZ2WYKO48Zilcog+H1epGUlNTuNiF/m4KIiLrYHHiqTyKyzhYqiQlZMk31iVr29CArT2U/WayyOMw+JXXYbdNi+XY/5al8B6rvzJp9mrXzLwwrCVSzT6lWrkVnPwXLjhmKpKfd+GRMRKQBVsZERBpgZUxEpIEu1WZstl0WkLcvGfe18haDahwqcck6yZw9vkcrWdu4Shx2dmBQFYq3AGTnZGebqyqVTisysljNtseHon1VNX6zbdI6DN4UzPH4ZExEpAFWxkREGmBlTESkAVbGREQaCJsEnkpjvGqSzGwyzcoIbbL4VRKOsrJkyToZO5OGdrK7u69xnZUOJGaTRbJjqpZl9nrLzslsWU7PiqF6fVRmj5HFpksHDytx8MmYiEgDrIyJiDTAypiISAOsjImINBA2CTwVoUhCqPZWU+nh11ZsKmXJYlM5T9n1kfXcs5K87CiGYMpS6bVlpQeb2d52VkaYMzsTsSqV+1Y1fjuTjarlh/uM2qr4ZExEpAFWxkREGmBlTESkAVbGREQaCJsEntlklCxJI2O255XdPX9UynN6AkizPfdkVJMcqtvZeZ6qPcBUvhPV+8DOCWetJPXMHtPufY2cHvZSVpadQ81awSdjIiINsDImItIAK2MiIg2wMiYi0kBYJ/BU2JnwsXueNrPJCtVzUkn0mR2yEFBLxFlJbNmZzLHSe1KlLJ3vM5V5Gq0cMxTzF6qQ3T/R0dEB6xobG02Vb2fiEuCTMRGRFlgZExFpgJUxEZEGtG4zPrvNx+xoWipTG7XFznY11Y4aZttc7WSl/dNs/KF42d9sO7Wd7cNWqI7eJ2snNU7dZeX629kJyen73c4OTXa3lfPJmIhIA6yMiYg0wMqYiEgDrIyJiDSgbQLP5XL5JRVkDfvGxIEsaWAl2WJnA30okj4qx1RNmKiObGX2mqkm01T3NVu+ynaq+4Ui+So7pjFZp7qfjJ3JOl2StqqMvwOye52dPoiIwhwrYyIiDQRdGb/99tuYMGECMjIy4HK58Oqrr/p9LoTA3LlzkZ6ejri4OOTl5aGiosKueImIuqSgK+MTJ05g+PDhWLp0qfTzRYsW4amnnsKKFSuwZ88exMfHIz8/HydPnrQcLBFRlyUsACDWrVvn+7mlpUWkpaWJJ554wreutrZWuN1u8dJLLymV6fV6BQABQLhcLt/Suu7s5ezP21pU94uMjAxYZPuaXWJiYgIWlf0iIiICFivnqXJMs/vJ4lXdT/WYsuuhUpbKflzsW8zeP3Ydr63faSv3gZV7yuv1dlj32dpmXFlZierqauTl5fnWeTwe5OTkYNeuXXYeioioS7H11bbq6moAQGpqqt/61NRU32dGDQ0Nfq/e1NXV2RkSEVFYCPnbFCUlJfB4PL6lX79+oQ6JiKjT2VoZp6WlAQBqamr81tfU1Pg+M5o9eza8Xq9vqaqqsjMkIqKwYGszRVZWFtLS0lBWVoZLL70UwOlmhz179mDq1KnSfdxuN9xut/QzcVZvGbO9dXTpLWV2ahdZjx7ZOZmdlsoK2THt7IEno3I97P5+jeVbGZZVhWpvR9XtVNg9hZDKd2LnMWXlqwxRGwzjvnYPoRl0ZXz8+HF8/vnnvp8rKyvx/vvvo1evXujfvz9mzJiBBQsWYMCAAcjKysKcOXOQkZGBSZMm2Rk3EVHXovoaW6utW7dKX90oLCwUQpx+vW3OnDkiNTVVuN1uMWbMGFFeXq5c/tmvtqGd10rsfk0rnF59UnmlL5hX/cxeMyuvwDl5PZwuPyoqKmCx83iq5dsZh933v0pZofidC8Vrm4Daq20u4fTf50Gqq6uDx+MJWO90M4Xdf6Y5ycqfWnZeM6cHelGl8iexneWzmSL48lRmqLZ6TBVW7lkrM/94vV4kJSW1X75yaURE5Bhth9A0Mvu0o7qf0/9HNvsUoLqfbDvZOuP1kCU5nH4KtvvJ2+mncWP5dj4FA4FP2qrlW4nDbDJK9TtRKU+2jeyvDrPly1h5Gne8jnC0dCIiUsLKmIhIA6yMiYg0wMqYiEgDWifwXB3MgWeWrBFfxthgbyXxpJqsMCbUrCQgZXGYna/M7Os/qgk32bUwm1QyG2swx+wohrao3C9WylKlsq/q9ZHFe8EFF/j9fHZHsfY4PVekrHzV+sDpRDGfjImINMDKmIhIA6yMiUgqUgj8txDY1NKC/xYCkXp11u1ytG4z7syutSpdpFXjsdLOa2w7tdKGptI+ZrYtO5jtVFg5T7P3iZ0v8Vu5V42dN+y8roBarkO2zYNCYB5OP7GNEQICwG8Vj2kcpfH+++/vMIa2ON3t3s77QFZnKOcwbIuCiLqU0fihgog48zM5h5UxEUntAND6zNhy5mdyjtbNFEQUOo+f+e9onK6IH29nW7KOlTERSTVDvY2YrAub8YxVON3QbyWxorqv2Q4MquWbHZNVZQS4ttaZLV+184zZDgwydo6kp0ql04eVzkVmhdMY36pCdU4cz5iIKEywMiYi0gArYyIiDbAyJiLSgLZvU7hcrg5Hr1IZVc3K5JExMTF+Pzc1NSntJ6OaJFDpGSVL5qgmEs0mK5ye7sjKtEvG71h2jnZOK6Q6cpnZHpt259SN9zGg9jtg93kaWZliyWyiW7ad6sSuKqPpWfnu+GRMRKQBVsZERBpgZUxEpAFWxkREGtA2gWccek7W2K8y3KSVBvXGxka/n2UN+KoJDVnPH1m8smSCyn52Jn2c7skoo5rAs3MqKRmz5x6K66+6nSzxbDZes3Go3v+qjOWp9GaVxQWoJ/TN9PTkEJpERGGGlTERkQZYGVOXFAlgDoDNZ/4b2MhFpBdt24yJrHgIwHycftrIO7OOw0GSzsKmMlZp7Lc78WFmm2D2lSU1VJIJKj2B2mI26SnrxWVnYkjG7HCZQOCUQVdCbfhQO3t7yajce6q9Rq0Mf2r83lXvKdWemGaHalWlUp7dSWeV+8DKebKZgrqkgCmDLPwPjKgzhM2TMVEwjFMGLQxhLEQqWBlTl2ScMiiCT8akubCpjFWmS7HSPmy2HVm2n50vuKu25anGYbxmsk4msnYvYwcY1disTHNjts3P7k4rTo9OZ7xGsvZhK1N+qWxnd6cMle/YzpHuZKxcs1BgmzERkQZYGRMRaSCoyrikpAQ/+tGPkJiYiD59+mDSpEkoLy/32+bkyZMoKipCSkoKEhISUFBQgJqaGluDJiLqaoKqjLdv346ioiLs3r0bW7ZsQVNTE66//nqcOHHCt83MmTOxYcMGlJaWYvv27Th8+DBuvPFG2wMnIupKXMJCduLYsWPo06cPtm/fjquuugperxe9e/fGmjVrcNNNNwEAPv30UwwePBi7du3CFVdc0WGZdXV18Hg8asErvIQtS0yojvxl7OggS0qojvgk4/QUNk4nK1TiX716dcA2kydPdvSYdjNeW1kMVu4D4z2qeo6y+zGcklayjkSyRLEKK51WzApmGiav14ukpKR2t7XUZuz1egEAvXr1AgDs27cPTU1NyMvL820zaNAg9O/fH7t27bJyKCKiLs30q20tLS2YMWMGRo0ahaFDhwIAqqurERMTg+TkZL9tU1NTUV1dLS2noaEBDQ0Nvp/r6urMhkREFLZMPxkXFRXhwIEDWLt2raUASkpK4PF4fEu/fv0slUdEFI5MVcbTpk3Da6+9hq1bt6Jv376+9WlpaWhsbERtba3f9jU1NUhLS5OWNXv2bHi9Xt9SVVVlJiQiorAWVDOFEALFxcVYt24dtm3bhqysLL/Ps7OzER0djbKyMhQUFAAAysvLcejQIeTm5krLdLvdcLvdAesjIyP9GshlCRKVBJ6VkZXMJhNU3XfffQHrjOe5ZMmSgG2cTtLYmQwpKSmxGk7Qx1QlS+7KdHYiVHUKIRnZvlZ6QdpF1tNTNuqfnZSnOzJ5fexOHAdVGRcVFWHNmjVYv349EhMTfe3AHo8HcXFx8Hg8uOOOOzBr1iz06tULSUlJKC4uRm5urtKbFNR9ReL0GMStA/s8jtPjSxB1F0FVxsuXLwcAXHPNNX7rV65cidtvvx0AsHjxYkRERKCgoAANDQ3Iz8/HsmXLbAmWui4OBk/dXdDNFB2JjY3F0qVLsXTpUtNBUfdjHAx+dAhjIQoFjk1BWggYDD6EsRCFgqUeeE4IpgeeyhRCssSHbJ2swd7YsK+aILQyrGZ6errfz0eOHAnYJpyo9iaTtRlDkqg0OxVTKHruWbn3VMjuKdV71Gz5KtNSqR4zFMPbhqq6U+mBFzbjGVPXZhwMHuCMztS9sJmCiEgDrIyJiDTAypiISANh3WZsTIBZSQjIGJMVqgkTVbI4jAk7XZIQTiejZKz0RDO7n8owrFbm8DMbv4yVa21Mfqv2VDX7O2YlsWj2mjndAy+YITSV4lDekoiIHMPKmIhIA6yMiYg0oHWb8dltMirtk6rtM2bb2lT3U+3gYWcbtGpZxutopf3TbFuhjGq7ndnrY6V91bivlXb8zh4trS1mR6KTdthxeBRBlbZrK3kUs9+J3TkBPhkTEWmAlTERkQZYGRMRaYCVMZHGIgHMAbD5zH85XkfXpXUC7+wGcrMN9LLpXmRTONlJNXkhSxwYkyGyhIBq+Tp0DrHyYr/TiSHVpKHZTh92dNgxDrrvAvDbM+VaGeHM7DnJqHTOsdJByM5po6x8JyrXLDo6OqBs1eml+GRMpDHjoPujQhgLOYuVMZHGjIPu7wxhLOQsrZspiLq7x8/8dzROV8SPt7MthTdWxkQaax10384BhkhPXb4ytpKsMyb/ZA39VhJKKokJ1eSC3duZZTaxIruOsgSejJ2jqqlsp5oECsV0R6rs7Ano9MiCoUjWqZZn1NjYaLp8thkTEWmAlTERkQZYGRMRaYCVMRGRBrRO4J3dYO50LyJZssh4TDt7fwFq8VrpfWRn70OnkzSqQ4Cq9MpT7bmnup0xDrun3zLGoTrcqp1JOCu9HVXO3e6hN81O66T63ZlNyMqS/qrnxCdjIiINsDImItIAK2MiIg2wMiYi0oDWCbyOGszNJk1Uh6XUoQuqas8r2bVQSdaZTWKpspJ4srM3n2r5ds7rp8psAkx2H5gdqlK2jdPDz1q5t3WdC9HK9eGTMRGRBlgZExFpgJUxEZEGWBkTEWlA6wReRz3wVHpGqSZpzPaqstIzzWyCRDWxKDsnY3LLbI+nttYZr7fTyToZ1e/S7qE2zTLG4XRvOxkrc9SZ/R2wczhLHeZ7tBoHn4zJVpzNmMgcrZ+MKfwYZzMGTs9UQUTtC+rJePny5Rg2bBiSkpKQlJSE3NxcbNy40ff5yZMnUVRUhJSUFCQkJKCgoAA1NTW2B036Ms5mPDqEsRCFk6CejPv27YuFCxdiwIABEELghRdewMSJE7F//35cfPHFmDlzJl5//XWUlpbC4/Fg2rRpuPHGG7FzZ/Bz2rpcrg7bjI3sbldTGRXOShuRSvuw050mrLxkL1u3A6efiCNwejbjHQpxWmXsuGL399TZVL9f2b2her+YbduXsXNKKLPtsE6PKihjezu+sKhnz57i+eefF7W1tSI6OlqUlpb6Pvvkk08EALFr1y7l8rxerwAgXC6XiIiI8C0AHF3OPlbrEhkZ6be4XK6AJRRxqe6rEq/d5xQJiDmA2Hzmv5EOXx8AWnxPoVhk90ZUVFTAYuUeUllkzJal+t3JttP5O/d6vR3WfabbjJubm1FaWooTJ04gNzcX+/btQ1NTE/Ly8nzbDBo0CP3798euXbtwxRVXSMtpaGhAQ0OD7+e6ujqzIZEGWmczJqLgBP02xYcffoiEhAS43W7cc889WLduHYYMGYLq6mrExMQgOTnZb/vU1FRUV1e3WV5JSQk8Ho9v6devX9AnQUQU7oKujC+66CK8//772LNnD6ZOnYrCwkJ8/PHHpgOYPXs2vF6vb6mqqjJdFhFRuAq6mSImJgYXXnghACA7OxvvvvsunnzySdxyyy1obGxEbW2t39NxTU0N0tLS2izP7XbD7XYHrBdC2NIAb2WaFZVRmmRUkwkq20VHRwds09jYqFS+Smyq+1m5jk6zezqsjlhJFqnsayWparYTj5XR++wc3VD1Otp5n6mee0xMjN/Pst9DKyx3+mhpaUFDQwOys7MRHR2NsrIy32fl5eU4dOgQcnNzrR6GiKhLC+rJePbs2Rg7diz69++P+vp6rFmzBtu2bcPmzZvh8Xhwxx13YNasWejVqxeSkpJQXFyM3NzcNpN3RER0WlCV8dGjR/Gb3/wGR44cgcfjwbBhw7B582Zcd911AIDFixcjIiICBQUFaGhoQH5+PpYtW+ZI4EREXYlLhKKRrx11dXXweDy2lWdlWnWzbXl2bidrT1dtM1Zpy+sKbcadTZc2Yzvbap2e8UVnndFm7PV6kZSU1O42XX5sCjt75lhJLpiN4+x3sNvjdGWp2stKpddiKHpLWam4zMZmZXQ9lRhU41KpbGS9QVXjt3N6JrP3sWqFqjKSYVuMla/K/S+EUO9RqbQVERE5ipUxEZEGWBkTEWmAlTERkQa6VALPmO0E5BlPp6e1sZLQMNtDTjV+Y2yyuKxk1lXiDUVG3s5j2t1LzOnrIfvuVO4z1QSeSvyqSVuzw3GqnGNb5cuo1BF2f298MiYi0gArY+pQpBCc147IYV2qmYKcMVsIzAXntSNyEp+MqUOjhOC8dkQOC+snY2OiSbV7omovH2MCQDW5YDZZJ4tDNSkpY7a3kXGbfwAYgx/mtdvpciGijaSKyrCjVnpByZhNeso4ndyVMcZvJfFkZ7dmO8/byndiZ49Zs3MEqrJyH4d1ZUyd43GcriBGC4EdLhdKQh0QURfEypg61AxggcsF2DgwDRH5Y5sxEZEGtH4yPrvtzOwUM1badI3HVG1rlrXbqb7gbmSl04rZThlWhnBUGbXNzvbhtmJzUme0g5vldPu2TCjOU6UjiJW2d5X7TLV9XhWfjImINMDKmIhIA6yMiYg0wMqYiEgDWifw7KCaWFFpjFdNiFlJKBnjGDNmTMA2Xq83YN0777yjFIdKgk12LWRJz1BMlWTnFEiqSVWVaxbuHSSssHOuRdXydThPuxOXfDImItIAK2MiIg2wMiYi0gArYyIiDWidwDu7kV6lEd9KzzGVxni7p0BSiWPSpEkB21xwwQUB6/Lz8wPWme0hpNpD0Wz5VnoQmk3mOJ3wCUWsoRhhTiYU19Z475kdma4toUga8smYiEgDrIyJiDTAypgoBCKBH+YVFAKRIXhvlvSidZsxUVf1EID54LyC9AOXCEVXlnbU1dXB4/EA6HgITRWyhnjVdcZkiN2XSiVJoEuSxu7hAo3MfieqnL6OqtenNY5NLS247qz1bwJoTcFGRQU+I6kmVc1yOmFlpXyz353TxwymfK/Xi6SkpPaPqRQZEdlqh8uF1l/tFgA7QhkMaYHNFEQhUAIAZ+YV/AdOzzNI3RsrY6IQaHa5sAAAXK6QNDuRfthMQUSkAW2fjCMiIvwayFV7aKlso0vO0ux8dKFI6qkMLakah2qCSrVXmwo7hzWVUU1mqlxH2bVQTRbpkvC1k9n4rXznsmMavwOV+zOYGPhkTESkAVbGREQasFQZL1y4EC6XCzNmzPCtO3nyJIqKipCSkoKEhAQUFBSgpqbGapxERF2a6Tbjd999F3/84x8xbNgwv/UzZ87E66+/jtLSUng8HkybNg033ngjdu7cGVT5Ki9Yq0yHo9rWFooX7VWOqdoWKWvXlJ272XNSbatVaTOzcl3NtrNbGVXNzpHoZFS2s3vEwM7m9AhqnTHKmtOjA5p6Mj5+/DgmT56M5557Dj179vSt93q9+NOf/oQ//OEPuPbaa5GdnY2VK1fin//8J3bv3m06SCKirs5UZVxUVITx48cjLy/Pb/2+ffvQ1NTkt37QoEHo378/du3aJS2roaEBdXV1fgsRUXcTdDPF2rVr8d577+Hdd98N+Ky6uhoxMTFITk72W5+amorq6mppeSUlJXjkkUeCDYOIqEsJ6sm4qqoK06dPx+rVqxEbG2tLALNnz4bX6/UtVVVVtpRLRBROgnoy3rdvH44ePYrLL7/ct665uRlvv/02nnnmGWzevBmNjY2ora31ezquqalBWlqatEy32w23293hsVU6b1hpxFd90d5s+arHNMvOEdRkdE0MAaHpCGJk5fpY6ShgZHZ0PSujmZntWCUry84p0WQJcrunZ7JTUJXxmDFj8OGHH/qtmzJlCgYNGoQHHngA/fr1Q3R0NMrKylBQUAAAKC8vx6FDh5Cbm2tf1EREXUxQlXFiYiKGDh3qty4+Ph4pKSm+9XfccQdmzZqFXr16ISkpCcXFxcjNzcUVV1xhX9RE3VwkTg9QPxqnh998HICzfxuR02wfm2Lx4sWIiIhAQUEBGhoakJ+fj2XLltl9GKJujTOFdD1az/QRLLtf/Ha6zZjsEe7fk5k2480Arj/r59aZQpyekUXXNmMZndqMVWb60HbUNpfL1eGobUZWell1Rg8eM+y+oexMFulSCerwPVlhjF+lQt2B00/EEfCfKSScpsKyMylsZ29T1WPYPWqbtpUxEbWtdWaQs9uMKbyxMiYKQ81gG3FXwyE0iYg0wMqYiEgD2jZTCCH8Gr/NJthUpswB7B3G0M6MtmoSQpaZVmE28We1PJXyQ5GUVHlbwOnhIFUTW7KyYmJiAtY1NTUFrDMeQ/UtCbP3sdMJ8lAkiu0+Jz4ZExFpgJUxEZEGWBkTEWmAlTERkQa0TeAZmW0YV02Aqcyxp5q8UN1OZd401bn5nB7iUrXXopleSm2RJUJl5dl57iplyeKS7We2m7DqvS7brqGhIWBdRkZGwLrDhw/7/WzlGqokrK0kiu3s9Wcnu3vg8cmYiEgDrIyJiDTAypiISAOsjImINBA2CTyzVHvDqYyjqpJwa4vKvpEA5sB/JC67ExXGOKyUbzapqrqf2USo7JxUErRt7WuMVzUusz0xzc7pB8iv7ZEjRwLWqfTYVL037By202zSU8bpsZ3tLr/LV8bhRDZ7w2Mhi4aIOhObKTQyGj98IRFnfiai7oGVsUZ24PSsDYD/7A1E1PWFTTOFDqM+ydrQVDtlqJDN3iArv7Gx0VT5gPk2Yivt5WbLN/v9ykYuk10zK6OjGTndGcXKva7SDmt21L/OoPI7ZufcearsLj9sKuPuQDZ7g9oAoEQU7vT93yERUTfCypiISAOsjImINBA2bcayJITKy/6qo4bZOSqc6ihTKkkxWeLJ6SmQZMwmu1Svv5XkqPEYqtfM6al67OwUY3cHAzsTdnaOeCijkhBXvdZOJ6Kt4JMxEZEGWBkTEWmAlTERkQZYGRMRaSBsEngyKg3vqiN42Uk1maASv5UefmaTVnYmCJ2+1qpU4zA7xY/TiSG7e3s53Xs1YERCm6fQMju9kZXvxMzogJx2iYgozLAyJurCWsfI3nzmv+xer6+wbqYgovbJxsg2jn9CeuCTMVEXxjGyw0e3fDJWTWzZOUWRjErSx0riRqUnl6x81aSD0wlC1UTlzTff7PdzaWlpwDaq353KfWBn4km2zmxvTVlZO4VAHk5XxGePkW08B6cTrXYnIFXitdLr0uz0T1YSo92yMibqLh4HIOA/RjbpiZUxURfW7HLhtw6PwUH2CKrNeP78+XC5XH7LoEGDfJ+fPHkSRUVFSElJQUJCAgoKClBTU2N70EREXU3QCbyLL74YR44c8S07dvwwU9vMmTOxYcMGlJaWYvv27Th8+DBuvPFGWwMmIuqKgm6miIqKQlpaWsB6r9eLP/3pT1izZg2uvfZaAMDKlSsxePBg7N69G1dccYX1aA2c7oVjZy8lsz3A7B4a0M5EisrwmGYTIbKy2tr3r3/9q21lqeyr2qtT9dzNzr+oMnQloPadqw7RqZLgBALjlcUqO6Zq0tZYvpWeqqrDiZpJejraA6+iogIZGRk4//zzMXnyZBw6dAgAsG/fPjQ1NSEvL8+37aBBg9C/f3/s2rWrzfIaGhpQV1fntxARdTdBVcY5OTlYtWoVNm3ahOXLl6OyshJXXnkl6uvrUV1djZiYGCQnJ/vtk5qaiurq6jbLLCkpgcfj8S39+vUzdSJEROEsqGaKsWPH+v49bNgw5OTkIDMzE3/5y18QFxdnKoDZs2dj1qxZvp/r6upYIRNRt2Pp1bbk5GQMHDgQn3/+Oa677jo0NjaitrbW7+m4pqZG2sbcyu12w+12mzq+2aldVNtXje09Zl+8l5XV1joj1WOaHZ3O7ChlquWZbWNsa18ZlXittP+r3FehmNZJxmxOQLV9VUaHUe1Upz+z0mFHpSwrLHWHPn78OA4ePIj09HRkZ2cjOjoaZWVlvs/Ly8tx6NAh5ObmWg6UqDviQD/dR1BPxvfffz8mTJiAzMxMHD58GPPmzUNkZCR+9atfwePx4I477sCsWbPQq1cvJCUlobi4GLm5uY68SUHUHXCgn+4jqMr4X//6F371q1/h22+/Re/evTF69Gjs3r0bvXv3BgAsXrwYERERKCgoQENDA/Lz87Fs2TJHAifqDjjQT/fhEqFo2GpHXV0dPB6P0rYqg97ImG2/srvNWIWVtrZQtBmrDK6k83TpZjl1TnPww5Nxy5l/tz4Z69JOrcLumT5U6HR9vF4vkpKS2t0mrMemMJusMFuB2t1Z5NZbbw1Y9+KLL5oqy2xlYPfNGYpj6sDKORnvvbMrrkVCIEII/LilJWCgH9VOHyrJUdWKy2wFZ+VBacKECQHr1q9f32FZTp+T3cK6Mibq6ppdLjzmcuFUmP/lQB3j4PJERBpgZUxEpAFWxkREGgibNmOzCSqzo6XJjmllxDNZ/CpJCCu90GTHNJZnd6LCzlHbVMqXsdLrTzb6l/F7j46O7nCbttbJmE0UW3nzwHieqj3wzH53VnqlXnPNNQHrNmzY4Pezaq9UK2JiYvx+bmxsDNjG7KiLAJ+MlUQKgf9uaWEvKCIHRQKYIwQ2CYE5QiCyC751056weTIOpdlCYK4Q7AVF5KCHAMxD9+1tyCdjBaPOVMQAe0EROcXY23BUCGMJBVbGCna6XGhtfTp7unMiss8OwO/3bGcIYwkFrbtDn90YLgvT2MXSyjCM7YnE6T+hzp7uvDU1ozpdjZVpYVSYLd/u7tZ2JnjsHmrTScbkDgA0NTUFrFNJLto5hGlbjHGo3sdmqZTf3u+ZkUqizO6edVamWery3aE7SzO6V9sVUSh0998zNlMQEWmAlTERkQZYGRMRaUDrNuOOGtt1mJtMFoMs8WR2ji7V+GXlqyTAdBlHWHZOsmvrdKJJxnhMWawqvbHaYud3YPbetnINVe5R1aS2bDuzY25b+d0PxbCafDImItIAK2MiIg2wMiYi0oDWbcZnC0UbjtkRmKzMi2fczsp5q8Rh90vwdn4noWgfljEeU9YWL1snE4rOSyq5AyvX2mzuQ7XTk+q1NbLye6hyvVU6+nDUNiKiMMPKmIhIA6yMiYg0wMqYiEgDWifwOhq1rb3t29vPbOJJlkiQlaX64rpK4kC2n+o6lamYrCTE7OysoJpAsjLKnJHZ+0B2PDuTjXYnVVXitTsxaudIdHbGplofqFxHWUcfK/hkTESkAVbGREQaYGVMRKQBVsZERBrQNoHncrmCTuDZ3UvJWJ6VJITTI3OpnrvZZIhqsst4HVVjVY3LztG6dJiuCVDr4acav2qCKmDKI0kCUrUHmy4j/6lQ7c0XinPikzERkQZYGRMRaYCVMRGRBlgZExFpQNsEnhDClgSLao8tWQJDdYg/O+MwUhlysa2y7ExQqZZlPE+z00FZ4XRiTvX6m2X30KQq0z+p3j9me7Q63TtWlZ3fk0qilUNoEhGFGVbGREQaCLoy/vrrr3HrrbciJSUFcXFxuOSSS7B3717f50IIzJ07F+np6YiLi0NeXh4qKipsDZqIqKsJqjL+7rvvMGrUKERHR2Pjxo34+OOP8fvf/x49e/b0bbNo0SI89dRTWLFiBfbs2YP4+Hjk5+fj5MmTtgdPRNRliCA88MADYvTo0W1+3tLSItLS0sQTTzzhW1dbWyvcbrd46aWXlI7h9XoFgIAlIiKiw0V1PyvbmV1cLpfSohJXZGRkwKJSlmpcVs7TyWto5VqbjT8iIsLW6+P0eZq9j1WvmdO/J07fZ2Z/D2VLTExMwNLWtl6vt8O6L6gn47/97W8YMWIEbr75ZvTp0weXXXYZnnvuOd/nlZWVqK6uRl5enm+dx+NBTk4Odu3aJS2zoaEBdXV1fgsRUXcTVGX8xRdfYPny5RgwYAA2b96MqVOn4t5778ULL7wAAKiurgYApKam+u2Xmprq+8yopKQEHo/Ht/Tr18/MeRARhbWgKuOWlhZcfvnlePzxx3HZZZfhrrvuwr//+79jxYoVpgOYPXs2vF6vb6mqqjJdFhFRuAqqMk5PT8eQIUP81g0ePBiHDh0CAKSlpQEAampq/LapqanxfWbkdruRlJTktxARdTdB9cAbNWoUysvL/dZ99tlnyMzMBABkZWUhLS0NZWVluPTSSwEAdXV12LNnD6ZOnWopUDvnOVMt3+w8XlZ6mBnjtXsoP7PnZOewlE73srKzLFl5TsdvpYelbJ1KvGb3a2s7s0Opmr2OVu5P1TrCyO55A4N6m+Kdd94RUVFR4rHHHhMVFRVi9erVokePHuLFF1/0bbNw4UKRnJws1q9fLz744AMxceJEkZWVJb7//nulY7T1NoXZRfbmgeq+ZjO2VjLOTmfu7cxCm43f7jc4nLw+smvkdPx2vi1jJV7VNw9kizF+lbdUrLz1EorrE0zdovI2RVCVsRBCbNiwQQwdOlS43W4xaNAg8eyzz/p93tLSIubMmSNSU1OF2+0WY8aMEeXl5crlszJmZRzKhZVx+/uxMm7/e2prW5XK2CWEJtMdnFFXVwePx2NbeVamUNehmcLur8fpZgqV+FXLCgWV787p+O0eCMpsvLL9VDndTGG2fBmz1yeYusXr9XaYD9N21Da7WGnXMfsLZqWd1+wviZ2Vgeq0P3aWL/ue7DxP1bLsHEnP7L2nup/qOalcM7tH0jPua/f/bFViC8XogFYepjhQEBGRBlgZExFpgJUxEZEGWBkTEWmgSyXw7EyiAPYmi8yWbyWJpZKIU01yqCb1VBIYdr8sr/KGiJUEkvG+ksVv5xsQZt9caYvKMa0ktux8W8POtylUz0mbN3lCHQAREbEyJiLSAitjIiINaNdmbKX9Rpe2HzvjsPt6mC1Pdb9QnLvT37tK+bpc61D8Djh9nir76nLebcWhEp92lXF9fb3pfe0e4Szcma1EOmM7Ozl9TJX7qqmpydEYZHR5+AgFHc49mBjq6+s7HOZBu7EpWlpacPjwYSQmJqK+vh79+vVDVVVVWI5zXFdXx/hDiPGHVrjHD1g/ByEE6uvrkZGRIX0j6WzaPRlHRESgb9++AH549SXcB51n/KHF+EMr3OMHrJ2D6sBnTOAREWmAlTERkQa0rozdbjfmzZsHt9sd6lBMYfyhxfhDK9zjBzr3HLRL4BERdUdaPxkTEXUXrIyJiDTAypiISAOsjImINKBtZbx06VKcd955iI2NRU5ODt55551Qh9Smt99+GxMmTEBGRgZcLhdeffVVv8+FEJg7dy7S09MRFxeHvLw8VFRUhCZYg5KSEvzoRz9CYmIi+vTpg0mTJqG8vNxvm5MnT6KoqAgpKSlISEhAQUEBampqQhSxv+XLl2PYsGG+l/Jzc3OxceNG3+c6xy6zcOFCuFwuzJgxw7dO93OYP38+XC6X3zJo0CDf57rHDwBff/01br31VqSkpCAuLg6XXHIJ9u7d6/u8M36HtayMX375ZcyaNQvz5s3De++9h+HDhyM/Px9Hjx4NdWhSJ06cwPDhw7F06VLp54sWLcJTTz2FFStWYM+ePYiPj0d+fj5OnjzZyZEG2r59O4qKirB7925s2bIFTU1NuP7663HixAnfNjNnzsSGDRtQWlqK7du34/Dhw7jxxhtDGPUP+vbti4ULF2Lfvn3Yu3cvrr32WkycOBEfffQRAL1jN3r33Xfxxz/+EcOGDfNbHw7ncPHFF+PIkSO+ZceOHb7PdI//u+++w6hRoxAdHY2NGzfi448/xu9//3v07NnTt02n/A4LDY0cOVIUFRX5fm5ubhYZGRmipKQkhFGpASDWrVvn+7mlpUWkpaWJJ554wreutrZWuN1u8dJLL4UgwvYdPXpUABDbt28XQpyONTo6WpSWlvq2+eSTTwQAsWvXrlCF2a6ePXuK559/Pqxir6+vFwMGDBBbtmwRV199tZg+fboQIjyu/7x588Tw4cOln4VD/A888IAYPXp0m5931u+wdk/GjY2N2LdvH/Ly8nzrIiIikJeXh127doUwMnMqKytRXV3tdz4ejwc5OTlano/X6wUA9OrVCwCwb98+NDU1+cU/aNAg9O/fX7v4m5ubsXbtWpw4cQK5ublhFXtRURHGjx/vFysQPte/oqICGRkZOP/88zF58mQcOnQIQHjE/7e//Q0jRozAzTffjD59+uCyyy7Dc8895/u8s36HtauMv/nmGzQ3NyM1NdVvfWpqKqqrq0MUlXmtMYfD+bS0tGDGjBkYNWoUhg4dCuB0/DExMUhOTvbbVqf4P/zwQyQkJMDtduOee+7BunXrMGTIkLCIHQDWrl2L9957DyUlJQGfhcM55OTkYNWqVdi0aROWL1+OyspKXHnllaivrw+L+L/44gssX74cAwYMwObNmzF16lTce++9eOGFFwB03u+wdqO2UegUFRXhwIEDfu194eCiiy7C+++/D6/Xi1deeQWFhYXYvn17qMNSUlVVhenTp2PLli2IjY0NdTimjB071vfvYcOGIScnB5mZmfjLX/6CuLi4EEampqWlBSNGjMDjjz8OALjssstw4MABrFixAoWFhZ0Wh3ZPxueccw4iIyMDsq01NTVIS0sLUVTmtcas+/lMmzYNr732GrZu3eobwhQ4HX9jYyNqa2v9ttcp/piYGFx44YXIzs5GSUkJhg8fjieffDIsYt+3bx+OHj2Kyy+/HFFRUYiKisL27dvx1FNPISoqCqmpqdqfg1FycjIGDhyIzz//PCy+g/T0dAwZMsRv3eDBg31NLZ31O6xdZRwTE4Ps7GyUlZX51rW0tKCsrAy5ubkhjMycrKwspKWl+Z1PXV0d9uzZo8X5CCEwbdo0rFu3Dn//+9+RlZXl93l2djaio6P94i8vL8ehQ4e0iF+mpaUFDQ0NYRH7mDFj8OGHH+L999/3LSNGjMDkyZN9/9b9HIyOHz+OgwcPIj09PSy+g1GjRgW8zvnZZ58hMzMTQCf+DtuWCrTR2rVrhdvtFqtWrRIff/yxuOuuu0RycrKorq4OdWhS9fX1Yv/+/WL//v0CgPjDH/4g9u/fL7766ishhBALFy4UycnJYv369eKDDz4QEydOFFlZWeL7778PceRCTJ06VXg8HrFt2zZx5MgR3/J///d/vm3uuece0b9/f/H3v/9d7N27V+Tm5orc3NwQRv2DBx98UGzfvl1UVlaKDz74QDz44IPC5XKJN998Uwihd+xtOfttCiH0P4f77rtPbNu2TVRWVoqdO3eKvLw8cc4554ijR48KIfSP/5133hFRUVHiscceExUVFWL16tWiR48e4sUXX/Rt0xm/w1pWxkII8fTTT4v+/fuLmJgYMXLkSLF79+5Qh9SmrVu3CgABS2FhoRDi9Ksxc+bMEampqcLtdosxY8aI8vLy0AZ9hixuAGLlypW+bb7//nvxH//xH6Jnz56iR48e4uc//7k4cuRI6II+y7/927+JzMxMERMTI3r37i3GjBnjq4iF0Dv2thgrY93P4ZZbbhHp6ekiJiZGnHvuueKWW24Rn3/+ue9z3eMXQogNGzaIoUOHCrfbLQYNGiSeffZZv88743eYQ2gSEWlAuzZjIqLuiJUxEZEGWBkTEWmAlTERkQZYGRMRaYCVMRGRBlgZExFpgJUxEZEGWBkTEWmAlTERkQZYGRMRaYCVMRGRBv4fpKTcW3PMr/AAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Select an index to visualize from the entire dataset\n",
    "index_to_visualize = np.random.randint(0, len(all_images))\n",
    "\n",
    "# index_to_visualize = 11548\n",
    "# Visualize the selected image with predicted and true midpoints\n",
    "visualize_midpoints(all_images[index_to_visualize], all_pred_midpoints[index_to_visualize, 0, :, :] * 64, title=\"Predicted Midpoints\")\n",
    "visualize_midpoints(all_images[index_to_visualize], all_true_midpoints[index_to_visualize, 0, :, :] * 64, title=\"Ground Truth Midpoints\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1727987790.870206 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.871400 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.872067 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.872712 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.873559 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.874510 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.875561 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.876804 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.877854 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.879073 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.880299 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.881769 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.883039 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.884296 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.885748 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.887023 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.888511 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.890158 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.892064 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.894231 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.896168 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.898290 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.901208 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.901814 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.902518 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.903972 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.905381 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.906860 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.908515 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.912093 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.916212 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.918848 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.930667 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.931202 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.931689 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.932237 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.932814 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.933316 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.933853 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.936608 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.939334 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.940827 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.943196 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.945838 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.948405 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987790.952766 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.001814 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.002470 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.003129 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.003868 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.004613 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.005381 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.006176 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.006979 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.007795 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.008622 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.009669 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.010496 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.011393 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.012164 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.012925 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.013733 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.015239 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.016582 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.017393 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.018348 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.019543 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.021131 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.029539 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.030168 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.030753 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.031421 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.032017 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.032668 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.033255 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.033927 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.034556 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.035442 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.036230 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.037101 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.039795 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.042402 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.047626 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.052807 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.056236 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.058672 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.062151 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.159653 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.160319 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.161007 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.161684 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.162386 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.163074 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.163768 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.164530 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.165324 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.166154 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.167019 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.167917 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.168873 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.169954 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.171134 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.172412 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.174841 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.175977 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.177298 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.179624 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.181227 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.183236 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.186109 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.195168 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.196054 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.196914 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.197960 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.198982 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.199915 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.200798 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.201625 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.202592 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.204037 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.205301 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.206732 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.211842 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.216787 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.220731 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.230886 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.237332 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.247366 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.253884 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.447912 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.448869 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.449817 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.450789 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.451791 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.452831 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.453862 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.454933 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.456127 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.457385 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.458634 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.459923 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.461312 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.462947 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.464687 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.468648 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.470465 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.472443 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.474602 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.477068 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.480830 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.492597 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.493966 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.495314 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.496805 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.498100 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.499739 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.501069 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.502694 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.504159 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.505472 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.506960 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.508507 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.516300 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.523327 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.533305 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.543030 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.553792 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.564742 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.584985 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.973086 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.974584 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.976170 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.977667 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.979244 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.980896 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.982651 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.984344 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.986346 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.988693 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.990761 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.992879 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.995022 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987791.997869 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.000960 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.004175 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.011326 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.014895 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.019317 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.023306 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.030581 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.047279 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.049626 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.052061 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.054707 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.057049 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.059957 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.062262 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.065252 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.067488 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.069765 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.072401 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.075139 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.088106 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.103944 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.124083 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.143285 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.164453 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.185967 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987792.226324 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.000868 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.003409 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.005944 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.008463 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.011177 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.013992 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.017039 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.019856 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.023268 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.026269 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.029924 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.033604 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.037661 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.042994 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.048508 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.054024 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.067084 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.073985 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.081928 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.095369 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.099564 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.103798 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.109320 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.113690 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.117950 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.122896 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.127108 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.133086 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.137469 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.142654 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.148069 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.173793 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.205537 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.244497 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.282103 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.321445 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.364379 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987793.454275 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987794.997166 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.001658 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.006203 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.010756 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.015630 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.020796 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.026629 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.032004 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.038583 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.044474 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.051733 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.059066 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.066953 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.077911 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.088652 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.099662 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.124653 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.137768 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.153249 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.173911 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.182201 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.190322 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.198402 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.209276 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.217618 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.227357 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.235358 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.246541 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.254558 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.264109 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.274345 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.320817 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.381165 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.458291 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.532474 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.610161 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.713147 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987795.877972 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987798.956832 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987798.964830 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987798.972755 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987798.981115 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987798.990432 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.000054 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.010438 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.020328 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.031321 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.042182 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.055467 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.068825 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.083444 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.102657 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.123169 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.142135 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.186985 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.211683 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.240566 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.274301 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.280377 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.282585 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.284767 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.287019 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.289888 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.292548 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.294686 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.297628 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.299887 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.302461 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.305093 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.320907 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.340637 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.359465 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.378404 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.397897 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.437902 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987799.477626 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.187021 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.189272 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.191443 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.193713 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.196166 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.198622 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.201237 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.203627 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.206317 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.209010 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.212212 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.215390 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.218973 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.223595 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.229009 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.233744 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.277414 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.289645 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.295827 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.303001 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.322073 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.323274 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.324426 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.325470 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.326389 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.333843 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.341211 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.347170 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.355304 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.362810 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.369973 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.380867 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.468016 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.468944 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.469869 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.470806 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.471753 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.472704 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.473667 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.474691 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.475678 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.476783 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.477893 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.479190 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.480645 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.482158 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.483682 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.485276 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.487351 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.493692 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1727987800.495931 3432083 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 31ms/step - loss: 0.0114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01135531347244978"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.evaluate(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbAAAAHDCAYAAABF+E9FAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAABT+UlEQVR4nO3deVxUVf8H8M+wI8ggqCAqiLngvi887oahZWaipWaiLZa5pvaoT7llSWaWuVbWzyU1S3u0rNTM1MxQk7Q090JxA9NkcGM/vz98mBiZixw415mLn/frNa/izJ1zz7n3zny9937vOSYhhAAREZHBuDi6AURERMXBAEZERIbEAEZERIbEAEZERIbEAEZERIbEAEZERIbEAEZERIbEAEZERIbEAEZERIbEAEa6mzp1Kkwmk9Syly5d0rlVRGR0DGCKLF26FCaTCfv27XN0UwxhxowZWL9+vfJ6Bw0aBF9fX+X1ltQ333yDqVOnFnn5jh07wmQyoWbNmnbf37JlC0wmE0wmE9auXWvz3sGDB9G7d2+EhYXBy8sLlStXRpcuXTBv3jyb5apVq2at4/ZX165dpfsIwPr5Z555xu77L7/8snWZ2/+RsmHDBnTo0AEVK1ZEmTJlUL16dTz22GPYtGmTdZlTp05pttlkMuGNN94oVrsB4MiRI+jatSt8fX0REBCAJ598En/99VeRP//ll1+iadOm8PLyQmhoKKZMmYLs7OwCy6WmpmLIkCGoUKECfHx80KlTJ/zyyy/FrvPChQuYMGECOnXqhLJly8JkMmH79u1SfTcqN0c3gEq/V155BRMmTLApmzFjBnr37o2ePXs6plF32TfffIMFCxZIBTEvLy+cPHkSe/fuRcuWLW3eW7lyJby8vJCenm5T/tNPP6FTp04IDQ3Fs88+i+DgYJw5cwa7d+/Gu+++ixEjRtgs37hxY4wdO7bAukNCQoreOTvt/vzzz7Fw4UJ4eHjYvPfJJ5/Ybfdbb72Fl156CR06dMDEiRNRpkwZnDx5Et999x1Wr15dIKD269cPDz74YIF1N2nSpFhtPnv2LNq3bw+z2YwZM2bg2rVreOutt3Dw4EHs3bu3QD9ut3HjRvTs2RMdO3bEvHnzcPDgQbz22mu4ePEiFi1aZF0uNzcXDz30EH799Ve89NJLKF++PBYuXIiOHTsiISHB5h8sRa3z2LFjmDlzJmrWrIkGDRogPj6+WNvAkAQpsWTJEgFA/Pzzz45uiiH4+PiI2NjYAuVTpkwRAMRff/1VrHpjY2OFj49PCVun3rBhw4TM161Dhw6iXr16onbt2mL06NE27928eVP4+fmJmJgYAUCsWbPG+t6DDz4oKlSoIK5cuVKgzpSUFJu/w8LCxEMPPSTXkTsAIHr27ClcXFzE+vXrbd7btWuXAGBtd94+zsrKEn5+fqJLly5268zf7sTERAFAzJo1S2m7hw4dKry9vcXp06etZVu2bBEAxPvvv3/Hz9etW1c0atRIZGVlWctefvllYTKZxJEjR6xln376aYF9dvHiReHv7y/69etXrDrT0tLE5cuXhRBCrFmzRgAQ27ZtK3rnDYyXEHWUdzkrKSkJ3bt3h6+vLypXrowFCxYAuHWpp3PnzvDx8UFYWBhWrVpl8/m///4b48aNQ4MGDeDr6ws/Pz9069YNv/76a4F1nT59Gj169ICPjw8qVqyIF198EZs3b7Z7OWHPnj3o2rUrzGYzypQpgw4dOmDXrl2F9kUIgfLly2PMmDHWstzcXPj7+8PV1RWpqanW8pkzZ8LNzQ3Xrl0DUPAemMlkwvXr17Fs2TLrpZ9BgwbZrC81NRWDBg2Cv78/zGYzBg8ejBs3bhTaRhlF2QanT5/GCy+8gNq1a8Pb2xuBgYHo06cPTp06ZbNcVlYWpk2bhpo1a8LLywuBgYFo27YttmzZAuDWcZC3z/Nf7iqKfv364dNPP0Vubq61bMOGDbhx4wYee+yxAsv/8ccfqFevHvz9/Qu8V7FixSKts6QqV66M9u3bFzieV65ciQYNGqB+/fo25ZcuXUJaWhratGljt77itttiseDo0aOwWCx3XPbzzz9H9+7dERoaai2LiopCrVq18NlnnxX62cOHD+Pw4cMYMmQI3Nz+uaj1wgsvQAhhc4l37dq1CAoKQq9evaxlFSpUwGOPPYYvvvgCGRkZ0nWWLVsWAQEBd+xjacQAprOcnBx069YNVatWxZtvvolq1aph+PDhWLp0Kbp27YrmzZtj5syZKFu2LAYOHIjExETrZ//880+sX78e3bt3x9tvv42XXnoJBw8eRIcOHXD+/HnrctevX0fnzp3x3XffYeTIkXj55Zfx008/Yfz48QXa8/3336N9+/ZIS0vDlClTMGPGDKSmpqJz587Yu3evZj9MJhPatGmDH374wVr222+/WX8c8v/479y5E02aNNG8F/Xxxx/D09MT7dq1w8cff4yPP/4Yzz33nM0yjz32GK5evYq4uDg89thjWLp0KaZNm3aHrV00Rd0GP//8M3766Sf07dsXc+fOxfPPP4+tW7eiY8eONsF06tSpmDZtGjp16oT58+fj5ZdfRmhoqPW+xnPPPYcuXbpY+573Kor+/fvjwoULNv8IWbVqFe6//367P+xhYWFISEjAoUOHilR/VlYWLl26VOB18+bNIn2+sHZv2LDB+o+Y7OxsrFmzBv379y+wbMWKFeHt7Y0NGzbg77//LlL9N27csNvu/PeH1q1bhzp16mDdunWF1nXu3DlcvHgRzZs3L/Bey5YtsX///kI/n/f+7Z8PCQlBlSpVbD6/f/9+NG3aFC4utj+9LVu2xI0bN3D8+HHpOu9pDj4DLDXsXUKMjY0VAMSMGTOsZVeuXBHe3t7CZDKJ1atXW8uPHj0qAIgpU6ZYy9LT00VOTo7NehITE4Wnp6d49dVXrWWzZ88WAGwu2dy8eVNERETYXE7Izc0VNWvWFNHR0SI3N9e67I0bN0R4eLjmJZw8s2bNEq6uriItLU0IIcTcuXNFWFiYaNmypRg/frwQQoicnBzh7+8vXnzxRevn8i4L5nenS4hPPfWUTfmjjz4qAgMDC22fEHe+hCizDW7cuFHg8/Hx8QKAWL58ubWsUaNGd7wUV9xLiEII0bx5c/H0008LIW4dPx4eHmLZsmVi27ZtBS5Hffvtt8LV1VW4urqKyMhI8e9//1ts3rxZZGZmFlhHWFiYAGD3FRcXV+S25gdADBs2TPz999/Cw8NDfPzxx0IIIb7++mthMpnEqVOn7F4mnjx5sgAgfHx8RLdu3cTrr78uEhISCtSfdwlR6xUfH29dNu87uWTJkkLb/PPPPxfYp3leeuklAUCkp6drfn7WrFkCgEhKSirwXosWLUTr1q2tf/v4+BQ4toW4tX0AiE2bNknXmR8vIZJy+TOy/P39Ubt2bfj4+NhcAqpduzb8/f3x559/Wss8PT2t/1LLycnB5cuX4evri9q1a9tkLW3atAmVK1dGjx49rGVeXl549tlnbdpx4MABnDhxAv3798fly5et/2q9fv067r//fvzwww82l6pu165dO+Tk5OCnn34CcOtMq127dmjXrh127twJADh06BBSU1PRrl274mwqq+eff77Aui9fvoy0tLQS1SuzDby9va2fy8rKwuXLl1GjRg34+/vbbH9/f3/8/vvvOHHiRInapqV///7473//i8zMTKxduxaurq549NFH7S7bpUsXxMfHo0ePHvj111/x5ptvIjo6GpUrV8aXX35ZYPlWrVphy5YtBV79+vUrUZvLlSuHrl274pNPPgFw66zxX//6F8LCwuwuP23aNKxatQpNmjTB5s2b8fLLL6NZs2Zo2rQpjhw5UmD5IUOG2G133bp1rcsMGjQIQogCl6dvl3e26enpWeA9Ly8vm2WK8/n8n71582aR1iNT572MWYg68/LyQoUKFWzKzGYzqlSpUuA+iNlsxpUrV6x/5+bm4t1338XChQuRmJiInJwc63uBgYHW/z99+jTuu+++AvXVqFHD5u+8H9jY2FjN9losFpQrV87ue02bNkWZMmWwc+dOREdHY+fOnZg2bRqCg4Mxb948pKenWwNZ27ZtNddRFPnvRQCwtunKlSvw8/Mrdr0y2+DmzZuIi4vDkiVLcO7cOYh8k5fnv6/y6quv4pFHHkGtWrVQv359dO3aFU8++SQaNmxY7Hbm17dvX4wbNw4bN27EypUr0b17d5QtW1Zz+RYtWlgD3q+//op169bhnXfeQe/evXHgwAGbH/ny5csjKipKSTtv179/fzz55JNISkrC+vXr8eabbxa6fL9+/dCvXz+kpaVhz549WLp0KVatWoWHH34Yhw4dsv7IA0DNmjWVtTvvHyp595/yy8uWzP+PGdnP5/+st7d3kdYjU+e9jAFMZ66urlLl+X8kZ8yYgUmTJuGpp57C9OnTERAQABcXF4wePbrQMyUteZ+ZNWsWGjdubHeZwp6hcnd3R6tWrfDDDz/g5MmTSE5ORrt27RAUFISsrCzs2bMHO3fuRERERIGgLaso26c4ZLbBiBEjsGTJEowePRqRkZEwm80wmUzo27evzfZv3749/vjjD3zxxRf49ttv8eGHH+Kdd97Be++9p/k8lIxKlSqhY8eOmD17Nnbt2oXPP/+8SJ/z8PBAixYt0KJFC9SqVQuDBw/GmjVrMGXKlBK3qSh69OgBT09PxMbGIiMjw27SiT1+fn7o0qULunTpAnd3dyxbtgx79uxBhw4ddGlnpUqVANx6nup2Fy5cQEBAgN0zIXufr1q1aoHP538EolKlSprrAf55fEGmznsZA5gTW7t2LTp16oSPPvrIpjw1NRXly5e3/h0WFobDhw9DCGFzFnby5Embz913330Abv1AFPdfr+3atcPMmTPx3XffoXz58oiIiIDJZEK9evWwc+dO7Ny5E927d79jPUXNwlNNZhusXbsWsbGxmD17trUsPT3dJuMyT0BAAAYPHozBgwfj2rVraN++PaZOnWoNYCXtb//+/fHMM8/A39/f7vNPd5KXDGDvx1Mv3t7e6NmzJ1asWIFu3brZHLNF1bx5cyxbtkzXdleuXBkVKlSwOwjB3r17Nf+hkyfv/X379tkElvPnz+Ps2bMYMmSIzbI7d+5Ebm6uTSLHnj17UKZMGdSqVUu6znsZ74E5MVdX1wJnHGvWrMG5c+dsyqKjo3Hu3Dmbexzp6elYvHixzXLNmjXDfffdh7feesuaHZZfUUYdaNeuHTIyMjBnzhy0bdvW+sOcl1F4/vz5It3/8vHxsRsI9CazDext/3nz5tlcygWAy5cv2/zt6+uLGjVq2Fz+8fHxAYBi97l3796YMmWK3YeD89u2bZvds9RvvvkGwK17rbJk0tFvN27cOEyZMgWTJk3SXObGjRuaD99u3LgRgP7tjomJwVdffYUzZ85Yy7Zu3Yrjx4+jT58+1rKsrCwcPXrUJqDWq1cPERER+OCDD2yOjUWLFsFkMqF3797Wst69eyMlJQX//e9/rWWXLl3CmjVr8PDDD1vP9GTqvJfxDMyJde/eHa+++ioGDx6Mf/3rXzh48CBWrlyJ6tWr2yz33HPPYf78+ejXrx9GjRqFSpUqWUdqAP7517+Liws+/PBDdOvWDfXq1cPgwYNRuXJlnDt3Dtu2bYOfnx82bNhQaJsiIyPh5uaGY8eO2fwrsH379tbRAYoSwJo1a4bvvvsOb7/9NkJCQhAeHo5WrVpJbR8tWVlZeO211wqUBwQE4IUXXijyNujevTs+/vhjmM1m1K1bF/Hx8fjuu+9s7j8CQN26ddGxY0c0a9YMAQEB2LdvH9auXYvhw4fb9BcARo4ciejoaLi6uqJv375F7pPZbC7SKB4jRozAjRs38OijjyIiIgKZmZn46aef8Omnn6JatWoYPHiwzfLnzp3DihUrCtTj6+trHSVl3bp1GDx4MJYsWXLHhIjbNWrUCI0aNSp0mRs3buBf//oXWrduja5du6Jq1apITU3F+vXrsXPnTvTs2bPACBu//PKL3Xbfd999iIyMlG73f/7zH6xZswadOnXCqFGjcO3aNcyaNQsNGjSw2Wbnzp1DnTp1EBsbi6VLl1rLZ82ahR49euCBBx5A3759cejQIcyfPx/PPPMM6tSpY12ud+/eaN26NQYPHozDhw9bR+LIyckp8JhIUesEYD3ef//9dwC3Htf48ccfAdwaCafUclwCZOmilUZvL6U7f4p0frePjJCeni7Gjh0rKlWqJLy9vUWbNm1EfHy86NChg+jQoYPNZ//880/x0EMPCW9vb1GhQgUxduxY8fnnnwsAYvfu3TbL7t+/X/Tq1UsEBgYKT09PERYWJh577DGxdevWIvW1RYsWAoDYs2ePtezs2bMCgKhatWqB5e2l0R89elS0b99eeHt7CwDWlHqtkTjytm9iYmKhbct7dMHe67777pPaBleuXBGDBw8W5cuXF76+viI6OlocPXpUhIWF2TwC8Nprr4mWLVsKf39/4e3tLSIiIsTrr79uk7qenZ0tRowYISpUqCBMJtMdU+q1jpH87KXRb9y4UTz11FMiIiJC+Pr6Cg8PD1GjRg0xYsQIuyNxaG2rsLAw63JFTUcX4p80+sLcvo+zsrLE4sWLRc+ePUVYWJjw9PQUZcqUEU2aNBGzZs0SGRkZ1s/eKY0+/36RabcQQhw6dEg88MADokyZMsLf31888cQTIjk52WaZvPXbewRk3bp1onHjxsLT01NUqVJFvPLKK3YfX/j777/F008/LQIDA0WZMmVEhw4dNEfwKWqdhW2T0swkRAnvipPTmjNnDl588UWcPXsWlStXdnRziIiUYgArJW7evGmTWpueno4mTZogJyfH+nQ/EVFpwntgpUSvXr0QGhqKxo0bw2KxYMWKFTh69ChWrlzp6KYREemCAayUiI6OxocffoiVK1ciJycHdevWxerVq/H44487umlERLrgJUQiIjIkPgdGRESGxABGRESGpNs9sAULFmDWrFlITk5Go0aNMG/evCKN35Wbm4vz58+jbNmyDhtuiIiIHEMIgatXryIkJKTAvGn2FlZu9erVwsPDQ/zf//2f+P3338Wzzz4r/P39CzxIac+ZM2cKfSiPL7744ouv0v86c+bMHeOFLkkcrVq1QosWLTB//nwAt86qqlatihEjRmDChAmFftZisdidDl0lraguO8K71hmiqk2afyrx/PLPOlsUqvrrbPTe/s5I9pjQ2vda20h222nVr1Wu1c57cV9S4VJTU2E2mwtdRvklxMzMTCQkJGDixInWMhcXF0RFRdkdsDMjI8Nm0NOrV6+qblIBqi5N6v2l07udjvrRULVeo7df5bpVLa/VB9ljSFW5owKYqu3mbJxtOxemKPtAeRLHpUuXkJOTg6CgIJvyoKAgJCcnF1g+Li4OZrPZ+rp97hsiIiJ7HJ6FOHHiRFgsFusr/3QGREREWpRfQixfvjxcXV2RkpJiU56SkoLg4OACy3t6ehY62ykREZE9ygOYh4cHmjVrhq1bt1rnE8rNzcXWrVtt5ke6G2RvMGtdB9ZKdlCVBKF1rTcrK0tqeb3vIalKBlFVv97bXzbRQfa40lpvYf1SlQShtQ7Zez+3T+6pVX+ZMmWKNSOzoxj9/qqqelxdXe2Wa+33osjNzcWFCxekk9Hs0eU5sDFjxiA2NhbNmzdHy5YtMWfOHFy/fr3AZHpEVLqZTCYMHjwYDz/8MDw8PPhsJ0EIgUuXLmHs2LFFmgW+MLoEsMcffxx//fUXJk+ejOTkZDRu3BibNm0qkNhBRKXb4MGD0bdvX90fjSFjKVu2LIYOHYrp06eX6KzW6QbzTUtLu2Puf1FpXdKRPS3W+3kp2dN92eW1+it7eUnv58kc9byaqsstd+MSoqo0elWXEAvrm4+PD1asWMHJVMmuCxcuYODAgUhNTbX7vsVigZ+fX6F1ODwLkYhKp8DAQHh4eDi6GeSk3Nzc7hig7oQBjIh0YTKZeM+LNKk4Pkr1hJayl0n0HiVA61+jmZmZUvXIZsGVJGOoKGS3j7u7u91yraxLLarqUXUVXdWl18K+1KoyOFUNMaXVVjc3N+uwV/mXcbI7FmRwPAMjIiolPvjgA/Tv3/+urvP8+fNo0aIFjh07dlfXC5TyMzAiouK6dOkSli5dil27duHixYvw9fVFlSpV0K1bN3Tv3h1eXl6ObuIdTZ06FdeuXcNbb73llPWVFAMYEdFtzp49i2eeeQZly5bFCy+8gBo1asDd3R1//PEH1q1bhwoVKqBDhw4FPpedna05Y4AzM2q7eQmRiOg2M2fOhKurK5YvX44uXbogPDwcVapUQYcOHTBnzhy0b98eANCiRQusXbsWY8aMQbt27fB///d/AIC1a9eiZ8+eiIyMRExMDL755htr3fYuuV29ehUtWrRAQkICACAhIQEtWrTA3r17MXDgQLRt2xZPPfUUTp06ZdPOpUuXIjo6Gh06dMD06dNtZvb44IMP8PXXX2PHjh1o0aKFtf689X/77bcYMmQI2rRpg40bN9q9/Lhq1Sr06NGj0PrynDt3Ds8//zzatm2L/v3747ffflOwJwrHAEZETu/QlUP45uw3OHTlkO7rSk1NxZ49e9CnTx94e3vbXSZ/YsrixYvRsWNHfPLJJ+jRowe2bduG2bNn44knnsDq1avRq1cvvPrqq9i3b590WxYtWoRRo0Zh+fLlcHNzw/Tp063vbdmyBYsXL8YLL7yAZcuWoXz58vj888+t7w8YMABRUVGIjIzExo0bsXHjRjRs2ND6/oIFC9C3b1989tlniIyMvGNb7lTfokWLMGDAAKxcuRKhoaF45ZVXlAwXVRhDnTOqeshSKytP1QPFWmSzDbUU5wFYmXr0zmaUzRLUux69535StV8KW7fsOlQ9yKwlKyvLun+Ksr0K++7NOzIPy/9cbi0bWH0gRtQZoaSd9pw9exZCCISFhdmUR0VFWb/Dffr0wYgRt9oQHR1tPUsBgJdffhndu3dHnz59AABhYWE4dOgQVqxYgebNm0u1ZejQoWjWrBkAIDY2FqNHj0ZGRgY8PT2tAfORRx6xLrt3717rWViZMmXg6emJrKwsu+NQ9u3bF507dy5yW+5U34ABA9C2bVsAwJAhQ/D444/j7NmzqFatmlSfZfAMjIic1qErh2yCFwAs/3P5XTkTu93SpUuxcuVKVK9e3eYfo3Xq1LFZ7tSpU2jUqJFNWcOGDZGYmCi9zpo1a1r/Py9oXLlyxbqe+vXr2yzfoEGDItddt25d6fYUpkaNGtb/z2vr33//rXQdt2MAIyKnlXQ9SapchSpVqsBkMuH06dMFyqtWrVpg+iety4xa7F3h0LrUZi+xQtXQardnUdo7C5a56pK/rXl16f3cHwMYETmtUJ9QqXIV/P390apVK6xZswY3b96U/ny1atXw66+/2pT99ttvqF69urV+4Faafp7jx48Xaz2HDtmeid7+t7u7e5GDULly5XD58mWboHP7s10y9d0NDGBE5LTql6uPgdUH2pTFVo9F/XL1NT6hxvjx45GdnY2BAwfi22+/RWJiIk6dOoVvvvkGp06d0rxPDABPPvkkvvrqK6xduxZJSUlYuXIltm3bhgEDBgC4debToEEDLFu2DImJiUhISMCiRYuk29i3b19s2LABX375JU6fPo33338ff/75p80yISEhOHnyJE6dOoXU1NRCkyqaNWuGK1euYPny5Th79iw+++wzxMfHF7u+u8FQSRxEdO8ZUWcEOgV3QtL1JIT6hOoevIBblwtXrlyJJUuWYMGCBbh48SI8PDwQHh6OAQMGWBM07OnYsSPGjh2LFStWYPbs2QgJCcHkyZOtyRgAMGnSJEyfPh1PPvkkwsLCMHLkSOkJfx944AGcO3cO8+bNQ2ZmJjp16oSYmBiboNOzZ08kJCQgNjYWN27cwHvvvYdKlSrZrS88PBzjx4/HkiVL8NFHH6Fz584YMGAA1q1bV6z67gZDTaeiNS2ILK0H9vI/Q1EUsu2RPfXWe3oR2bEfZetx1KUGR82mq2p8QWdUnGMlLCwMCxcuNNRMzGRLz+/SpUuXMGzYsAL3GoUQyM3N5XQqRERUejGAERGRITGAERGRITGAERGRITGAERGRIRkqjV4r+042I0Z2edksO1XjyamaOVp2u8mO/agqK1JrhmWtZ01kM6QcldWpRSsbVtUYj4B2n7WoGlOxOHWR89E7UzYnJ6dE2co8AyMiIkNiACMiIkNiACMiIkNiACMicpCpU6di3Lhx1r+fe+45zJ49u0R1qqjDKAyVxEFEdDdMnToVX3/9NYBbyTbBwcF48MEHMXjwYM3kGxXefPPNItefkJCA559/Ht9//z3Kli1brDqMzlC9VJVdpio7Su+sNq16ZGdMVjVGn94ZSVrZd1pjTjrTtA6AfHtk9y8gn3mpajZoI43bqEpkZCQmT56MrKws7Nq1yxoYBg8ebLNcVlaWZgatlrztfPt/tcaBlaGiDqMwVAAjIrpbPDw8rAMR9+7dG9u3b8fOnTtx+vRpXLt2DXXr1sWaNWvg4eGBL774AsnJyXj33Xexe/duuLi4oHHjxhg7dixCQkIA3PoHzty5c/Hll1/C1dUVPXr0KPAPg+eeew61atXC2LFjAQCZmZl4//33sWnTJly5cgVBQUEYNGgQWrRogeeffx4A0LlzZwDAQw89hKlTpxaoIy0tDbNnz8bOnTuRmZmJpk2bYty4cQgNvTWn2oYNG/D2229jxowZePvtt5GSkoJGjRphypQp1v4nJCRg7ty5+PPPP+Hm5obq1avjtddec+hI9AADGBEZgM+hQ/BMSkJGaCiu19d/OhV7PD09YbFYAAA///wzfHx8MH/+fAC3nlUcOXIkGjRogMWLF8PV1RUfffQRRo4ciU8++QTu7u5YuXIlvvrqK0yaNAnVq1fHihUrsH37djRv3lxznVOmTMHBgwcxbtw41KxZE+fPn0dqaiqCgoIwc+ZMjB8/HmvXroWPj0+BGZbzTJs2DWfOnMHs2bPh4+ODefPmYfTo0fjss8+slxrT09OxYsUKTJs2DS4uLpg8eTLmzJmD1157DdnZ2Rg3bhx69uyJ119/HVlZWfj999+VPe9aEgxgROTUKs+bh0rLl1v/vjBwIM6NGHHX1i+EwN69e7F792489thjuHLlCry8vPDKK69YLx1+8803yM3NxSuvvGL9YZ8yZQo6deqEhIQEtG7dGp988gkGDRqEzp07w2QyYeLEidi9e7fmek+fPo3vvvsO8+fPR6tWrQDcmqcsT96lwoCAAJt7YPklJSXhhx9+wIcffohGjRoBAKZPn47u3btj+/btiIqKAnArAE+cONFaf58+ffDhhx8CAK5fv45r166hbdu21vfDw8OLtzEVYwAjIqflc+iQTfACgErLlyO1Uyfdz8R+/PFHtG/fHtnZ2cjNzUXXrl0xZMgQzJw5EzVq1LC573XixAmcPXsWHTp0sKkjMzMTZ8+exbVr13Dp0iXUq1fP+p6bmxvq1KmjeX/x+PHjcHV1tZkIU1ZiYiJcXV1RP9+28vf3R1hYGBITE61lXl5eNsGxfPnyuHLlCoBbgbJ79+4YOXIkWrZsiZYtW6JLly5OMc8bAxgROS3PpCTNcr0DWLNmzTBhwgS4u7ujfPnyNpl93t7eNsvevHkTERERmD59eoF6ypUrV6z1e3p6FutzxXF71qLJZLIJrFOmTEHfvn3x008/YcuWLXjvvfcwf/58NGjQ4K610R6nDWAmk6nANVZVWYVaGUNaWXCqxk5UNWajqmw3LVpZf7JjKuo9s7NsdqJsO1Vl3snWX9h6i5O5aI+qcSe1uLi4KJlBPeN/iQZFLVfJ29sbVatWLdKytWvXxpYtW1CuXDn4+vraXaZ8+fL4/fff0bRpUwghkJ2djSNHjiAiIsLuPq9RowZyc3ORkJBgvYSYX17QKez3IDw8HDk5OTh06JD1EmJqaipOnz6N6tWrF6lv+ftYu3ZtDB48GE899RQ2b95c4gDm4uJS4NgVQhT5u8cHmYnIaV2vXx8XBg60KbsQG+uwRA4t3bp1g7+/P8aNG4f9+/fj3LlzSEhIwFtvvYWUlBQAQN++fbFs2TJs374dp06dwsyZM3Ht2jXNOkNCQvDQQw9h+vTp2L59u7XOLVu2AAAqVaoEk8mEH3/8EVeuXMGNGzcK1BEaGooOHTrg9ddfx4EDB3D8+HFMnjwZFStWLHC5U8u5c+cwf/58/Pbbb7hw4QJ2796NpKQkVKtWTX5DKea0Z2BERABwbsQIpHbq5PAsxMJ4eXnh/fffx/z58/Hvf/8bN27cQIUKFdCiRQv4+PgAAJ544glcunQJU6dOhYuLCx5++GF07Nix0CA2YcIELFy4EDNnzoTFYkFwcDAGDRoEAKhYsSKGDBmC+fPn49VXX8WDDz6IqVOnFqhj8uTJmD17Nl588UVkZWWhSZMmmDNnTpEfdvby8sLp06cxfvx4WCwWlC9fHn369EGvXr2kt5NqJuFkTyimpaXBbDZLXUKUJXsJUYvsZRUn29SanO0SotZ6VT3g7GyXEAvbbqoe5pe9hCjLxcUFYWFhWLBggVPc7Cfnc+nSJbzwwgs4ffq0TXneJUSLxQI/P79C6+AlRCIiMiQGMCIiMiSnvQcmk4kiS+WMt85E1aUwrUtwqrI3ZS93yWYnynK2S7vFuYQoe3ld7+9ASWfaVY1jPDone7/zMvuEZ2BERGRIDGBERGRIDGBEpIvc3FxeoiNNKm4TMYARkS4uXLiAS5cuIT093dFNISeTk5MDi8WCv/76q0T1OG0SBxEZW3Z2NsaOHYuhQ4eiefPmcHNzc4opOMix8p7xev3113Hz5s0S1eW0DzLbo+qBUL0fUFW1vGxWnhbZ/qqawVm2fq0sx4yMDKn6Zen9wLWs4mQhatF7X2rJ3weTyQSz2XzHh1JVrzc/rX5pPQyvtd1KawazLNmxN/N/N4QQ+Ouvv+4YvIryIDPPwIhIV0IIpKamIjU1Vfd7Ygxgd0dJApjSduhSKxERkc4YwIiIyJAYwIiIyJCkA9gPP/yAhx9+GCEhITCZTFi/fr3N+0IITJ48GZUqVYK3tzeioqJw4sQJVe0lIiICUIwkjuvXr6NRo0Z46qmn7M4H8+abb2Lu3LlYtmwZwsPDMWnSJERHR+Pw4cPw8vIqUWNVzWisit7t0TvbUKt+rfJatWrZLT9+/LjdctkZtLWyDfXOpNN7v8gq7Aa5qtm49e6Dqu+eVpKFbP15x+iBSwdwKu0UqvlVQ+PyjTWPab3HcXRUdqiqcUhlxznVi3QA69atG7p162b3PSEE5syZg1deeQWPPPIIAGD58uUICgrC+vXr0bdv35K1loiomN7c/yYWH15s/fvZus86sDWkgtJwmZiYiOTkZERFRVnLzGYzWrVqhfj4eLufycjIQFpams2LnFfDmzfRw2JBwxI+gEh0Nx24dMAmeAHA4sOLISo71WOwJEnpc2DJyckAgKCgIJvyoKAg63u3i4uLw7Rp01Q2g3Qy5uJFPPv339a/54f74K1KnG2XnN+ptFP23wgEWp4VqAXgOIC9HCnEUByehThx4kRYLBbr68yZM45uEtnRUgib4AUAwxOvI6juaeTer89DikSqVPOrZrc87g9gN4DluPXfOOcamIjuQGkACw4OBgCkpKTYlKekpFjfu52npyf8/PxsXuR8amp8sWtdBtAGvBRDTq1x+cYF7nnNcO+JCddslxuPW/9YI2NQegkxPDwcwcHB2Lp1Kxo3bgzg1tiGe/bswdChQ1Wuyoaq4WNkM4CcLctRz/pPmEyAneWPB/6vrnIC4kwJp0aQzJDSm97tkR3GCNA/O06rTbLr1Xt2cNn11qxZ89b/VAYQCOAycPjcevvLAtgjtVZ1x4qjhtrSItserf7KZCfKTLMiHcCuXbuGkydPWv9OTEzEgQMHEBAQgNDQUIwePRqvvfYaatasaU2jDwkJQc+ePWVXRU5kr8mED8qVw5ArV6xlcW2AvVX+98dlx7SLSMq5/71w656XPVrl5HykA9i+ffvQqVMn699jxowBAMTGxmLp0qX497//jevXr2PIkCFITU1F27ZtsWnTphI/A0aO93bFiviubFkEBF/C/oY3/gleO2H9USAyir0A3gAwIV9Z3P/KyRgMNZ2KltJ6CdFRtLZPjRo1rP9/M/AmMstmwuOqB5J+SlKyXl5CLHy9gLrR0LW+M1rrdtQlRFnFWW9L4J8sxGKuV/ZYcdSxruoSsRbZwRHsybuEyOlUSDfel73hfdnb0c0gKrG94FmXUTk8jZ6IiKg4nPoM7PbTTlWX8lSdLmvNIJydnW23XO+ZfLVotVPrcpRWe/QelFlrvbKXfFVtT733i1b9d+PStNY69M5y1OJsl49lqcrW0yJ76U/rt0ZredkxDJ3ldgvPwIiIyJAYwIiIyJAYwIiIyJAYwIiIyJAYwIiIyJCcOguxqJkrqmY3lX0IUnZ5R82qKptZ5uZm/7CQza6UfZBcq52OyoyTpSqT7m5k3mntA0dlRsr22VEPSmvRe716P0iu6pi729mkPAMjIiJDYgAjIiJDYgAjIiJDYgAjIiJDYgAjIiJDcuosxKKSzfoz+uypsrOqytIaI1HvWXZl69c740nv+mWzW4tTlxZHZXaqOoZkjwlVmcGq2i87Pqls5q6jxpCUnT7GXr+EEJoZzwXqLXrTiIiInAcDGBERGRIDGBERGRIDGBERGRIDGBERGVKpyEKUnRlZK1NGNsNIq37ZDCNZsu2XzQxSNR6e3vXrTdUsu47cDqqy5mQzYh2VBaeqX1r7THZGY1Xjkxp9PFAtJf1N5BkYEREZEgMYEREZEgMYEREZEgMYEREZEgMYEREZklNnIRZ1TLjMzEypelWNcad3ppJshpfsGHp6z4Krd1ahUbIiHZWRB6jrg6PGG1VFtp2yWX96z7qt92zxqtzt/cszMCIiMiQGMCIiMiQGMCIiMiQGMCIiMiQGMCIiMiSnzkK8nd5ZYVqznqoaz0w2S1B2/Dlny8rTe7ZbR41VaCSO6pve21pVVp6z7WNV46g6KgtRi17HIc/AiIjIkBjAiIjIkBjAiIjIkAx1D4yIiqYlgFoATgqBvZL3XomMgmdgRKVMHIA9AD4GEC8EZjhZogKRKibhZNPgpqWlwWw2w83NrUAmjWwmjqenp93yjIwMu+V6Z+6oypzSyuhRlYGlank3N/sn+Kpmpi6ttDLRgDtvu5a4Fbxul/nDDxAtW1r/9vLysvt52UxZVd8N2VnVtdYrm0nsqO92aaUiczqvzGKxwM/Pr9D18RIiUSlSS6M88efN2FXmBGoG1ETLkJYaSxEZCwMYUSlyXKN84JHXsffqrf8f22rsXWsPkZ54D4yoFNkL4I3byuLaAHur/PP37D2zgcp3s1VE+mAAIyplJgJoBeBJABuWvoz/dLGzUODdbRORHhjAiEqhvQBWAPBvH21/gct3szVE+nDae2Ba2Uf2eHh42C3XyjbUWl52ZmfZjBvZcb9kxwCUzRKUrV+2HqNnG2pltGmNgakqy7Sw7Sa7jvbV2wNRANrmK9wJ4JzmKpSsV7YerT7LZtzqnW0oO6afo8ai1Pu3SYuqmbuLur+cNoARkSLfATiCW5cNL0M6eBE5KwYwonvBOTBwUanDe2BERGRIDGBERGRIUgEsLi4OLVq0QNmyZVGxYkX07NkTx44ds1kmPT0dw4YNQ2BgIHx9fRETE4OUlBSljSYiIpIaC7Fr167o27cvWrRogezsbPznP//BoUOHcPjwYfj4+AAAhg4diq+//hpLly6F2WzG8OHD4eLigl27dhVpHXljITqT0jxjrz2OGtdNK+tPi97ZmHqTzXIs7meMQPY75mz7Um96z8KuRdVvXHHaX5SxECFK4OLFiwKA2LFjhxBCiNTUVOHu7i7WrFljXebIkSMCgIiPjy9SnRaLRQBwqpeLi4vdl6PbpdfLZDLZfem9XldXV6mX7H5xVL9k+6v6M0Z4GX1f6v1S1V+t7az3b1xx2m+xWO4YL0p0D8xisQAAAgICAAAJCQnIyspCVFSUdZmIiAiEhoYiPj6+JKsiIiKyUew0+tzcXIwePRpt2rRB/fr1AQDJycnw8PCAv7+/zbJBQUFITk62W09GRobNA8dpaWnFbRIREd1Din0GNmzYMBw6dAirV68uUQPi4uJgNputr6pVq5aoPiIiujcUK4ANHz4cX331FbZt24YqVf4Z5jo4OBiZmZlITU21WT4lJQXBwcF265o4cSIsFov1debMmeI0iYiI7jFSlxCFEBgxYgTWrVuH7du3Izw83Ob9Zs2awd3dHVu3bkVMTAwA4NixY0hKSkJkZKTdOj09PTVnTr49c0XonGEkmykjmzXnbJlijsqu1Jp9V++xE2WPH70z3YpzPBj9GJKd8VmL1j7QewxA2WNC1XdM1TEnu91kqaqnqKQC2LBhw7Bq1Sp88cUXKFu2rPW+ltlshre3N8xmM55++mmMGTMGAQEB8PPzw4gRIxAZGYnWrVvr0gEiIro3ST0HphVdlyxZgkGDBgG49SDz2LFj8cknnyAjIwPR0dFYuHCh5iXE2+V/DsxZzsC0yD5TYfR/PaviqDMwWffas0bFoeoMTO8zJKOfganiqO2jpbDvUlGeA5MKYHcDA9jdwwBWOAawO2MAu4UBrPB6tJQ0gHEsRCIiMiQGMCIiMiSnng/s9tNLvcfxkr00pHVJULadqsiOk6e1vN7jn6ma0VhvpflSoapt7ahsOlWzjMvSe/uoomr7yP5G3O3vDM/AiIjIkBjAiIjIkBjAiIjIkBjAiIjIkBjAiIjIkJw6C/F2RpkBWVU7ZR/4lX1QWmt5rfVmZ2dL1S877pqbm/3DUau/Hh4edsszMzOL0Dr1VD2gXdjDoLJZXrIZsXo/kKsq+1H2gVwtqrIWZbePqtnHtaiayVrV4At6ZRjzDIyIiAyJAYyIiAyJAYyIiAyJAYyIiAyJAYyIiAzJUFmIqjJZZMcMdBSt7DVV2W5a202rHr3Hz5OtRysr0lH7V1W2YWGZg7J9kB2PUoveM/nK0nu8Ttl+ybZH72PRUftFi8zxI/M7wDMwIiIyJAYwIiIyJAYwIiIyJAYwIiIyJAYwIiIyJENlIaoiO96bVlabVtaZqiw4rXpkxyTUotVfre2jNVah1tiDes+aa5SxMbWoHH9O1SzgqsY8VEX2GPL29rZbnpGRYbdcq1/ONvajLL2zRmWzN/U6fngGRkREhsQARkREhsQARkREhsQARkREhsQARkREhmSoLERVmTuyGTGOGudM7/HeZNup99iDzpYBp7fiZA5qbQvZGXgdlR2nKjNVazzQmzdvSrVH9phTlX3nbNmJquqRrZ8zMhMR0T2JAYyIiAyJAYyIiAyJAYyIiAyJAYyIiAzJUFmIelOVkaQ1ZqBWVp7sDMWy45npnb2panw1vbMu9c7w0qL3mJDFWYdsPVpUfWdkqZr9WvaYk91nznYsypLdv7LjydrLbOaMzEREVOoxgBERkSExgBERkSExgBERkSExgBERkSExCzEfVeOWyWZIaY3rprVerRmQZWllBslmRWqVy46RKJvxJFu/1vbUWq/sWI6yGXZa2aqFHT9a69A6hmSPFdlsOlUzFOs93qWqrD/ZY1TvbENVWaBa7VQ1bixnZCYiIsqHAYyIiAyJAYyIiAyJAYyIiAyJAYyIiAypVGQh6p2JoyqTSGY8sOKsVzYrT9X2UZXFp/dM2VrtVzWDtuz20co2LCybUWsdWtmGHh4edsu1+qxV7mxj92ltU72zKLW+Y1oclV2pagxGreNHNrtVZiZrIUSR28kzMCIiMiQGMCIiMiQGMCIiMiQGMCIiMiSpALZo0SI0bNgQfn5+8PPzQ2RkJDZu3Gh9Pz09HcOGDUNgYCB8fX0RExODlJQU5Y0mIiIyCYm0lA0bNsDV1RU1a9aEEALLli3DrFmzsH//ftSrVw9Dhw7F119/jaVLl8JsNmP48OFwcXHBrl27itygtLQ0mM1muLi4FMhQkR3jTjYrTHaWUVVZfKrIttPZqBrbUIujtr/serXqAeTH3CusLpn6tWjVr7VvtPalqnEzZTOJtcaQlB3PVO/fFFWM9BthsVjg5+dX6DJSAcyegIAAzJo1C71790aFChWwatUq9O7dGwBw9OhR1KlTB/Hx8WjdunWR6mMAKz4jHZz2MIAVXg/AAHan9TKAFc5IvxFFCWDFvgeWk5OD1atX4/r164iMjERCQgKysrIQFRVlXSYiIgKhoaGIj48v7mqIiIjskn6Q+eDBg4iMjER6ejp8fX2xbt061K1bFwcOHICHhwf8/f1tlg8KCkJycrJmfRkZGcjIyLD+nZaWJtskIiK6B0mfgdWuXRsHDhzAnj17MHToUMTGxuLw4cPFbkBcXBzMZrP1VbVq1WLXRURE9w7pAObh4YEaNWqgWbNmiIuLQ6NGjfDuu+8iODgYmZmZSE1NtVk+JSUFwcHBmvVNnDgRFovF+jpz5ox0J4iI6N5T4rEQc3NzkZGRgWbNmsHd3R1bt25FTEwMAODYsWNISkpCZGSk5uc9PT3h6elpt96SUnXD0lHJGqpmf5Vtp+wNdS2yN9pV3UjWe3w4vWcVLs7YjKr2maPG+pNN1JH9TmrRStaQ/e7pPY6nKnr/lt3tBDapADZx4kR069YNoaGhuHr1KlatWoXt27dj8+bNMJvNePrppzFmzBgEBATAz88PI0aMQGRkZJEzEImIiIpKKoBdvHgRAwcOxIULF2A2m9GwYUNs3rwZXbp0AQC88847cHFxQUxMDDIyMhAdHY2FCxfq0nAiIrq3lfg5MNXyngOTITNUP6Du9N3ZLiGqei7KUZcQtai6JGjUyyRF4WyXEFV99xy1j430vJQKzvjd0PU5MCIiIkdiACMiIkMy1IzMjspq06L3JSOtyzmyWYhaZGdSlr084GyXW1T1V6vczc3+10lrOxQn21C2D7KXFmXbZC+DGIDN4AQl4WwZpUa/tFimTBm75Vr7S/Z4uNuX0XkGRkREhsQARkREhsQARkREhsQARkREhsQARkREhsQARkREhuTUafRFHVlC75E4HJU6m52dLbW83gOQqkqR1Xu0BNkUcdn2yD42oJXKXpztILvPZGc0lq1fK/3aUbOea1H1W2CUdHmt/t64cUPX9er96M/teAZGRESGxABGRESGxABGRESGxABGRESGxABGRESG5NRZiLdnqMhmG6rKOpPNeJKlKqNKNqPH3d3dbrlW9qNW/R4eHnbLMzMzperRIrt/ZcnOiyabhaiqncUhm32n6tiSzUaT/Q6oyqBVlY2p97xlqjJl9Xa3M7Z5BkZERIbEAEZERIbEAEZERIbEAEZERIbEAEZERIbktFmIJpOpQOaNbAaTqowqvTmqPVlZWUrq0co21Nr+WplKstl9elPVHkceh1qZplr7TItsH7SOLWf7TqrKMJZtv97LOyorUmu/y37ni4pnYEREZEgMYEREZEgMYEREZEgMYEREZEgMYEREZEhOm4UohChyhoqqmXxVjSum9+yyztZf2Qwm2bEBZbMZVY09KDvDstZ6VWbYyR5bstmGWlT1wVFj9+l9rMjSao8W2e2m9+zmsvVzLEQiIqJ8GMCIiMiQGMCIiMiQGMCIiMiQGMCIiMiQnDYL0R5Vs31qLa93/Y6aCdpRYwnKkt3+emeQyWYb3g2yx67es5Ubhd7fAdnt5qjvpKpjWu/M6aLiGRgRERkSAxgRERkSAxgRERkSAxgRERkSAxgRERmSobIQVZHNxJHNMFKVzWiUzC9V7VSVmaVqf6lyNzL7VG07oxxzpZWq2eVVjUOqxVmOE56BERGRITGAERGRITGAERGRITGAERGRITGAERGRIZXqLERVs7DKjvul9zhneo9npveMzKq4u7vbLc/KypKqR9VM2aoUtl6jz8btKM42S7oWrfU6auxEZ9+/PAMjIiJDYgAjIiJDYgAjIiJDKlEAe+ONN2AymTB69GhrWXp6OoYNG4bAwED4+voiJiYGKSkpJW0nERGRjWIHsJ9//hnvv/8+GjZsaFP+4osvYsOGDVizZg127NiB8+fPo1evXiVuKBERkQ1RDFevXhU1a9YUW7ZsER06dBCjRo0SQgiRmpoq3N3dxZo1a6zLHjlyRAAQ8fHxRarbYrEIAAKAMJlMNq+8cmd53d6+u9VOVet1tnqcbT/q3S9XV1e7r7uxbmc7FmW3kaPa4+LiYvflqO0mW4+q9araDoW9LBbLHeNFsc7Ahg0bhoceeghRUVE25QkJCcjKyrIpj4iIQGhoKOLj44uzKiIiIruknwNbvXo1fvnlF/z8888F3ktOToaHhwf8/f1tyoOCgpCcnGy3voyMDGRkZFj/TktLk20SERHdg6TOwM6cOYNRo0Zh5cqV8PLyUtKAuLg4mM1m66tq1apK6iUiotJNKoAlJCTg4sWLaNq0Kdzc3ODm5oYdO3Zg7ty5cHNzQ1BQEDIzM5GammrzuZSUFAQHB9utc+LEibBYLNbXmTNnit0ZIiK6d0hdQrz//vtx8OBBm7LBgwcjIiIC48ePR9WqVeHu7o6tW7ciJiYGAHDs2DEkJSUhMjLSbp2enp7w9PQsZvOJiOheJRXAypYti/r169uU+fj4IDAw0Fr+9NNPY8yYMQgICICfnx9GjBiByMhItG7dWl2rb6NqnDPZsRNlxwlz1MzOWrTWKzvWolY9WlTNiK1Ftj2yy6saH07V7LiA/LiQes9arWqbym4j2fVq0fu7p+oY0nt5LbK/rarWezvlg/m+8847cHFxQUxMDDIyMhAdHY2FCxeqXg0REd3jTEKv0FhMaWlpMJvNAApGc1VnKqrOwFSt11FnYFpUjXavqn5HjQyuxRlH6Ha2MzDZY9TZtqne3z1Hfbf1pnI/WiwW+Pn5FboMx0IkIiJDYgAjIiJDYgAjIiJDcuoZmYt63VTV9XbZezyy65W9v6DVTr3vUam6F6WqflX3QfTOGlW13uLQe5tqLa9q2znbNtX6bqu6d+WoLD6t3w6t+lX9xmmx11+ZOngGRkREhsQARkREhsQARkREhsQARkREhsQARkREhuTUWYh60cqs0RrNQCvDSzZDRyuDSVUGkCqyWZFa7XTUOG2q6lfVHtlMvcKyPbW2td7HitH3paMyUFVRlXmscvxNe/QenajA+orWLCIiIufCAEZERIbEAEZERIbEAEZERIbEAEZERIZ0T2YhatGaO0kVVePAaVGVaeUss63m0coOzc7Otlsu2x7Z7FC991dhGYWy837JrtvJpgfUpPf8ZKqOIdn6ZeckdDay262k2bM8AyMiIkNiACMiIkNiACMiIkNiACMiIkNiACMiIkMyVBaiqswjR2Vg6T1+m1a5h4eH3fLMzEyp9jgqQ0p2dlxV7ZHN3pStR3ZMTkA721B2DDpHZb6qIvsd0BpLUJbWsaUqY1XVsetss4mrmsm6QL0l+jQREZGDMIAREZEhMYAREZEhMYAREZEhMYAREZEhGSoLUTZjRXYMPVl6Z2CpyhiSzTbUYpTx2LTIZg9q0TvDrrDjU9VYiLL0PtZVZdzK0jtjVRVVma+yMzvL9svNzX5IUfWbezuegRERkSExgBERkSExgBERkSExgBERkSEZKomDiMjZtQRQC8BxAHsd3JbSzmkDmMlkKpB5o5WJo5VBo5WZJZvRo2q2Vb3Jrlc2I0lvemfY6Z3RJqs427+kY8cVd92qMmKLMwu1CrLjTmodc9OnTy9Qdkacwa9nf4Vfph+G7T6DR44etb73BoCJdurRO+tS1finsvTOhr2d0wYwIiJntzlnM37Ej0AI0PIs8MhR2/cnAFgHnonphffAiIiK4Yw4cyt4/U+ty/aXq3WX2nMvYgAjIiqGy8I2Yh0PtL/c8bvQlnsVAxgRUTEEmmwj1t4qwBttbJeJAy8f6on3wIiIiqGqqSraoq3NZcTlTevgWpkqqJSWhgt+fnh9yxYHtrD0MwlHpWBpSEtLg9lsdsi6tTKztDKYtMb9UjVrruzyemfxOfvsrKo5avy/wrJktY45VbNrq9oHqrad7HdS1Xq1lrf3HcsNyUWOOQe4DOCc1GpKzNmOUZXfYYvFAj8/v0KX4RkYEVEJuJx3Qc5pYw90bVS8B0ZERIbEAEZERIbEAEZERIbEAEZERIZkqCQOrcwXrYwqrXHdtJaXzdyRnWVUNttQtj2y2YaqxmOTnflaqx69szRll3eyBF0A8tmGqrLUVB0rsvvA2WZMlv2O6T3eqOx3Urb9svv3bo+vyjMwIiIyJAYwIiIyJAYwIiIyJAYwIiIyJKkANnXqVOtEk3mviIgI6/vp6ekYNmwYAgMD4evri5iYGKSkpChvNBERkXQWYr169fDdd9/9U0G+sdlefPFFfP3111izZg3MZjOGDx+OXr16YdeuXUoaq5X5Ipvh4mwz88qOHyabtah3vxyVmSU7Tp7e4+eponI8OVV9UFWPs413KUv22NUq13vGZFXjnzoqa7SopAOYm5sbgoODC5RbLBZ89NFHWLVqFTp37gwAWLJkCerUqYPdu3ejdevWJW8tERHR/0jfAztx4gRCQkJQvXp1PPHEE0hKSgIAJCQkICsrC1FRUdZlIyIiEBoaivj4eM36MjIykJaWZvMiIiK6E6kA1qpVKyxduhSbNm3CokWLkJiYiHbt2uHq1atITk6Gh4cH/P39bT4TFBSE5ORkzTrj4uJgNputr6pVqxarI0REdG+RuoTYrVs36/83bNgQrVq1QlhYGD777DN4e3sXqwETJ07EmDFjrH+npaUxiBER0R2VKI3e398ftWrVwsmTJxEcHIzMzEykpqbaLJOSkmL3nlkeT09P+Pn52byIiIjupERjIV67dg1//PEHnnzySTRr1gzu7u7YunUrYmJiAADHjh1DUlISIiMjlTRWNiOmODPe2qOVgSVbj6pZTGWX11rvqFGj7Ja/8847dsu1tr8WvbMiZTOtnG0maJVZjrKZlKq+S1r0nhHYURm3qjJltbINZbMT9c6gdfasUakANm7cODz88MMICwvD+fPnMWXKFLi6uqJfv34wm814+umnMWbMGAQEBMDPzw8jRoxAZGQkMxCJiEg5qQB29uxZ9OvXD5cvX0aFChXQtm1b7N69GxUqVABw61/uLi4uiImJQUZGBqKjo7Fw4UJdGk5ERPc2qQC2evXqQt/38vLCggULsGDBghI1ivTRUgjUAnAcwF7JS0JERM7GUPOBUfHFCYHx+f5+o7zAAdcLqJRTyWFtIiIqCQ7mew9oeVvwAoAJfwGJlk+x02unQ9pERFRShjoDk82I0TtTSXYmaNn1qsoUq31r5QXKa10GVlRJwJH/HoFb8j+Hwpw5c6TaqcXZsv5UrdeR/VKVdabqu6SKbL/0zr5TlXUpm7WoasZt2d8mZxsPtKh4BnYPOK5VHnjrv7nlnDtVlojIHgawe8BekwkzbyuLawPsrXLr/12u8DAgIuMx1CVEKr7/uLhgvRCoUVfgeOQ/wctjr4fN5UMiIqPgL9c9ZK/JhL1HTBBpAqYAwPumN4MXERkWf73uQaZzJuAc4ObL3U9ExnVP/oKpyrhRNfuo1mDHjz/+uN3yd999V6p+rYwz2bnXZDOeHJVtKNserfHqtI4HvWd2LiwDTnZ8T0fNQi27D2TXq3d2nLNl36mahd3Zvqslxbv3RERkSAxgRERkSAxgRERkSAxgRERkSAxgRERkSCbhZOk2aWlpMJvNdt9TNQOyo2ZzlRUQEGC3/OrVq3bLs7OzpepXlR2naqZpvcnOKO2osRMLO871Pka1MjJlM25VZbvpndmp9/ikqjhq7EdH/iZaLBb4+fkVugzPwIiIyJAYwIiIyJAYwIiIyJAYwIiIyJAYwIiIyJBKxViIjpp5WdU4c1r1X7lyRUk9jsr8kqWVAafVr6ysLKn6ZbeDqqxFlbMfa20jrXLZGX5Vzdir6lhxVD2yGc9a9D6mVXFzsx8KtDKbnWWsRZ6BERGRITGAERGRITGAERGRITGAERGRITGAERGRIZWKLERZeo/ppypDR3YWVkdlG2ot7+7ubrdcK9NKKwNO1czXsv2VzTJVNY5gYbTq0nssPr3HHnS2mYJVZVdq7S9nm4FaVfbj3d5fPAMjIiJDYgAjIiJDYgAjIiJDYgAjIiJDYgAjIiJDMlQWot7joumdaSWboeNsmWVatLINZWeIdjay4+GpzDbU4owz56qg97Gu93imRp/9XdVxJZt5XFI8AyMiIkNiACMiIkNiACMiIkNiACMiIkNiACMiIkMyVBaiLNmxBPXOQtSi90zKWlRlQslmGOm9X7Q42/hzxaEqC06Lqnpkx/fUIntMONuYilq02i87nqbe45nK0vot0Gu/8AyMiIgMiQGMiIgMiQGMiIgMiQGMiIgMiQGMiIgMqVRnIarKPNJ7/DlVWYuOyn6Upap+VRlbWlRliskqLFNPNitP72NXdls4WzagFr2z+LT2sewxpGo/6n2c6LXfeQZGRESGxABGRESGxABGRESGxABGRESGJB3Azp07hwEDBiAwMBDe3t5o0KAB9u3bZ31fCIHJkyejUqVK8Pb2RlRUFE6cOKG00URERFJZiFeuXEGbNm3QqVMnbNy4ERUqVMCJEydQrlw56zJvvvkm5s6di2XLliE8PByTJk1CdHQ0Dh8+DC8vrxI1VnYcNVWzreo9Jp6qjCdHjd0nm90nu7wW2cwmvTOqVI3xeDcy9VRloKrKvJT9Tjoqg1bVep0tG1PVmJmq6i9yO4REzRMmTMCuXbuwc+dOu+8LIRASEoKxY8di3LhxAACLxYKgoCAsXboUffv2veM60tLSYDab7b7nqADmbJxt4FZHBTBHBXKt9jvbP4wA+bY66of1XgtgRnc3ApjFYoGfn1+hy0hFhC+//BLNmzdHnz59ULFiRTRp0gSLFy+2vp+YmIjk5GRERUVZy8xmM1q1aoX4+Hi7dWZkZCAtLc3mRUREdCdSAezPP//EokWLULNmTWzevBlDhw7FyJEjsWzZMgBAcnIyACAoKMjmc0FBQdb3bhcXFwez2Wx9Va1atTj9ICKie4xUAMvNzUXTpk0xY8YMNGnSBEOGDMGzzz6L9957r9gNmDhxIiwWi/V15syZYtdFRET3DqkAVqlSJdStW9emrE6dOkhKSgIABAcHAwBSUlJslklJSbG+dztPT0/4+fnZvIiIiO5EKguxTZs2OHbsmE3Z8ePHERYWBgAIDw9HcHAwtm7disaNGwO4lZSxZ88eDB06tMSNVXUz3FE3+Z1tvc42lqOqjDa9yW5Pd3d3u+XZ2dl2ywu7Qa4qWUC2HtnkBa0xErWWVzXjs96cLVvPUUklTpPwJiTs3btXuLm5iddff12cOHFCrFy5UpQpU0asWLHCuswbb7wh/P39xRdffCF+++038cgjj4jw8HBx8+bNIq3DYrEIAHZfJpPJ7ktreUe99G6nVv1G2T6urq52X45ul14vd3d3uy+t/eXi4qL5ctSxKNserX1slGNU1fbU+7uq6jhxxpfFYrljvJAKYEIIsWHDBlG/fn3h6ekpIiIixAcffGDzfm5urpg0aZIICgoSnp6e4v777xfHjh0rcv0MYMWv3yjbhwGMAczZj1FV25MBrPivogQwqefA7obCngNz1KU5WXq38248g6EnvacjcTaOvISo6lh0tkuIjiK7PUvrJcS7QflzYERERM6CAYyIiAzJUDMyq8pe07qko1WP1mm9bLnWerVO92XbI3u5QlZpHQdOb1lZWVLLF+dymqpLW6ou5amaFVtrea1y2XEq9R5PU2t52XEzZfurRdV2cJbbGDwDIyIiQ2IAIyIiQ2IAIyIiQ2IAIyIiQ2IAIyIiQzJUFqJsZpNW5otWVpjemVlaD65q8fDwsFuu1X69HwbVe4ZrrYdftZYvrROWFods9prsNnJUtptsv2Sz+7SoOoZUZQ86W5apo7bn7XgGRkREhsQARkREhsQARkREhsQARkREhuR0SRzFuannqBuTetcvmwThKHpvf1Xb7V7kqG1hlO+SquWdrR5n+w7o9bvudAHs6tWrjm6C05AdQ8/o7rUxEh3J2QKMs9XvbO61/gK3YoHW1Fp5nG4+sNzcXJw/fx5ly5bF1atXUbVqVZw5c+aO88KUFmlpafdUn9nf0o39Ld306K8QAlevXkVISIjmYxF5nO4MzMXFBVWqVAHwz7MDfn5+98TBkN+91mf2t3Rjf0s31f2905lXHiZxEBGRITGAERGRITl1APP09MSUKVPg6enp6KbcNfdan9nf0o39Ld0c3V+nS+IgIiIqCqc+AyMiItLCAEZERIbEAEZERIbEAEZERIbk1AFswYIFqFatGry8vNCqVSvs3bvX0U1S4ocffsDDDz+MkJAQmEwmrF+/3uZ9IQQmT56MSpUqwdvbG1FRUThx4oRjGqtAXFwcWrRogbJly6JixYro2bMnjh07ZrNMeno6hg0bhsDAQPj6+iImJgYpKSkOanHJLFq0CA0bNrQ+3BkZGYmNGzda3y9NfbXnjTfegMlkwujRo61lpanPU6dOhclksnlFRERY3y9Nfc1z7tw5DBgwAIGBgfD29kaDBg2wb98+6/uO+s1y2gD26aefYsyYMZgyZQp++eUXNGrUCNHR0bh48aKjm1Zi169fR6NGjbBgwQK777/55puYO3cu3nvvPezZswc+Pj6Ijo5Genr6XW6pGjt27MCwYcOwe/dubNmyBVlZWXjggQdw/fp16zIvvvgiNmzYgDVr1mDHjh04f/48evXq5cBWF1+VKlXwxhtvICEhAfv27UPnzp3xyCOP4PfffwdQuvp6u59//hnvv/8+GjZsaFNe2vpcr149XLhwwfr68ccfre+Vtr5euXIFbdq0gbu7OzZu3IjDhw9j9uzZKFeunHUZh/1mCSfVsmVLMWzYMOvfOTk5IiQkRMTFxTmwVeoBEOvWrbP+nZubK4KDg8WsWbOsZampqcLT01N88sknDmihehcvXhQAxI4dO4QQt/rn7u4u1qxZY13myJEjAoCIj493VDOVKleunPjwww9LdV+vXr0qatasKbZs2SI6dOggRo0aJYQofft3ypQpolGjRnbfK219FUKI8ePHi7Zt22q+78jfLKc8A8vMzERCQgKioqKsZS4uLoiKikJ8fLwDW6a/xMREJCcn2/TdbDajVatWpabvFosFABAQEAAASEhIQFZWlk2fIyIiEBoaavg+5+TkYPXq1bh+/ToiIyNLdV+HDRuGhx56yKZvQOncvydOnEBISAiqV6+OJ554AklJSQBKZ1+//PJLNG/eHH369EHFihXRpEkTLF682Pq+I3+znDKAXbp0CTk5OQgKCrIpDwoKQnJysoNadXfk9a+09j03NxejR49GmzZtUL9+fQC3+uzh4QF/f3+bZY3c54MHD8LX1xeenp54/vnnsW7dOtStW7dU9hUAVq9ejV9++QVxcXEF3ittfW7VqhWWLl2KTZs2YdGiRUhMTES7du1w9erVUtdXAPjzzz+xaNEi1KxZE5s3b8bQoUMxcuRILFu2DIBjf7OcbjR6Kt2GDRuGQ4cO2dwzKI1q166NAwcOwGKxYO3atYiNjcWOHTsc3SxdnDlzBqNGjcKWLVvg5eXl6Oborlu3btb/b9iwIVq1aoWwsDB89tln8Pb2dmDL9JGbm4vmzZtjxowZAIAmTZrg0KFDeO+99xAbG+vQtjnlGVj58uXh6upaIHMnJSUFwcHBDmrV3ZHXv9LY9+HDh+Orr77Ctm3brFPmALf6nJmZidTUVJvljdxnDw8P1KhRA82aNUNcXBwaNWqEd999t1T2NSEhARcvXkTTpk3h5uYGNzc37NixA3PnzoWbmxuCgoJKXZ/z8/f3R61atXDy5MlSuX8rVaqEunXr2pTVqVPHetnUkb9ZThnAPDw80KxZM2zdutValpubi61btyIyMtKBLdNfeHg4goODbfqelpaGPXv2GLbvQggMHz4c69atw/fff4/w8HCb95s1awZ3d3ebPh87dgxJSUmG7fPtcnNzkZGRUSr7ev/99+PgwYM4cOCA9dW8eXM88cQT1v8vbX3O79q1a/jjjz9QqVKlUrl/27RpU+Cxl+PHjyMsLAyAg3+zdE0RKYHVq1cLT09PsXTpUnH48GExZMgQ4e/vL5KTkx3dtBK7evWq2L9/v9i/f78AIN5++22xf/9+cfr0aSGEEG+88Ybw9/cXX3zxhfjtt9/EI488IsLDw8XNmzcd3PLiGTp0qDCbzWL79u3iwoUL1teNGzesyzz//PMiNDRUfP/992Lfvn0iMjJSREZGOrDVxTdhwgSxY8cOkZiYKH777TcxYcIEYTKZxLfffiuEKF191ZI/C1GI0tXnsWPHiu3bt4vExESxa9cuERUVJcqXLy8uXrwohChdfRVCiL179wo3Nzfx+uuvixMnToiVK1eKMmXKiBUrVliXcdRvltMGMCGEmDdvnggNDRUeHh6iZcuWYvfu3Y5ukhLbtm0TAAq8YmNjhRC30lInTZokgoKChKenp7j//vvFsWPHHNvoErDXVwBiyZIl1mVu3rwpXnjhBVGuXDlRpkwZ8eijj4oLFy44rtEl8NRTT4mwsDDh4eEhKlSoIO6//35r8BKidPVVy+0BrDT1+fHHHxeVKlUSHh4eonLlyuLxxx8XJ0+etL5fmvqaZ8OGDaJ+/frC09NTREREiA8++MDmfUf9ZnE6FSIiMiSnvAdGRER0JwxgRERkSAxgRERkSAxgRERkSAxgRERkSAxgRERkSAxgRERkSAxgRERkSAxgRERkSAxgRERkSAxgRERkSAxgRERkSP8P6tmwDZcRgWQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize variables to track the min and max MSE\n",
    "min_mse = float('inf')\n",
    "max_mse = float('-inf')\n",
    "min_mse_index = -1\n",
    "max_mse_index = -1\n",
    "\n",
    "# Loop through each prediction to calculate the MSE\n",
    "for i in range(len(all_pred_midpoints)):\n",
    "    mse = np.mean((all_pred_midpoints[i] - all_true_midpoints[i]) **2)\n",
    "    \n",
    "    if mse < min_mse:\n",
    "        min_mse = mse\n",
    "        min_mse_index = i\n",
    "    \n",
    "    if mse > max_mse:\n",
    "        max_mse = mse\n",
    "        max_mse_index = i\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot an image with its centers\n",
    "def plot_image_with_centers(image, true_center, predicted_center, title):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image.squeeze(), cmap='gray')  # Display the image\n",
    "\n",
    "    # Plot the actual center (Groundtruth)\n",
    "    plt.scatter(true_center[:, 0], true_center[:, 1], color='green', label='Groundtruth', s=10)\n",
    "\n",
    "    # Plot the predicted center\n",
    "    plt.scatter(predicted_center[:, 0], predicted_center[:, 1], color='red', label='Predictions', s=10)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the image with the least MSE\n",
    "plot_image_with_centers(all_images[min_mse_index],\n",
    "                        all_true_midpoints[min_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[min_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        f'Image with Least MSE. MSE: {min_mse:.4f}')\n",
    "\n",
    "# Plotting the image with the largest MSE\n",
    "plot_image_with_centers(all_images[max_mse_index],\n",
    "                        all_true_midpoints[max_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        all_pred_midpoints[max_mse_index][0] * 64,  # Adjust for scaling if needed\n",
    "                        f'Image with Largest MSE. MSE: {max_mse:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11548"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_mse_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "objectdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
